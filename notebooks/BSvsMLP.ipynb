{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "### Load libraries ###\n",
    "\n",
    "# interactive plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg' # ‘png’, ‘retina’, ‘jpeg’, ‘svg’, ‘pdf’\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "# Data management libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Machine learning libraries\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import  MLPClassifier, MLPRegressor\n",
    "\n",
    "# XAI libraries\n",
    "import dalex as dx\n",
    "from lime.lime_tabular import LimeTabularExplainer \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Other libraries\n",
    "# from utils import plotModelGridError, confusion_matrix\n",
    "from neuralsens import partial_derivatives as ns\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af5185",
   "metadata": {},
   "source": [
    "### 1. Data load and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_call_option(S, K, T, r, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the Black-Scholes price of a European call option.\n",
    "    \n",
    "    Parameters:\n",
    "    S: Current stock price.\n",
    "    K: Strike price of the option.\n",
    "    T: Time to expiration in years.\n",
    "    r: Risk-free interest rate (annualized).\n",
    "    sigma: Volatility of the underlying stock (annualized).\n",
    "    Returns:\n",
    "        The Black-Scholes price of the call option.\n",
    "    \"\"\"\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    \n",
    "    call_price = (S * si.norm.cdf(d1, 0.0, 1.0) - \n",
    "                  K * np.exp(-r * T) * si.norm.cdf(d2, 0.0, 1.0))\n",
    "    \n",
    "    return call_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d96c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/calls_2025_05_28.csv')\n",
    "df_final = df[['price', 'strike', 'T', 'impliedVolatility', 'midPrice']].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_final.rename(columns={\n",
    "    'price': 'S',  # Current stock price\n",
    "    'strike': 'K',  # Strike price\n",
    "    'T': 'T',  # Time to expiration in years\n",
    "    'impliedVolatility': 'sigma',  # Volatility of the underlying stock\n",
    "    'midPrice': 'call_price'  # Black-Scholes price of the call option\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e739afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many with sigma == 0\n",
    "print(f\"Number of options with sigma == 0: {df_final[df_final['sigma'] == 0].shape[0]}\")\n",
    "\n",
    "# Filter out rows where sigma is zero\n",
    "df_final = df_final[df_final['sigma'] > 0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0cc35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92975f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = df_final.columns.drop('call_price').tolist()\n",
    "TARGET = 'call_price'\n",
    "\n",
    "X = df_final[INPUTS]\n",
    "y = df_final[TARGET]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041a05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataset to store model predictions\n",
    "dfTR_eval = X_train.copy()\n",
    "dfTR_eval['midPrice'] = y_train\n",
    "dfTS_eval = X_test.copy()\n",
    "dfTS_eval['midPrice'] = y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f237c",
   "metadata": {},
   "source": [
    "### 2. MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77124b22",
   "metadata": {},
   "source": [
    "#### A. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354a8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Create a preprocessor to perform the steps defined above\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, INPUTS)\n",
    "        ])\n",
    "\n",
    "param = {'MLP__alpha': [0.001], # Initial value of regularization\n",
    "         'MLP__hidden_layer_sizes':[(80,)],\n",
    "         'MLP__learning_rate_init': [0.01],\n",
    "         'MLP__activation': ['tanh']\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('MLP', MLPRegressor(solver='adam', \n",
    "                max_iter=2000, # Maximum number of iterations\n",
    "                tol=1e-4, # Tolerance for the optimization\n",
    "                random_state=150,\n",
    "                verbose = True))]) # For replication\n",
    "\n",
    "# We use Grid Search Cross Validation to find the best parameter for the model in the grid defined \n",
    "nFolds = 10\n",
    "MLP_fit = GridSearchCV(estimator=pipe, # Structure of the model to use\n",
    "                       param_grid=param, # Defined grid to search in\n",
    "                       n_jobs=-1, # Number of cores to use (parallelize)\n",
    "                       scoring='neg_mean_squared_error', # RMSE https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "                       cv=nFolds) # Number of Folds \n",
    "MLP_fit.fit(X_train[INPUTS], y_train) # Search in grid\n",
    "\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(MLP_fit, '../models/MLP_simple_vs_BS_v2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3f3e0",
   "metadata": {},
   "source": [
    "#### B. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9d6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Cargamos el modelo guardado\n",
    "MLP_fit = joblib.load('../models/MLP_simple_vs_BS_v2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abbc62",
   "metadata": {},
   "source": [
    "### 3. MLP vs Black-Scholes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb2639",
   "metadata": {},
   "source": [
    "#### A. Graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dcb4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plotModelGridError(MLP_fit):\n",
    "    results = MLP_fit.cv_results_\n",
    "    mean_test_scores = results['mean_test_score']\n",
    "    params = results['params']\n",
    "\n",
    "    # Convertir a error (RMSE)\n",
    "    errors = np.sqrt(-mean_test_scores)\n",
    "\n",
    "    # Etiquetas incluyendo todos los hiperparámetros relevantes\n",
    "    param_labels = [\n",
    "        f\"act: {p['MLP__activation']}, alpha: {p['MLP__alpha']}, size: {p['MLP__hidden_layer_sizes']}, lr: {p['MLP__learning_rate_init']}\"\n",
    "        for p in params\n",
    "    ]\n",
    "\n",
    "    # Obtener todos los learning rates únicos para codificarlos por color\n",
    "    lrs = [p['MLP__learning_rate_init'] for p in params]\n",
    "    unique_lrs = sorted(set(lrs))\n",
    "    lr_color_map = {lr: cm.viridis(i / len(unique_lrs)) for i, lr in enumerate(unique_lrs)}\n",
    "    bar_colors = [lr_color_map[lr] for lr in lrs]\n",
    "\n",
    "    # Ordenar por error creciente\n",
    "    sorted_indices = np.argsort(errors)\n",
    "    errors_sorted = errors[sorted_indices]\n",
    "    param_labels_sorted = [param_labels[i] for i in sorted_indices]\n",
    "    bar_colors_sorted = [bar_colors[i] for i in sorted_indices]\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    bars = plt.barh(param_labels_sorted, errors_sorted, color=bar_colors_sorted)\n",
    "    plt.xlabel(\"RMSE\")\n",
    "    plt.title(\"Errores del Modelo (RMSE) según Grid Search, agrupados por Learning Rate\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Crear leyenda manual\n",
    "    legend_handles = [\n",
    "        plt.Rectangle((0, 0), 1, 1, color=lr_color_map[lr]) for lr in unique_lrs\n",
    "    ]\n",
    "    legend_labels = [f\"lr: {lr}\" for lr in unique_lrs]\n",
    "    plt.legend(legend_handles, legend_labels, title=\"Learning Rate\", loc=\"lower right\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567dbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plotModelGridError(MLP_fit)\n",
    "# La mejor combinación es ReLu, alpha=0.001, size=(60,), lr=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4a3fc",
   "metadata": {},
   "source": [
    "#### B. Comparison of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1acdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions on the training set using Black-Scholes formula\n",
    "dfTR_eval['BS_predict'] = black_scholes_call_option(\n",
    "    dfTR_eval['S'],\n",
    "    dfTR_eval['K'],\n",
    "    dfTR_eval['T'],\n",
    "    0.045,  # Assuming a risk-free interest rate of 5%\n",
    "    dfTR_eval['sigma']\n",
    ")\n",
    "\n",
    "# Calculate the predictions on the test set using Black-Scholes formula\n",
    "dfTS_eval['BS_predict'] = black_scholes_call_option(\n",
    "    dfTS_eval['S'],\n",
    "    dfTS_eval['K'],\n",
    "    dfTS_eval['T'],\n",
    "    0.045,  # Assuming a risk-free interest rate of 5%\n",
    "    dfTS_eval['sigma']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca043fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTR_eval['MLP_pred'] = MLP_fit.predict(X_train[INPUTS])\n",
    "dfTS_eval['MLP_pred'] = MLP_fit.predict(X_test[INPUTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde923e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and test MAE - Mean Absolute error\n",
    "print('MLP Predictions')\n",
    "print('Training MAE:',mean_absolute_error(dfTR_eval['midPrice'], dfTR_eval['MLP_pred']))\n",
    "print('Test MAE:',mean_absolute_error(dfTS_eval['midPrice'], dfTS_eval['MLP_pred']))\n",
    "#Training and test RMSE - Root Mean Square Error\n",
    "print('Training RMSE:',math.sqrt(mean_squared_error(dfTR_eval['midPrice'], dfTR_eval['MLP_pred'])))\n",
    "print('Test RMSE:',math.sqrt(mean_squared_error(dfTS_eval['midPrice'], dfTS_eval['MLP_pred'])))\n",
    "#Training and test r^2 \n",
    "print('Training R2:',r2_score(dfTR_eval['midPrice'], dfTR_eval['MLP_pred']))\n",
    "print('Test R2:',r2_score(dfTS_eval['midPrice'], dfTS_eval['MLP_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfee0ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Black-Scholes Predictions')\n",
    "#Training and test MAE - Mean Absolute error\n",
    "print('Training MAE:',mean_absolute_error(dfTR_eval['midPrice'], dfTR_eval['BS_predict']))\n",
    "print('Test MAE:',mean_absolute_error(dfTS_eval['midPrice'], dfTS_eval['BS_predict']))\n",
    "#Training and test RMSE - Root Mean Square Error\n",
    "print('Training RMSE:',math.sqrt(mean_squared_error(dfTR_eval['midPrice'], dfTR_eval['BS_predict'])))\n",
    "print('Test RMSE:',math.sqrt(mean_squared_error(dfTS_eval['midPrice'], dfTS_eval['BS_predict'])))\n",
    "#Training and test r^2 \n",
    "print('Training R2:',r2_score(dfTR_eval['midPrice'], dfTR_eval['BS_predict']))\n",
    "print('Test R2:',r2_score(dfTS_eval['midPrice'], dfTS_eval['BS_predict']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a7680",
   "metadata": {},
   "source": [
    "#### C. Case to case comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73566e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dfTS_eval['MLP_diff'] = np.abs(dfTS_eval['midPrice'] - dfTS_eval['MLP_pred'])\n",
    "dfTS_eval['BS_diff'] = np.abs(dfTS_eval['midPrice'] - dfTS_eval['BS_predict'])\n",
    "dfTS_eval['MLP_better'] = dfTS_eval['MLP_diff'] < dfTS_eval['BS_diff']\n",
    "\n",
    "# Casos en los que MLP es mejor\n",
    "mlp_better_cases = dfTS_eval[dfTS_eval['MLP_better']]\n",
    "bs_better_cases = dfTS_eval[~dfTS_eval['MLP_better']]\n",
    "\n",
    "# Diferencias de error entre ambos modelos\n",
    "mlp_margin = bs_better_cases['BS_diff'] - bs_better_cases['MLP_diff']\n",
    "bs_margin = mlp_better_cases['MLP_diff'] - mlp_better_cases['BS_diff']\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "print(\"Cuando BS gana:\")\n",
    "print(\"   Media de mejora:\", mlp_margin.mean())\n",
    "print(\"   Mediana de mejora:\", mlp_margin.median())\n",
    "\n",
    "print(\"Cuando MLP gana:\")\n",
    "print(\"   Media de mejora:\", bs_margin.mean())\n",
    "print(\"   Mediana de mejora:\", bs_margin.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b99de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plotModelDiagnosis\n",
    "plotModelDiagnosis(dfTR_eval, 'MLP_pred', 'midPrice')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd989f",
   "metadata": {},
   "source": [
    "### 4. Neuralsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e74831",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP_fit.best_estimator_['MLP']\n",
    "wts = mlp.coefs_\n",
    "bias = mlp.intercepts_\n",
    "actfunc = ['identity',MLP_fit.best_estimator_['MLP'].get_params()['activation'],mlp.out_activation_]\n",
    "X = MLP_fit.best_estimator_['preprocessor'].transform(X_train) # Preprocess the variables\n",
    "coefnames = MLP_fit.best_estimator_['preprocessor'].get_feature_names_out(INPUTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e9fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=coefnames)\n",
    "y = pd.DataFrame(y_train, columns=[TARGET])\n",
    "sens_end_layer = 'last'\n",
    "sens_end_input = False\n",
    "sens_origin_layer = 0\n",
    "sens_origin_input = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e95d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp = ns.jacobian_mlp(wts, bias, actfunc, X, y,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a5085",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9818821",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef4dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df03583",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns.alpha_sens_curves(sensmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd69a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partDeriv = sensmlp.raw_sens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21294de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partDeriv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314be223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_partial_derivative_distributions(df):\n",
    "    \"\"\"\n",
    "    Dibuja histogramas con líneas de media y mediana para cada derivada parcial\n",
    "    contenida en un DataFrame, útil para detectar outliers o anomalías.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con columnas como num__S, num__K, etc.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    for i, column in enumerate(df.columns, 1):\n",
    "        plt.subplot(2, 2, i)\n",
    "        sns.histplot(df[column], kde=True, bins=100)\n",
    "        plt.axvline(df[column].mean(), color='red', linestyle='--', label=f\"Media: {df[column].mean():.2f}\")\n",
    "        plt.axvline(df[column].median(), color='green', linestyle=':', label=f\"Mediana: {df[column].median():.2f}\")\n",
    "        plt.title(f\"Distribución de ∂Precio/∂{column.split('__')[-1]}\")\n",
    "        plt.xlabel(\"Valor de la derivada parcial\")\n",
    "        plt.ylabel(\"Frecuencia\")\n",
    "        plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de25765",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_partial_derivative_distributions(df_partDeriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad06c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers_std(df, column, n_std=3):\n",
    "    media = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    return df[np.abs(df[column] - media) > n_std * std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_sigma = get_outliers_std(df_partDeriv, 'num__sigma', n_std=3)\n",
    "\n",
    "## get a subdataframe with the outliers using the positional index in outlier_indices\n",
    "outlier_rows = dfTR_eval.iloc[outliers_sigma.index]\n",
    "# Display the outlier rows\n",
    "outlier_rows.head(50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3895dcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_rows[outlier_rows['sigma']== 0].head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d37ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/sp500_calls_2025_05_28.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcec5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['impliedVolatility']0].info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
