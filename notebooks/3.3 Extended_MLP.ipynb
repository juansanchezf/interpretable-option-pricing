{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e607f6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as si\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "### Load libraries ###\n",
    "\n",
    "# interactive plotting\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'png' # ‘png’, ‘retina’, ‘jpeg’, ‘svg’, ‘pdf’\n",
    "\n",
    "# plotting libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_theme()\n",
    "\n",
    "\n",
    "# Data management libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Machine learning libraries\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.neural_network import  MLPClassifier, MLPRegressor\n",
    "\n",
    "# XAI libraries\n",
    "import dalex as dx\n",
    "from lime.lime_tabular import LimeTabularExplainer \n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Other libraries\n",
    "# from utils import plotModelGridError, confusion_matrix\n",
    "from neuralsens import partial_derivatives as ns\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29af5185",
   "metadata": {},
   "source": [
    "### 1. Data load and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b5a81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def black_scholes_call_option(S, K, T, r, sigma):\n",
    "    \"\"\"\n",
    "    Calculate the Black-Scholes price of a European call option.\n",
    "    \n",
    "    Parameters:\n",
    "    S: Current stock price.\n",
    "    K: Strike price of the option.\n",
    "    T: Time to expiration in years.\n",
    "    r: Risk-free interest rate (annualized).\n",
    "    sigma: Volatility of the underlying stock (annualized).\n",
    "    Returns:\n",
    "        The Black-Scholes price of the call option.\n",
    "    \"\"\"\n",
    "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
    "    d2 = d1 - sigma * np.sqrt(T)\n",
    "    \n",
    "    call_price = (S * si.norm.cdf(d1, 0.0, 1.0) - \n",
    "                  K * np.exp(-r * T) * si.norm.cdf(d2, 0.0, 1.0))\n",
    "    \n",
    "    return call_price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d96c20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/calls_2025_06_07.csv')\n",
    "df = df.dropna()\n",
    "df_final = df[['price', 'strike', 'T', 'impliedVolatility', 'midPrice','openInterest','volume', 'inTheMoney']].copy()\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_final.rename(columns={\n",
    "    'price': 'S',  # Current stock price\n",
    "    'strike': 'K',  # Strike price\n",
    "    'T': 'T',  # Time to expiration in years\n",
    "    'impliedVolatility': 'sigma',  # Volatility of the underlying stock\n",
    "    'midPrice': 'call_price'  # Black-Scholes price of the call option\n",
    "}, inplace=True)\n",
    "\n",
    "# Change inTheMoney to binary \n",
    "df_final['inTheMoney'] = df_final['inTheMoney'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55bdd976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'K', 'T', 'sigma', 'openInterest', 'volume', 'inTheMoney']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.columns.drop('call_price').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b92975f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUTS = df_final.columns.drop('call_price').tolist()\n",
    "TARGET = 'call_price'\n",
    "\n",
    "X = df_final[INPUTS]\n",
    "y = df_final[TARGET]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041a05fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create dataset to store model predictions\n",
    "dfTR_eval = X_train.copy()\n",
    "dfTR_eval['midPrice'] = y_train\n",
    "dfTS_eval = X_test.copy()\n",
    "dfTS_eval['midPrice'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "978dc79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25299 entries, 54071 to 118385\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   S             25299 non-null  float64\n",
      " 1   K             25299 non-null  float64\n",
      " 2   T             25299 non-null  float64\n",
      " 3   sigma         25299 non-null  float64\n",
      " 4   openInterest  25299 non-null  float64\n",
      " 5   volume        25299 non-null  float64\n",
      " 6   inTheMoney    25299 non-null  int64  \n",
      " 7   midPrice      25299 non-null  float64\n",
      "dtypes: float64(7), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "dfTS_eval.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648f237c",
   "metadata": {},
   "source": [
    "### 2. MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77124b22",
   "metadata": {},
   "source": [
    "#### A. Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a21f5c",
   "metadata": {},
   "source": [
    "##### GRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354a8cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8725.29552322\n",
      "Iteration 1, loss = 8558.35451955\n",
      "Iteration 1, loss = 8570.62264207\n",
      "Iteration 1, loss = 8569.43930680\n",
      "Iteration 1, loss = 8782.48056165\n",
      "Iteration 1, loss = 8531.64659207\n",
      "Iteration 1, loss = 8417.14361118\n",
      "Iteration 1, loss = 8501.04430693\n",
      "Iteration 2, loss = 5512.14410146\n",
      "Iteration 2, loss = 5499.38709177\n",
      "Iteration 2, loss = 5659.18201177\n",
      "Iteration 2, loss = 5524.76517682\n",
      "Iteration 2, loss = 5687.79389185\n",
      "Iteration 2, loss = 5497.79733282\n",
      "Iteration 2, loss = 5417.30604279\n",
      "Iteration 2, loss = 5449.13190530\n",
      "Iteration 3, loss = 4226.86618461\n",
      "Iteration 3, loss = 4196.36882330\n",
      "Iteration 3, loss = 4378.27210010\n",
      "Iteration 3, loss = 4355.50568680\n",
      "Iteration 3, loss = 4236.00348056\n",
      "Iteration 3, loss = 4232.92087495\n",
      "Iteration 3, loss = 4132.65080988\n",
      "Iteration 3, loss = 4197.50657644\n",
      "Iteration 4, loss = 3555.72032920\n",
      "Iteration 4, loss = 3428.07644969\n",
      "Iteration 4, loss = 3458.09529064\n",
      "Iteration 4, loss = 3401.40675274\n",
      "Iteration 4, loss = 3539.01980511\n",
      "Iteration 4, loss = 3338.42338255\n",
      "Iteration 4, loss = 3449.72835195\n",
      "Iteration 4, loss = 3419.77678011\n",
      "Iteration 5, loss = 2978.34226263\n",
      "Iteration 5, loss = 2843.39805316\n",
      "Iteration 5, loss = 2869.73316407\n",
      "Iteration 5, loss = 2781.51573934\n",
      "Iteration 5, loss = 2904.73322846\n",
      "Iteration 5, loss = 2965.89065209\n",
      "Iteration 5, loss = 2895.31367662\n",
      "Iteration 6, loss = 2558.48231840\n",
      "Iteration 5, loss = 2872.33777159\n",
      "Iteration 6, loss = 2431.61672700\n",
      "Iteration 6, loss = 2447.00160187\n",
      "Iteration 6, loss = 2363.85348965\n",
      "Iteration 6, loss = 2533.33805882\n",
      "Iteration 6, loss = 2482.79296169\n",
      "Iteration 6, loss = 2498.26294498\n",
      "Iteration 7, loss = 2130.21351537\n",
      "Iteration 6, loss = 2481.34468276\n",
      "Iteration 7, loss = 2245.59898275\n",
      "Iteration 7, loss = 2143.80737192\n",
      "Iteration 7, loss = 2059.58052906\n",
      "Iteration 7, loss = 2222.27869538\n",
      "Iteration 7, loss = 2180.12620717\n",
      "Iteration 7, loss = 2196.94232102\n",
      "Iteration 7, loss = 2189.93239320\n",
      "Iteration 8, loss = 2018.06287272\n",
      "Iteration 8, loss = 1904.34581046\n",
      "Iteration 8, loss = 1907.79012025\n",
      "Iteration 8, loss = 1975.36520607\n",
      "Iteration 8, loss = 1825.57963801\n",
      "Iteration 8, loss = 1948.54034497\n",
      "Iteration 8, loss = 1968.69995996\n",
      "Iteration 8, loss = 1971.33319325\n",
      "Iteration 9, loss = 1741.23775005\n",
      "Iteration 9, loss = 1837.04187121\n",
      "Iteration 9, loss = 1740.84932444\n",
      "Iteration 9, loss = 1799.67293123\n",
      "Iteration 9, loss = 1659.33648867\n",
      "Iteration 9, loss = 1777.49204023\n",
      "Iteration 9, loss = 1795.12464579\n",
      "Iteration 10, loss = 1609.42333208\n",
      "Iteration 9, loss = 1798.73663316\n",
      "Iteration 10, loss = 1693.91793691\n",
      "Iteration 10, loss = 1601.69855763\n",
      "Iteration 10, loss = 1658.91619672\n",
      "Iteration 10, loss = 1527.36778232\n",
      "Iteration 10, loss = 1638.60361809\n",
      "Iteration 10, loss = 1659.07362610\n",
      "Iteration 11, loss = 1516.07726347\n",
      "Iteration 11, loss = 1588.97402591\n",
      "Iteration 11, loss = 1501.84701560\n",
      "Iteration 10, loss = 1669.32473440\n",
      "Iteration 11, loss = 1546.95858522\n",
      "Iteration 11, loss = 1420.31956217\n",
      "Iteration 12, loss = 1423.44871113\n",
      "Iteration 11, loss = 1539.23180993\n",
      "Iteration 12, loss = 1485.49909557\n",
      "Iteration 11, loss = 1549.26375777\n",
      "Iteration 12, loss = 1404.41860134\n",
      "Iteration 12, loss = 1451.37165071\n",
      "Iteration 12, loss = 1336.73074544\n",
      "Iteration 11, loss = 1565.00062864\n",
      "Iteration 13, loss = 1352.84373205\n",
      "Iteration 12, loss = 1435.47938639\n",
      "Iteration 13, loss = 1410.30517472\n",
      "Iteration 12, loss = 1460.07688144\n",
      "Iteration 13, loss = 1330.45492112\n",
      "Iteration 13, loss = 1367.17004934\n",
      "Iteration 13, loss = 1258.76873724\n",
      "Iteration 12, loss = 1474.46050166\n",
      "Iteration 13, loss = 1358.12874581\n",
      "Iteration 14, loss = 1332.84727510\n",
      "Iteration 14, loss = 1292.35067793\n",
      "Iteration 13, loss = 1380.87291273\n",
      "Iteration 14, loss = 1266.24032151\n",
      "Iteration 14, loss = 1308.80881362\n",
      "Iteration 14, loss = 1203.54821780\n",
      "Iteration 13, loss = 1402.20685667\n",
      "Iteration 15, loss = 1235.43990824\n",
      "Iteration 15, loss = 1281.56841902\n",
      "Iteration 14, loss = 1314.79287633\n",
      "Iteration 14, loss = 1298.23577551\n",
      "Iteration 15, loss = 1200.77075203\n",
      "Iteration 15, loss = 1247.49313966\n",
      "Iteration 14, loss = 1335.36693895\n",
      "Iteration 16, loss = 1199.06862606\n",
      "Iteration 15, loss = 1258.69615096\n",
      "Iteration 15, loss = 1156.13565086\n",
      "Iteration 16, loss = 1241.60727172\n",
      "Iteration 15, loss = 1232.36434630\n",
      "Iteration 16, loss = 1160.82182408\n",
      "Iteration 16, loss = 1209.95458133\n",
      "Iteration 16, loss = 1211.24624604\n",
      "Iteration 15, loss = 1273.54064850\n",
      "Iteration 17, loss = 1188.81737590\n",
      "Iteration 16, loss = 1197.70652160\n",
      "Iteration 16, loss = 1113.96828366\n",
      "Iteration 17, loss = 1171.53024804\n",
      "Iteration 17, loss = 1183.30769515\n",
      "Iteration 17, loss = 1124.79104681\n",
      "Iteration 17, loss = 1172.27320271\n",
      "Iteration 18, loss = 1150.79458293\n",
      "Iteration 16, loss = 1231.70525359\n",
      "Iteration 17, loss = 1079.14781448\n",
      "Iteration 17, loss = 1157.26891188\n",
      "Iteration 18, loss = 1139.30897271\n",
      "Iteration 18, loss = 1083.34992493\n",
      "Iteration 18, loss = 1139.72964936\n",
      "Iteration 18, loss = 1129.88757023\n",
      "Iteration 19, loss = 1117.60844461\n",
      "Iteration 17, loss = 1185.81461440\n",
      "Iteration 18, loss = 1049.55136087\n",
      "Iteration 18, loss = 1127.01319640\n",
      "Iteration 19, loss = 1057.72022912\n",
      "Iteration 19, loss = 1115.18991023\n",
      "Iteration 19, loss = 1112.39986037\n",
      "Iteration 20, loss = 1098.35684665\n",
      "Iteration 19, loss = 1107.23785531\n",
      "Iteration 18, loss = 1151.61298003\n",
      "Iteration 19, loss = 1097.75731125\n",
      "Iteration 19, loss = 1020.90342932\n",
      "Iteration 20, loss = 1081.94076008\n",
      "Iteration 20, loss = 1091.05946677\n",
      "Iteration 21, loss = 1067.19900794\n",
      "Iteration 20, loss = 1030.78232606\n",
      "Iteration 20, loss = 1081.41045444\n",
      "Iteration 19, loss = 1124.45187669\n",
      "Iteration 20, loss = 1073.40280003\n",
      "Iteration 20, loss = 1000.25916309\n",
      "Iteration 21, loss = 1061.12875509\n",
      "Iteration 21, loss = 1010.11866751\n",
      "Iteration 22, loss = 1054.03673252\n",
      "Iteration 21, loss = 1071.92373951\n",
      "Iteration 21, loss = 1081.90520831\n",
      "Iteration 21, loss = 1048.34533772\n",
      "Iteration 22, loss = 1043.82919436\n",
      "Iteration 20, loss = 1097.71077327\n",
      "Iteration 21, loss = 995.30873199\n",
      "Iteration 23, loss = 1043.10243096\n",
      "Iteration 22, loss = 980.42808159\n",
      "Iteration 22, loss = 1044.57451048\n",
      "Iteration 22, loss = 1048.42442405\n",
      "Iteration 22, loss = 972.45290300\n",
      "Iteration 22, loss = 1028.23802525\n",
      "Iteration 23, loss = 1043.87239868\n",
      "Iteration 23, loss = 975.75254346\n",
      "Iteration 24, loss = 1019.54375781\n",
      "Iteration 23, loss = 1048.06280716\n",
      "Iteration 21, loss = 1066.69340160\n",
      "Iteration 23, loss = 1043.18779371\n",
      "Iteration 24, loss = 1023.39861946\n",
      "Iteration 23, loss = 974.44930485\n",
      "Iteration 24, loss = 960.15316292\n",
      "Iteration 23, loss = 1030.71727419\n",
      "Iteration 25, loss = 1009.45529753\n",
      "Iteration 24, loss = 1026.95627501\n",
      "Iteration 24, loss = 1035.72471093\n",
      "Iteration 22, loss = 1043.40643790\n",
      "Iteration 24, loss = 960.65344372\n",
      "Iteration 25, loss = 959.56910691\n",
      "Iteration 24, loss = 1003.89542761\n",
      "Iteration 25, loss = 1019.12419200\n",
      "Iteration 25, loss = 1020.57566144\n",
      "Iteration 26, loss = 991.64452557\n",
      "Iteration 25, loss = 1016.58453929\n",
      "Iteration 23, loss = 1044.88434585\n",
      "Iteration 25, loss = 937.61481696\n",
      "Iteration 26, loss = 992.48966106\n",
      "Iteration 25, loss = 1009.59491562\n",
      "Iteration 26, loss = 995.17024676\n",
      "Iteration 26, loss = 936.13824889\n",
      "Iteration 27, loss = 988.87164451\n",
      "Iteration 26, loss = 1004.71922370\n",
      "Iteration 24, loss = 1027.66030848\n",
      "Iteration 26, loss = 924.13879411\n",
      "Iteration 27, loss = 983.24124217\n",
      "Iteration 27, loss = 918.87307521\n",
      "Iteration 27, loss = 985.94025618\n",
      "Iteration 27, loss = 985.27455694\n",
      "Iteration 26, loss = 982.47100965\n",
      "Iteration 28, loss = 997.07514126\n",
      "Iteration 25, loss = 1005.01166625\n",
      "Iteration 27, loss = 917.76804570\n",
      "Iteration 28, loss = 910.54901402\n",
      "Iteration 28, loss = 981.31746840\n",
      "Iteration 28, loss = 985.15745258\n",
      "Iteration 27, loss = 959.85623627\n",
      "Iteration 28, loss = 981.30106257\n",
      "Iteration 29, loss = 986.84787065\n",
      "Iteration 26, loss = 993.81504626\n",
      "Iteration 29, loss = 967.57444002\n",
      "Iteration 28, loss = 913.58493127\n",
      "Iteration 29, loss = 919.23331146\n",
      "Iteration 28, loss = 959.83353228\n",
      "Iteration 29, loss = 975.55478415\n",
      "Iteration 29, loss = 963.67105730\n",
      "Iteration 30, loss = 966.13353070\n",
      "Iteration 27, loss = 987.78615026\n",
      "Iteration 30, loss = 967.32204944\n",
      "Iteration 29, loss = 954.91561766\n",
      "Iteration 29, loss = 911.36497122\n",
      "Iteration 30, loss = 907.64904860\n",
      "Iteration 30, loss = 961.98359235\n",
      "Iteration 31, loss = 962.35138364\n",
      "Iteration 30, loss = 960.09752177\n",
      "Iteration 28, loss = 980.58338213\n",
      "Iteration 31, loss = 949.74135913\n",
      "Iteration 30, loss = 956.46591621\n",
      "Iteration 31, loss = 950.98112769\n",
      "Iteration 30, loss = 902.41388346\n",
      "Iteration 31, loss = 895.65565016\n",
      "Iteration 32, loss = 956.32060413\n",
      "Iteration 31, loss = 949.75046376\n",
      "Iteration 29, loss = 979.60260894\n",
      "Iteration 31, loss = 930.32341400\n",
      "Iteration 32, loss = 969.24321445\n",
      "Iteration 32, loss = 943.89678568\n",
      "Iteration 31, loss = 894.72070058\n",
      "Iteration 32, loss = 899.57924923\n",
      "Iteration 33, loss = 949.45193371\n",
      "Iteration 32, loss = 958.32520597\n",
      "Iteration 30, loss = 967.97748622\n",
      "Iteration 32, loss = 944.38941202\n",
      "Iteration 33, loss = 954.60383314\n",
      "Iteration 33, loss = 929.10593250\n",
      "Iteration 32, loss = 887.88713350\n",
      "Iteration 33, loss = 883.40931556\n",
      "Iteration 33, loss = 947.57068284\n",
      "Iteration 31, loss = 961.81518558\n",
      "Iteration 34, loss = 937.14151746\n",
      "Iteration 33, loss = 932.75680256\n",
      "Iteration 34, loss = 939.70019467\n",
      "Iteration 33, loss = 881.65540937\n",
      "Iteration 34, loss = 922.54452732\n",
      "Iteration 34, loss = 880.05174561\n",
      "Iteration 35, loss = 926.76552102\n",
      "Iteration 34, loss = 931.71774029\n",
      "Iteration 32, loss = 966.04192716\n",
      "Iteration 34, loss = 932.71529817\n",
      "Iteration 35, loss = 946.56281443\n",
      "Iteration 34, loss = 877.37957977\n",
      "Iteration 35, loss = 934.65349840\n",
      "Iteration 36, loss = 946.39611024\n",
      "Iteration 35, loss = 880.28883673\n",
      "Iteration 33, loss = 947.65457200\n",
      "Iteration 35, loss = 931.90133886\n",
      "Iteration 36, loss = 931.30108883\n",
      "Iteration 35, loss = 887.17265513\n",
      "Iteration 35, loss = 920.26873210\n",
      "Iteration 36, loss = 916.24369310\n",
      "Iteration 37, loss = 914.89247272\n",
      "Iteration 36, loss = 868.02692432\n",
      "Iteration 37, loss = 939.36163413\n",
      "Iteration 36, loss = 931.13558690\n",
      "Iteration 36, loss = 865.96139228\n",
      "Iteration 34, loss = 936.67554517\n",
      "Iteration 36, loss = 903.91143179\n",
      "Iteration 37, loss = 929.67045755\n",
      "Iteration 37, loss = 879.86749387\n",
      "Iteration 38, loss = 934.75023255\n",
      "Iteration 35, loss = 930.13839395\n",
      "Iteration 37, loss = 940.22207592\n",
      "Iteration 38, loss = 935.12475006\n",
      "Iteration 37, loss = 866.23775004\n",
      "Iteration 37, loss = 923.30121032\n",
      "Iteration 38, loss = 921.40028268\n",
      "Iteration 38, loss = 923.76571974\n",
      "Iteration 38, loss = 876.32797732\n",
      "Iteration 36, loss = 946.28400130\n",
      "Iteration 38, loss = 853.26764169\n",
      "Iteration 39, loss = 940.22746070\n",
      "Iteration 39, loss = 908.21144792\n",
      "Iteration 39, loss = 919.04976493\n",
      "Iteration 38, loss = 917.55531117\n",
      "Iteration 39, loss = 870.73296449\n",
      "Iteration 37, loss = 932.76555866\n",
      "Iteration 39, loss = 922.65055623\n",
      "Iteration 40, loss = 925.17561708\n",
      "Iteration 39, loss = 856.00057260\n",
      "Iteration 39, loss = 919.47440564\n",
      "Iteration 40, loss = 904.76054146\n",
      "Iteration 40, loss = 924.89823829\n",
      "Iteration 40, loss = 863.04350728\n",
      "Iteration 41, loss = 910.67832813\n",
      "Iteration 38, loss = 934.20910683\n",
      "Iteration 40, loss = 919.14764589\n",
      "Iteration 40, loss = 864.02701311\n",
      "Iteration 41, loss = 903.06805624\n",
      "Iteration 40, loss = 910.04666066\n",
      "Iteration 41, loss = 915.77836123\n",
      "Iteration 42, loss = 921.78033460\n",
      "Iteration 41, loss = 862.70981115\n",
      "Iteration 41, loss = 898.14239976\n",
      "Iteration 39, loss = 930.17325981\n",
      "Iteration 41, loss = 849.76213058\n",
      "Iteration 42, loss = 904.61077364\n",
      "Iteration 42, loss = 899.11719007\n",
      "Iteration 41, loss = 892.19824090\n",
      "Iteration 42, loss = 861.79091999\n",
      "Iteration 43, loss = 912.59013737\n",
      "Iteration 42, loss = 924.01224913\n",
      "Iteration 40, loss = 925.60062934\n",
      "Iteration 42, loss = 853.36278183\n",
      "Iteration 43, loss = 901.63702726\n",
      "Iteration 43, loss = 909.37683874\n",
      "Iteration 42, loss = 896.34306699\n",
      "Iteration 43, loss = 867.39493603\n",
      "Iteration 41, loss = 918.31357311\n",
      "Iteration 44, loss = 899.80378125\n",
      "Iteration 43, loss = 908.49506723\n",
      "Iteration 43, loss = 841.23978326\n",
      "Iteration 44, loss = 888.56314079\n",
      "Iteration 44, loss = 910.95385735\n",
      "Iteration 43, loss = 895.68117197\n",
      "Iteration 44, loss = 851.84885302\n",
      "Iteration 45, loss = 893.31042928\n",
      "Iteration 45, loss = 883.56642220\n",
      "Iteration 45, loss = 886.39967950\n",
      "Iteration 44, loss = 895.97703827\n",
      "Iteration 44, loss = 889.10534060\n",
      "Iteration 42, loss = 895.48319970\n",
      "Iteration 44, loss = 845.00405653\n",
      "Iteration 45, loss = 842.67592689\n",
      "Iteration 46, loss = 905.10046145\n",
      "Iteration 45, loss = 884.73109825\n",
      "Iteration 43, loss = 908.60967158\n",
      "Iteration 45, loss = 899.30694843\n",
      "Iteration 46, loss = 900.58917529\n",
      "Iteration 46, loss = 882.78344362\n",
      "Iteration 45, loss = 836.67333491\n",
      "Iteration 46, loss = 841.79996985\n",
      "Iteration 47, loss = 909.65466963\n",
      "Iteration 46, loss = 879.32675744\n",
      "Iteration 46, loss = 839.81164680\n",
      "Iteration 47, loss = 894.70880235\n",
      "Iteration 47, loss = 901.87562119\n",
      "Iteration 44, loss = 908.04889877\n",
      "Iteration 46, loss = 893.21370163\n",
      "Iteration 47, loss = 858.13736158\n",
      "Iteration 48, loss = 894.25288119\n",
      "Iteration 47, loss = 846.69339563\n",
      "Iteration 47, loss = 901.69789909\n",
      "Iteration 48, loss = 889.63996224\n",
      "Iteration 47, loss = 902.27860104\n",
      "Iteration 45, loss = 898.62040166\n",
      "Iteration 48, loss = 881.51610703\n",
      "Iteration 48, loss = 842.02981747\n",
      "Iteration 48, loss = 842.21774463\n",
      "Iteration 49, loss = 900.69873002\n",
      "Iteration 48, loss = 875.40468825\n",
      "Iteration 49, loss = 884.02378030\n",
      "Iteration 46, loss = 899.63464450\n",
      "Iteration 48, loss = 897.03920389\n",
      "Iteration 49, loss = 874.47519007\n",
      "Iteration 49, loss = 854.73236348\n",
      "Iteration 50, loss = 884.72383334\n",
      "Iteration 49, loss = 833.65595775\n",
      "Iteration 50, loss = 882.40478615\n",
      "Iteration 50, loss = 859.26006021\n",
      "Iteration 49, loss = 895.66125431\n",
      "Iteration 49, loss = 893.32932269\n",
      "Iteration 47, loss = 882.65325862\n",
      "Iteration 50, loss = 839.77881763\n",
      "Iteration 50, loss = 815.86747462\n",
      "Iteration 51, loss = 879.00526029\n",
      "Iteration 51, loss = 879.47682126\n",
      "Iteration 51, loss = 874.81967759\n",
      "Iteration 50, loss = 891.43372229\n",
      "Iteration 50, loss = 871.63827678\n",
      "Iteration 48, loss = 888.77872142\n",
      "Iteration 51, loss = 822.72269693\n",
      "Iteration 51, loss = 821.03869292\n",
      "Iteration 52, loss = 879.05639035\n",
      "Iteration 51, loss = 875.60214015\n",
      "Iteration 52, loss = 881.85504301\n",
      "Iteration 51, loss = 863.67738165\n",
      "Iteration 52, loss = 875.09318365\n",
      "Iteration 49, loss = 889.34977728\n",
      "Iteration 52, loss = 819.74223198\n",
      "Iteration 52, loss = 839.62618030\n",
      "Iteration 53, loss = 870.67218269\n",
      "Iteration 53, loss = 877.14429218\n",
      "Iteration 53, loss = 865.24343169\n",
      "Iteration 52, loss = 873.25282699\n",
      "Iteration 52, loss = 885.10151862\n",
      "Iteration 53, loss = 839.52571968\n",
      "Iteration 50, loss = 884.65860090\n",
      "Iteration 53, loss = 822.81320784\n",
      "Iteration 54, loss = 889.48036662\n",
      "Iteration 53, loss = 874.00348047\n",
      "Iteration 54, loss = 878.60943344Iteration 54, loss = 866.07745670\n",
      "\n",
      "Iteration 53, loss = 878.56305729\n",
      "Iteration 54, loss = 843.27154941\n",
      "Iteration 55, loss = 887.67585343\n",
      "Iteration 51, loss = 889.39035580\n",
      "Iteration 54, loss = 825.80907978\n",
      "Iteration 55, loss = 882.95349314\n",
      "Iteration 54, loss = 869.76629104\n",
      "Iteration 55, loss = 855.48868233\n",
      "Iteration 54, loss = 893.84382995\n",
      "Iteration 52, loss = 891.65571275\n",
      "Iteration 55, loss = 834.46256579\n",
      "Iteration 56, loss = 866.85087278\n",
      "Iteration 55, loss = 830.36476738\n",
      "Iteration 55, loss = 869.88196999\n",
      "Iteration 56, loss = 863.84749463\n",
      "Iteration 56, loss = 871.62655529\n",
      "Iteration 55, loss = 878.49878446\n",
      "Iteration 53, loss = 877.21959895\n",
      "Iteration 56, loss = 806.99461318\n",
      "Iteration 56, loss = 817.48269681\n",
      "Iteration 57, loss = 873.66614758\n",
      "Iteration 57, loss = 871.50682852\n",
      "Iteration 56, loss = 846.71212675\n",
      "Iteration 57, loss = 884.49369449\n",
      "Iteration 56, loss = 868.93166686\n",
      "Iteration 54, loss = 882.37157976\n",
      "Iteration 57, loss = 823.05850373\n",
      "Iteration 57, loss = 838.52877453\n",
      "Iteration 58, loss = 891.57105343\n",
      "Iteration 58, loss = 869.66561804\n",
      "Iteration 57, loss = 879.20505631\n",
      "Iteration 58, loss = 879.78409146\n",
      "Iteration 57, loss = 877.82161600\n",
      "Iteration 58, loss = 838.22811561\n",
      "Iteration 55, loss = 865.75893922\n",
      "Iteration 58, loss = 825.39451504\n",
      "Iteration 59, loss = 872.35258883\n",
      "Iteration 59, loss = 863.89356768\n",
      "Iteration 58, loss = 894.91507208\n",
      "Iteration 59, loss = 871.42693843\n",
      "Iteration 58, loss = 889.91844328\n",
      "Iteration 56, loss = 860.62624070\n",
      "Iteration 59, loss = 830.84036149\n",
      "Iteration 59, loss = 826.20628887\n",
      "Iteration 59, loss = 860.69525343\n",
      "Iteration 60, loss = 876.12738040\n",
      "Iteration 60, loss = 876.72598830\n",
      "Iteration 59, loss = 871.89549086\n",
      "Iteration 60, loss = 864.96360419\n",
      "Iteration 57, loss = 870.48465055\n",
      "Iteration 60, loss = 814.08086808\n",
      "Iteration 60, loss = 820.01296022\n",
      "Iteration 60, loss = 860.69439761\n",
      "Iteration 61, loss = 855.59998641\n",
      "Iteration 61, loss = 863.37027627\n",
      "Iteration 60, loss = 870.53282325\n",
      "Iteration 61, loss = 863.46120984\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 58, loss = 870.58815160\n",
      "Iteration 61, loss = 850.68411805\n",
      "Iteration 62, loss = 857.53606768\n",
      "Iteration 61, loss = 820.13869055\n",
      "Iteration 61, loss = 815.07924499\n",
      "Iteration 61, loss = 867.01539695\n",
      "Iteration 62, loss = 881.75839036\n",
      "Iteration 62, loss = 852.95759869\n",
      "Iteration 63, loss = 853.89509955\n",
      "Iteration 62, loss = 811.67810300\n",
      "Iteration 59, loss = 856.83687079\n",
      "Iteration 62, loss = 817.29943621\n",
      "Iteration 63, loss = 867.62451184\n",
      "Iteration 1, loss = 8602.54509103\n",
      "Iteration 62, loss = 862.30381998\n",
      "Iteration 63, loss = 858.15026360\n",
      "Iteration 64, loss = 839.63592353\n",
      "Iteration 63, loss = 813.67615460\n",
      "Iteration 63, loss = 818.10225113\n",
      "Iteration 60, loss = 870.00667228\n",
      "Iteration 64, loss = 862.50615994\n",
      "Iteration 2, loss = 5523.02329939\n",
      "Iteration 63, loss = 866.54074492\n",
      "Iteration 64, loss = 871.42761325\n",
      "Iteration 65, loss = 843.76088639\n",
      "Iteration 64, loss = 829.86151082\n",
      "Iteration 64, loss = 802.89086927\n",
      "Iteration 61, loss = 857.59530588\n",
      "Iteration 3, loss = 4249.10604230\n",
      "Iteration 65, loss = 845.83295078\n",
      "Iteration 64, loss = 862.50727553\n",
      "Iteration 65, loss = 845.93439518\n",
      "Iteration 66, loss = 844.58108953\n",
      "Iteration 65, loss = 823.38887662\n",
      "Iteration 65, loss = 806.80757931\n",
      "Iteration 62, loss = 859.51884615\n",
      "Iteration 4, loss = 3458.53962547\n",
      "Iteration 65, loss = 854.94959641\n",
      "Iteration 66, loss = 860.30410785\n",
      "Iteration 66, loss = 871.05033919\n",
      "Iteration 67, loss = 850.04487334\n",
      "Iteration 66, loss = 808.54616453\n",
      "Iteration 66, loss = 825.59646385\n",
      "Iteration 63, loss = 850.94241322\n",
      "Iteration 5, loss = 2894.97553010\n",
      "Iteration 67, loss = 855.95828202\n",
      "Iteration 67, loss = 870.22863981\n",
      "Iteration 66, loss = 864.91048755\n",
      "Iteration 68, loss = 838.64230516\n",
      "Iteration 67, loss = 793.17344825\n",
      "Iteration 64, loss = 851.70086238\n",
      "Iteration 67, loss = 820.64550125\n",
      "Iteration 6, loss = 2480.59528366\n",
      "Iteration 68, loss = 860.69808757\n",
      "Iteration 67, loss = 872.71941163\n",
      "Iteration 68, loss = 858.89948510\n",
      "Iteration 69, loss = 866.05397171\n",
      "Iteration 68, loss = 827.84513310\n",
      "Iteration 65, loss = 849.98213249\n",
      "Iteration 68, loss = 860.79705434\n",
      "Iteration 68, loss = 808.69963682\n",
      "Iteration 7, loss = 2173.50855980\n",
      "Iteration 69, loss = 851.99101602\n",
      "Iteration 69, loss = 848.72352200\n",
      "Iteration 70, loss = 857.60046316\n",
      "Iteration 69, loss = 861.95194541\n",
      "Iteration 66, loss = 858.49008365\n",
      "Iteration 69, loss = 789.57472512\n",
      "Iteration 69, loss = 814.62331370\n",
      "Iteration 70, loss = 845.80821706\n",
      "Iteration 8, loss = 1942.09733653\n",
      "Iteration 70, loss = 872.61791178\n",
      "Iteration 71, loss = 855.65610856\n",
      "Iteration 70, loss = 855.33116947\n",
      "Iteration 67, loss = 859.54472159\n",
      "Iteration 70, loss = 814.83278489\n",
      "Iteration 71, loss = 870.96400046\n",
      "Iteration 70, loss = 825.82474565\n",
      "Iteration 9, loss = 1761.46616482\n",
      "Iteration 71, loss = 885.98103892\n",
      "Iteration 72, loss = 830.31290513\n",
      "Iteration 71, loss = 874.13088748\n",
      "Iteration 68, loss = 856.66980488\n",
      "Iteration 71, loss = 825.34328360\n",
      "Iteration 72, loss = 845.51556990\n",
      "Iteration 10, loss = 1632.37351892\n",
      "Iteration 71, loss = 808.51526331\n",
      "Iteration 72, loss = 857.17244917\n",
      "Iteration 73, loss = 854.35615437\n",
      "Iteration 72, loss = 871.81504244\n",
      "Iteration 11, loss = 1520.09996490\n",
      "Iteration 73, loss = 840.45686288\n",
      "Iteration 69, loss = 860.58067714\n",
      "Iteration 72, loss = 820.02635777\n",
      "Iteration 72, loss = 811.69618279\n",
      "Iteration 73, loss = 849.71882735\n",
      "Iteration 74, loss = 829.62942807\n",
      "Iteration 73, loss = 862.27436697\n",
      "Iteration 74, loss = 840.37813261\n",
      "Iteration 70, loss = 879.86830020\n",
      "Iteration 73, loss = 810.44671861\n",
      "Iteration 12, loss = 1418.72959227\n",
      "Iteration 73, loss = 840.82435530\n",
      "Iteration 74, loss = 835.80250027\n",
      "Iteration 74, loss = 857.29805035\n",
      "Iteration 75, loss = 831.27387020\n",
      "Iteration 75, loss = 860.87473964\n",
      "Iteration 75, loss = 839.59332130\n",
      "Iteration 74, loss = 803.49928576\n",
      "Iteration 71, loss = 876.32674285\n",
      "Iteration 13, loss = 1348.54530641\n",
      "Iteration 74, loss = 805.60861035\n",
      "Iteration 76, loss = 842.36101506\n",
      "Iteration 75, loss = 844.83731806\n",
      "Iteration 72, loss = 851.96366387\n",
      "Iteration 76, loss = 850.06531171\n",
      "Iteration 75, loss = 805.43366798\n",
      "Iteration 14, loss = 1281.80936827\n",
      "Iteration 75, loss = 806.40662650\n",
      "Iteration 76, loss = 853.43133635\n",
      "Iteration 77, loss = 823.44150402\n",
      "Iteration 76, loss = 867.31169226\n",
      "Iteration 77, loss = 841.97758224\n",
      "Iteration 76, loss = 812.43081779\n",
      "Iteration 73, loss = 842.72334063\n",
      "Iteration 76, loss = 814.39778552\n",
      "Iteration 77, loss = 859.32253716\n",
      "Iteration 77, loss = 858.02786638\n",
      "Iteration 78, loss = 830.75805051\n",
      "Iteration 15, loss = 1217.62908333\n",
      "Iteration 78, loss = 839.73693806\n",
      "Iteration 78, loss = 846.34388884\n",
      "Iteration 74, loss = 868.94375139\n",
      "Iteration 77, loss = 809.29654857\n",
      "Iteration 77, loss = 807.95612964\n",
      "Iteration 79, loss = 815.75310485\n",
      "Iteration 78, loss = 839.94768709\n",
      "Iteration 16, loss = 1182.67726476\n",
      "Iteration 78, loss = 793.39660581\n",
      "Iteration 79, loss = 853.85564868\n",
      "Iteration 79, loss = 877.78565267\n",
      "Iteration 75, loss = 850.00627239\n",
      "Iteration 80, loss = 825.89770233\n",
      "Iteration 79, loss = 868.18924776\n",
      "Iteration 78, loss = 799.11775785\n",
      "Iteration 17, loss = 1149.32105273\n",
      "Iteration 79, loss = 816.65371256\n",
      "Iteration 80, loss = 837.75741156\n",
      "Iteration 80, loss = 860.70415398\n",
      "Iteration 80, loss = 850.89151218\n",
      "Iteration 79, loss = 797.30102158\n",
      "Iteration 81, loss = 832.08787002\n",
      "Iteration 76, loss = 860.27220310\n",
      "Iteration 18, loss = 1110.67658586\n",
      "Iteration 81, loss = 842.74786538\n",
      "Iteration 80, loss = 816.83374833\n",
      "Iteration 81, loss = 834.71719871\n",
      "Iteration 77, loss = 845.42254380\n",
      "Iteration 82, loss = 813.90721225\n",
      "Iteration 81, loss = 851.78596484\n",
      "Iteration 80, loss = 791.75419686\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 1086.19881795\n",
      "Iteration 82, loss = 851.36498817\n",
      "Iteration 81, loss = 796.67256592\n",
      "Iteration 78, loss = 840.08258734\n",
      "Iteration 82, loss = 850.10246908\n",
      "Iteration 83, loss = 817.30571686\n",
      "Iteration 82, loss = 855.79673347\n",
      "Iteration 20, loss = 1058.69857196\n",
      "Iteration 1, loss = 8567.59366172\n",
      "Iteration 83, loss = 843.52216880\n",
      "Iteration 83, loss = 848.99044577\n",
      "Iteration 79, loss = 830.95453295\n",
      "Iteration 82, loss = 817.25883169\n",
      "Iteration 84, loss = 802.42301297\n",
      "Iteration 21, loss = 1039.85299987\n",
      "Iteration 83, loss = 840.91220405\n",
      "Iteration 2, loss = 5492.55320036\n",
      "Iteration 84, loss = 832.80915392\n",
      "Iteration 80, loss = 838.07002381\n",
      "Iteration 84, loss = 833.31078626\n",
      "Iteration 83, loss = 814.45014180\n",
      "Iteration 85, loss = 842.74285014\n",
      "Iteration 84, loss = 840.70924663\n",
      "Iteration 22, loss = 1011.98161443\n",
      "Iteration 3, loss = 4223.06235085\n",
      "Iteration 85, loss = 840.92823517\n",
      "Iteration 85, loss = 828.84281503\n",
      "Iteration 84, loss = 813.28249488\n",
      "Iteration 85, loss = 834.13735551\n",
      "Iteration 81, loss = 848.60565433\n",
      "Iteration 86, loss = 841.25751629\n",
      "Iteration 23, loss = 1018.15410126\n",
      "Iteration 86, loss = 857.35225108\n",
      "Iteration 4, loss = 3455.86454703\n",
      "Iteration 85, loss = 794.73999125\n",
      "Iteration 86, loss = 840.27149423\n",
      "Iteration 86, loss = 847.47315930\n",
      "Iteration 87, loss = 825.88274852\n",
      "Iteration 82, loss = 837.45865101\n",
      "Iteration 24, loss = 1000.34179015\n",
      "Iteration 87, loss = 844.48424900\n",
      "Iteration 5, loss = 2904.78575346\n",
      "Iteration 86, loss = 803.95551620\n",
      "Iteration 87, loss = 842.22302867\n",
      "Iteration 87, loss = 841.25658884\n",
      "Iteration 25, loss = 993.63003889\n",
      "Iteration 88, loss = 840.33555201\n",
      "Iteration 83, loss = 834.76079865\n",
      "Iteration 88, loss = 822.21422545\n",
      "Iteration 6, loss = 2493.18409854\n",
      "Iteration 88, loss = 832.66871378\n",
      "Iteration 87, loss = 795.18688633\n",
      "Iteration 88, loss = 837.07309053\n",
      "Iteration 26, loss = 976.23051739\n",
      "Iteration 89, loss = 833.38056526\n",
      "Iteration 84, loss = 835.17086825\n",
      "Iteration 89, loss = 820.53370205\n",
      "Iteration 7, loss = 2193.82051707\n",
      "Iteration 89, loss = 818.87740395\n",
      "Iteration 89, loss = 835.88384611\n",
      "Iteration 88, loss = 799.49424520\n",
      "Iteration 90, loss = 847.32598087\n",
      "Iteration 85, loss = 856.05017715\n",
      "Iteration 27, loss = 956.88266509\n",
      "Iteration 90, loss = 817.84539730\n",
      "Iteration 90, loss = 831.17342521\n",
      "Iteration 90, loss = 833.83955920Iteration 8, loss = 1958.75900715\n",
      "\n",
      "Iteration 89, loss = 798.35910556\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 91, loss = 799.14246055\n",
      "Iteration 91, loss = 845.64431543\n",
      "Iteration 28, loss = 957.54967965\n",
      "Iteration 86, loss = 849.51800503\n",
      "Iteration 91, loss = 833.14761378\n",
      "Iteration 91, loss = 838.18155552\n",
      "Iteration 9, loss = 1781.45197769\n",
      "Iteration 92, loss = 839.47797191\n",
      "Iteration 92, loss = 827.41989803\n",
      "Iteration 87, loss = 834.57496191\n",
      "Iteration 29, loss = 943.66736977\n",
      "Iteration 92, loss = 838.59414802\n",
      "Iteration 92, loss = 827.48772688\n",
      "Iteration 1, loss = 11284.23440881\n",
      "Iteration 10, loss = 1647.56407519\n",
      "Iteration 30, loss = 940.09571043\n",
      "Iteration 93, loss = 796.97259498\n",
      "Iteration 93, loss = 830.87477323\n",
      "Iteration 93, loss = 855.02896855\n",
      "Iteration 88, loss = 840.69715761\n",
      "Iteration 93, loss = 854.07944281\n",
      "Iteration 2, loss = 10071.10270104\n",
      "Iteration 11, loss = 1538.29250215\n",
      "Iteration 31, loss = 925.77274518\n",
      "Iteration 89, loss = 833.87209199\n",
      "Iteration 94, loss = 822.34884775\n",
      "Iteration 94, loss = 857.54132787\n",
      "Iteration 94, loss = 843.52759539\n",
      "Iteration 94, loss = 834.04322636\n",
      "Iteration 3, loss = 9407.50989865\n",
      "Iteration 95, loss = 844.12161408\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 90, loss = 837.63068875\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 95, loss = 799.09286326\n",
      "Iteration 32, loss = 935.34594401\n",
      "Iteration 12, loss = 1440.01208926\n",
      "Iteration 95, loss = 838.96032996\n",
      "Iteration 95, loss = 822.47923009\n",
      "Iteration 4, loss = 8787.50708423\n",
      "Iteration 96, loss = 801.67162038\n",
      "Iteration 13, loss = 1358.96817092\n",
      "Iteration 33, loss = 921.92324602\n",
      "Iteration 96, loss = 835.20042410\n",
      "Iteration 96, loss = 832.70506083\n",
      "Iteration 1, loss = 11688.96978898\n",
      "Iteration 5, loss = 8235.04410260\n",
      "Iteration 1, loss = 11395.58485647\n",
      "Iteration 97, loss = 792.00846011\n",
      "Iteration 14, loss = 1295.91922888\n",
      "Iteration 97, loss = 846.38187027\n",
      "Iteration 34, loss = 912.10977625\n",
      "Iteration 97, loss = 841.80123361\n",
      "Iteration 6, loss = 7764.35450024\n",
      "Iteration 2, loss = 10451.33498414\n",
      "Iteration 2, loss = 10156.37833454\n",
      "Iteration 98, loss = 804.38490861\n",
      "Iteration 35, loss = 925.98763317\n",
      "Iteration 15, loss = 1233.45707080\n",
      "Iteration 98, loss = 832.89351338\n",
      "Iteration 98, loss = 834.96399246\n",
      "Iteration 3, loss = 9773.63639585\n",
      "Iteration 7, loss = 7352.23075831\n",
      "Iteration 3, loss = 9479.52293438\n",
      "Iteration 99, loss = 791.82092144\n",
      "Iteration 16, loss = 1179.78315554\n",
      "Iteration 99, loss = 840.23608192\n",
      "Iteration 36, loss = 900.91891666\n",
      "Iteration 99, loss = 819.98198973\n",
      "Iteration 4, loss = 9139.29197668\n",
      "Iteration 8, loss = 6984.73665058\n",
      "Iteration 4, loss = 8851.22168205\n",
      "Iteration 100, loss = 831.99067729\n",
      "Iteration 37, loss = 912.97840868\n",
      "Iteration 100, loss = 855.76523625\n",
      "Iteration 17, loss = 1153.49764621\n",
      "Iteration 100, loss = 836.53436276\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 8572.42900028\n",
      "Iteration 9, loss = 6653.86492935\n",
      "Iteration 5, loss = 8289.25174026\n",
      "Iteration 38, loss = 907.37724528\n",
      "Iteration 101, loss = 822.24268222\n",
      "Iteration 101, loss = 831.72508169\n",
      "Iteration 18, loss = 1106.49211117\n",
      "Iteration 6, loss = 8088.81232414\n",
      "Iteration 10, loss = 6353.56937655\n",
      "Iteration 39, loss = 910.10007567\n",
      "Iteration 6, loss = 7804.75671519\n",
      "Iteration 102, loss = 845.01914624\n",
      "Iteration 1, loss = 11680.65254902\n",
      "Iteration 102, loss = 796.60596657\n",
      "Iteration 19, loss = 1075.15726008\n",
      "Iteration 7, loss = 7663.39849235\n",
      "Iteration 11, loss = 6078.60117700\n",
      "Iteration 7, loss = 7385.16229428\n",
      "Iteration 40, loss = 891.41475046\n",
      "Iteration 103, loss = 817.06921962\n",
      "Iteration 103, loss = 812.33522740\n",
      "Iteration 2, loss = 10448.65446451\n",
      "Iteration 20, loss = 1047.89773634\n",
      "Iteration 8, loss = 7285.29264495\n",
      "Iteration 12, loss = 5822.47556489\n",
      "Iteration 41, loss = 882.68709487\n",
      "Iteration 8, loss = 7011.28717845\n",
      "Iteration 104, loss = 812.11457983\n",
      "Iteration 104, loss = 825.91039469\n",
      "Iteration 3, loss = 9769.77329780\n",
      "Iteration 21, loss = 1026.36451571\n",
      "Iteration 9, loss = 6943.21480889\n",
      "Iteration 13, loss = 5582.98002279\n",
      "Iteration 42, loss = 900.48143966\n",
      "Iteration 9, loss = 6673.98758059\n",
      "Iteration 105, loss = 800.33429798\n",
      "Iteration 105, loss = 848.56992463\n",
      "Iteration 4, loss = 9139.00251583\n",
      "Iteration 10, loss = 6630.83985350\n",
      "Iteration 22, loss = 999.21812324\n",
      "Iteration 43, loss = 893.12809867\n",
      "Iteration 14, loss = 5358.65350678\n",
      "Iteration 106, loss = 834.02037232\n",
      "Iteration 10, loss = 6365.55255655\n",
      "Iteration 106, loss = 808.95127055\n",
      "Iteration 5, loss = 8573.98913888\n",
      "Iteration 23, loss = 1001.57059152\n",
      "Iteration 15, loss = 5151.23063617\n",
      "Iteration 44, loss = 885.51815158\n",
      "Iteration 11, loss = 6344.68560083\n",
      "Iteration 107, loss = 841.16420344\n",
      "Iteration 107, loss = 795.83096181\n",
      "Iteration 11, loss = 6077.02274580\n",
      "Iteration 6, loss = 8086.85001607\n",
      "Iteration 12, loss = 6077.81868305\n",
      "Iteration 16, loss = 4959.74724278\n",
      "Iteration 24, loss = 982.74777970\n",
      "Iteration 45, loss = 876.53001115\n",
      "Iteration 108, loss = 824.77621561\n",
      "Iteration 12, loss = 5808.85337877\n",
      "Iteration 108, loss = 803.15194031\n",
      "Iteration 7, loss = 7664.55103575\n",
      "Iteration 13, loss = 5829.30554530\n",
      "Iteration 17, loss = 4781.59289532\n",
      "Iteration 46, loss = 884.01322457\n",
      "Iteration 25, loss = 973.81700740\n",
      "Iteration 109, loss = 830.69520884\n",
      "Iteration 13, loss = 5561.43749683\n",
      "Iteration 109, loss = 801.79582955\n",
      "Iteration 18, loss = 4615.67144236\n",
      "Iteration 8, loss = 7285.79968095\n",
      "Iteration 14, loss = 5596.78904898\n",
      "Iteration 47, loss = 882.62412322\n",
      "Iteration 26, loss = 966.85030704\n",
      "Iteration 14, loss = 5331.37457081\n",
      "Iteration 110, loss = 808.00760225\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 110, loss = 822.61391088\n",
      "Iteration 9, loss = 6945.05634356\n",
      "Iteration 19, loss = 4461.16242170\n",
      "Iteration 15, loss = 5381.86225338\n",
      "Iteration 27, loss = 944.97448970\n",
      "Iteration 111, loss = 826.02311308\n",
      "Iteration 48, loss = 875.72308144\n",
      "Iteration 15, loss = 5119.29504318\n",
      "Iteration 10, loss = 6634.66019814\n",
      "Iteration 1, loss = 11520.77846042\n",
      "Iteration 16, loss = 5183.48160659\n",
      "Iteration 28, loss = 936.04028143\n",
      "Iteration 20, loss = 4317.96606880\n",
      "Iteration 112, loss = 822.59661880\n",
      "Iteration 49, loss = 867.99616831\n",
      "Iteration 16, loss = 4922.99329711\n",
      "Iteration 11, loss = 6345.46572556\n",
      "Iteration 29, loss = 919.14769396\n",
      "Iteration 2, loss = 10291.74354572\n",
      "Iteration 21, loss = 4181.49301884\n",
      "Iteration 113, loss = 827.85516649\n",
      "Iteration 50, loss = 875.57075156\n",
      "Iteration 17, loss = 4739.64573756\n",
      "Iteration 17, loss = 4998.83398030\n",
      "Iteration 30, loss = 924.50405441\n",
      "Iteration 12, loss = 6076.80210480\n",
      "Iteration 3, loss = 9612.76144106\n",
      "Iteration 114, loss = 829.70998243\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 4052.73852305\n",
      "Iteration 51, loss = 867.40737673\n",
      "Iteration 18, loss = 4571.42755575\n",
      "Iteration 18, loss = 4825.96179442\n",
      "Iteration 31, loss = 890.97371168\n",
      "Iteration 13, loss = 5828.07594685\n",
      "Iteration 23, loss = 3931.24997809\n",
      "Iteration 4, loss = 8981.07845763\n",
      "Iteration 52, loss = 874.48551406\n",
      "Iteration 19, loss = 4414.53804475\n",
      "Iteration 19, loss = 4664.26357200\n",
      "Iteration 32, loss = 910.54750300\n",
      "Iteration 1, loss = 11452.34197775\n",
      "Iteration 14, loss = 5596.44880884\n",
      "Iteration 24, loss = 3815.45639641\n",
      "Iteration 53, loss = 869.29136123\n",
      "Iteration 5, loss = 8415.82204273\n",
      "Iteration 20, loss = 4266.56646200\n",
      "Iteration 2, loss = 10221.18028039\n",
      "Iteration 20, loss = 4513.78935397\n",
      "Iteration 15, loss = 5381.71139905\n",
      "Iteration 33, loss = 894.93609609\n",
      "Iteration 25, loss = 3705.77390930\n",
      "Iteration 6, loss = 7930.55418513\n",
      "Iteration 54, loss = 860.41147327\n",
      "Iteration 3, loss = 9543.60607723\n",
      "Iteration 21, loss = 4370.15453289\n",
      "Iteration 16, loss = 5182.21574923\n",
      "Iteration 34, loss = 892.11542336\n",
      "Iteration 21, loss = 4126.62259584\n",
      "Iteration 26, loss = 3601.67614145\n",
      "Iteration 4, loss = 8915.87855164\n",
      "Iteration 7, loss = 7508.91954901\n",
      "Iteration 55, loss = 854.33233392\n",
      "Iteration 17, loss = 4995.70609114\n",
      "Iteration 35, loss = 886.33354228\n",
      "Iteration 22, loss = 4234.43597964\n",
      "Iteration 22, loss = 3994.98231225\n",
      "Iteration 27, loss = 3501.62133360\n",
      "Iteration 5, loss = 8355.85936365\n",
      "Iteration 8, loss = 7131.34741421\n",
      "Iteration 56, loss = 842.98424062\n",
      "Iteration 18, loss = 4824.12822257\n",
      "Iteration 23, loss = 3870.71538794\n",
      "Iteration 36, loss = 869.22352037\n",
      "Iteration 23, loss = 4105.14914408\n",
      "Iteration 28, loss = 3407.70017602\n",
      "Iteration 9, loss = 6792.16928887\n",
      "Iteration 57, loss = 882.98499521\n",
      "Iteration 6, loss = 7875.24015379\n",
      "Iteration 19, loss = 4664.26783865\n",
      "Iteration 24, loss = 3982.28076797\n",
      "Iteration 24, loss = 3752.76140376\n",
      "Iteration 37, loss = 883.66125884\n",
      "Iteration 29, loss = 3318.46929105\n",
      "Iteration 10, loss = 6483.12090932\n",
      "Iteration 58, loss = 884.20767382\n",
      "Iteration 20, loss = 4512.62599018\n",
      "Iteration 7, loss = 7456.72604064\n",
      "Iteration 38, loss = 876.95170315\n",
      "Iteration 25, loss = 3865.70451514\n",
      "Iteration 25, loss = 3640.02041761\n",
      "Iteration 30, loss = 3235.03112909\n",
      "Iteration 59, loss = 860.31988849\n",
      "Iteration 21, loss = 4369.09241094\n",
      "Iteration 11, loss = 6195.13212440\n",
      "Iteration 8, loss = 7082.60330197\n",
      "Iteration 39, loss = 864.10924825\n",
      "Iteration 26, loss = 3533.55828232\n",
      "Iteration 31, loss = 3155.74332202\n",
      "Iteration 12, loss = 5926.84845845\n",
      "Iteration 60, loss = 861.30611035\n",
      "Iteration 26, loss = 3756.06491644\n",
      "Iteration 22, loss = 4233.64052622\n",
      "Iteration 9, loss = 6746.83357191\n",
      "Iteration 27, loss = 3431.75909733\n",
      "Iteration 40, loss = 865.19649538\n",
      "Iteration 61, loss = 848.58015127\n",
      "Iteration 32, loss = 3080.35511693\n",
      "Iteration 27, loss = 3651.95316815\n",
      "Iteration 13, loss = 5678.26406043\n",
      "Iteration 23, loss = 4105.56296353\n",
      "Iteration 10, loss = 6440.01023684\n",
      "Iteration 28, loss = 3334.15323820\n",
      "Iteration 62, loss = 846.43426709\n",
      "Iteration 41, loss = 855.56569814\n",
      "Iteration 28, loss = 3553.72041446\n",
      "Iteration 14, loss = 5447.52800182\n",
      "Iteration 33, loss = 3007.76107793\n",
      "Iteration 24, loss = 3984.03824065\n",
      "Iteration 11, loss = 6155.00329940\n",
      "Iteration 63, loss = 850.55217108\n",
      "Iteration 29, loss = 3240.47888042\n",
      "Iteration 29, loss = 3459.67412148\n",
      "Iteration 15, loss = 5233.80990234\n",
      "Iteration 42, loss = 872.10219668\n",
      "Iteration 34, loss = 2938.13993540\n",
      "Iteration 25, loss = 3867.95112924\n",
      "Iteration 12, loss = 5889.55851667\n",
      "Iteration 64, loss = 854.35724624\n",
      "Iteration 16, loss = 5036.18998210\n",
      "Iteration 30, loss = 3152.23932718\n",
      "Iteration 43, loss = 860.40533456\n",
      "Iteration 30, loss = 3370.84378025\n",
      "Iteration 35, loss = 2870.07256173\n",
      "Iteration 13, loss = 5644.32867290\n",
      "Iteration 26, loss = 3757.98650807\n",
      "Iteration 65, loss = 855.33375674\n",
      "Iteration 44, loss = 856.69384769\n",
      "Iteration 31, loss = 3285.55256757\n",
      "Iteration 36, loss = 2806.16753139\n",
      "Iteration 17, loss = 4851.17563267\n",
      "Iteration 31, loss = 3067.81548029\n",
      "Iteration 27, loss = 3653.51107523\n",
      "Iteration 14, loss = 5417.38137039\n",
      "Iteration 18, loss = 4680.77823678\n",
      "Iteration 37, loss = 2743.78343315\n",
      "Iteration 66, loss = 852.60889890\n",
      "Iteration 45, loss = 846.25552155\n",
      "Iteration 32, loss = 2986.54855466\n",
      "Iteration 32, loss = 3204.07064402\n",
      "Iteration 28, loss = 3554.40929878\n",
      "Iteration 15, loss = 5206.96963719\n",
      "Iteration 19, loss = 4523.06510378\n",
      "Iteration 33, loss = 2910.45455321\n",
      "Iteration 33, loss = 3124.85739456\n",
      "Iteration 38, loss = 2684.72379141\n",
      "Iteration 67, loss = 849.06309384\n",
      "Iteration 46, loss = 858.96242179\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 3460.25871442\n",
      "Iteration 16, loss = 5012.70076000\n",
      "Iteration 20, loss = 4374.08248846\n",
      "Iteration 34, loss = 3050.69618771\n",
      "Iteration 47, loss = 869.72865503\n",
      "Iteration 34, loss = 2836.04850782\n",
      "Iteration 39, loss = 2628.58252531\n",
      "Iteration 17, loss = 4830.81887719\n",
      "Iteration 30, loss = 3370.26856807\n",
      "Iteration 1, loss = 11520.69488819\n",
      "Iteration 21, loss = 4233.52986502\n",
      "Iteration 48, loss = 846.19030944\n",
      "Iteration 35, loss = 2764.50963028\n",
      "Iteration 35, loss = 2978.48872372\n",
      "Iteration 40, loss = 2574.55836205\n",
      "Iteration 31, loss = 3283.99357793\n",
      "Iteration 18, loss = 4662.26378470\n",
      "Iteration 22, loss = 4100.87541962\n",
      "Iteration 2, loss = 10288.94986246\n",
      "Iteration 49, loss = 832.57626357\n",
      "Iteration 36, loss = 2696.63687090\n",
      "Iteration 41, loss = 2521.81632847\n",
      "Iteration 36, loss = 2909.91197986\n",
      "Iteration 32, loss = 3200.60210824\n",
      "Iteration 23, loss = 3975.89028495\n",
      "Iteration 19, loss = 4506.11347656\n",
      "Iteration 3, loss = 9608.66700020\n",
      "Iteration 50, loss = 831.49864212\n",
      "Iteration 37, loss = 2843.11008556\n",
      "Iteration 42, loss = 2470.36495997\n",
      "Iteration 33, loss = 3120.72636100\n",
      "Iteration 37, loss = 2632.03788967\n",
      "Iteration 24, loss = 3857.31505511\n",
      "Iteration 20, loss = 4358.16585370\n",
      "Iteration 4, loss = 8975.68146671\n",
      "Iteration 51, loss = 854.72143947\n",
      "Iteration 38, loss = 2780.07107554\n",
      "Iteration 34, loss = 3044.35611441\n",
      "Iteration 43, loss = 2422.23675954\n",
      "Iteration 25, loss = 3744.10353020\n",
      "Iteration 38, loss = 2570.48994613\n",
      "Iteration 21, loss = 4219.57492884\n",
      "Iteration 5, loss = 8410.37213094\n",
      "Iteration 52, loss = 854.15774352\n",
      "Iteration 39, loss = 2719.87830604\n",
      "Iteration 44, loss = 2377.37583136\n",
      "Iteration 39, loss = 2511.74635432\n",
      "Iteration 26, loss = 3635.89535032\n",
      "Iteration 35, loss = 2971.76577781\n",
      "Iteration 53, loss = 845.20411388\n",
      "Iteration 6, loss = 7925.99608805\n",
      "Iteration 22, loss = 4089.43763250\n",
      "Iteration 40, loss = 2662.25716704\n",
      "Iteration 45, loss = 2333.87256334\n",
      "Iteration 27, loss = 3533.08563734\n",
      "Iteration 40, loss = 2455.10912449\n",
      "Iteration 36, loss = 2902.61342360\n",
      "Iteration 7, loss = 7502.10068111\n",
      "Iteration 54, loss = 849.74267337\n",
      "Iteration 23, loss = 3966.35846557\n",
      "Iteration 41, loss = 2606.43901630\n",
      "Iteration 28, loss = 3436.43886630\n",
      "Iteration 41, loss = 2400.09369871\n",
      "Iteration 46, loss = 2292.92062099\n",
      "Iteration 8, loss = 7123.63193016\n",
      "Iteration 37, loss = 2836.53804123\n",
      "Iteration 55, loss = 857.81999515\n",
      "Iteration 42, loss = 2552.40210701\n",
      "Iteration 24, loss = 3849.87184255\n",
      "Iteration 42, loss = 2347.25228540\n",
      "Iteration 29, loss = 3344.22072948\n",
      "Iteration 47, loss = 2254.06228694\n",
      "Iteration 9, loss = 6783.90482511\n",
      "Iteration 38, loss = 2773.31349169\n",
      "Iteration 25, loss = 3738.66985980\n",
      "Iteration 43, loss = 2501.97191572\n",
      "Iteration 56, loss = 827.82180319\n",
      "Iteration 43, loss = 2297.57747786\n",
      "Iteration 48, loss = 2216.73671835\n",
      "Iteration 30, loss = 3255.36948339\n",
      "Iteration 10, loss = 6472.85733432\n",
      "Iteration 39, loss = 2712.36288192\n",
      "Iteration 57, loss = 839.53157338\n",
      "Iteration 26, loss = 3634.14515417\n",
      "Iteration 44, loss = 2454.79907638\n",
      "Iteration 31, loss = 3170.16531105\n",
      "Iteration 49, loss = 2180.33052933\n",
      "Iteration 44, loss = 2248.45245969\n",
      "Iteration 11, loss = 6183.68965641\n",
      "Iteration 40, loss = 2653.77562302\n",
      "Iteration 58, loss = 829.20488396\n",
      "Iteration 32, loss = 3088.63847781\n",
      "Iteration 27, loss = 3535.29112511\n",
      "Iteration 45, loss = 2407.93253901\n",
      "Iteration 12, loss = 5914.78389439\n",
      "Iteration 45, loss = 2203.16927200\n",
      "Iteration 50, loss = 2145.60896912\n",
      "Iteration 41, loss = 2597.26711596\n",
      "Iteration 59, loss = 817.52332470\n",
      "Iteration 28, loss = 3441.40447491\n",
      "Iteration 13, loss = 5664.99968609\n",
      "Iteration 33, loss = 3010.63528877\n",
      "Iteration 46, loss = 2364.37390786\n",
      "Iteration 51, loss = 2112.60120905\n",
      "Iteration 46, loss = 2159.40364631\n",
      "Iteration 42, loss = 2542.82568245\n",
      "Iteration 60, loss = 826.47947006\n",
      "Iteration 14, loss = 5433.18010721\n",
      "Iteration 34, loss = 2935.26970078\n",
      "Iteration 47, loss = 2322.37035996\n",
      "Iteration 29, loss = 3351.40107224\n",
      "Iteration 47, loss = 2118.37489025\n",
      "Iteration 52, loss = 2081.20164896\n",
      "Iteration 61, loss = 808.98359934\n",
      "Iteration 43, loss = 2492.02384595\n",
      "Iteration 15, loss = 5217.78220001\n",
      "Iteration 48, loss = 2282.69447689\n",
      "Iteration 35, loss = 2864.04567530\n",
      "Iteration 30, loss = 3264.92844133\n",
      "Iteration 48, loss = 2078.17836085\n",
      "Iteration 44, loss = 2442.46290017\n",
      "Iteration 53, loss = 2051.06998806\n",
      "Iteration 62, loss = 815.09355646\n",
      "Iteration 36, loss = 2795.55021837\n",
      "Iteration 16, loss = 5018.90819155\n",
      "Iteration 49, loss = 2242.96627551\n",
      "Iteration 49, loss = 2041.01885587\n",
      "Iteration 63, loss = 819.54568321\n",
      "Iteration 31, loss = 3182.47086790Iteration 54, loss = 2021.04660346\n",
      "\n",
      "Iteration 45, loss = 2396.39695920\n",
      "Iteration 37, loss = 2730.54311637\n",
      "Iteration 50, loss = 2205.88751828\n",
      "Iteration 17, loss = 4834.27696162\n",
      "Iteration 50, loss = 2004.96156888\n",
      "Iteration 64, loss = 810.71306975\n",
      "Iteration 32, loss = 3103.49684765\n",
      "Iteration 55, loss = 1993.58417791\n",
      "Iteration 46, loss = 2351.23384892\n",
      "Iteration 38, loss = 2668.58501595\n",
      "Iteration 51, loss = 2170.01400589\n",
      "Iteration 18, loss = 4663.23171338\n",
      "Iteration 51, loss = 1969.89905287\n",
      "Iteration 65, loss = 809.36632663\n",
      "Iteration 33, loss = 3027.90818572\n",
      "Iteration 56, loss = 1966.69869787\n",
      "Iteration 47, loss = 2308.58653911\n",
      "Iteration 39, loss = 2609.04233681\n",
      "Iteration 52, loss = 2135.83780454\n",
      "Iteration 19, loss = 4504.35982090\n",
      "Iteration 66, loss = 809.20527754\n",
      "Iteration 52, loss = 1937.54957270\n",
      "Iteration 57, loss = 1940.66161135\n",
      "Iteration 34, loss = 2954.92193731\n",
      "Iteration 48, loss = 2266.95506532\n",
      "Iteration 40, loss = 2552.54267587\n",
      "Iteration 53, loss = 2103.60325314\n",
      "Iteration 20, loss = 4353.30986947\n",
      "Iteration 53, loss = 1905.39932655\n",
      "Iteration 67, loss = 808.87574920\n",
      "Iteration 41, loss = 2498.04865132\n",
      "Iteration 49, loss = 2228.60345999\n",
      "Iteration 58, loss = 1916.23066629\n",
      "Iteration 35, loss = 2886.14313976\n",
      "Iteration 54, loss = 2072.22431423\n",
      "Iteration 21, loss = 4212.05777164\n",
      "Iteration 54, loss = 1875.39675203\n",
      "Iteration 68, loss = 803.45643951\n",
      "Iteration 50, loss = 2191.66054091\n",
      "Iteration 59, loss = 1892.55582889\n",
      "Iteration 42, loss = 2445.55976406\n",
      "Iteration 55, loss = 2042.85894594\n",
      "Iteration 36, loss = 2818.76534535\n",
      "Iteration 22, loss = 4078.94515011\n",
      "Iteration 69, loss = 798.82842410\n",
      "Iteration 55, loss = 1847.18894498\n",
      "Iteration 60, loss = 1868.43231457\n",
      "Iteration 51, loss = 2155.49485871\n",
      "Iteration 56, loss = 2014.09470040\n",
      "Iteration 37, loss = 2754.91527776\n",
      "Iteration 43, loss = 2396.47216267\n",
      "Iteration 70, loss = 800.11882680\n",
      "Iteration 23, loss = 3953.38115971\n",
      "Iteration 56, loss = 1818.65806451\n",
      "Iteration 61, loss = 1845.73832653\n",
      "Iteration 38, loss = 2694.38932338\n",
      "Iteration 52, loss = 2121.56715105\n",
      "Iteration 71, loss = 815.72142757\n",
      "Iteration 57, loss = 1985.53914491\n",
      "Iteration 44, loss = 2348.38189020\n",
      "Iteration 24, loss = 3835.01337783\n",
      "Iteration 57, loss = 1792.91284599\n",
      "Iteration 62, loss = 1823.52789870\n",
      "Iteration 39, loss = 2635.69092627\n",
      "Iteration 72, loss = 798.63924504\n",
      "Iteration 25, loss = 3722.64088459\n",
      "Iteration 45, loss = 2303.66944342\n",
      "Iteration 53, loss = 2088.12788084\n",
      "Iteration 58, loss = 1958.80164146\n",
      "Iteration 58, loss = 1767.68146335\n",
      "Iteration 63, loss = 1802.63739587\n",
      "Iteration 40, loss = 2579.74030405\n",
      "Iteration 73, loss = 800.39097524\n",
      "Iteration 26, loss = 3616.03353307\n",
      "Iteration 46, loss = 2259.72003324\n",
      "Iteration 54, loss = 2056.58744814\n",
      "Iteration 59, loss = 1932.68771869\n",
      "Iteration 59, loss = 1742.54913478\n",
      "Iteration 74, loss = 796.61861971\n",
      "Iteration 41, loss = 2525.60387630\n",
      "Iteration 64, loss = 1781.97610312\n",
      "Iteration 47, loss = 2217.96483835\n",
      "Iteration 27, loss = 3514.84720630\n",
      "Iteration 60, loss = 1907.75505024\n",
      "Iteration 55, loss = 2026.57809348\n",
      "Iteration 60, loss = 1718.89468130\n",
      "Iteration 75, loss = 788.62736997\n",
      "Iteration 28, loss = 3418.75114594\n",
      "Iteration 61, loss = 1884.02883028\n",
      "Iteration 65, loss = 1761.49867794\n",
      "Iteration 56, loss = 1996.19258728\n",
      "Iteration 42, loss = 2473.95840850\n",
      "Iteration 48, loss = 2177.78528825\n",
      "Iteration 61, loss = 1695.30686968\n",
      "Iteration 43, loss = 2425.25604223\n",
      "Iteration 76, loss = 813.51941166\n",
      "Iteration 57, loss = 1968.47723183\n",
      "Iteration 49, loss = 2140.27431569\n",
      "Iteration 29, loss = 3326.56462340\n",
      "Iteration 66, loss = 1742.31624477\n",
      "Iteration 62, loss = 1860.96103968\n",
      "Iteration 62, loss = 1672.72773247\n",
      "Iteration 58, loss = 1941.27744480\n",
      "Iteration 67, loss = 1724.08365009\n",
      "Iteration 50, loss = 2104.71732216\n",
      "Iteration 30, loss = 3238.26244422\n",
      "Iteration 44, loss = 2378.11868327\n",
      "Iteration 63, loss = 1839.29896812\n",
      "Iteration 77, loss = 794.01675644\n",
      "Iteration 63, loss = 1651.33475405\n",
      "Iteration 51, loss = 2069.67566458\n",
      "Iteration 31, loss = 3154.53851016\n",
      "Iteration 59, loss = 1914.52422381\n",
      "Iteration 68, loss = 1705.01411650\n",
      "Iteration 64, loss = 1818.14417491\n",
      "Iteration 78, loss = 774.02083071\n",
      "Iteration 45, loss = 2334.22787033\n",
      "Iteration 32, loss = 3074.76576294\n",
      "Iteration 52, loss = 2036.74256831\n",
      "Iteration 64, loss = 1630.41010570\n",
      "Iteration 65, loss = 1797.07241289\n",
      "Iteration 60, loss = 1888.66903451\n",
      "Iteration 69, loss = 1686.79559401\n",
      "Iteration 79, loss = 812.04954403\n",
      "Iteration 46, loss = 2291.36643258\n",
      "Iteration 66, loss = 1777.23644084\n",
      "Iteration 33, loss = 2997.42595021\n",
      "Iteration 65, loss = 1610.27140805\n",
      "Iteration 80, loss = 786.95931713\n",
      "Iteration 53, loss = 2004.39445636\n",
      "Iteration 47, loss = 2250.66383956\n",
      "Iteration 70, loss = 1669.81334023\n",
      "Iteration 61, loss = 1863.52586995\n",
      "Iteration 34, loss = 2923.61900191\n",
      "Iteration 67, loss = 1758.18576976\n",
      "Iteration 66, loss = 1591.35397465\n",
      "Iteration 54, loss = 1973.84295013\n",
      "Iteration 81, loss = 792.54555651\n",
      "Iteration 71, loss = 1654.09956154\n",
      "Iteration 48, loss = 2211.21086738\n",
      "Iteration 62, loss = 1838.87740271\n",
      "Iteration 35, loss = 2854.29032267\n",
      "Iteration 68, loss = 1738.83411829\n",
      "Iteration 82, loss = 787.37910242\n",
      "Iteration 49, loss = 2173.18884794\n",
      "Iteration 55, loss = 1944.26933216\n",
      "Iteration 67, loss = 1572.19629991\n",
      "Iteration 72, loss = 1637.67081107\n",
      "Iteration 63, loss = 1815.39048576\n",
      "Iteration 36, loss = 2786.95550568\n",
      "Iteration 69, loss = 1719.80273634\n",
      "Iteration 83, loss = 784.76411214\n",
      "Iteration 56, loss = 1914.81564794\n",
      "Iteration 50, loss = 2137.89294126\n",
      "Iteration 73, loss = 1622.28616323\n",
      "Iteration 68, loss = 1554.79347719\n",
      "Iteration 64, loss = 1793.07578851\n",
      "Iteration 37, loss = 2721.61423568\n",
      "Iteration 70, loss = 1702.64137778\n",
      "Iteration 57, loss = 1887.74905146\n",
      "Iteration 51, loss = 2103.40023006\n",
      "Iteration 84, loss = 782.36679923\n",
      "Iteration 69, loss = 1536.32939587\n",
      "Iteration 74, loss = 1607.78141090\n",
      "Iteration 38, loss = 2660.05712824\n",
      "Iteration 65, loss = 1771.53986635\n",
      "Iteration 71, loss = 1685.96545333\n",
      "Iteration 52, loss = 2071.17352664\n",
      "Iteration 85, loss = 769.04683893\n",
      "Iteration 58, loss = 1861.43423264\n",
      "Iteration 39, loss = 2600.28216371\n",
      "Iteration 75, loss = 1593.57496077\n",
      "Iteration 70, loss = 1519.67495403\n",
      "Iteration 66, loss = 1751.15228423\n",
      "Iteration 72, loss = 1669.79541809\n",
      "Iteration 53, loss = 2039.60305157\n",
      "Iteration 86, loss = 797.24735405\n",
      "Iteration 40, loss = 2542.94860891\n",
      "Iteration 59, loss = 1835.00591577\n",
      "Iteration 71, loss = 1503.55759116\n",
      "Iteration 76, loss = 1577.88360847\n",
      "Iteration 67, loss = 1730.88640596\n",
      "Iteration 41, loss = 2487.30843283\n",
      "Iteration 73, loss = 1653.91486634\n",
      "Iteration 54, loss = 2009.63453333\n",
      "Iteration 87, loss = 798.31637645\n",
      "Iteration 60, loss = 1810.35376242\n",
      "Iteration 77, loss = 1564.20528314\n",
      "Iteration 72, loss = 1487.77258342\n",
      "Iteration 68, loss = 1711.78434826\n",
      "Iteration 42, loss = 2435.34243237\n",
      "Iteration 88, loss = 794.54243458\n",
      "Iteration 74, loss = 1639.23802537\n",
      "Iteration 55, loss = 1981.20970124\n",
      "Iteration 61, loss = 1786.13432428\n",
      "Iteration 69, loss = 1692.50056528\n",
      "Iteration 73, loss = 1472.46059190\n",
      "Iteration 43, loss = 2386.62074940\n",
      "Iteration 78, loss = 1548.94716542\n",
      "Iteration 56, loss = 1952.69026160\n",
      "Iteration 75, loss = 1624.78074960\n",
      "Iteration 89, loss = 785.00533559\n",
      "Iteration 62, loss = 1762.45323887\n",
      "Iteration 44, loss = 2338.42807439\n",
      "Iteration 74, loss = 1457.56276616\n",
      "Iteration 70, loss = 1675.06366322\n",
      "Iteration 79, loss = 1534.35861264\n",
      "Iteration 76, loss = 1608.68752905\n",
      "Iteration 57, loss = 1926.26017386\n",
      "Iteration 90, loss = 803.14368332\n",
      "Iteration 63, loss = 1740.14789598\n",
      "Iteration 45, loss = 2293.69325645\n",
      "Iteration 75, loss = 1443.73364438\n",
      "Iteration 71, loss = 1657.63998156\n",
      "Iteration 80, loss = 1521.46345397\n",
      "Iteration 77, loss = 1593.76027538\n",
      "Iteration 58, loss = 1900.98741963\n",
      "Iteration 64, loss = 1718.89351448\n",
      "Iteration 91, loss = 800.28318968\n",
      "Iteration 46, loss = 2251.39879591\n",
      "Iteration 72, loss = 1640.93787327\n",
      "Iteration 81, loss = 1508.39593852\n",
      "Iteration 76, loss = 1429.61663302\n",
      "Iteration 59, loss = 1874.87966069\n",
      "Iteration 78, loss = 1578.60032775\n",
      "Iteration 65, loss = 1697.63205077\n",
      "Iteration 92, loss = 777.52582908\n",
      "Iteration 47, loss = 2210.80184071\n",
      "Iteration 73, loss = 1624.46178252\n",
      "Iteration 82, loss = 1494.71120063\n",
      "Iteration 77, loss = 1416.71744895\n",
      "Iteration 60, loss = 1850.93415378\n",
      "Iteration 79, loss = 1564.50398083\n",
      "Iteration 66, loss = 1678.02153509\n",
      "Iteration 93, loss = 784.52843660\n",
      "Iteration 48, loss = 2172.66125941\n",
      "Iteration 83, loss = 1482.76161799\n",
      "Iteration 74, loss = 1608.03937298\n",
      "Iteration 78, loss = 1404.31054554\n",
      "Iteration 61, loss = 1826.72675854\n",
      "Iteration 94, loss = 792.11286676\n",
      "Iteration 80, loss = 1551.16872377\n",
      "Iteration 67, loss = 1657.42525574\n",
      "Iteration 49, loss = 2135.61686392\n",
      "Iteration 75, loss = 1592.61047896\n",
      "Iteration 79, loss = 1391.62350114\n",
      "Iteration 84, loss = 1469.76909502\n",
      "Iteration 81, loss = 1538.29477994\n",
      "Iteration 62, loss = 1803.24387371\n",
      "Iteration 68, loss = 1638.23210696\n",
      "Iteration 95, loss = 787.70132529\n",
      "Iteration 50, loss = 2100.75472052\n",
      "Iteration 76, loss = 1576.27676900\n",
      "Iteration 80, loss = 1379.00522352\n",
      "Iteration 63, loss = 1780.85139318\n",
      "Iteration 85, loss = 1459.64466174\n",
      "Iteration 82, loss = 1524.69599523\n",
      "Iteration 96, loss = 768.41171436\n",
      "Iteration 69, loss = 1619.03936510\n",
      "Iteration 51, loss = 2067.13341849\n",
      "Iteration 81, loss = 1367.21647431\n",
      "Iteration 77, loss = 1561.33989251\n",
      "Iteration 64, loss = 1759.70711287\n",
      "Iteration 86, loss = 1448.09492714\n",
      "Iteration 83, loss = 1512.81655191\n",
      "Iteration 70, loss = 1600.98639910\n",
      "Iteration 97, loss = 789.95412185\n",
      "Iteration 82, loss = 1354.75190933\n",
      "Iteration 52, loss = 2035.06333995\n",
      "Iteration 78, loss = 1546.21742976\n",
      "Iteration 65, loss = 1739.07728720\n",
      "Iteration 87, loss = 1436.09493233\n",
      "Iteration 84, loss = 1499.70855556\n",
      "Iteration 71, loss = 1583.33804120\n",
      "Iteration 83, loss = 1344.06081038\n",
      "Iteration 79, loss = 1531.85145163\n",
      "Iteration 98, loss = 784.35021479\n",
      "Iteration 53, loss = 2004.59256911\n",
      "Iteration 66, loss = 1719.84808180\n",
      "Iteration 72, loss = 1567.07022633\n",
      "Iteration 88, loss = 1425.83057848\n",
      "Iteration 85, loss = 1488.04996897\n",
      "Iteration 84, loss = 1332.76214921\n",
      "Iteration 80, loss = 1517.37207380\n",
      "Iteration 54, loss = 1975.70905761\n",
      "Iteration 99, loss = 782.06082247\n",
      "Iteration 73, loss = 1550.14231641\n",
      "Iteration 67, loss = 1699.68783627\n",
      "Iteration 89, loss = 1416.57055985\n",
      "Iteration 86, loss = 1475.89204791\n",
      "Iteration 85, loss = 1322.96242239\n",
      "Iteration 81, loss = 1503.67829028\n",
      "Iteration 55, loss = 1948.13311072\n",
      "Iteration 100, loss = 784.21903009\n",
      "Iteration 74, loss = 1534.01154116\n",
      "Iteration 90, loss = 1406.58147664\n",
      "Iteration 68, loss = 1681.39049810\n",
      "Iteration 87, loss = 1463.46713611\n",
      "Iteration 56, loss = 1920.87158065\n",
      "Iteration 86, loss = 1311.39459580\n",
      "Iteration 82, loss = 1489.53860055\n",
      "Iteration 75, loss = 1518.35198966\n",
      "Iteration 91, loss = 1395.79967171\n",
      "Iteration 101, loss = 766.05974010\n",
      "Iteration 88, loss = 1452.23681584\n",
      "Iteration 69, loss = 1663.12309425\n",
      "Iteration 87, loss = 1301.13951959\n",
      "Iteration 57, loss = 1894.70527603\n",
      "Iteration 83, loss = 1476.50003241\n",
      "Iteration 76, loss = 1503.36678391\n",
      "Iteration 92, loss = 1387.05886921\n",
      "Iteration 102, loss = 783.22216887\n",
      "Iteration 89, loss = 1442.48226724\n",
      "Iteration 70, loss = 1645.70626375\n",
      "Iteration 88, loss = 1292.28195868\n",
      "Iteration 58, loss = 1870.49932970\n",
      "Iteration 84, loss = 1464.17991172\n",
      "Iteration 77, loss = 1488.91307104\n",
      "Iteration 93, loss = 1377.03907222\n",
      "Iteration 103, loss = 781.19373391\n",
      "Iteration 59, loss = 1846.12609808\n",
      "Iteration 71, loss = 1629.08424272\n",
      "Iteration 90, loss = 1430.47141551\n",
      "Iteration 89, loss = 1282.25357012\n",
      "Iteration 85, loss = 1453.31076178\n",
      "Iteration 78, loss = 1475.27835976\n",
      "Iteration 94, loss = 1369.05105457\n",
      "Iteration 104, loss = 769.97902297\n",
      "Iteration 60, loss = 1823.75495690\n",
      "Iteration 91, loss = 1419.54479023\n",
      "Iteration 86, loss = 1440.64973064\n",
      "Iteration 72, loss = 1613.59433610\n",
      "Iteration 90, loss = 1273.58237453\n",
      "Iteration 79, loss = 1461.20192462\n",
      "Iteration 61, loss = 1801.22047215\n",
      "Iteration 95, loss = 1359.01353298\n",
      "Iteration 105, loss = 776.72132650\n",
      "Iteration 92, loss = 1410.85386087\n",
      "Iteration 73, loss = 1597.91664107\n",
      "Iteration 87, loss = 1429.81513067\n",
      "Iteration 91, loss = 1264.49296334\n",
      "Iteration 80, loss = 1447.98975999\n",
      "Iteration 62, loss = 1779.80574330\n",
      "Iteration 96, loss = 1350.33630531\n",
      "Iteration 106, loss = 779.87433390\n",
      "Iteration 93, loss = 1400.47870707\n",
      "Iteration 74, loss = 1582.19812761\n",
      "Iteration 88, loss = 1418.78598831\n",
      "Iteration 92, loss = 1255.33030979\n",
      "Iteration 63, loss = 1759.07807207\n",
      "Iteration 81, loss = 1433.68698194\n",
      "Iteration 97, loss = 1341.76798759\n",
      "Iteration 107, loss = 774.00224538\n",
      "Iteration 94, loss = 1391.93561911\n",
      "Iteration 75, loss = 1567.12018247\n",
      "Iteration 89, loss = 1407.48059110\n",
      "Iteration 93, loss = 1247.06881480\n",
      "Iteration 64, loss = 1739.33203977\n",
      "Iteration 98, loss = 1333.62477579\n",
      "Iteration 82, loss = 1419.95525518\n",
      "Iteration 108, loss = 767.76414715\n",
      "Iteration 76, loss = 1553.14744651\n",
      "Iteration 95, loss = 1382.52662249\n",
      "Iteration 90, loss = 1398.33080075\n",
      "Iteration 94, loss = 1238.47872106\n",
      "Iteration 65, loss = 1719.46660810\n",
      "Iteration 83, loss = 1406.81284667\n",
      "Iteration 99, loss = 1325.63608066\n",
      "Iteration 109, loss = 769.02081697\n",
      "Iteration 77, loss = 1538.37874855\n",
      "Iteration 96, loss = 1372.64493342\n",
      "Iteration 91, loss = 1388.03882473\n",
      "Iteration 95, loss = 1229.87102443\n",
      "Iteration 66, loss = 1701.52199884\n",
      "Iteration 100, loss = 1318.15835928\n",
      "Iteration 84, loss = 1395.30695025\n",
      "Iteration 78, loss = 1525.99852586\n",
      "Iteration 110, loss = 780.48402247\n",
      "Iteration 97, loss = 1363.27275325\n",
      "Iteration 92, loss = 1377.15623001\n",
      "Iteration 96, loss = 1222.14572326\n",
      "Iteration 67, loss = 1682.36610969\n",
      "Iteration 85, loss = 1384.20719340\n",
      "Iteration 101, loss = 1311.58271924\n",
      "Iteration 79, loss = 1512.11493766\n",
      "Iteration 111, loss = 774.07863795\n",
      "Iteration 98, loss = 1354.27717861\n",
      "Iteration 93, loss = 1368.20211898\n",
      "Iteration 68, loss = 1664.79693832\n",
      "Iteration 97, loss = 1213.78955710\n",
      "Iteration 86, loss = 1371.97101394\n",
      "Iteration 102, loss = 1303.49059002\n",
      "Iteration 80, loss = 1498.80267059\n",
      "Iteration 112, loss = 782.66268118\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 94, loss = 1359.11550823\n",
      "Iteration 99, loss = 1345.24264606\n",
      "Iteration 69, loss = 1647.66278627\n",
      "Iteration 87, loss = 1361.61899457\n",
      "Iteration 98, loss = 1205.08976731\n",
      "Iteration 103, loss = 1296.22472459\n",
      "Iteration 81, loss = 1485.46382641\n",
      "Iteration 100, loss = 1335.54311397\n",
      "Iteration 95, loss = 1349.09786599\n",
      "Iteration 1, loss = 11482.34343093\n",
      "Iteration 88, loss = 1349.87754554\n",
      "Iteration 70, loss = 1631.09706119\n",
      "Iteration 99, loss = 1198.92739218\n",
      "Iteration 82, loss = 1472.19984746\n",
      "Iteration 104, loss = 1289.95369060\n",
      "Iteration 96, loss = 1340.05167449\n",
      "Iteration 101, loss = 1329.77847515\n",
      "Iteration 89, loss = 1339.10790970\n",
      "Iteration 71, loss = 1615.60182764\n",
      "Iteration 2, loss = 10254.70132698\n",
      "Iteration 100, loss = 1192.51056861\n",
      "Iteration 83, loss = 1459.89348974\n",
      "Iteration 105, loss = 1283.47082541\n",
      "Iteration 3, loss = 9583.40069511\n",
      "Iteration 90, loss = 1329.66133582\n",
      "Iteration 102, loss = 1320.73968995\n",
      "Iteration 72, loss = 1600.91314790\n",
      "Iteration 97, loss = 1330.52575587\n",
      "Iteration 101, loss = 1184.54637040\n",
      "Iteration 84, loss = 1447.91246298\n",
      "Iteration 91, loss = 1318.81695451\n",
      "Iteration 4, loss = 8956.19925336\n",
      "Iteration 106, loss = 1277.04663295\n",
      "Iteration 102, loss = 1178.13420568\n",
      "Iteration 73, loss = 1586.09054811\n",
      "Iteration 103, loss = 1313.29057896\n",
      "Iteration 98, loss = 1320.39660787\n",
      "Iteration 92, loss = 1308.90475303\n",
      "Iteration 107, loss = 1269.77484699\n",
      "Iteration 85, loss = 1436.83432316\n",
      "Iteration 5, loss = 8396.53333942\n",
      "Iteration 74, loss = 1571.53006980\n",
      "Iteration 104, loss = 1306.40565515\n",
      "Iteration 103, loss = 1172.43215950\n",
      "Iteration 86, loss = 1424.93435247\n",
      "Iteration 99, loss = 1312.72546485\n",
      "Iteration 93, loss = 1300.26178533\n",
      "Iteration 75, loss = 1557.10397293\n",
      "Iteration 108, loss = 1264.02540368\n",
      "Iteration 105, loss = 1298.58359854\n",
      "Iteration 6, loss = 7917.41734632\n",
      "Iteration 104, loss = 1165.78919212\n",
      "Iteration 87, loss = 1414.61141755\n",
      "Iteration 76, loss = 1543.24426685\n",
      "Iteration 94, loss = 1291.36546886\n",
      "Iteration 100, loss = 1304.53142265\n",
      "Iteration 109, loss = 1257.95862781\n",
      "Iteration 106, loss = 1291.76395381\n",
      "Iteration 7, loss = 7498.07230053\n",
      "Iteration 105, loss = 1158.81546348\n",
      "Iteration 110, loss = 1251.30876746\n",
      "Iteration 88, loss = 1402.80568681\n",
      "Iteration 77, loss = 1529.53557534\n",
      "Iteration 107, loss = 1284.75727264\n",
      "Iteration 101, loss = 1296.77345964\n",
      "Iteration 95, loss = 1282.01581522\n",
      "Iteration 8, loss = 7124.36499722\n",
      "Iteration 106, loss = 1153.59612907\n",
      "Iteration 111, loss = 1244.31547681\n",
      "Iteration 89, loss = 1392.60860313\n",
      "Iteration 108, loss = 1277.88519414\n",
      "Iteration 78, loss = 1517.09189890\n",
      "Iteration 102, loss = 1288.14003067\n",
      "Iteration 96, loss = 1273.76929948\n",
      "Iteration 9, loss = 6790.70281577\n",
      "Iteration 107, loss = 1146.06805002\n",
      "Iteration 109, loss = 1271.11710053\n",
      "Iteration 112, loss = 1238.03142550\n",
      "Iteration 90, loss = 1383.48048110\n",
      "Iteration 103, loss = 1280.30896325\n",
      "Iteration 79, loss = 1504.21342187\n",
      "Iteration 97, loss = 1264.75634743\n",
      "Iteration 10, loss = 6484.12696784\n",
      "Iteration 108, loss = 1141.11421075\n",
      "Iteration 110, loss = 1263.47574630\n",
      "Iteration 91, loss = 1372.72117342\n",
      "Iteration 113, loss = 1233.65112281\n",
      "Iteration 104, loss = 1273.22227366\n",
      "Iteration 80, loss = 1490.78542569\n",
      "Iteration 98, loss = 1255.78060959\n",
      "Iteration 11, loss = 6198.66551507\n",
      "Iteration 109, loss = 1135.48143288\n",
      "Iteration 114, loss = 1227.00806004\n",
      "Iteration 105, loss = 1264.64577121\n",
      "Iteration 111, loss = 1256.77390236\n",
      "Iteration 92, loss = 1362.23613135\n",
      "Iteration 81, loss = 1477.64652556\n",
      "Iteration 99, loss = 1248.62326863\n",
      "Iteration 12, loss = 5932.49231324\n",
      "Iteration 110, loss = 1129.81037584\n",
      "Iteration 115, loss = 1220.75742502\n",
      "Iteration 106, loss = 1258.83566389\n",
      "Iteration 112, loss = 1249.37638237\n",
      "Iteration 82, loss = 1465.14248209\n",
      "Iteration 93, loss = 1353.95885015\n",
      "Iteration 13, loss = 5686.32980218\n",
      "Iteration 100, loss = 1241.20967953\n",
      "Iteration 111, loss = 1125.19490745\n",
      "Iteration 116, loss = 1215.83129469\n",
      "Iteration 107, loss = 1251.01537935\n",
      "Iteration 14, loss = 5458.89521366\n",
      "Iteration 113, loss = 1244.01570895\n",
      "Iteration 94, loss = 1344.52269924\n",
      "Iteration 83, loss = 1453.04690096\n",
      "Iteration 101, loss = 1233.65922092\n",
      "Iteration 112, loss = 1119.51347142\n",
      "Iteration 117, loss = 1211.31683811\n",
      "Iteration 108, loss = 1244.78388188\n",
      "Iteration 15, loss = 5248.29068318\n",
      "Iteration 114, loss = 1237.36437230\n",
      "Iteration 84, loss = 1441.19041834\n",
      "Iteration 95, loss = 1335.23234321\n",
      "Iteration 102, loss = 1225.92120909\n",
      "Iteration 113, loss = 1114.52795025\n",
      "Iteration 109, loss = 1237.41246740\n",
      "Iteration 103, loss = 1219.05034133\n",
      "Iteration 85, loss = 1429.60427851\n",
      "Iteration 115, loss = 1230.52506390\n",
      "Iteration 16, loss = 5053.51417481\n",
      "Iteration 118, loss = 1205.14197115\n",
      "Iteration 96, loss = 1327.24691519\n",
      "Iteration 114, loss = 1109.15956979\n",
      "Iteration 86, loss = 1418.76387277\n",
      "Iteration 104, loss = 1210.96536526\n",
      "Iteration 116, loss = 1224.60569663\n",
      "Iteration 17, loss = 4871.95426077\n",
      "Iteration 110, loss = 1231.36714781\n",
      "Iteration 119, loss = 1199.90233996\n",
      "Iteration 97, loss = 1318.02807965\n",
      "Iteration 115, loss = 1103.42717934\n",
      "Iteration 87, loss = 1407.88913751\n",
      "Iteration 18, loss = 4703.12572689\n",
      "Iteration 120, loss = 1196.21937399\n",
      "Iteration 105, loss = 1204.32793948\n",
      "Iteration 117, loss = 1219.04495177\n",
      "Iteration 111, loss = 1225.13532339\n",
      "Iteration 98, loss = 1309.89696383\n",
      "Iteration 116, loss = 1099.40391086Iteration 88, loss = 1397.16762126\n",
      "\n",
      "Iteration 19, loss = 4547.21042639\n",
      "Iteration 121, loss = 1190.30475868\n",
      "Iteration 106, loss = 1197.59730000\n",
      "Iteration 112, loss = 1218.61375942\n",
      "Iteration 118, loss = 1212.48581012\n",
      "Iteration 99, loss = 1302.25465555\n",
      "Iteration 89, loss = 1386.70077480\n",
      "Iteration 117, loss = 1093.38209274\n",
      "Iteration 107, loss = 1189.92561268\n",
      "Iteration 20, loss = 4399.30142207\n",
      "Iteration 122, loss = 1186.02681253\n",
      "Iteration 113, loss = 1213.69344696\n",
      "Iteration 119, loss = 1206.21485826\n",
      "Iteration 100, loss = 1295.69829298\n",
      "Iteration 90, loss = 1378.09600895\n",
      "Iteration 108, loss = 1184.12968575\n",
      "Iteration 118, loss = 1090.36151148\n",
      "Iteration 123, loss = 1181.64398782\n",
      "Iteration 114, loss = 1206.95539976\n",
      "Iteration 21, loss = 4261.28113197\n",
      "Iteration 120, loss = 1201.19991374\n",
      "Iteration 109, loss = 1176.98248149\n",
      "Iteration 91, loss = 1367.83178497\n",
      "Iteration 101, loss = 1287.30657386\n",
      "Iteration 119, loss = 1083.74129966\n",
      "Iteration 124, loss = 1176.37360292\n",
      "Iteration 115, loss = 1200.54481899\n",
      "Iteration 22, loss = 4131.17387587\n",
      "Iteration 121, loss = 1195.67368276\n",
      "Iteration 102, loss = 1280.41569950\n",
      "Iteration 110, loss = 1170.89461070\n",
      "Iteration 92, loss = 1357.60004435\n",
      "Iteration 120, loss = 1082.02330029\n",
      "Iteration 125, loss = 1172.16887023\n",
      "Iteration 116, loss = 1195.05081249\n",
      "Iteration 23, loss = 4008.06593768\n",
      "Iteration 122, loss = 1189.65718995\n",
      "Iteration 121, loss = 1075.73495761\n",
      "Iteration 93, loss = 1348.62850178\n",
      "Iteration 103, loss = 1273.39986339\n",
      "Iteration 111, loss = 1164.72712022\n",
      "Iteration 126, loss = 1165.36218277\n",
      "Iteration 24, loss = 3891.84348517\n",
      "Iteration 117, loss = 1189.35271074\n",
      "Iteration 122, loss = 1071.93097154\n",
      "Iteration 123, loss = 1185.76695585\n",
      "Iteration 104, loss = 1266.29637222\n",
      "Iteration 94, loss = 1339.93043022\n",
      "Iteration 112, loss = 1159.22373488\n",
      "Iteration 123, loss = 1067.83165251\n",
      "Iteration 118, loss = 1183.74467209\n",
      "Iteration 127, loss = 1164.89774312\n",
      "Iteration 25, loss = 3781.55020217\n",
      "Iteration 124, loss = 1178.61796312\n",
      "Iteration 105, loss = 1260.10869389\n",
      "Iteration 95, loss = 1330.54065905\n",
      "Iteration 113, loss = 1153.89049151\n",
      "Iteration 124, loss = 1063.36284574\n",
      "Iteration 128, loss = 1157.35758636\n",
      "Iteration 119, loss = 1177.47530696\n",
      "Iteration 125, loss = 1175.40033705\n",
      "Iteration 26, loss = 3676.42914170\n",
      "Iteration 106, loss = 1253.48394173\n",
      "Iteration 114, loss = 1147.10104285\n",
      "Iteration 96, loss = 1322.02693214\n",
      "Iteration 126, loss = 1168.47889362\n",
      "Iteration 129, loss = 1154.62550049\n",
      "Iteration 120, loss = 1175.49311487\n",
      "Iteration 125, loss = 1059.95698174\n",
      "Iteration 115, loss = 1142.35726720\n",
      "Iteration 27, loss = 3576.70761733\n",
      "Iteration 107, loss = 1246.29944995\n",
      "Iteration 97, loss = 1313.47526755\n",
      "Iteration 121, loss = 1168.10794326\n",
      "Iteration 130, loss = 1151.14704752\n",
      "Iteration 127, loss = 1166.50555345\n",
      "Iteration 126, loss = 1055.05348152\n",
      "Iteration 28, loss = 3481.85907844\n",
      "Iteration 116, loss = 1136.97260326\n",
      "Iteration 108, loss = 1240.26045223\n",
      "Iteration 98, loss = 1305.01851941\n",
      "Iteration 122, loss = 1163.59171109\n",
      "Iteration 127, loss = 1051.17579653\n",
      "Iteration 131, loss = 1145.74714425\n",
      "Iteration 128, loss = 1158.13486783\n",
      "Iteration 29, loss = 3391.41824136\n",
      "Iteration 117, loss = 1131.36039155\n",
      "Iteration 109, loss = 1233.84493475\n",
      "Iteration 99, loss = 1297.16082579\n",
      "Iteration 123, loss = 1158.57522919\n",
      "Iteration 128, loss = 1045.45142890\n",
      "Iteration 132, loss = 1140.41711740\n",
      "Iteration 129, loss = 1155.31571352\n",
      "Iteration 118, loss = 1126.16970960\n",
      "Iteration 30, loss = 3304.77998463\n",
      "Iteration 110, loss = 1228.18772051\n",
      "Iteration 129, loss = 1042.61844362\n",
      "Iteration 100, loss = 1290.48595738\n",
      "Iteration 124, loss = 1153.24355286\n",
      "Iteration 133, loss = 1138.03023259\n",
      "Iteration 130, loss = 1150.93679675\n",
      "Iteration 31, loss = 3221.51573008\n",
      "Iteration 119, loss = 1119.87587115\n",
      "Iteration 111, loss = 1222.73918784\n",
      "Iteration 130, loss = 1038.88476340\n",
      "Iteration 101, loss = 1282.98695039\n",
      "Iteration 134, loss = 1134.15224712\n",
      "Iteration 125, loss = 1148.68432140\n",
      "Iteration 32, loss = 3141.72230424\n",
      "Iteration 120, loss = 1118.33295469\n",
      "Iteration 131, loss = 1143.90422779\n",
      "Iteration 112, loss = 1216.95876905\n",
      "Iteration 131, loss = 1036.23336035\n",
      "Iteration 102, loss = 1275.22859511\n",
      "Iteration 135, loss = 1130.65438810\n",
      "Iteration 126, loss = 1143.57214471\n",
      "Iteration 121, loss = 1110.98987925\n",
      "Iteration 33, loss = 3064.85303611\n",
      "Iteration 132, loss = 1032.32730517\n",
      "Iteration 132, loss = 1140.00120051\n",
      "Iteration 113, loss = 1211.41874917\n",
      "Iteration 103, loss = 1268.60017998\n",
      "Iteration 122, loss = 1107.20174998\n",
      "Iteration 136, loss = 1125.92638780\n",
      "Iteration 127, loss = 1139.59011264\n",
      "Iteration 34, loss = 2991.15355484\n",
      "Iteration 133, loss = 1027.98002862\n",
      "Iteration 133, loss = 1135.71399649\n",
      "Iteration 114, loss = 1205.39154185\n",
      "Iteration 104, loss = 1261.40191197\n",
      "Iteration 123, loss = 1102.34499785\n",
      "Iteration 128, loss = 1134.29370643\n",
      "Iteration 137, loss = 1121.05353948\n",
      "Iteration 134, loss = 1023.56350549\n",
      "Iteration 35, loss = 2921.24311326\n",
      "Iteration 134, loss = 1130.32888370\n",
      "Iteration 115, loss = 1199.74360890\n",
      "Iteration 124, loss = 1096.82903423\n",
      "Iteration 138, loss = 1118.99422506\n",
      "Iteration 129, loss = 1129.98309022\n",
      "Iteration 105, loss = 1255.26901765\n",
      "Iteration 135, loss = 1125.94605801\n",
      "Iteration 36, loss = 2853.49789157\n",
      "Iteration 135, loss = 1021.66712449\n",
      "Iteration 116, loss = 1193.89411013\n",
      "Iteration 139, loss = 1114.95842426\n",
      "Iteration 125, loss = 1092.42504535\n",
      "Iteration 136, loss = 1121.09851105\n",
      "Iteration 130, loss = 1126.20495619\n",
      "Iteration 37, loss = 2788.76228144\n",
      "Iteration 106, loss = 1248.61062314\n",
      "Iteration 136, loss = 1018.16393383\n",
      "Iteration 140, loss = 1111.64464446\n",
      "Iteration 117, loss = 1187.19995585\n",
      "Iteration 126, loss = 1087.65863962\n",
      "Iteration 137, loss = 1114.78978212\n",
      "Iteration 131, loss = 1123.38754068\n",
      "Iteration 38, loss = 2727.39724043\n",
      "Iteration 107, loss = 1241.38583292\n",
      "Iteration 137, loss = 1014.18472601\n",
      "Iteration 138, loss = 1112.81163925\n",
      "Iteration 141, loss = 1107.64352800\n",
      "Iteration 127, loss = 1083.45308351\n",
      "Iteration 118, loss = 1181.93866416\n",
      "Iteration 132, loss = 1119.19633255\n",
      "Iteration 39, loss = 2667.41815684\n",
      "Iteration 138, loss = 1010.53827540\n",
      "Iteration 108, loss = 1235.26712901\n",
      "Iteration 119, loss = 1174.83328231\n",
      "Iteration 139, loss = 1107.85234608\n",
      "Iteration 128, loss = 1078.59057509\n",
      "Iteration 142, loss = 1104.08504532\n",
      "Iteration 133, loss = 1113.65245791\n",
      "Iteration 40, loss = 2609.73584581\n",
      "Iteration 139, loss = 1009.07243895\n",
      "Iteration 109, loss = 1229.09375930\n",
      "Iteration 129, loss = 1074.66551187\n",
      "Iteration 143, loss = 1100.76244393\n",
      "Iteration 140, loss = 1104.10569110\n",
      "Iteration 41, loss = 2554.01953763\n",
      "Iteration 134, loss = 1110.00273674\n",
      "Iteration 140, loss = 1006.60843901\n",
      "Iteration 110, loss = 1223.71208551\n",
      "Iteration 120, loss = 1172.76933058\n",
      "Iteration 130, loss = 1070.38840385\n",
      "Iteration 144, loss = 1097.24323068\n",
      "Iteration 141, loss = 1099.72272864\n",
      "Iteration 135, loss = 1106.25716363\n",
      "Iteration 42, loss = 2502.31019893\n",
      "Iteration 111, loss = 1217.73718282\n",
      "Iteration 141, loss = 1001.45596033\n",
      "Iteration 145, loss = 1093.59327449\n",
      "Iteration 131, loss = 1065.75056066\n",
      "Iteration 142, loss = 1095.33320274\n",
      "Iteration 121, loss = 1165.82824074\n",
      "Iteration 136, loss = 1103.32855277\n",
      "Iteration 43, loss = 2453.77171374\n",
      "Iteration 142, loss = 997.06986717\n",
      "Iteration 112, loss = 1211.92713667\n",
      "Iteration 132, loss = 1063.00784526\n",
      "Iteration 122, loss = 1162.05798612\n",
      "Iteration 146, loss = 1090.39136547\n",
      "Iteration 143, loss = 1091.76227808\n",
      "Iteration 137, loss = 1100.35869064\n",
      "Iteration 143, loss = 996.08326958\n",
      "Iteration 44, loss = 2406.52210477\n",
      "Iteration 133, loss = 1056.64235687\n",
      "Iteration 113, loss = 1206.50158028\n",
      "Iteration 147, loss = 1087.48337168\n",
      "Iteration 144, loss = 1087.81192481\n",
      "Iteration 123, loss = 1157.50567348\n",
      "Iteration 138, loss = 1094.95993293\n",
      "Iteration 144, loss = 991.62164462\n",
      "Iteration 45, loss = 2362.09347866\n",
      "Iteration 134, loss = 1053.95991763\n",
      "Iteration 114, loss = 1201.14970801\n",
      "Iteration 148, loss = 1083.25766245\n",
      "Iteration 135, loss = 1049.62835947\n",
      "Iteration 139, loss = 1094.37466865\n",
      "Iteration 145, loss = 1084.81047857\n",
      "Iteration 145, loss = 988.48493970\n",
      "Iteration 124, loss = 1152.49064890\n",
      "Iteration 46, loss = 2319.74239609\n",
      "Iteration 115, loss = 1195.92623310\n",
      "Iteration 149, loss = 1082.93459148\n",
      "Iteration 136, loss = 1046.50267555\n",
      "Iteration 47, loss = 2279.50701622\n",
      "Iteration 140, loss = 1091.15787560\n",
      "Iteration 146, loss = 1081.05632105\n",
      "Iteration 146, loss = 986.11669915\n",
      "Iteration 125, loss = 1148.33510465\n",
      "Iteration 116, loss = 1190.59446795\n",
      "Iteration 150, loss = 1077.43347090\n",
      "Iteration 137, loss = 1042.64415422\n",
      "Iteration 48, loss = 2240.84395838\n",
      "Iteration 141, loss = 1086.83617431\n",
      "Iteration 147, loss = 1078.09512404\n",
      "Iteration 147, loss = 981.95300649\n",
      "Iteration 126, loss = 1143.41639269\n",
      "Iteration 148, loss = 1074.87037306\n",
      "Iteration 49, loss = 2202.94457076\n",
      "Iteration 151, loss = 1074.79360802\n",
      "Iteration 142, loss = 1081.91173668\n",
      "Iteration 117, loss = 1185.06233276\n",
      "Iteration 138, loss = 1037.86310324\n",
      "Iteration 148, loss = 982.22088806\n",
      "Iteration 127, loss = 1139.94836010\n",
      "Iteration 50, loss = 2167.18068300\n",
      "Iteration 149, loss = 1072.06497901\n",
      "Iteration 152, loss = 1071.44195879\n",
      "Iteration 118, loss = 1180.22293624\n",
      "Iteration 139, loss = 1036.76763795\n",
      "Iteration 143, loss = 1081.98588370\n",
      "Iteration 128, loss = 1135.96639999\n",
      "Iteration 149, loss = 977.17962288\n",
      "Iteration 150, loss = 1066.14791120\n",
      "Iteration 51, loss = 2132.88005129\n",
      "Iteration 140, loss = 1032.82707917\n",
      "Iteration 153, loss = 1069.20610997\n",
      "Iteration 119, loss = 1175.36275529\n",
      "Iteration 144, loss = 1076.90124844\n",
      "Iteration 129, loss = 1131.93880869\n",
      "Iteration 150, loss = 974.75576920\n",
      "Iteration 151, loss = 1064.76486263\n",
      "Iteration 52, loss = 2099.52152465\n",
      "Iteration 141, loss = 1027.55144808\n",
      "Iteration 154, loss = 1064.80106259\n",
      "Iteration 120, loss = 1171.98788866\n",
      "Iteration 145, loss = 1075.58221232\n",
      "Iteration 130, loss = 1127.23480792\n",
      "Iteration 151, loss = 972.45223695\n",
      "Iteration 53, loss = 2067.71890370\n",
      "Iteration 152, loss = 1061.55720556\n",
      "Iteration 142, loss = 1022.76534430\n",
      "Iteration 155, loss = 1062.28794166\n",
      "Iteration 121, loss = 1166.64643587\n",
      "Iteration 131, loss = 1122.62575978\n",
      "Iteration 146, loss = 1072.89236306\n",
      "Iteration 152, loss = 969.49951036\n",
      "Iteration 54, loss = 2038.21182149\n",
      "Iteration 153, loss = 1058.50407635\n",
      "Iteration 156, loss = 1059.77422080\n",
      "Iteration 132, loss = 1118.94761905\n",
      "Iteration 147, loss = 1069.66011979\n",
      "Iteration 143, loss = 1021.68970435\n",
      "Iteration 122, loss = 1162.57235328\n",
      "Iteration 153, loss = 966.35635460\n",
      "Iteration 55, loss = 2009.42887338\n",
      "Iteration 154, loss = 1054.93152181\n",
      "Iteration 157, loss = 1057.13502082\n",
      "Iteration 148, loss = 1067.96191849\n",
      "Iteration 123, loss = 1157.61203175\n",
      "Iteration 133, loss = 1112.35419085\n",
      "Iteration 144, loss = 1017.19430841\n",
      "Iteration 154, loss = 964.44637140\n",
      "Iteration 56, loss = 1981.03549472\n",
      "Iteration 155, loss = 1051.38595317\n",
      "Iteration 158, loss = 1051.32378479\n",
      "Iteration 149, loss = 1065.09073788\n",
      "Iteration 124, loss = 1152.40831054\n",
      "Iteration 145, loss = 1015.03511169\n",
      "Iteration 134, loss = 1110.07708608\n",
      "Iteration 155, loss = 961.67202176\n",
      "Iteration 57, loss = 1954.37689952\n",
      "Iteration 156, loss = 1048.60448978\n",
      "Iteration 159, loss = 1051.75274111\n",
      "Iteration 150, loss = 1061.97671270\n",
      "Iteration 146, loss = 1011.76469577\n",
      "Iteration 156, loss = 958.90613080\n",
      "Iteration 135, loss = 1105.54806399\n",
      "Iteration 125, loss = 1147.36137314\n",
      "Iteration 58, loss = 1928.77885517\n",
      "Iteration 160, loss = 1049.88766963\n",
      "Iteration 157, loss = 1045.68542297\n",
      "Iteration 151, loss = 1059.91841092\n",
      "Iteration 136, loss = 1102.08150937\n",
      "Iteration 147, loss = 1008.57977993\n",
      "Iteration 126, loss = 1140.99795529\n",
      "Iteration 59, loss = 1904.12868103\n",
      "Iteration 157, loss = 955.70083462\n",
      "Iteration 161, loss = 1046.93963432\n",
      "Iteration 148, loss = 1005.61344463\n",
      "Iteration 158, loss = 1038.98100638\n",
      "Iteration 152, loss = 1056.10345928\n",
      "Iteration 127, loss = 1136.98487856\n",
      "Iteration 137, loss = 1098.10308074\n",
      "Iteration 60, loss = 1880.08165889\n",
      "Iteration 162, loss = 1044.26813713\n",
      "Iteration 158, loss = 952.32005466\n",
      "Iteration 149, loss = 1001.68317862\n",
      "Iteration 153, loss = 1053.79459689\n",
      "Iteration 138, loss = 1093.96364912\n",
      "Iteration 128, loss = 1133.33016056\n",
      "Iteration 61, loss = 1856.30052012\n",
      "Iteration 159, loss = 1040.09649326\n",
      "Iteration 159, loss = 950.10565542\n",
      "Iteration 163, loss = 1041.92431569\n",
      "Iteration 150, loss = 999.60157798\n",
      "Iteration 62, loss = 1833.71557108\n",
      "Iteration 139, loss = 1092.72169651\n",
      "Iteration 129, loss = 1129.34224710\n",
      "Iteration 154, loss = 1052.88558034\n",
      "Iteration 160, loss = 1037.03437508\n",
      "Iteration 160, loss = 946.86140325\n",
      "Iteration 164, loss = 1037.77099618\n",
      "Iteration 140, loss = 1089.37476457\n",
      "Iteration 151, loss = 996.51551759\n",
      "Iteration 63, loss = 1811.61417760\n",
      "Iteration 155, loss = 1050.29077582\n",
      "Iteration 130, loss = 1124.16915761\n",
      "Iteration 161, loss = 1035.16147886\n",
      "Iteration 161, loss = 943.81768448\n",
      "Iteration 165, loss = 1037.40812972\n",
      "Iteration 141, loss = 1083.98468527\n",
      "Iteration 152, loss = 992.42286180\n",
      "Iteration 64, loss = 1790.98342761\n",
      "Iteration 131, loss = 1120.86224421\n",
      "Iteration 156, loss = 1047.39916254\n",
      "Iteration 162, loss = 1031.22555777\n",
      "Iteration 162, loss = 943.21262103\n",
      "Iteration 166, loss = 1035.65232003\n",
      "Iteration 153, loss = 991.09122669\n",
      "Iteration 142, loss = 1078.63183126\n",
      "Iteration 65, loss = 1770.87189457\n",
      "Iteration 132, loss = 1116.79790952\n",
      "Iteration 163, loss = 1029.86901707\n",
      "Iteration 157, loss = 1046.45748919\n",
      "Iteration 163, loss = 939.67523520\n",
      "Iteration 167, loss = 1032.59102173\n",
      "Iteration 66, loss = 1751.91959587\n",
      "Iteration 143, loss = 1078.43181464\n",
      "Iteration 154, loss = 987.81989472\n",
      "Iteration 133, loss = 1111.03742452\n",
      "Iteration 158, loss = 1043.01167464\n",
      "Iteration 164, loss = 1025.33689302\n",
      "Iteration 168, loss = 1031.37354031\n",
      "Iteration 67, loss = 1732.65296131\n",
      "Iteration 164, loss = 939.69097750\n",
      "Iteration 144, loss = 1071.72790677\n",
      "Iteration 155, loss = 985.55418289\n",
      "Iteration 134, loss = 1108.38554732\n",
      "Iteration 159, loss = 1041.63001614\n",
      "Iteration 165, loss = 1025.03554306\n",
      "Iteration 68, loss = 1714.51596921\n",
      "Iteration 165, loss = 935.12562432\n",
      "Iteration 169, loss = 1029.83672129\n",
      "Iteration 145, loss = 1069.14749743\n",
      "Iteration 135, loss = 1104.50609859\n",
      "Iteration 156, loss = 982.61650886\n",
      "Iteration 166, loss = 1021.78896930\n",
      "Iteration 160, loss = 1038.67650089\n",
      "Iteration 166, loss = 934.57740025\n",
      "Iteration 69, loss = 1695.89188200\n",
      "Iteration 170, loss = 1027.48441899\n",
      "Iteration 146, loss = 1065.15905014\n",
      "Iteration 136, loss = 1101.12408935\n",
      "Iteration 157, loss = 980.47307606\n",
      "Iteration 167, loss = 1019.46430584\n",
      "Iteration 161, loss = 1036.34620626\n",
      "Iteration 167, loss = 933.02627620\n",
      "Iteration 147, loss = 1063.04040824\n",
      "Iteration 70, loss = 1678.61399359\n",
      "Iteration 137, loss = 1096.83314620\n",
      "Iteration 158, loss = 976.92725153\n",
      "Iteration 171, loss = 1025.70531034\n",
      "Iteration 168, loss = 1017.34568469\n",
      "Iteration 162, loss = 1035.25831795\n",
      "Iteration 148, loss = 1059.10241194\n",
      "Iteration 168, loss = 930.21614890\n",
      "Iteration 159, loss = 976.39608961\n",
      "Iteration 138, loss = 1094.17302839\n",
      "Iteration 71, loss = 1662.14029537\n",
      "Iteration 172, loss = 1023.07724692\n",
      "Iteration 169, loss = 1016.81663013\n",
      "Iteration 149, loss = 1055.47957041\n",
      "Iteration 163, loss = 1031.06204294\n",
      "Iteration 169, loss = 929.25458836\n",
      "Iteration 139, loss = 1091.27051364\n",
      "Iteration 160, loss = 972.88883829\n",
      "Iteration 72, loss = 1646.58759353\n",
      "Iteration 173, loss = 1020.73571817\n",
      "Iteration 150, loss = 1053.21329645\n",
      "Iteration 170, loss = 1013.04461091\n",
      "Iteration 164, loss = 1031.88997977\n",
      "Iteration 73, loss = 1630.32758351\n",
      "Iteration 161, loss = 970.02825920\n",
      "Iteration 170, loss = 926.77262497\n",
      "Iteration 140, loss = 1088.66290465\n",
      "Iteration 174, loss = 1017.50083484\n",
      "Iteration 151, loss = 1050.25396446\n",
      "Iteration 165, loss = 1027.62160013\n",
      "Iteration 171, loss = 1011.81714443\n",
      "Iteration 74, loss = 1614.65138564\n",
      "Iteration 141, loss = 1083.54795398\n",
      "Iteration 162, loss = 967.67420972\n",
      "Iteration 175, loss = 1016.34698217\n",
      "Iteration 171, loss = 925.43733318\n",
      "Iteration 152, loss = 1047.17521595\n",
      "Iteration 172, loss = 1007.51345448\n",
      "Iteration 166, loss = 1026.51374873\n",
      "Iteration 176, loss = 1014.70610250\n",
      "Iteration 75, loss = 1598.84520641\n",
      "Iteration 163, loss = 964.18163161\n",
      "Iteration 142, loss = 1079.28173820\n",
      "Iteration 172, loss = 923.66873076\n",
      "Iteration 153, loss = 1045.40360954\n",
      "Iteration 167, loss = 1024.34408063\n",
      "Iteration 173, loss = 1007.36279510\n",
      "Iteration 76, loss = 1584.45259110\n",
      "Iteration 173, loss = 921.33813402\n",
      "Iteration 143, loss = 1079.68429447\n",
      "Iteration 164, loss = 964.61797528\n",
      "Iteration 177, loss = 1013.01413418\n",
      "Iteration 154, loss = 1043.25852453\n",
      "Iteration 168, loss = 1021.51517777\n",
      "Iteration 174, loss = 1003.82309860\n",
      "Iteration 144, loss = 1073.39707469\n",
      "Iteration 77, loss = 1569.41699359\n",
      "Iteration 174, loss = 919.78088763\n",
      "Iteration 165, loss = 960.41308033\n",
      "Iteration 178, loss = 1011.24590349\n",
      "Iteration 169, loss = 1018.09030089\n",
      "Iteration 145, loss = 1070.72878205\n",
      "Iteration 155, loss = 1040.13943405\n",
      "Iteration 175, loss = 918.28014348\n",
      "Iteration 175, loss = 1001.43568293\n",
      "Iteration 78, loss = 1556.49064291\n",
      "Iteration 166, loss = 958.25697200\n",
      "Iteration 179, loss = 1008.63458670\n",
      "Iteration 170, loss = 1015.48201254\n",
      "Iteration 167, loss = 957.19004887\n",
      "Iteration 156, loss = 1037.79218040\n",
      "Iteration 79, loss = 1542.72389339\n",
      "Iteration 176, loss = 915.04960365\n",
      "Iteration 146, loss = 1067.27899201\n",
      "Iteration 176, loss = 1000.11171190\n",
      "Iteration 180, loss = 1008.22082661\n",
      "Iteration 157, loss = 1036.34860231\n",
      "Iteration 171, loss = 1013.47105406\n",
      "Iteration 80, loss = 1528.38024065\n",
      "Iteration 168, loss = 955.31272589\n",
      "Iteration 177, loss = 914.78929560\n",
      "Iteration 147, loss = 1065.43785749\n",
      "Iteration 177, loss = 998.35880427\n",
      "Iteration 181, loss = 1005.44124996\n",
      "Iteration 158, loss = 1032.37228320\n",
      "Iteration 172, loss = 1009.75734815\n",
      "Iteration 81, loss = 1515.17938087\n",
      "Iteration 178, loss = 912.13357762\n",
      "Iteration 178, loss = 996.76642178\n",
      "Iteration 169, loss = 952.96655941\n",
      "Iteration 148, loss = 1062.13411452\n",
      "Iteration 182, loss = 1002.84521772\n",
      "Iteration 173, loss = 1008.53714490\n",
      "Iteration 159, loss = 1032.54363551\n",
      "Iteration 179, loss = 993.95120407\n",
      "Iteration 149, loss = 1058.12204401\n",
      "Iteration 82, loss = 1501.96666600\n",
      "Iteration 170, loss = 949.61610003\n",
      "Iteration 179, loss = 912.26253484\n",
      "Iteration 183, loss = 1000.99052012\n",
      "Iteration 174, loss = 1006.91168216\n",
      "Iteration 180, loss = 992.48630772\n",
      "Iteration 160, loss = 1029.01785508\n",
      "Iteration 171, loss = 949.73303605\n",
      "Iteration 180, loss = 910.59137055\n",
      "Iteration 150, loss = 1056.20692387\n",
      "Iteration 83, loss = 1489.29860527\n",
      "Iteration 184, loss = 999.51204707\n",
      "Iteration 161, loss = 1026.08328556\n",
      "Iteration 181, loss = 989.49486924\n",
      "Iteration 175, loss = 1004.30927144\n",
      "Iteration 172, loss = 946.86570657\n",
      "Iteration 181, loss = 907.75189991\n",
      "Iteration 84, loss = 1477.07149867\n",
      "Iteration 151, loss = 1052.35296108\n",
      "Iteration 185, loss = 999.67958190\n",
      "Iteration 182, loss = 986.78614725\n",
      "Iteration 176, loss = 1000.93600911\n",
      "Iteration 162, loss = 1023.47143890\n",
      "Iteration 85, loss = 1464.66904688\n",
      "Iteration 182, loss = 906.19071253\n",
      "Iteration 173, loss = 945.28495771\n",
      "Iteration 152, loss = 1049.42000688\n",
      "Iteration 186, loss = 996.45586739\n",
      "Iteration 183, loss = 985.62891652\n",
      "Iteration 163, loss = 1020.26305471\n",
      "Iteration 177, loss = 999.74886035\n",
      "Iteration 86, loss = 1453.69834402\n",
      "Iteration 183, loss = 905.25536182\n",
      "Iteration 174, loss = 944.56914959\n",
      "Iteration 153, loss = 1046.33919777\n",
      "Iteration 184, loss = 982.02795444\n",
      "Iteration 187, loss = 994.20966984\n",
      "Iteration 175, loss = 942.39996066\n",
      "Iteration 87, loss = 1441.67791784\n",
      "Iteration 178, loss = 997.96038309\n",
      "Iteration 164, loss = 1019.82029644\n",
      "Iteration 184, loss = 902.73194570\n",
      "Iteration 154, loss = 1042.07804443\n",
      "Iteration 176, loss = 938.81205080\n",
      "Iteration 188, loss = 993.00583298\n",
      "Iteration 185, loss = 982.72731998\n",
      "Iteration 88, loss = 1430.69161994\n",
      "Iteration 179, loss = 996.35919066\n",
      "Iteration 165, loss = 1016.99509613\n",
      "Iteration 185, loss = 902.01434434\n",
      "Iteration 155, loss = 1038.72843454\n",
      "Iteration 177, loss = 938.05999263\n",
      "Iteration 189, loss = 991.61742484\n",
      "Iteration 186, loss = 979.83419985\n",
      "Iteration 180, loss = 995.43904070\n",
      "Iteration 89, loss = 1420.66998871\n",
      "Iteration 166, loss = 1014.55966550\n",
      "Iteration 186, loss = 900.61670596\n",
      "Iteration 156, loss = 1035.42766235\n",
      "Iteration 178, loss = 935.72383215\n",
      "Iteration 187, loss = 976.84297523\n",
      "Iteration 190, loss = 990.84411568\n",
      "Iteration 90, loss = 1410.58058264\n",
      "Iteration 181, loss = 992.18514042\n",
      "Iteration 187, loss = 898.52426284\n",
      "Iteration 167, loss = 1012.31150045\n",
      "Iteration 157, loss = 1032.57171915\n",
      "Iteration 188, loss = 977.23704695\n",
      "Iteration 179, loss = 934.62224893\n",
      "Iteration 191, loss = 987.77674086\n",
      "Iteration 91, loss = 1400.32736125\n",
      "Iteration 182, loss = 991.00764344\n",
      "Iteration 168, loss = 1010.46107674\n",
      "Iteration 188, loss = 897.64135480\n",
      "Iteration 158, loss = 1029.40574480\n",
      "Iteration 180, loss = 933.91109841\n",
      "Iteration 192, loss = 986.58352352\n",
      "Iteration 189, loss = 974.71620363\n",
      "Iteration 92, loss = 1389.95962487\n",
      "Iteration 189, loss = 895.91043374\n",
      "Iteration 169, loss = 1009.74882865\n",
      "Iteration 183, loss = 989.07470714\n",
      "Iteration 181, loss = 930.84634548\n",
      "Iteration 193, loss = 983.80316303\n",
      "Iteration 159, loss = 1028.85044075\n",
      "Iteration 190, loss = 974.33790076\n",
      "Iteration 93, loss = 1381.12208649\n",
      "Iteration 170, loss = 1006.03175906\n",
      "Iteration 184, loss = 987.53302366\n",
      "Iteration 190, loss = 893.96266335\n",
      "Iteration 194, loss = 984.14393507\n",
      "Iteration 182, loss = 929.92894218\n",
      "Iteration 191, loss = 970.65256522\n",
      "Iteration 160, loss = 1024.29421435\n",
      "Iteration 94, loss = 1371.35554524\n",
      "Iteration 171, loss = 1005.97078463\n",
      "Iteration 185, loss = 985.22180240\n",
      "Iteration 191, loss = 894.41872379\n",
      "Iteration 195, loss = 980.07462119\n",
      "Iteration 161, loss = 1021.76708951\n",
      "Iteration 183, loss = 928.54542214\n",
      "Iteration 192, loss = 970.16955421\n",
      "Iteration 95, loss = 1361.26900196\n",
      "Iteration 172, loss = 1003.11916026\n",
      "Iteration 186, loss = 984.76876047\n",
      "Iteration 192, loss = 893.41404204\n",
      "Iteration 196, loss = 979.29785410\n",
      "Iteration 162, loss = 1018.79738040\n",
      "Iteration 193, loss = 967.67684837\n",
      "Iteration 184, loss = 926.59796711\n",
      "Iteration 173, loss = 1001.06911156\n",
      "Iteration 96, loss = 1351.55975646\n",
      "Iteration 187, loss = 982.68048863\n",
      "Iteration 193, loss = 891.51417427\n",
      "Iteration 163, loss = 1016.29453280\n",
      "Iteration 197, loss = 976.94987806\n",
      "Iteration 185, loss = 924.39901793\n",
      "Iteration 194, loss = 967.67950320\n",
      "Iteration 174, loss = 1000.13481421\n",
      "Iteration 97, loss = 1342.23297458\n",
      "Iteration 188, loss = 981.64495042\n",
      "Iteration 194, loss = 889.46360709\n",
      "Iteration 198, loss = 975.86821587\n",
      "Iteration 195, loss = 964.47102044\n",
      "Iteration 186, loss = 922.61276140\n",
      "Iteration 164, loss = 1016.04097169\n",
      "Iteration 175, loss = 997.69190426\n",
      "Iteration 98, loss = 1332.78118017\n",
      "Iteration 189, loss = 979.29487101\n",
      "Iteration 187, loss = 921.24903105\n",
      "Iteration 195, loss = 887.76003416\n",
      "Iteration 199, loss = 973.84630420\n",
      "Iteration 196, loss = 963.26244817\n",
      "Iteration 165, loss = 1012.51237403\n",
      "Iteration 176, loss = 994.02533713\n",
      "Iteration 190, loss = 978.57309241\n",
      "Iteration 99, loss = 1324.14048316\n",
      "Iteration 188, loss = 919.66328177\n",
      "Iteration 196, loss = 888.11812532\n",
      "Iteration 197, loss = 960.66191720\n",
      "Iteration 200, loss = 973.03439844\n",
      "Iteration 166, loss = 1009.79231526\n",
      "Iteration 100, loss = 1316.98518672\n",
      "Iteration 177, loss = 991.81563660\n",
      "Iteration 189, loss = 916.94436512\n",
      "Iteration 197, loss = 887.22988689\n",
      "Iteration 191, loss = 977.36160046\n",
      "Iteration 201, loss = 970.51058502\n",
      "Iteration 198, loss = 960.00644937\n",
      "Iteration 167, loss = 1007.14939358\n",
      "Iteration 101, loss = 1308.38715895\n",
      "Iteration 178, loss = 990.37461178\n",
      "Iteration 190, loss = 916.10213217\n",
      "Iteration 198, loss = 885.06298465\n",
      "Iteration 192, loss = 975.51095850\n",
      "Iteration 199, loss = 958.28949888\n",
      "Iteration 202, loss = 969.83506046\n",
      "Iteration 168, loss = 1006.37505351\n",
      "Iteration 102, loss = 1299.39973004\n",
      "Iteration 179, loss = 989.24244253\n",
      "Iteration 193, loss = 972.73138283\n",
      "Iteration 191, loss = 914.40043941\n",
      "Iteration 199, loss = 882.90355833\n",
      "Iteration 200, loss = 956.11406977\n",
      "Iteration 203, loss = 967.41025660\n",
      "Iteration 169, loss = 1005.21265733\n",
      "Iteration 103, loss = 1293.16059878\n",
      "Iteration 180, loss = 988.19354698\n",
      "Iteration 192, loss = 913.00259962\n",
      "Iteration 201, loss = 954.31666372\n",
      "Iteration 194, loss = 971.50145242\n",
      "Iteration 204, loss = 965.95595165\n",
      "Iteration 200, loss = 884.05238085\n",
      "Iteration 170, loss = 1000.64320969\n",
      "Iteration 181, loss = 985.40439301\n",
      "Iteration 104, loss = 1284.24153928\n",
      "Iteration 193, loss = 911.37268693\n",
      "Iteration 202, loss = 954.07644284\n",
      "Iteration 205, loss = 964.78293260\n",
      "Iteration 195, loss = 969.40234759\n",
      "Iteration 201, loss = 881.43238012\n",
      "Iteration 171, loss = 1001.03172208\n",
      "Iteration 182, loss = 983.29422794\n",
      "Iteration 105, loss = 1278.22651142\n",
      "Iteration 203, loss = 951.97836055\n",
      "Iteration 194, loss = 909.27572623\n",
      "Iteration 206, loss = 964.43423208\n",
      "Iteration 196, loss = 968.09147640\n",
      "Iteration 202, loss = 881.57827931\n",
      "Iteration 172, loss = 997.68851213\n",
      "Iteration 106, loss = 1270.37885602\n",
      "Iteration 183, loss = 983.90168035\n",
      "Iteration 197, loss = 967.97955102\n",
      "Iteration 204, loss = 950.26591614\n",
      "Iteration 195, loss = 906.78330342\n",
      "Iteration 207, loss = 963.83012106\n",
      "Iteration 203, loss = 881.78954567\n",
      "Iteration 173, loss = 995.49656099\n",
      "Iteration 107, loss = 1263.49687044\n",
      "Iteration 184, loss = 980.61491462\n",
      "Iteration 198, loss = 965.96433619\n",
      "Iteration 208, loss = 962.47268540\n",
      "Iteration 205, loss = 948.83458282\n",
      "Iteration 204, loss = 879.28338385\n",
      "Iteration 196, loss = 906.28595471\n",
      "Iteration 174, loss = 995.23299794\n",
      "Iteration 108, loss = 1256.19782021\n",
      "Iteration 185, loss = 978.29137845\n",
      "Iteration 199, loss = 963.70052236\n",
      "Iteration 209, loss = 962.09733664\n",
      "Iteration 205, loss = 878.09894295\n",
      "Iteration 206, loss = 948.28774362\n",
      "Iteration 197, loss = 905.08820829\n",
      "Iteration 175, loss = 993.11520854\n",
      "Iteration 109, loss = 1249.41353420\n",
      "Iteration 200, loss = 965.15512091\n",
      "Iteration 186, loss = 977.36662321\n",
      "Iteration 210, loss = 958.34835676\n",
      "Iteration 207, loss = 946.76915140\n",
      "Iteration 198, loss = 903.14934927\n",
      "Iteration 206, loss = 875.69583449\n",
      "Iteration 176, loss = 990.27269982\n",
      "Iteration 201, loss = 961.20365610\n",
      "Iteration 110, loss = 1244.11833371\n",
      "Iteration 187, loss = 976.04674683\n",
      "Iteration 211, loss = 957.12218357\n",
      "Iteration 208, loss = 944.57958342\n",
      "Iteration 199, loss = 900.91896094\n",
      "Iteration 202, loss = 961.77635634\n",
      "Iteration 207, loss = 875.94789917\n",
      "Iteration 177, loss = 987.06977096\n",
      "Iteration 111, loss = 1236.88006212\n",
      "Iteration 212, loss = 956.06812591\n",
      "Iteration 209, loss = 944.93527204\n",
      "Iteration 200, loss = 902.55131662\n",
      "Iteration 178, loss = 986.52336628\n",
      "Iteration 203, loss = 961.49003245\n",
      "Iteration 188, loss = 974.30206692\n",
      "Iteration 112, loss = 1231.04683779\n",
      "Iteration 208, loss = 873.16050069\n",
      "Iteration 213, loss = 956.08078684\n",
      "Iteration 210, loss = 941.82039288\n",
      "Iteration 179, loss = 985.46746141\n",
      "Iteration 189, loss = 971.93172038\n",
      "Iteration 201, loss = 899.15030827\n",
      "Iteration 204, loss = 958.95609091\n",
      "Iteration 113, loss = 1225.01179709\n",
      "Iteration 209, loss = 872.07679179\n",
      "Iteration 214, loss = 953.41479305\n",
      "Iteration 211, loss = 940.10006506\n",
      "Iteration 190, loss = 971.57960632\n",
      "Iteration 180, loss = 983.73585257\n",
      "Iteration 205, loss = 957.23836502\n",
      "Iteration 202, loss = 898.22155667\n",
      "Iteration 210, loss = 872.30729964\n",
      "Iteration 114, loss = 1219.04302499\n",
      "Iteration 212, loss = 939.12871898\n",
      "Iteration 215, loss = 952.97053750\n",
      "Iteration 191, loss = 969.33949634\n",
      "Iteration 181, loss = 981.18219147\n",
      "Iteration 206, loss = 955.18832439\n",
      "Iteration 203, loss = 898.27164544\n",
      "Iteration 211, loss = 870.23631763\n",
      "Iteration 115, loss = 1213.32375711\n",
      "Iteration 216, loss = 951.42789371\n",
      "Iteration 213, loss = 939.32611926\n",
      "Iteration 204, loss = 895.60834653\n",
      "Iteration 182, loss = 979.91393050\n",
      "Iteration 192, loss = 968.90292550\n",
      "Iteration 207, loss = 954.20279966\n",
      "Iteration 116, loss = 1207.24393183\n",
      "Iteration 212, loss = 870.71513821\n",
      "Iteration 214, loss = 936.96608041\n",
      "Iteration 217, loss = 950.72357485\n",
      "Iteration 205, loss = 894.48505811\n",
      "Iteration 183, loss = 979.91404303\n",
      "Iteration 208, loss = 952.87466398\n",
      "Iteration 193, loss = 966.26970228\n",
      "Iteration 117, loss = 1199.70940838\n",
      "Iteration 206, loss = 892.55530046\n",
      "Iteration 213, loss = 868.85834507\n",
      "Iteration 215, loss = 936.46611980\n",
      "Iteration 218, loss = 947.82886216\n",
      "Iteration 184, loss = 976.85969360\n",
      "Iteration 209, loss = 951.02879364\n",
      "Iteration 194, loss = 966.36921033\n",
      "Iteration 207, loss = 891.35806460\n",
      "Iteration 214, loss = 869.57674455\n",
      "Iteration 216, loss = 934.35041520\n",
      "Iteration 219, loss = 947.22878087\n",
      "Iteration 118, loss = 1194.70638639\n",
      "Iteration 185, loss = 974.40860576\n",
      "Iteration 210, loss = 950.84308615\n",
      "Iteration 208, loss = 890.94408179\n",
      "Iteration 215, loss = 868.51968979\n",
      "Iteration 217, loss = 933.63983509\n",
      "Iteration 119, loss = 1187.87723663\n",
      "Iteration 220, loss = 946.45830539\n",
      "Iteration 195, loss = 963.89282385\n",
      "Iteration 186, loss = 973.17771041\n",
      "Iteration 211, loss = 948.51964373\n",
      "Iteration 209, loss = 888.72234643\n",
      "Iteration 216, loss = 867.64855137\n",
      "Iteration 221, loss = 946.49326687\n",
      "Iteration 120, loss = 1184.85961178\n",
      "Iteration 218, loss = 930.79086867\n",
      "Iteration 196, loss = 962.25026126\n",
      "Iteration 187, loss = 972.03762730\n",
      "Iteration 212, loss = 948.36574504\n",
      "Iteration 210, loss = 887.14801744\n",
      "Iteration 217, loss = 865.08992405\n",
      "Iteration 121, loss = 1179.19340349\n",
      "Iteration 219, loss = 931.21752993\n",
      "Iteration 222, loss = 944.66426288\n",
      "Iteration 188, loss = 970.67111781\n",
      "Iteration 213, loss = 947.56122389\n",
      "Iteration 197, loss = 961.11109827\n",
      "Iteration 211, loss = 885.19532803\n",
      "Iteration 218, loss = 865.48557538\n",
      "Iteration 122, loss = 1173.62716581\n",
      "Iteration 220, loss = 929.94008485\n",
      "Iteration 223, loss = 943.07073665\n",
      "Iteration 214, loss = 945.86059731\n",
      "Iteration 219, loss = 862.66742163\n",
      "Iteration 198, loss = 959.71676325\n",
      "Iteration 189, loss = 968.00039269\n",
      "Iteration 212, loss = 885.17705285\n",
      "Iteration 123, loss = 1168.88832444\n",
      "Iteration 221, loss = 930.17952867\n",
      "Iteration 224, loss = 942.88831557\n",
      "Iteration 215, loss = 945.90646287\n",
      "Iteration 220, loss = 862.89615366\n",
      "Iteration 213, loss = 884.44048680\n",
      "Iteration 199, loss = 957.31834002\n",
      "Iteration 190, loss = 967.72744364\n",
      "Iteration 124, loss = 1164.04607167\n",
      "Iteration 222, loss = 928.27120464\n",
      "Iteration 225, loss = 942.00435422\n",
      "Iteration 216, loss = 943.39707285\n",
      "Iteration 200, loss = 957.48888330\n",
      "Iteration 221, loss = 860.82669447\n",
      "Iteration 214, loss = 883.29635254\n",
      "Iteration 125, loss = 1159.45081152\n",
      "Iteration 191, loss = 965.32295893\n",
      "Iteration 223, loss = 925.92499211\n",
      "Iteration 226, loss = 940.66947175\n",
      "Iteration 217, loss = 942.28186676\n",
      "Iteration 201, loss = 954.54901685\n",
      "Iteration 222, loss = 859.57557072\n",
      "Iteration 215, loss = 882.83997862\n",
      "Iteration 192, loss = 964.28328260\n",
      "Iteration 126, loss = 1154.22076240\n",
      "Iteration 224, loss = 925.42972713\n",
      "Iteration 227, loss = 938.17155775\n",
      "Iteration 202, loss = 953.98509881\n",
      "Iteration 218, loss = 941.54735760\n",
      "Iteration 223, loss = 861.27628458\n",
      "Iteration 216, loss = 880.94266179\n",
      "Iteration 193, loss = 962.92795807\n",
      "Iteration 225, loss = 925.29543093\n",
      "Iteration 127, loss = 1150.70677285\n",
      "Iteration 228, loss = 937.63467851\n",
      "Iteration 219, loss = 940.05650383\n",
      "Iteration 203, loss = 952.02557507\n",
      "Iteration 224, loss = 860.15905504\n",
      "Iteration 226, loss = 923.62754714\n",
      "Iteration 128, loss = 1146.84547856\n",
      "Iteration 194, loss = 962.24306637\n",
      "Iteration 217, loss = 879.22627874\n",
      "Iteration 229, loss = 936.80479128\n",
      "Iteration 220, loss = 938.30833062\n",
      "Iteration 204, loss = 950.63134988\n",
      "Iteration 225, loss = 859.49358681\n",
      "Iteration 195, loss = 960.19521252\n",
      "Iteration 227, loss = 922.80828664\n",
      "Iteration 129, loss = 1142.77701857\n",
      "Iteration 218, loss = 878.81093793\n",
      "Iteration 230, loss = 936.08052611\n",
      "Iteration 226, loss = 857.04141637\n",
      "Iteration 221, loss = 937.57950950\n",
      "Iteration 205, loss = 949.41698651\n",
      "Iteration 196, loss = 958.94215529\n",
      "Iteration 130, loss = 1137.33622293\n",
      "Iteration 228, loss = 921.56968185\n",
      "Iteration 219, loss = 877.50701702\n",
      "Iteration 231, loss = 935.79495073\n",
      "Iteration 227, loss = 855.86420082\n",
      "Iteration 222, loss = 936.20000470\n",
      "Iteration 206, loss = 948.11656555\n",
      "Iteration 229, loss = 920.61209658\n",
      "Iteration 131, loss = 1133.69036157\n",
      "Iteration 197, loss = 957.46305027\n",
      "Iteration 220, loss = 875.49606002\n",
      "Iteration 232, loss = 934.18182350\n",
      "Iteration 228, loss = 853.96571924\n",
      "Iteration 223, loss = 938.98941030\n",
      "Iteration 198, loss = 956.25772102\n",
      "Iteration 230, loss = 919.59800622\n",
      "Iteration 207, loss = 946.74245637\n",
      "Iteration 132, loss = 1129.47360997\n",
      "Iteration 221, loss = 875.23858333\n",
      "Iteration 233, loss = 932.62270542\n",
      "Iteration 229, loss = 854.75902149\n",
      "Iteration 208, loss = 945.14965252\n",
      "Iteration 224, loss = 935.52741728\n",
      "Iteration 231, loss = 919.69279385\n",
      "Iteration 199, loss = 954.08174351\n",
      "Iteration 133, loss = 1123.71824219\n",
      "Iteration 222, loss = 873.35216651\n",
      "Iteration 234, loss = 932.81397864\n",
      "Iteration 225, loss = 935.24268771\n",
      "Iteration 230, loss = 853.57589067\n",
      "Iteration 209, loss = 944.06505844\n",
      "Iteration 232, loss = 917.66818371\n",
      "Iteration 200, loss = 953.39232639\n",
      "Iteration 134, loss = 1120.33306976\n",
      "Iteration 223, loss = 873.62692700\n",
      "Iteration 226, loss = 932.71048219\n",
      "Iteration 235, loss = 931.28265946\n",
      "Iteration 210, loss = 942.13647434\n",
      "Iteration 231, loss = 854.17559044\n",
      "Iteration 201, loss = 951.77986588\n",
      "Iteration 233, loss = 915.96219930\n",
      "Iteration 135, loss = 1116.37954117\n",
      "Iteration 224, loss = 872.25640307\n",
      "Iteration 227, loss = 931.77400936\n",
      "Iteration 236, loss = 928.73815309\n",
      "Iteration 232, loss = 852.05644932\n",
      "Iteration 211, loss = 940.96503740\n",
      "Iteration 234, loss = 916.63531225\n",
      "Iteration 202, loss = 950.90219643\n",
      "Iteration 136, loss = 1113.61204795\n",
      "Iteration 225, loss = 872.25456554\n",
      "Iteration 237, loss = 928.33689662\n",
      "Iteration 228, loss = 930.92603121\n",
      "Iteration 212, loss = 939.84503535\n",
      "Iteration 233, loss = 852.64661958\n",
      "Iteration 235, loss = 914.60970796\n",
      "Iteration 137, loss = 1108.10115358\n",
      "Iteration 203, loss = 948.98249365\n",
      "Iteration 238, loss = 926.75805220\n",
      "Iteration 226, loss = 869.32118730\n",
      "Iteration 229, loss = 929.29599058\n",
      "Iteration 234, loss = 851.53806885\n",
      "Iteration 236, loss = 912.61946215\n",
      "Iteration 204, loss = 947.63188338\n",
      "Iteration 213, loss = 940.15914634\n",
      "Iteration 138, loss = 1106.31043902\n",
      "Iteration 227, loss = 869.44973950\n",
      "Iteration 239, loss = 925.70793833\n",
      "Iteration 230, loss = 928.91108803\n",
      "Iteration 235, loss = 851.64921887\n",
      "Iteration 237, loss = 911.78029486\n",
      "Iteration 205, loss = 947.30814529\n",
      "Iteration 214, loss = 939.45621559\n",
      "Iteration 139, loss = 1103.16995596\n",
      "Iteration 228, loss = 868.14025916\n",
      "Iteration 240, loss = 923.37675914\n",
      "Iteration 231, loss = 927.79996159\n",
      "Iteration 236, loss = 849.33018264\n",
      "Iteration 238, loss = 909.18760487\n",
      "Iteration 206, loss = 945.13457782\n",
      "Iteration 140, loss = 1100.05073853\n",
      "Iteration 215, loss = 937.67357111\n",
      "Iteration 229, loss = 865.87408419\n",
      "Iteration 241, loss = 922.86367287\n",
      "Iteration 239, loss = 910.07271701\n",
      "Iteration 232, loss = 927.11850433\n",
      "Iteration 207, loss = 943.38121064\n",
      "Iteration 237, loss = 849.45158909\n",
      "Iteration 216, loss = 936.56740452\n",
      "Iteration 141, loss = 1095.01639799\n",
      "Iteration 230, loss = 865.97256363\n",
      "Iteration 242, loss = 921.76432235\n",
      "Iteration 240, loss = 908.04208909\n",
      "Iteration 233, loss = 928.21689629\n",
      "Iteration 208, loss = 942.29768910\n",
      "Iteration 142, loss = 1091.31989582\n",
      "Iteration 217, loss = 934.81031814\n",
      "Iteration 238, loss = 849.01710057\n",
      "Iteration 231, loss = 864.48321393\n",
      "Iteration 243, loss = 919.98878476\n",
      "Iteration 209, loss = 940.75016750\n",
      "Iteration 241, loss = 907.17599364\n",
      "Iteration 234, loss = 926.05599545\n",
      "Iteration 218, loss = 934.02756932\n",
      "Iteration 143, loss = 1091.08591409\n",
      "Iteration 239, loss = 847.95363762\n",
      "Iteration 232, loss = 862.82900707\n",
      "Iteration 244, loss = 920.16167385\n",
      "Iteration 242, loss = 905.35696362\n",
      "Iteration 210, loss = 938.90734066\n",
      "Iteration 219, loss = 932.99668783\n",
      "Iteration 235, loss = 925.12552445\n",
      "Iteration 144, loss = 1085.47648332\n",
      "Iteration 240, loss = 846.99540172\n",
      "Iteration 233, loss = 864.23908749\n",
      "Iteration 245, loss = 918.66616955\n",
      "Iteration 243, loss = 905.13762323\n",
      "Iteration 211, loss = 937.82572748\n",
      "Iteration 220, loss = 931.05380870\n",
      "Iteration 236, loss = 923.59232106\n",
      "Iteration 145, loss = 1082.36819800\n",
      "Iteration 241, loss = 845.85687778\n",
      "Iteration 234, loss = 862.06544525\n",
      "Iteration 244, loss = 903.88801605\n",
      "Iteration 212, loss = 936.99509282\n",
      "Iteration 221, loss = 929.24236650\n",
      "Iteration 245, loss = 901.93624039\n",
      "Iteration 237, loss = 922.87682043\n",
      "Iteration 146, loss = 1078.88782552\n",
      "Iteration 242, loss = 845.81576951\n",
      "Iteration 246, loss = 919.46733748\n",
      "Iteration 235, loss = 862.39954149\n",
      "Iteration 213, loss = 937.25212881\n",
      "Iteration 222, loss = 928.06217546\n",
      "Iteration 238, loss = 923.06803732\n",
      "Iteration 147, loss = 1077.19846488\n",
      "Iteration 246, loss = 903.27225725\n",
      "Iteration 243, loss = 845.08054227\n",
      "Iteration 247, loss = 918.69591832\n",
      "Iteration 236, loss = 859.74296118\n",
      "Iteration 214, loss = 937.01711770\n",
      "Iteration 223, loss = 926.64782893\n",
      "Iteration 247, loss = 902.40680103\n",
      "Iteration 239, loss = 921.77540765\n",
      "Iteration 148, loss = 1073.71905182\n",
      "Iteration 244, loss = 843.86119844\n",
      "Iteration 215, loss = 933.49367555\n",
      "Iteration 248, loss = 917.04976103\n",
      "Iteration 237, loss = 858.62305504\n",
      "Iteration 224, loss = 926.61991265\n",
      "Iteration 248, loss = 901.25274270\n",
      "Iteration 240, loss = 919.91104128\n",
      "Iteration 149, loss = 1069.52732698\n",
      "Iteration 245, loss = 840.44779956\n",
      "Iteration 216, loss = 933.30782947\n",
      "Iteration 249, loss = 916.05568324\n",
      "Iteration 238, loss = 858.85200610\n",
      "Iteration 225, loss = 927.06349554\n",
      "Iteration 249, loss = 899.63750375\n",
      "Iteration 241, loss = 919.98449306\n",
      "Iteration 246, loss = 842.53046533\n",
      "Iteration 150, loss = 1066.80669485\n",
      "Iteration 250, loss = 913.86215964\n",
      "Iteration 217, loss = 931.80357167\n",
      "Iteration 239, loss = 857.80422671\n",
      "Iteration 250, loss = 898.07290170\n",
      "Iteration 242, loss = 919.79956920\n",
      "Iteration 226, loss = 924.73792752\n",
      "Iteration 247, loss = 840.65115039\n",
      "Iteration 151, loss = 1063.82438822\n",
      "Iteration 251, loss = 914.09444390\n",
      "Iteration 218, loss = 931.27081605\n",
      "Iteration 240, loss = 854.73369723\n",
      "Iteration 251, loss = 897.89370315\n",
      "Iteration 243, loss = 917.98754750\n",
      "Iteration 227, loss = 924.67390128\n",
      "Iteration 248, loss = 841.26214955\n",
      "Iteration 152, loss = 1060.14568260\n",
      "Iteration 252, loss = 912.88051703\n",
      "Iteration 219, loss = 929.76813810\n",
      "Iteration 241, loss = 857.30350515\n",
      "Iteration 252, loss = 896.37543488\n",
      "Iteration 244, loss = 916.49836560\n",
      "Iteration 249, loss = 838.19243782\n",
      "Iteration 228, loss = 922.25527188\n",
      "Iteration 153, loss = 1058.12405429\n",
      "Iteration 220, loss = 929.23523394\n",
      "Iteration 253, loss = 911.92542854\n",
      "Iteration 242, loss = 855.88365247\n",
      "Iteration 253, loss = 896.44502267\n",
      "Iteration 245, loss = 912.78947265\n",
      "Iteration 250, loss = 838.56517656\n",
      "Iteration 229, loss = 921.70653494\n",
      "Iteration 254, loss = 911.06544485\n",
      "Iteration 154, loss = 1054.84550826\n",
      "Iteration 243, loss = 854.47383148\n",
      "Iteration 221, loss = 926.32190063\n",
      "Iteration 254, loss = 895.44057435\n",
      "Iteration 246, loss = 914.79386290\n",
      "Iteration 251, loss = 838.33430231\n",
      "Iteration 155, loss = 1051.67720591\n",
      "Iteration 230, loss = 920.78557852\n",
      "Iteration 222, loss = 926.14761432\n",
      "Iteration 244, loss = 853.11502547\n",
      "Iteration 255, loss = 910.49553896\n",
      "Iteration 255, loss = 893.85004789\n",
      "Iteration 247, loss = 913.07673849\n",
      "Iteration 252, loss = 839.17162637\n",
      "Iteration 156, loss = 1049.47554899\n",
      "Iteration 223, loss = 922.98490149\n",
      "Iteration 231, loss = 920.46310747\n",
      "Iteration 256, loss = 909.69210402\n",
      "Iteration 245, loss = 850.69935217\n",
      "Iteration 256, loss = 893.16146419\n",
      "Iteration 248, loss = 913.69354504\n",
      "Iteration 253, loss = 835.98539812\n",
      "Iteration 157, loss = 1047.29869495\n",
      "Iteration 224, loss = 924.37190798\n",
      "Iteration 232, loss = 916.99857679\n",
      "Iteration 257, loss = 909.38252414\n",
      "Iteration 246, loss = 854.14717178\n",
      "Iteration 257, loss = 893.98726289\n",
      "Iteration 254, loss = 835.47840584\n",
      "Iteration 249, loss = 908.55778458\n",
      "Iteration 158, loss = 1044.10062604\n",
      "Iteration 225, loss = 924.69138662\n",
      "Iteration 247, loss = 851.49659900\n",
      "Iteration 233, loss = 919.53610576\n",
      "Iteration 258, loss = 892.18850724\n",
      "Iteration 258, loss = 907.77680729\n",
      "Iteration 250, loss = 910.04830905\n",
      "Iteration 159, loss = 1043.17326284\n",
      "Iteration 226, loss = 922.24267828\n",
      "Iteration 255, loss = 835.20782940\n",
      "Iteration 248, loss = 851.34567494\n",
      "Iteration 259, loss = 890.71863867\n",
      "Iteration 259, loss = 907.23528212\n",
      "Iteration 234, loss = 919.23890827\n",
      "Iteration 251, loss = 909.87790588\n",
      "Iteration 160, loss = 1039.01313340\n",
      "Iteration 256, loss = 834.48908435\n",
      "Iteration 227, loss = 922.48664789\n",
      "Iteration 260, loss = 891.54305093\n",
      "Iteration 249, loss = 846.69437056\n",
      "Iteration 260, loss = 907.42245082\n",
      "Iteration 235, loss = 917.58158796\n",
      "Iteration 252, loss = 909.91763290\n",
      "Iteration 257, loss = 833.86964363\n",
      "Iteration 228, loss = 919.58734696\n",
      "Iteration 161, loss = 1037.09733580\n",
      "Iteration 250, loss = 848.46518005\n",
      "Iteration 261, loss = 890.01116090\n",
      "Iteration 236, loss = 914.91214261\n",
      "Iteration 261, loss = 905.50319077\n",
      "Iteration 258, loss = 833.86136546\n",
      "Iteration 253, loss = 907.42908417\n",
      "Iteration 229, loss = 918.26106736\n",
      "Iteration 162, loss = 1033.50543521\n",
      "Iteration 262, loss = 889.47496755\n",
      "Iteration 251, loss = 848.17454193\n",
      "Iteration 237, loss = 914.82009945\n",
      "Iteration 262, loss = 904.93577489\n",
      "Iteration 254, loss = 906.48179553\n",
      "Iteration 259, loss = 832.02574640\n",
      "Iteration 230, loss = 917.04630922\n",
      "Iteration 263, loss = 890.49296689\n",
      "Iteration 163, loss = 1030.73281334\n",
      "Iteration 252, loss = 848.18754340\n",
      "Iteration 238, loss = 914.04373682\n",
      "Iteration 263, loss = 905.79597390\n",
      "Iteration 255, loss = 905.56070493\n",
      "Iteration 260, loss = 832.26019162\n",
      "Iteration 231, loss = 916.59827027\n",
      "Iteration 264, loss = 887.86139876\n",
      "Iteration 164, loss = 1030.69182235\n",
      "Iteration 239, loss = 913.84246603\n",
      "Iteration 253, loss = 846.80913376\n",
      "Iteration 264, loss = 903.90439108\n",
      "Iteration 256, loss = 905.09700066\n",
      "Iteration 261, loss = 832.06784486\n",
      "Iteration 232, loss = 914.52101874\n",
      "Iteration 165, loss = 1027.25307561\n",
      "Iteration 265, loss = 885.50846513\n",
      "Iteration 254, loss = 845.42519151\n",
      "Iteration 240, loss = 911.09861310\n",
      "Iteration 262, loss = 831.05358676\n",
      "Iteration 257, loss = 904.41255897\n",
      "Iteration 265, loss = 900.98261227\n",
      "Iteration 233, loss = 915.74998539\n",
      "Iteration 166, loss = 1024.84407970\n",
      "Iteration 266, loss = 887.72123146\n",
      "Iteration 255, loss = 844.87216989\n",
      "Iteration 241, loss = 912.76296239\n",
      "Iteration 258, loss = 904.56017763\n",
      "Iteration 263, loss = 830.78614906\n",
      "Iteration 266, loss = 902.43565542\n",
      "Iteration 234, loss = 915.41929845\n",
      "Iteration 267, loss = 884.80401873\n",
      "Iteration 167, loss = 1021.81268789\n",
      "Iteration 256, loss = 844.41769865\n",
      "Iteration 242, loss = 912.94148360\n",
      "Iteration 259, loss = 902.34751464\n",
      "Iteration 264, loss = 829.67506505\n",
      "Iteration 235, loss = 914.33891154\n",
      "Iteration 268, loss = 884.42252809\n",
      "Iteration 267, loss = 899.56134370\n",
      "Iteration 257, loss = 844.46644851\n",
      "Iteration 168, loss = 1020.56665926\n",
      "Iteration 243, loss = 911.02854823\n",
      "Iteration 260, loss = 902.68363349\n",
      "Iteration 265, loss = 829.34408238\n",
      "Iteration 236, loss = 911.80354463\n",
      "Iteration 258, loss = 844.46324474\n",
      "Iteration 268, loss = 899.17954892\n",
      "Iteration 269, loss = 884.07507002\n",
      "Iteration 169, loss = 1019.61717226\n",
      "Iteration 244, loss = 908.99255176\n",
      "Iteration 261, loss = 901.35545283\n",
      "Iteration 266, loss = 827.97006141\n",
      "Iteration 237, loss = 911.16344021\n",
      "Iteration 259, loss = 842.51105639\n",
      "Iteration 270, loss = 883.51362846\n",
      "Iteration 269, loss = 898.85478109\n",
      "Iteration 170, loss = 1015.04679872\n",
      "Iteration 262, loss = 900.57841994\n",
      "Iteration 245, loss = 905.43218006\n",
      "Iteration 238, loss = 911.13745242\n",
      "Iteration 267, loss = 828.62540131\n",
      "Iteration 271, loss = 882.98685227\n",
      "Iteration 260, loss = 842.42139815\n",
      "Iteration 270, loss = 898.20408983\n",
      "Iteration 171, loss = 1015.30512730\n",
      "Iteration 239, loss = 909.81604245\n",
      "Iteration 246, loss = 909.43777484\n",
      "Iteration 263, loss = 900.13580706\n",
      "Iteration 268, loss = 827.52620921\n",
      "Iteration 272, loss = 880.74494009\n",
      "Iteration 261, loss = 840.50164654\n",
      "Iteration 271, loss = 898.43520865\n",
      "Iteration 172, loss = 1010.53225329\n",
      "Iteration 240, loss = 908.68551662\n",
      "Iteration 273, loss = 881.01888852\n",
      "Iteration 264, loss = 899.16393520\n",
      "Iteration 269, loss = 826.45647609\n",
      "Iteration 247, loss = 906.62268422\n",
      "Iteration 262, loss = 839.83035725\n",
      "Iteration 272, loss = 897.00678779\n",
      "Iteration 173, loss = 1008.48315997\n",
      "Iteration 265, loss = 896.84157626\n",
      "Iteration 241, loss = 908.41116092\n",
      "Iteration 248, loss = 906.33610323\n",
      "Iteration 274, loss = 879.62662460\n",
      "Iteration 270, loss = 827.07212336\n",
      "Iteration 263, loss = 840.35012062\n",
      "Iteration 174, loss = 1007.29476147\n",
      "Iteration 273, loss = 896.23823762\n",
      "Iteration 266, loss = 897.30498542\n",
      "Iteration 275, loss = 878.96330229\n",
      "Iteration 242, loss = 909.82565003\n",
      "Iteration 249, loss = 903.20672287\n",
      "Iteration 271, loss = 825.26449317\n",
      "Iteration 264, loss = 839.88301596\n",
      "Iteration 274, loss = 893.56436517\n",
      "Iteration 175, loss = 1006.02575597\n",
      "Iteration 267, loss = 895.86846281\n",
      "Iteration 250, loss = 902.49941311\n",
      "Iteration 243, loss = 907.71790484\n",
      "Iteration 276, loss = 878.55345276\n",
      "Iteration 272, loss = 824.92330387\n",
      "Iteration 265, loss = 837.74084685\n",
      "Iteration 275, loss = 894.29039054\n",
      "Iteration 176, loss = 1002.75812311\n",
      "Iteration 268, loss = 896.70377751\n",
      "Iteration 277, loss = 878.45807169\n",
      "Iteration 244, loss = 905.77188809\n",
      "Iteration 251, loss = 904.53815548\n",
      "Iteration 273, loss = 825.33947314\n",
      "Iteration 266, loss = 838.48712028\n",
      "Iteration 177, loss = 999.10140966\n",
      "Iteration 276, loss = 893.15180804\n",
      "Iteration 269, loss = 894.61537105\n",
      "Iteration 278, loss = 876.54428180\n",
      "Iteration 245, loss = 901.87971404\n",
      "Iteration 252, loss = 904.13269702\n",
      "Iteration 274, loss = 824.12445312\n",
      "Iteration 267, loss = 836.99265260\n",
      "Iteration 178, loss = 997.79681038\n",
      "Iteration 277, loss = 892.77760987\n",
      "Iteration 270, loss = 894.83225744\n",
      "Iteration 246, loss = 906.39489741\n",
      "Iteration 279, loss = 877.24885325\n",
      "Iteration 253, loss = 901.48647834\n",
      "Iteration 268, loss = 836.73191581\n",
      "Iteration 275, loss = 822.68878135\n",
      "Iteration 179, loss = 996.97357033\n",
      "Iteration 278, loss = 892.02246277\n",
      "Iteration 271, loss = 893.71420413\n",
      "Iteration 247, loss = 903.60777633\n",
      "Iteration 280, loss = 874.67702124\n",
      "Iteration 254, loss = 900.55998042\n",
      "Iteration 269, loss = 835.22049808\n",
      "Iteration 180, loss = 995.14360345\n",
      "Iteration 276, loss = 823.12906312\n",
      "Iteration 279, loss = 893.46874763\n",
      "Iteration 272, loss = 894.01016674\n",
      "Iteration 248, loss = 903.71753177\n",
      "Iteration 281, loss = 876.66225740\n",
      "Iteration 270, loss = 835.62037260\n",
      "Iteration 181, loss = 992.56645335\n",
      "Iteration 277, loss = 822.54202162\n",
      "Iteration 255, loss = 899.62005075\n",
      "Iteration 280, loss = 890.78768605\n",
      "Iteration 273, loss = 892.72564749\n",
      "Iteration 282, loss = 876.16251163\n",
      "Iteration 249, loss = 899.36498394\n",
      "Iteration 278, loss = 822.55466770\n",
      "Iteration 271, loss = 834.82387501\n",
      "Iteration 182, loss = 991.11805711\n",
      "Iteration 256, loss = 898.77304532\n",
      "Iteration 281, loss = 891.63688970\n",
      "Iteration 283, loss = 875.46975090\n",
      "Iteration 250, loss = 898.79884332\n",
      "Iteration 274, loss = 891.30247808\n",
      "Iteration 279, loss = 822.06924476\n",
      "Iteration 272, loss = 835.48885236\n",
      "Iteration 257, loss = 899.37660285\n",
      "Iteration 183, loss = 991.37421631\n",
      "Iteration 282, loss = 890.95907180\n",
      "Iteration 251, loss = 901.25714419\n",
      "Iteration 284, loss = 874.27372391\n",
      "Iteration 280, loss = 820.15943240\n",
      "Iteration 273, loss = 834.34949298\n",
      "Iteration 275, loss = 890.37275258\n",
      "Iteration 184, loss = 988.55325963\n",
      "Iteration 258, loss = 898.80004783\n",
      "Iteration 283, loss = 889.62495549\n",
      "Iteration 252, loss = 902.09517410\n",
      "Iteration 281, loss = 820.29362933\n",
      "Iteration 285, loss = 873.66354296\n",
      "Iteration 274, loss = 833.84398645\n",
      "Iteration 185, loss = 986.08636465\n",
      "Iteration 276, loss = 890.99006986\n",
      "Iteration 259, loss = 897.17120613\n",
      "Iteration 284, loss = 888.83663252\n",
      "Iteration 253, loss = 898.52786847\n",
      "Iteration 275, loss = 832.37571192\n",
      "Iteration 286, loss = 873.32687102\n",
      "Iteration 282, loss = 818.22773043\n",
      "Iteration 186, loss = 984.58199441\n",
      "Iteration 277, loss = 889.63548498\n",
      "Iteration 260, loss = 897.56080590\n",
      "Iteration 285, loss = 887.98492914\n",
      "Iteration 254, loss = 897.29355629\n",
      "Iteration 283, loss = 819.29055072\n",
      "Iteration 276, loss = 832.94696730\n",
      "Iteration 287, loss = 873.18728208\n",
      "Iteration 187, loss = 982.87732230\n",
      "Iteration 278, loss = 890.39249268\n",
      "Iteration 261, loss = 895.11402213\n",
      "Iteration 286, loss = 888.49146905\n",
      "Iteration 255, loss = 896.63885919\n",
      "Iteration 284, loss = 818.77182877\n",
      "Iteration 288, loss = 870.22328001\n",
      "Iteration 277, loss = 831.56622750\n",
      "Iteration 188, loss = 981.49162085\n",
      "Iteration 279, loss = 888.33420201\n",
      "Iteration 262, loss = 895.33102435\n",
      "Iteration 256, loss = 896.10702835\n",
      "Iteration 287, loss = 887.10582900\n",
      "Iteration 289, loss = 871.57039750\n",
      "Iteration 285, loss = 817.51864324\n",
      "Iteration 278, loss = 830.94751679\n",
      "Iteration 280, loss = 887.62799088\n",
      "Iteration 189, loss = 979.16736336\n",
      "Iteration 257, loss = 895.93500070\n",
      "Iteration 263, loss = 895.15840524\n",
      "Iteration 288, loss = 884.95895130\n",
      "Iteration 279, loss = 830.25158396\n",
      "Iteration 290, loss = 871.00196421\n",
      "Iteration 286, loss = 816.82959842\n",
      "Iteration 190, loss = 978.97915782\n",
      "Iteration 281, loss = 887.55624831\n",
      "Iteration 258, loss = 895.54126190\n",
      "Iteration 264, loss = 893.24272431\n",
      "Iteration 289, loss = 885.73447702\n",
      "Iteration 291, loss = 869.32828875\n",
      "Iteration 280, loss = 829.66311818\n",
      "Iteration 191, loss = 976.17139871\n",
      "Iteration 287, loss = 815.79185960\n",
      "Iteration 282, loss = 885.70230562\n",
      "Iteration 265, loss = 893.59736265\n",
      "Iteration 259, loss = 894.13208480\n",
      "Iteration 290, loss = 884.49707175\n",
      "Iteration 292, loss = 869.09614487\n",
      "Iteration 281, loss = 830.08937699\n",
      "Iteration 288, loss = 816.29328022\n",
      "Iteration 192, loss = 974.11634659\n",
      "Iteration 260, loss = 894.80929529\n",
      "Iteration 283, loss = 886.08068634\n",
      "Iteration 266, loss = 893.02305922\n",
      "Iteration 291, loss = 883.39084478\n",
      "Iteration 282, loss = 827.67311663\n",
      "Iteration 293, loss = 868.29134892\n",
      "Iteration 193, loss = 972.81951974\n",
      "Iteration 289, loss = 816.48091837\n",
      "Iteration 267, loss = 890.00186570\n",
      "Iteration 284, loss = 883.93137836\n",
      "Iteration 261, loss = 891.65320339\n",
      "Iteration 292, loss = 883.30188761\n",
      "Iteration 283, loss = 828.78796000\n",
      "Iteration 294, loss = 869.72671667\n",
      "Iteration 290, loss = 816.28624770\n",
      "Iteration 194, loss = 971.77789538\n",
      "Iteration 285, loss = 883.20953335\n",
      "Iteration 262, loss = 892.56857009\n",
      "Iteration 268, loss = 891.10079908\n",
      "Iteration 293, loss = 882.88349619\n",
      "Iteration 284, loss = 825.94119446\n",
      "Iteration 295, loss = 865.88547712\n",
      "Iteration 291, loss = 815.53406827\n",
      "Iteration 195, loss = 970.37998391\n",
      "Iteration 263, loss = 893.15002187\n",
      "Iteration 286, loss = 883.02773880\n",
      "Iteration 269, loss = 889.79434525\n",
      "Iteration 294, loss = 882.22407520\n",
      "Iteration 285, loss = 827.03687946\n",
      "Iteration 296, loss = 868.46298497\n",
      "Iteration 292, loss = 813.51520735\n",
      "Iteration 264, loss = 890.42740133\n",
      "Iteration 196, loss = 967.93266899\n",
      "Iteration 287, loss = 881.37147888\n",
      "Iteration 270, loss = 890.70746921\n",
      "Iteration 295, loss = 879.60862280\n",
      "Iteration 286, loss = 825.17862900\n",
      "Iteration 265, loss = 890.48031872\n",
      "Iteration 297, loss = 866.02861721\n",
      "Iteration 293, loss = 813.82342601\n",
      "Iteration 197, loss = 967.27438392\n",
      "Iteration 288, loss = 881.95994815\n",
      "Iteration 296, loss = 883.52836829\n",
      "Iteration 271, loss = 888.83673666\n",
      "Iteration 287, loss = 824.31865150\n",
      "Iteration 266, loss = 889.83026201\n",
      "Iteration 298, loss = 865.65114328\n",
      "Iteration 294, loss = 812.58527152\n",
      "Iteration 198, loss = 966.52208622\n",
      "Iteration 289, loss = 881.93286529\n",
      "Iteration 297, loss = 879.61035830\n",
      "Iteration 288, loss = 825.67095476\n",
      "Iteration 267, loss = 886.05582223\n",
      "Iteration 272, loss = 889.36761877\n",
      "Iteration 299, loss = 866.35837295\n",
      "Iteration 199, loss = 965.19026260\n",
      "Iteration 295, loss = 811.47136001\n",
      "Iteration 290, loss = 881.82270028\n",
      "Iteration 298, loss = 879.54620767\n",
      "Iteration 273, loss = 887.95929418\n",
      "Iteration 268, loss = 888.87749827\n",
      "Iteration 289, loss = 825.02976406\n",
      "Iteration 300, loss = 864.66539177\n",
      "Iteration 200, loss = 963.11992390\n",
      "Iteration 296, loss = 811.10191489\n",
      "Iteration 291, loss = 880.05054718\n",
      "Iteration 299, loss = 878.61168071\n",
      "Iteration 290, loss = 824.54219297\n",
      "Iteration 269, loss = 887.67690128\n",
      "Iteration 274, loss = 887.25750973\n",
      "Iteration 301, loss = 865.70808884\n",
      "Iteration 201, loss = 962.62550213\n",
      "Iteration 297, loss = 812.73433645\n",
      "Iteration 292, loss = 878.99362412\n",
      "Iteration 300, loss = 878.37816333\n",
      "Iteration 275, loss = 886.93654121\n",
      "Iteration 270, loss = 888.11678174\n",
      "Iteration 291, loss = 822.48238289\n",
      "Iteration 302, loss = 863.79887169\n",
      "Iteration 298, loss = 810.46130106\n",
      "Iteration 202, loss = 961.10125549\n",
      "Iteration 301, loss = 878.38522105\n",
      "Iteration 293, loss = 878.91870010\n",
      "Iteration 276, loss = 885.61515988\n",
      "Iteration 271, loss = 887.12590032\n",
      "Iteration 303, loss = 863.05471171\n",
      "Iteration 292, loss = 822.43041375\n",
      "Iteration 299, loss = 809.35983667\n",
      "Iteration 203, loss = 959.18771456\n",
      "Iteration 302, loss = 876.48910555\n",
      "Iteration 294, loss = 876.85785618\n",
      "Iteration 304, loss = 863.06792156\n",
      "Iteration 293, loss = 821.72970132\n",
      "Iteration 277, loss = 885.40858445\n",
      "Iteration 272, loss = 886.86819094\n",
      "Iteration 204, loss = 957.33047319\n",
      "Iteration 300, loss = 811.00586330\n",
      "Iteration 273, loss = 886.40274596\n",
      "Iteration 294, loss = 820.47078686\n",
      "Iteration 305, loss = 861.90913264\n",
      "Iteration 303, loss = 876.03564263\n",
      "Iteration 295, loss = 876.79881016\n",
      "Iteration 278, loss = 884.89438966\n",
      "Iteration 205, loss = 957.70665787\n",
      "Iteration 301, loss = 810.05055781\n",
      "Iteration 274, loss = 884.69398565\n",
      "Iteration 295, loss = 820.77527467\n",
      "Iteration 296, loss = 876.64102657\n",
      "Iteration 306, loss = 863.48797196\n",
      "Iteration 304, loss = 876.17985917\n",
      "Iteration 279, loss = 884.04694578\n",
      "Iteration 206, loss = 955.19127883\n",
      "Iteration 302, loss = 806.72535151\n",
      "Iteration 275, loss = 884.94489988\n",
      "Iteration 296, loss = 820.22869352\n",
      "Iteration 297, loss = 875.79236608\n",
      "Iteration 307, loss = 859.65562184\n",
      "Iteration 305, loss = 873.50898081\n",
      "Iteration 280, loss = 883.56453083\n",
      "Iteration 303, loss = 805.81790961\n",
      "Iteration 207, loss = 954.02383973\n",
      "Iteration 276, loss = 884.50691425\n",
      "Iteration 298, loss = 875.18439350\n",
      "Iteration 297, loss = 820.07066080\n",
      "Iteration 308, loss = 860.79907408\n",
      "Iteration 306, loss = 875.58013996\n",
      "Iteration 281, loss = 884.17654025\n",
      "Iteration 304, loss = 803.84342468\n",
      "Iteration 208, loss = 952.70704759\n",
      "Iteration 277, loss = 883.48621065\n",
      "Iteration 298, loss = 818.84522106\n",
      "Iteration 299, loss = 873.84830602\n",
      "Iteration 309, loss = 860.87423975\n",
      "Iteration 282, loss = 881.68238932\n",
      "Iteration 307, loss = 872.32069769\n",
      "Iteration 278, loss = 883.45118454\n",
      "Iteration 299, loss = 817.79864177\n",
      "Iteration 300, loss = 873.77012450\n",
      "Iteration 209, loss = 949.90297967\n",
      "Iteration 310, loss = 860.10151297\n",
      "Iteration 305, loss = 806.70704131\n",
      "Iteration 283, loss = 882.77030119\n",
      "Iteration 308, loss = 873.30510107\n",
      "Iteration 279, loss = 882.46051995\n",
      "Iteration 210, loss = 947.12843981\n",
      "Iteration 311, loss = 859.00119574\n",
      "Iteration 300, loss = 818.20451194\n",
      "Iteration 301, loss = 872.85884098\n",
      "Iteration 306, loss = 805.34342718\n",
      "Iteration 284, loss = 879.71814685\n",
      "Iteration 309, loss = 872.24407412\n",
      "Iteration 280, loss = 881.65401792\n",
      "Iteration 211, loss = 947.67263976\n",
      "Iteration 301, loss = 818.04522997\n",
      "Iteration 312, loss = 856.46482791\n",
      "Iteration 302, loss = 871.08258404\n",
      "Iteration 285, loss = 880.43157442\n",
      "Iteration 310, loss = 872.61872327\n",
      "Iteration 307, loss = 805.51169996\n",
      "Iteration 212, loss = 945.03012308\n",
      "Iteration 281, loss = 881.80867922\n",
      "Iteration 302, loss = 815.99844185\n",
      "Iteration 303, loss = 869.22438491\n",
      "Iteration 313, loss = 856.74631598\n",
      "Iteration 286, loss = 878.20886327\n",
      "Iteration 311, loss = 870.38243847\n",
      "Iteration 308, loss = 804.58892468\n",
      "Iteration 213, loss = 946.81855679\n",
      "Iteration 282, loss = 880.28350945\n",
      "Iteration 314, loss = 857.26571487\n",
      "Iteration 303, loss = 815.43083528\n",
      "Iteration 304, loss = 869.04159365\n",
      "Iteration 312, loss = 869.16152577\n",
      "Iteration 309, loss = 806.18561708\n",
      "Iteration 287, loss = 877.20335281\n",
      "Iteration 214, loss = 944.95675808\n",
      "Iteration 283, loss = 882.86893061\n",
      "Iteration 304, loss = 814.57097851\n",
      "Iteration 315, loss = 858.17014028\n",
      "Iteration 305, loss = 869.55065651\n",
      "Iteration 313, loss = 868.61968107\n",
      "Iteration 310, loss = 802.92117685\n",
      "Iteration 288, loss = 877.55426065\n",
      "Iteration 215, loss = 942.41764686\n",
      "Iteration 316, loss = 856.82658919\n",
      "Iteration 284, loss = 878.86773589\n",
      "Iteration 305, loss = 814.96571063\n",
      "Iteration 306, loss = 868.49811438\n",
      "Iteration 311, loss = 803.42738821\n",
      "Iteration 289, loss = 876.02554894\n",
      "Iteration 314, loss = 869.85320842\n",
      "Iteration 216, loss = 943.08744592\n",
      "Iteration 317, loss = 857.15411971\n",
      "Iteration 306, loss = 815.08931130\n",
      "Iteration 285, loss = 879.30308554\n",
      "Iteration 307, loss = 868.90269672\n",
      "Iteration 312, loss = 802.79161901\n",
      "Iteration 315, loss = 870.20199782\n",
      "Iteration 290, loss = 875.12536816\n",
      "Iteration 217, loss = 940.56124446\n",
      "Iteration 307, loss = 814.47109735\n",
      "Iteration 318, loss = 856.50407450\n",
      "Iteration 286, loss = 877.54633567\n",
      "Iteration 308, loss = 868.28935263\n",
      "Iteration 313, loss = 803.59978306\n",
      "Iteration 316, loss = 868.75764144\n",
      "Iteration 291, loss = 874.57538990\n",
      "Iteration 319, loss = 855.38045042\n",
      "Iteration 218, loss = 939.04324190\n",
      "Iteration 308, loss = 814.19805044\n",
      "Iteration 309, loss = 868.59314648\n",
      "Iteration 287, loss = 877.17844920\n",
      "Iteration 314, loss = 802.64262484\n",
      "Iteration 292, loss = 874.28176214\n",
      "Iteration 317, loss = 868.12931185\n",
      "Iteration 219, loss = 938.18231782\n",
      "Iteration 309, loss = 812.94886657\n",
      "Iteration 320, loss = 855.31030866\n",
      "Iteration 310, loss = 866.23271298\n",
      "Iteration 288, loss = 877.56169129\n",
      "Iteration 315, loss = 801.08433749\n",
      "Iteration 293, loss = 873.09013664\n",
      "Iteration 220, loss = 937.27719540\n",
      "Iteration 318, loss = 867.84684015\n",
      "Iteration 321, loss = 853.97141866\n",
      "Iteration 310, loss = 812.76168367\n",
      "Iteration 311, loss = 865.77904564\n",
      "Iteration 289, loss = 877.21213623\n",
      "Iteration 316, loss = 802.02286875\n",
      "Iteration 221, loss = 935.07919410\n",
      "Iteration 294, loss = 871.60423854\n",
      "Iteration 322, loss = 853.60254293\n",
      "Iteration 319, loss = 867.25094086\n",
      "Iteration 311, loss = 811.16804430\n",
      "Iteration 312, loss = 866.13005674\n",
      "Iteration 290, loss = 875.55748763\n",
      "Iteration 317, loss = 801.42390768\n",
      "Iteration 323, loss = 852.14883357\n",
      "Iteration 295, loss = 872.70132828\n",
      "Iteration 222, loss = 933.88365784\n",
      "Iteration 320, loss = 867.20355032\n",
      "Iteration 312, loss = 813.18703929\n",
      "Iteration 313, loss = 864.67080734\n",
      "Iteration 291, loss = 876.97812166\n",
      "Iteration 318, loss = 800.94542459\n",
      "Iteration 223, loss = 931.33005163\n",
      "Iteration 313, loss = 811.18355524\n",
      "Iteration 324, loss = 852.87041742\n",
      "Iteration 321, loss = 865.38232875\n",
      "Iteration 296, loss = 870.64577074\n",
      "Iteration 314, loss = 865.36802845\n",
      "Iteration 292, loss = 876.11524400\n",
      "Iteration 325, loss = 851.72691029\n",
      "Iteration 319, loss = 799.29850343\n",
      "Iteration 224, loss = 932.67025638\n",
      "Iteration 297, loss = 871.06019162\n",
      "Iteration 314, loss = 811.92257235\n",
      "Iteration 322, loss = 865.60951919\n",
      "Iteration 315, loss = 861.75836491\n",
      "Iteration 293, loss = 874.68881449\n",
      "Iteration 320, loss = 798.76415833\n",
      "Iteration 225, loss = 932.92028645\n",
      "Iteration 326, loss = 849.51921440\n",
      "Iteration 298, loss = 870.13827696\n",
      "Iteration 315, loss = 808.95087846\n",
      "Iteration 323, loss = 864.09198648\n",
      "Iteration 294, loss = 873.21196901\n",
      "Iteration 316, loss = 864.31174814\n",
      "Iteration 327, loss = 849.62110087\n",
      "Iteration 321, loss = 799.12492249\n",
      "Iteration 299, loss = 869.47294943\n",
      "Iteration 226, loss = 928.93015828\n",
      "Iteration 324, loss = 864.66061030\n",
      "Iteration 316, loss = 810.38234301\n",
      "Iteration 317, loss = 863.27969955\n",
      "Iteration 295, loss = 874.76999645\n",
      "Iteration 328, loss = 849.64702316\n",
      "Iteration 322, loss = 797.90685425\n",
      "Iteration 300, loss = 869.24105866\n",
      "Iteration 325, loss = 863.94230855\n",
      "Iteration 227, loss = 929.32006769\n",
      "Iteration 317, loss = 810.15182923\n",
      "Iteration 296, loss = 872.82599624\n",
      "Iteration 318, loss = 862.39457068\n",
      "Iteration 323, loss = 799.28720844\n",
      "Iteration 329, loss = 849.03069450\n",
      "Iteration 301, loss = 868.38858810\n",
      "Iteration 326, loss = 862.64092049\n",
      "Iteration 228, loss = 927.78897344\n",
      "Iteration 318, loss = 808.70506272\n",
      "Iteration 297, loss = 872.98535335\n",
      "Iteration 324, loss = 799.13718775\n",
      "Iteration 319, loss = 861.37987527\n",
      "Iteration 330, loss = 847.19119580\n",
      "Iteration 302, loss = 867.35149112\n",
      "Iteration 229, loss = 925.25881790\n",
      "Iteration 327, loss = 862.61263681\n",
      "Iteration 319, loss = 808.48437714\n",
      "Iteration 298, loss = 872.34877759\n",
      "Iteration 320, loss = 860.60583479\n",
      "Iteration 303, loss = 866.64757419\n",
      "Iteration 331, loss = 846.06012626\n",
      "Iteration 325, loss = 796.98739316\n",
      "Iteration 230, loss = 923.87824770\n",
      "Iteration 328, loss = 863.37253443\n",
      "Iteration 299, loss = 870.14039217\n",
      "Iteration 320, loss = 807.50006986\n",
      "Iteration 332, loss = 845.01045752\n",
      "Iteration 321, loss = 860.20006202\n",
      "Iteration 326, loss = 797.33924075\n",
      "Iteration 304, loss = 866.50239816\n",
      "Iteration 231, loss = 922.14185987\n",
      "Iteration 329, loss = 862.88645378\n",
      "Iteration 300, loss = 870.92794131\n",
      "Iteration 333, loss = 845.81833869\n",
      "Iteration 327, loss = 795.54752135\n",
      "Iteration 321, loss = 805.67351569\n",
      "Iteration 322, loss = 859.30266191\n",
      "Iteration 305, loss = 865.57075575\n",
      "Iteration 232, loss = 921.24729384\n",
      "Iteration 330, loss = 861.78092129\n",
      "Iteration 301, loss = 870.98981464\n",
      "Iteration 328, loss = 795.96451209\n",
      "Iteration 334, loss = 846.29047616\n",
      "Iteration 322, loss = 807.49538146\n",
      "Iteration 323, loss = 859.94084867\n",
      "Iteration 331, loss = 861.44929159\n",
      "Iteration 233, loss = 921.82227507\n",
      "Iteration 306, loss = 865.69313470\n",
      "Iteration 302, loss = 868.29529805\n",
      "Iteration 329, loss = 793.72938921\n",
      "Iteration 335, loss = 844.22317201\n",
      "Iteration 324, loss = 860.23886668\n",
      "Iteration 323, loss = 806.59374483\n",
      "Iteration 332, loss = 859.92326692\n",
      "Iteration 234, loss = 921.98112738\n",
      "Iteration 307, loss = 865.35458641\n",
      "Iteration 303, loss = 869.36782884\n",
      "Iteration 330, loss = 796.50305995\n",
      "Iteration 336, loss = 844.44937087\n",
      "Iteration 325, loss = 858.43969310\n",
      "Iteration 324, loss = 806.07466401\n",
      "Iteration 235, loss = 920.17067149\n",
      "Iteration 333, loss = 860.34071580\n",
      "Iteration 304, loss = 867.89643238\n",
      "Iteration 331, loss = 794.65107266\n",
      "Iteration 308, loss = 865.48412880\n",
      "Iteration 337, loss = 843.80495027\n",
      "Iteration 326, loss = 857.32538515\n",
      "Iteration 325, loss = 806.13541946\n",
      "Iteration 236, loss = 918.18384409\n",
      "Iteration 305, loss = 868.36547512\n",
      "Iteration 332, loss = 794.90207155\n",
      "Iteration 334, loss = 860.44809990\n",
      "Iteration 309, loss = 864.23306788\n",
      "Iteration 338, loss = 843.60012469\n",
      "Iteration 327, loss = 856.77527484\n",
      "Iteration 237, loss = 917.22844823\n",
      "Iteration 326, loss = 804.39746982\n",
      "Iteration 333, loss = 795.64402880\n",
      "Iteration 310, loss = 862.66158686\n",
      "Iteration 306, loss = 867.28463573\n",
      "Iteration 339, loss = 841.63342826\n",
      "Iteration 335, loss = 857.86512339\n",
      "Iteration 328, loss = 856.21220391\n",
      "Iteration 238, loss = 917.03334396\n",
      "Iteration 327, loss = 805.30601153\n",
      "Iteration 334, loss = 794.35458474\n",
      "Iteration 307, loss = 867.38936858\n",
      "Iteration 311, loss = 861.81412357\n",
      "Iteration 239, loss = 916.47077876\n",
      "Iteration 340, loss = 840.16375771\n",
      "Iteration 336, loss = 859.42657894\n",
      "Iteration 329, loss = 855.00759204\n",
      "Iteration 328, loss = 804.43392750\n",
      "Iteration 335, loss = 794.41505672\n",
      "Iteration 308, loss = 867.87224453\n",
      "Iteration 312, loss = 863.75233579\n",
      "Iteration 240, loss = 915.03290460\n",
      "Iteration 341, loss = 842.29162803\n",
      "Iteration 330, loss = 856.09787366\n",
      "Iteration 337, loss = 858.42825444\n",
      "Iteration 336, loss = 792.55120084\n",
      "Iteration 309, loss = 866.12259279\n",
      "Iteration 329, loss = 802.53207845\n",
      "Iteration 313, loss = 860.97195710\n",
      "Iteration 241, loss = 914.20252652\n",
      "Iteration 342, loss = 842.81771235\n",
      "Iteration 331, loss = 854.36895147\n",
      "Iteration 337, loss = 793.67881905\n",
      "Iteration 330, loss = 803.22302394\n",
      "Iteration 338, loss = 858.13047677\n",
      "Iteration 310, loss = 865.92393583\n",
      "Iteration 314, loss = 862.14415788\n",
      "Iteration 242, loss = 915.07586475\n",
      "Iteration 343, loss = 842.04073854\n",
      "Iteration 331, loss = 802.72682510\n",
      "Iteration 311, loss = 864.16246523\n",
      "Iteration 332, loss = 855.41506380\n",
      "Iteration 338, loss = 791.71619628\n",
      "Iteration 339, loss = 856.19647833\n",
      "Iteration 243, loss = 913.44907757\n",
      "Iteration 315, loss = 861.55095299\n",
      "Iteration 344, loss = 839.71480767\n",
      "Iteration 333, loss = 854.79310307\n",
      "Iteration 312, loss = 866.10846459\n",
      "Iteration 332, loss = 802.89036589\n",
      "Iteration 339, loss = 792.47304347\n",
      "Iteration 340, loss = 855.79426980\n",
      "Iteration 244, loss = 910.64640585\n",
      "Iteration 345, loss = 841.43347800\n",
      "Iteration 316, loss = 862.39954676\n",
      "Iteration 334, loss = 855.53330666\n",
      "Iteration 313, loss = 864.17207820\n",
      "Iteration 333, loss = 800.74279867\n",
      "Iteration 340, loss = 789.41503681\n",
      "Iteration 341, loss = 856.89060749\n",
      "Iteration 245, loss = 908.86126863\n",
      "Iteration 346, loss = 840.82881834\n",
      "Iteration 317, loss = 860.28244613\n",
      "Iteration 334, loss = 805.57794900\n",
      "Iteration 314, loss = 864.57854452\n",
      "Iteration 335, loss = 854.38304784\n",
      "Iteration 341, loss = 792.04500731\n",
      "Iteration 347, loss = 839.65607030\n",
      "Iteration 246, loss = 912.43459175\n",
      "Iteration 342, loss = 857.14027503\n",
      "Iteration 318, loss = 858.87774861\n",
      "Iteration 315, loss = 864.08677965\n",
      "Iteration 336, loss = 852.85275160\n",
      "Iteration 335, loss = 802.72231680\n",
      "Iteration 342, loss = 789.70162781\n",
      "Iteration 348, loss = 839.34867358\n",
      "Iteration 247, loss = 908.69287416\n",
      "Iteration 343, loss = 858.75226630\n",
      "Iteration 319, loss = 858.39216287\n",
      "Iteration 316, loss = 864.01876251\n",
      "Iteration 343, loss = 789.50803754\n",
      "Iteration 248, loss = 909.92319472\n",
      "Iteration 336, loss = 801.47131005\n",
      "Iteration 349, loss = 839.43850059\n",
      "Iteration 337, loss = 852.33145761\n",
      "Iteration 344, loss = 853.45382111\n",
      "Iteration 249, loss = 905.38838468\n",
      "Iteration 317, loss = 862.93951141\n",
      "Iteration 320, loss = 858.62562007\n",
      "Iteration 350, loss = 838.91959322\n",
      "Iteration 338, loss = 851.97526516\n",
      "Iteration 337, loss = 802.32234389\n",
      "Iteration 344, loss = 790.62962511\n",
      "Iteration 345, loss = 856.10574773\n",
      "Iteration 250, loss = 904.32756669\n",
      "Iteration 345, loss = 790.39514255\n",
      "Iteration 321, loss = 856.26509049\n",
      "Iteration 338, loss = 797.93015578\n",
      "Iteration 351, loss = 837.54812906\n",
      "Iteration 339, loss = 851.97575916\n",
      "Iteration 318, loss = 862.09784055\n",
      "Iteration 346, loss = 855.65617014\n",
      "Iteration 251, loss = 906.06284470\n",
      "Iteration 346, loss = 788.67255221\n",
      "Iteration 352, loss = 837.09091014\n",
      "Iteration 319, loss = 861.75933101\n",
      "Iteration 340, loss = 850.38438938\n",
      "Iteration 339, loss = 802.26866791\n",
      "Iteration 322, loss = 858.37126610\n",
      "Iteration 347, loss = 854.31907339\n",
      "Iteration 347, loss = 787.51877612\n",
      "Iteration 252, loss = 906.20490710\n",
      "Iteration 353, loss = 836.94151903\n",
      "Iteration 341, loss = 851.36025194\n",
      "Iteration 320, loss = 861.10612281\n",
      "Iteration 340, loss = 799.15646675\n",
      "Iteration 323, loss = 856.27124028\n",
      "Iteration 348, loss = 853.73938678\n",
      "Iteration 348, loss = 788.89694357\n",
      "Iteration 253, loss = 903.53471707\n",
      "Iteration 354, loss = 835.76398008\n",
      "Iteration 342, loss = 849.90127596\n",
      "Iteration 321, loss = 860.03448760\n",
      "Iteration 341, loss = 799.59529067\n",
      "Iteration 324, loss = 856.35374103\n",
      "Iteration 254, loss = 902.35500971\n",
      "Iteration 349, loss = 786.54454343\n",
      "Iteration 349, loss = 852.95182027\n",
      "Iteration 343, loss = 849.31848032\n",
      "Iteration 355, loss = 837.92281188\n",
      "Iteration 322, loss = 861.24920304\n",
      "Iteration 342, loss = 800.19595361\n",
      "Iteration 325, loss = 856.32306279\n",
      "Iteration 350, loss = 787.25293634\n",
      "Iteration 255, loss = 902.12866578\n",
      "Iteration 350, loss = 852.57649859\n",
      "Iteration 344, loss = 850.55158340\n",
      "Iteration 343, loss = 798.00404057\n",
      "Iteration 356, loss = 836.11847914\n",
      "Iteration 323, loss = 858.83516292\n",
      "Iteration 256, loss = 902.19307216\n",
      "Iteration 326, loss = 855.81980739\n",
      "Iteration 351, loss = 852.54571282\n",
      "Iteration 351, loss = 788.27005145\n",
      "Iteration 357, loss = 834.75583429\n",
      "Iteration 345, loss = 849.31557046\n",
      "Iteration 324, loss = 859.63481686\n",
      "Iteration 344, loss = 800.31099447\n",
      "Iteration 257, loss = 901.34392731\n",
      "Iteration 327, loss = 854.51290817\n",
      "Iteration 352, loss = 851.13933465\n",
      "Iteration 346, loss = 848.76769221\n",
      "Iteration 352, loss = 788.50513008\n",
      "Iteration 325, loss = 859.46485661\n",
      "Iteration 358, loss = 836.03073716\n",
      "Iteration 258, loss = 900.54398675\n",
      "Iteration 345, loss = 798.90399177\n",
      "Iteration 353, loss = 851.97382319\n",
      "Iteration 328, loss = 854.31756800\n",
      "Iteration 347, loss = 846.39859322\n",
      "Iteration 326, loss = 859.65976564\n",
      "Iteration 353, loss = 786.56124035\n",
      "Iteration 259, loss = 898.70056700\n",
      "Iteration 359, loss = 834.43912778\n",
      "Iteration 346, loss = 796.20485440\n",
      "Iteration 354, loss = 851.69896863\n",
      "Iteration 329, loss = 851.97782778\n",
      "Iteration 354, loss = 787.82119679\n",
      "Iteration 327, loss = 857.92369824\n",
      "Iteration 348, loss = 848.58733356\n",
      "Iteration 260, loss = 897.68560639\n",
      "Iteration 360, loss = 834.89798266\n",
      "Iteration 347, loss = 797.92909471\n",
      "Iteration 330, loss = 853.08042315\n",
      "Iteration 355, loss = 851.57482875\n",
      "Iteration 328, loss = 857.93351267\n",
      "Iteration 355, loss = 785.63700906\n",
      "Iteration 349, loss = 846.47851724\n",
      "Iteration 361, loss = 833.82625185\n",
      "Iteration 261, loss = 896.03556501\n",
      "Iteration 348, loss = 797.40780104\n",
      "Iteration 331, loss = 852.07453939\n",
      "Iteration 329, loss = 854.56226993\n",
      "Iteration 356, loss = 851.00308091\n",
      "Iteration 350, loss = 846.89399823\n",
      "Iteration 356, loss = 784.80140566\n",
      "Iteration 262, loss = 895.95801451\n",
      "Iteration 362, loss = 833.73701530\n",
      "Iteration 332, loss = 852.22379700\n",
      "Iteration 349, loss = 797.58878805\n",
      "Iteration 330, loss = 856.81934422\n",
      "Iteration 357, loss = 850.07995023\n",
      "Iteration 357, loss = 784.32567321\n",
      "Iteration 263, loss = 897.71010775\n",
      "Iteration 351, loss = 847.63216808\n",
      "Iteration 350, loss = 796.98414634\n",
      "Iteration 363, loss = 833.38034641\n",
      "Iteration 333, loss = 850.27550863\n",
      "Iteration 331, loss = 854.79386833\n",
      "Iteration 358, loss = 849.58001220\n",
      "Iteration 264, loss = 894.68037120\n",
      "Iteration 358, loss = 783.07562625\n",
      "Iteration 352, loss = 847.21848597\n",
      "Iteration 351, loss = 796.69979732\n",
      "Iteration 364, loss = 829.49824315\n",
      "Iteration 334, loss = 853.97183350\n",
      "Iteration 332, loss = 855.65922568\n",
      "Iteration 359, loss = 849.04925103\n",
      "Iteration 265, loss = 894.53480072\n",
      "Iteration 359, loss = 784.51961469\n",
      "Iteration 353, loss = 845.40481195\n",
      "Iteration 352, loss = 798.79292372\n",
      "Iteration 335, loss = 851.59560820\n",
      "Iteration 333, loss = 853.99108952\n",
      "Iteration 365, loss = 832.77790108\n",
      "Iteration 266, loss = 894.94658478\n",
      "Iteration 360, loss = 849.89453726\n",
      "Iteration 360, loss = 784.45692060\n",
      "Iteration 354, loss = 846.49846582\n",
      "Iteration 353, loss = 796.64957056\n",
      "Iteration 336, loss = 851.27119725\n",
      "Iteration 334, loss = 856.24572427\n",
      "Iteration 361, loss = 848.59775452\n",
      "Iteration 366, loss = 834.50955973\n",
      "Iteration 267, loss = 891.62011844\n",
      "Iteration 355, loss = 844.08436918\n",
      "Iteration 361, loss = 782.05764292\n",
      "Iteration 354, loss = 796.06421737\n",
      "Iteration 335, loss = 855.54665494\n",
      "Iteration 337, loss = 850.96298254\n",
      "Iteration 362, loss = 847.70727891\n",
      "Iteration 268, loss = 892.77634238\n",
      "Iteration 367, loss = 833.13312245\n",
      "Iteration 356, loss = 841.42063729\n",
      "Iteration 362, loss = 783.81620246\n",
      "Iteration 355, loss = 794.83780981\n",
      "Iteration 336, loss = 854.93684223\n",
      "Iteration 338, loss = 848.27254652\n",
      "Iteration 363, loss = 847.85711184\n",
      "Iteration 269, loss = 891.42178344\n",
      "Iteration 368, loss = 832.46855236\n",
      "Iteration 357, loss = 843.14561091\n",
      "Iteration 363, loss = 784.33138085\n",
      "Iteration 356, loss = 792.94335904\n",
      "Iteration 337, loss = 853.84093637\n",
      "Iteration 339, loss = 849.51174950\n",
      "Iteration 364, loss = 842.80174309\n",
      "Iteration 369, loss = 831.62499573\n",
      "Iteration 364, loss = 782.98382113\n",
      "Iteration 358, loss = 839.71071664\n",
      "Iteration 270, loss = 892.10227148\n",
      "Iteration 357, loss = 795.06756794\n",
      "Iteration 340, loss = 847.66133593\n",
      "Iteration 365, loss = 847.25382065\n",
      "Iteration 338, loss = 852.37552527\n",
      "Iteration 370, loss = 832.89807892\n",
      "Iteration 365, loss = 781.12557844\n",
      "Iteration 359, loss = 843.02550191\n",
      "Iteration 358, loss = 793.79483121\n",
      "Iteration 271, loss = 892.13029362\n",
      "Iteration 341, loss = 848.48443790\n",
      "Iteration 366, loss = 848.17530441\n",
      "Iteration 339, loss = 851.79335540\n",
      "Iteration 371, loss = 831.69556724\n",
      "Iteration 360, loss = 840.86506516\n",
      "Iteration 366, loss = 781.46381879\n",
      "Iteration 272, loss = 891.37954370\n",
      "Iteration 367, loss = 847.74036813\n",
      "Iteration 359, loss = 795.58587688\n",
      "Iteration 342, loss = 848.13000662\n",
      "Iteration 340, loss = 852.17466511\n",
      "Iteration 372, loss = 831.11434019\n",
      "Iteration 361, loss = 840.75740113\n",
      "Iteration 273, loss = 890.91562396\n",
      "Iteration 367, loss = 780.22676376\n",
      "Iteration 368, loss = 846.33259945\n",
      "Iteration 360, loss = 793.68702136\n",
      "Iteration 341, loss = 850.82063065\n",
      "Iteration 343, loss = 846.61973881\n",
      "Iteration 373, loss = 829.05022344\n",
      "Iteration 362, loss = 840.39143237\n",
      "Iteration 274, loss = 889.31351810\n",
      "Iteration 368, loss = 780.56128841\n",
      "Iteration 342, loss = 851.20281735\n",
      "Iteration 369, loss = 846.63238652\n",
      "Iteration 344, loss = 848.18296770\n",
      "Iteration 374, loss = 829.73287670\n",
      "Iteration 361, loss = 794.63824811\n",
      "Iteration 363, loss = 840.05628618\n",
      "Iteration 275, loss = 888.37048763\n",
      "Iteration 369, loss = 780.41221796\n",
      "Iteration 343, loss = 850.28585469\n",
      "Iteration 370, loss = 845.51366557\n",
      "Iteration 345, loss = 845.87393047\n",
      "Iteration 362, loss = 793.91211428\n",
      "Iteration 375, loss = 830.06238729\n",
      "Iteration 276, loss = 888.04841041\n",
      "Iteration 370, loss = 779.50025704\n",
      "Iteration 364, loss = 839.40345862\n",
      "Iteration 344, loss = 852.28944402\n",
      "Iteration 371, loss = 845.78689706\n",
      "Iteration 346, loss = 844.12512080\n",
      "Iteration 376, loss = 827.52869969\n",
      "Iteration 363, loss = 792.95684804\n",
      "Iteration 277, loss = 886.38538953\n",
      "Iteration 371, loss = 780.22467499\n",
      "Iteration 365, loss = 837.45096247\n",
      "Iteration 345, loss = 848.56536969\n",
      "Iteration 372, loss = 845.25712245\n",
      "Iteration 377, loss = 828.15493037\n",
      "Iteration 364, loss = 793.23448083\n",
      "Iteration 347, loss = 846.28193124\n",
      "Iteration 278, loss = 886.26451485\n",
      "Iteration 372, loss = 777.89589703\n",
      "Iteration 366, loss = 838.77288394\n",
      "Iteration 346, loss = 845.98910715\n",
      "Iteration 373, loss = 842.65023558\n",
      "Iteration 378, loss = 826.90088668\n",
      "Iteration 365, loss = 791.82948282\n",
      "Iteration 348, loss = 843.92035810\n",
      "Iteration 279, loss = 886.36798891\n",
      "Iteration 373, loss = 778.98020369\n",
      "Iteration 367, loss = 835.99743821\n",
      "Iteration 347, loss = 850.89524746\n",
      "Iteration 374, loss = 843.00544944\n",
      "Iteration 379, loss = 827.14847886\n",
      "Iteration 366, loss = 793.32255441\n",
      "Iteration 349, loss = 844.77677054\n",
      "Iteration 280, loss = 884.98739060\n",
      "Iteration 374, loss = 778.33051080\n",
      "Iteration 368, loss = 836.54389767\n",
      "Iteration 348, loss = 847.86040657\n",
      "Iteration 380, loss = 828.70984165\n",
      "Iteration 375, loss = 844.36430969\n",
      "Iteration 367, loss = 791.33108995\n",
      "Iteration 281, loss = 885.52927737\n",
      "Iteration 350, loss = 843.10419810\n",
      "Iteration 375, loss = 776.85657882\n",
      "Iteration 369, loss = 836.45377809\n",
      "Iteration 349, loss = 848.70496308\n",
      "Iteration 381, loss = 827.40570465\n",
      "Iteration 368, loss = 791.74268787\n",
      "Iteration 351, loss = 843.30317416\n",
      "Iteration 376, loss = 842.72617585\n",
      "Iteration 282, loss = 883.57560609\n",
      "Iteration 376, loss = 776.55971744\n",
      "Iteration 350, loss = 847.50809601\n",
      "Iteration 370, loss = 836.15563167\n",
      "Iteration 382, loss = 826.96799889\n",
      "Iteration 369, loss = 792.63821381\n",
      "Iteration 377, loss = 844.08296445\n",
      "Iteration 352, loss = 844.12085121\n",
      "Iteration 283, loss = 885.78361326\n",
      "Iteration 377, loss = 778.63896131\n",
      "Iteration 351, loss = 846.99658456\n",
      "Iteration 383, loss = 826.17537566\n",
      "Iteration 371, loss = 834.80088511\n",
      "Iteration 370, loss = 791.22089528\n",
      "Iteration 378, loss = 842.80837233\n",
      "Iteration 353, loss = 842.69054707\n",
      "Iteration 284, loss = 882.31205692\n",
      "Iteration 378, loss = 778.32659189\n",
      "Iteration 352, loss = 848.30694494\n",
      "Iteration 372, loss = 835.49312539\n",
      "Iteration 371, loss = 789.64443519\n",
      "Iteration 384, loss = 825.75665084\n",
      "Iteration 379, loss = 841.93472019\n",
      "Iteration 354, loss = 841.81192385\n",
      "Iteration 285, loss = 883.09875354\n",
      "Iteration 379, loss = 774.22156297\n",
      "Iteration 353, loss = 846.98075033\n",
      "Iteration 385, loss = 824.73315051\n",
      "Iteration 372, loss = 790.94331637\n",
      "Iteration 373, loss = 834.63942551\n",
      "Iteration 355, loss = 841.23576802\n",
      "Iteration 380, loss = 843.59067283\n",
      "Iteration 286, loss = 880.94968630\n",
      "Iteration 380, loss = 776.59914751\n",
      "Iteration 354, loss = 845.72187781\n",
      "Iteration 373, loss = 790.24295287\n",
      "Iteration 356, loss = 839.80245098\n",
      "Iteration 386, loss = 825.77603149\n",
      "Iteration 287, loss = 881.37363717\n",
      "Iteration 374, loss = 833.23119641\n",
      "Iteration 381, loss = 841.57060168\n",
      "Iteration 381, loss = 773.67038188\n",
      "Iteration 355, loss = 846.28557135\n",
      "Iteration 288, loss = 881.92812876\n",
      "Iteration 357, loss = 840.28497001\n",
      "Iteration 374, loss = 788.28631366\n",
      "Iteration 387, loss = 824.98806886\n",
      "Iteration 375, loss = 833.05093714\n",
      "Iteration 382, loss = 842.04289118\n",
      "Iteration 382, loss = 776.47746045\n",
      "Iteration 375, loss = 789.55817124\n",
      "Iteration 289, loss = 879.93327839\n",
      "Iteration 358, loss = 839.84235885\n",
      "Iteration 356, loss = 844.32903662\n",
      "Iteration 376, loss = 831.66054634\n",
      "Iteration 388, loss = 825.06013244\n",
      "Iteration 383, loss = 840.82385616\n",
      "Iteration 383, loss = 775.77925574\n",
      "Iteration 290, loss = 878.85551656\n",
      "Iteration 377, loss = 834.17587298\n",
      "Iteration 359, loss = 840.87800478\n",
      "Iteration 357, loss = 844.13033759\n",
      "Iteration 376, loss = 787.51139922\n",
      "Iteration 389, loss = 824.70673931\n",
      "Iteration 384, loss = 840.48535543\n",
      "Iteration 384, loss = 775.84640026\n",
      "Iteration 360, loss = 838.65967330\n",
      "Iteration 291, loss = 880.13173786\n",
      "Iteration 358, loss = 844.63567353\n",
      "Iteration 378, loss = 832.13673050\n",
      "Iteration 390, loss = 825.13541190\n",
      "Iteration 385, loss = 840.05348370\n",
      "Iteration 377, loss = 789.99597993\n",
      "Iteration 385, loss = 774.69269791\n",
      "Iteration 292, loss = 879.05938790\n",
      "Iteration 361, loss = 839.65984286\n",
      "Iteration 391, loss = 823.53972631\n",
      "Iteration 359, loss = 845.11837095\n",
      "Iteration 379, loss = 831.63612349\n",
      "Iteration 386, loss = 839.32253166\n",
      "Iteration 378, loss = 787.64549052\n",
      "Iteration 386, loss = 774.06535200\n",
      "Iteration 293, loss = 878.02998916\n",
      "Iteration 362, loss = 838.44848421\n",
      "Iteration 392, loss = 822.47607443\n",
      "Iteration 360, loss = 842.66824757\n",
      "Iteration 380, loss = 831.53871438\n",
      "Iteration 387, loss = 838.90851124\n",
      "Iteration 379, loss = 788.40641997\n",
      "Iteration 387, loss = 774.72324683\n",
      "Iteration 363, loss = 838.20560582\n",
      "Iteration 294, loss = 876.04667633\n",
      "Iteration 361, loss = 843.99780849\n",
      "Iteration 388, loss = 839.41331014\n",
      "Iteration 381, loss = 827.99142009\n",
      "Iteration 393, loss = 822.19135228\n",
      "Iteration 380, loss = 787.16352449\n",
      "Iteration 388, loss = 773.22108436\n",
      "Iteration 364, loss = 838.27801067\n",
      "Iteration 362, loss = 842.77134677\n",
      "Iteration 295, loss = 877.89607597\n",
      "Iteration 389, loss = 839.77812987\n",
      "Iteration 381, loss = 785.15488236\n",
      "Iteration 382, loss = 832.28667528\n",
      "Iteration 394, loss = 821.79380481\n",
      "Iteration 389, loss = 773.10041300\n",
      "Iteration 365, loss = 836.20183580\n",
      "Iteration 363, loss = 842.61955152\n",
      "Iteration 390, loss = 839.89441432\n",
      "Iteration 382, loss = 786.46695458\n",
      "Iteration 296, loss = 876.10346328\n",
      "Iteration 383, loss = 830.95871472\n",
      "Iteration 390, loss = 772.61592444\n",
      "Iteration 395, loss = 821.70879502\n",
      "Iteration 366, loss = 837.32868967\n",
      "Iteration 391, loss = 838.42383830\n",
      "Iteration 364, loss = 842.39116894\n",
      "Iteration 384, loss = 830.75248615\n",
      "Iteration 383, loss = 786.41654683\n",
      "Iteration 297, loss = 875.45352023\n",
      "Iteration 391, loss = 772.98179244\n",
      "Iteration 367, loss = 835.07898757\n",
      "Iteration 396, loss = 823.70523065\n",
      "Iteration 392, loss = 836.58779112\n",
      "Iteration 365, loss = 841.45138749\n",
      "Iteration 392, loss = 773.32708859\n",
      "Iteration 384, loss = 787.37231017\n",
      "Iteration 385, loss = 829.65473279\n",
      "Iteration 397, loss = 822.50791658\n",
      "Iteration 298, loss = 874.58317955\n",
      "Iteration 368, loss = 835.87445547\n",
      "Iteration 393, loss = 835.31011411\n",
      "Iteration 366, loss = 841.73270041\n",
      "Iteration 393, loss = 771.36723605\n",
      "Iteration 398, loss = 821.15805833\n",
      "Iteration 385, loss = 785.73181802\n",
      "Iteration 386, loss = 828.87617239\n",
      "Iteration 369, loss = 836.50025049\n",
      "Iteration 299, loss = 873.40580145\n",
      "Iteration 394, loss = 836.57621112\n",
      "Iteration 367, loss = 839.48945931\n",
      "Iteration 386, loss = 786.07030207\n",
      "Iteration 399, loss = 822.11760270\n",
      "Iteration 394, loss = 771.90975266\n",
      "Iteration 387, loss = 828.59729800\n",
      "Iteration 300, loss = 873.84806534\n",
      "Iteration 370, loss = 836.16050847\n",
      "Iteration 368, loss = 841.96704137\n",
      "Iteration 400, loss = 819.98320485\n",
      "Iteration 395, loss = 836.64813312\n",
      "Iteration 395, loss = 771.75329974\n",
      "Iteration 387, loss = 784.97667615\n",
      "Iteration 388, loss = 827.98745643\n",
      "Iteration 371, loss = 833.94198225\n",
      "Iteration 301, loss = 873.13414635\n",
      "Iteration 401, loss = 820.67155747\n",
      "Iteration 369, loss = 840.82063668\n",
      "Iteration 396, loss = 837.64871103\n",
      "Iteration 388, loss = 784.32039561\n",
      "Iteration 396, loss = 771.87128201\n",
      "Iteration 389, loss = 826.90014373\n",
      "Iteration 302, loss = 872.87515651\n",
      "Iteration 372, loss = 836.29336493\n",
      "Iteration 402, loss = 819.94075951\n",
      "Iteration 370, loss = 840.85007310\n",
      "Iteration 397, loss = 772.60790771\n",
      "Iteration 389, loss = 784.81846067\n",
      "Iteration 397, loss = 837.52754854\n",
      "Iteration 390, loss = 828.19889621\n",
      "Iteration 373, loss = 833.37284784\n",
      "Iteration 303, loss = 873.19185140\n",
      "Iteration 403, loss = 818.72125195\n",
      "Iteration 371, loss = 837.67794585\n",
      "Iteration 398, loss = 835.49850130\n",
      "Iteration 398, loss = 770.80330886\n",
      "Iteration 390, loss = 784.10600110\n",
      "Iteration 391, loss = 827.77780517\n",
      "Iteration 304, loss = 871.34088930\n",
      "Iteration 374, loss = 831.66594845\n",
      "Iteration 404, loss = 817.65710856\n",
      "Iteration 399, loss = 835.71481942\n",
      "Iteration 399, loss = 771.41499401\n",
      "Iteration 391, loss = 782.64122927\n",
      "Iteration 372, loss = 841.16109945\n",
      "Iteration 392, loss = 826.99871040\n",
      "Iteration 305, loss = 871.38624544\n",
      "Iteration 375, loss = 833.52471275\n",
      "Iteration 405, loss = 819.38176434\n",
      "Iteration 373, loss = 838.16168440\n",
      "Iteration 400, loss = 834.13709579\n",
      "Iteration 400, loss = 771.16618382\n",
      "Iteration 392, loss = 783.45230280\n",
      "Iteration 393, loss = 825.11632304\n",
      "Iteration 306, loss = 870.34072446\n",
      "Iteration 376, loss = 830.18839617\n",
      "Iteration 406, loss = 819.27512691\n",
      "Iteration 374, loss = 836.89341637\n",
      "Iteration 393, loss = 781.54618388\n",
      "Iteration 401, loss = 834.79556775\n",
      "Iteration 401, loss = 770.59549160\n",
      "Iteration 394, loss = 825.93288304\n",
      "Iteration 307, loss = 870.19777833\n",
      "Iteration 377, loss = 834.40787098\n",
      "Iteration 407, loss = 820.19372623\n",
      "Iteration 402, loss = 833.93906892\n",
      "Iteration 375, loss = 838.14510528\n",
      "Iteration 394, loss = 782.99288506\n",
      "Iteration 402, loss = 768.60614277\n",
      "Iteration 395, loss = 825.45643698\n",
      "Iteration 308, loss = 871.53663880\n",
      "Iteration 378, loss = 831.22883790\n",
      "Iteration 408, loss = 817.35984380\n",
      "Iteration 403, loss = 832.92311077\n",
      "Iteration 395, loss = 783.44635603\n",
      "Iteration 376, loss = 834.85860079\n",
      "Iteration 379, loss = 830.84951402\n",
      "Iteration 309, loss = 869.22740103\n",
      "Iteration 396, loss = 825.64388915\n",
      "Iteration 403, loss = 769.94865980\n",
      "Iteration 409, loss = 819.19800115\n",
      "Iteration 396, loss = 783.20526380\n",
      "Iteration 377, loss = 839.20090442\n",
      "Iteration 404, loss = 830.09226758\n",
      "Iteration 397, loss = 826.38763330\n",
      "Iteration 310, loss = 868.91363316\n",
      "Iteration 404, loss = 769.29057361\n",
      "Iteration 380, loss = 831.49484900\n",
      "Iteration 410, loss = 816.62399447\n",
      "Iteration 378, loss = 836.18489138\n",
      "Iteration 397, loss = 783.37614379\n",
      "Iteration 405, loss = 770.89254477\n",
      "Iteration 405, loss = 833.82550045\n",
      "Iteration 398, loss = 824.14264050\n",
      "Iteration 311, loss = 867.85013521\n",
      "Iteration 381, loss = 829.70639616\n",
      "Iteration 411, loss = 817.39376913\n",
      "Iteration 379, loss = 836.21073893\n",
      "Iteration 398, loss = 784.00768560\n",
      "Iteration 399, loss = 825.09777735\n",
      "Iteration 312, loss = 868.61510959\n",
      "Iteration 406, loss = 768.29936781\n",
      "Iteration 406, loss = 832.60818759\n",
      "Iteration 382, loss = 830.25285532\n",
      "Iteration 412, loss = 816.57351378\n",
      "Iteration 380, loss = 836.54094513\n",
      "Iteration 399, loss = 782.23590976\n",
      "Iteration 313, loss = 867.70240897\n",
      "Iteration 400, loss = 824.11662877\n",
      "Iteration 407, loss = 766.85759139\n",
      "Iteration 407, loss = 831.70639479\n",
      "Iteration 383, loss = 830.37228272\n",
      "Iteration 413, loss = 817.56197662\n",
      "Iteration 381, loss = 835.25877314\n",
      "Iteration 400, loss = 781.69762262\n",
      "Iteration 314, loss = 868.36260091\n",
      "Iteration 401, loss = 823.27362764\n",
      "Iteration 408, loss = 829.98513559\n",
      "Iteration 408, loss = 767.47828820\n",
      "Iteration 384, loss = 828.89632669\n",
      "Iteration 414, loss = 815.14413925\n",
      "Iteration 382, loss = 834.39931354\n",
      "Iteration 401, loss = 781.30760047\n",
      "Iteration 315, loss = 868.85204791\n",
      "Iteration 409, loss = 831.56989184\n",
      "Iteration 402, loss = 822.75216221\n",
      "Iteration 409, loss = 767.44470804\n",
      "Iteration 415, loss = 816.37507910\n",
      "Iteration 383, loss = 834.81893506\n",
      "Iteration 385, loss = 829.00336293\n",
      "Iteration 402, loss = 780.14687595\n",
      "Iteration 316, loss = 867.60853433\n",
      "Iteration 403, loss = 824.06786186\n",
      "Iteration 416, loss = 815.55641963\n",
      "Iteration 410, loss = 767.73528625\n",
      "Iteration 410, loss = 828.05801642\n",
      "Iteration 386, loss = 830.19266620\n",
      "Iteration 384, loss = 834.20266220\n",
      "Iteration 403, loss = 781.16803482\n",
      "Iteration 317, loss = 865.98467027\n",
      "Iteration 404, loss = 821.55714572\n",
      "Iteration 417, loss = 813.86457878\n",
      "Iteration 411, loss = 768.19778151\n",
      "Iteration 411, loss = 829.76084729\n",
      "Iteration 387, loss = 828.46763773\n",
      "Iteration 404, loss = 780.55309828\n",
      "Iteration 385, loss = 834.80225663\n",
      "Iteration 318, loss = 865.44616976\n",
      "Iteration 405, loss = 821.98652344\n",
      "Iteration 418, loss = 816.27013868\n",
      "Iteration 412, loss = 828.59828599\n",
      "Iteration 412, loss = 768.78531744\n",
      "Iteration 386, loss = 834.63947647\n",
      "Iteration 388, loss = 826.91980279\n",
      "Iteration 405, loss = 779.81539612\n",
      "Iteration 319, loss = 864.97914796\n",
      "Iteration 406, loss = 821.09876087\n",
      "Iteration 413, loss = 830.55986699\n",
      "Iteration 419, loss = 814.10665676\n",
      "Iteration 413, loss = 767.71917472\n",
      "Iteration 389, loss = 828.57012512\n",
      "Iteration 406, loss = 779.94992993\n",
      "Iteration 387, loss = 833.57427454\n",
      "Iteration 320, loss = 864.61590006\n",
      "Iteration 407, loss = 820.36059132\n",
      "Iteration 414, loss = 826.65572052\n",
      "Iteration 420, loss = 813.74594644\n",
      "Iteration 414, loss = 765.73672683\n",
      "Iteration 390, loss = 828.11902448\n",
      "Iteration 407, loss = 778.08586372\n",
      "Iteration 388, loss = 832.87237414\n",
      "Iteration 408, loss = 819.76559755\n",
      "Iteration 321, loss = 863.25765072\n",
      "Iteration 415, loss = 828.21411053\n",
      "Iteration 421, loss = 813.63418269\n",
      "Iteration 408, loss = 778.29487235\n",
      "Iteration 391, loss = 825.05895195\n",
      "Iteration 415, loss = 765.25809217\n",
      "Iteration 389, loss = 833.78865533\n",
      "Iteration 409, loss = 819.14561550\n",
      "Iteration 322, loss = 865.00790624\n",
      "Iteration 416, loss = 826.29297669\n",
      "Iteration 392, loss = 827.50246314\n",
      "Iteration 422, loss = 813.71167815\n",
      "Iteration 409, loss = 778.19822646\n",
      "Iteration 416, loss = 767.08145166\n",
      "Iteration 390, loss = 832.46661174\n",
      "Iteration 417, loss = 825.73413136\n",
      "Iteration 410, loss = 820.83085517\n",
      "Iteration 323, loss = 861.90081062\n",
      "Iteration 393, loss = 824.01596545\n",
      "Iteration 423, loss = 812.84249514\n",
      "Iteration 410, loss = 778.16490115\n",
      "Iteration 391, loss = 830.40203873\n",
      "Iteration 417, loss = 765.80017813\n",
      "Iteration 418, loss = 826.87062442\n",
      "Iteration 324, loss = 862.97127646\n",
      "Iteration 411, loss = 779.32552600\n",
      "Iteration 411, loss = 820.87652504\n",
      "Iteration 424, loss = 812.36363229\n",
      "Iteration 394, loss = 826.86808541\n",
      "Iteration 418, loss = 766.55952390\n",
      "Iteration 392, loss = 831.71843530\n",
      "Iteration 419, loss = 824.88464012\n",
      "Iteration 325, loss = 863.29845962\n",
      "Iteration 412, loss = 779.94688217\n",
      "Iteration 425, loss = 812.47445093\n",
      "Iteration 393, loss = 829.99972514\n",
      "Iteration 412, loss = 820.73830998\n",
      "Iteration 419, loss = 766.33971479\n",
      "Iteration 395, loss = 826.02636849\n",
      "Iteration 326, loss = 863.00189079\n",
      "Iteration 420, loss = 825.57474272\n",
      "Iteration 426, loss = 813.62831093\n",
      "Iteration 413, loss = 777.63471091\n",
      "Iteration 394, loss = 831.31042954\n",
      "Iteration 396, loss = 825.20134036\n",
      "Iteration 420, loss = 765.28728064\n",
      "Iteration 413, loss = 819.88496670\n",
      "Iteration 421, loss = 823.97451002\n",
      "Iteration 327, loss = 861.86320428\n",
      "Iteration 427, loss = 811.65788883\n",
      "Iteration 414, loss = 775.33461142\n",
      "Iteration 397, loss = 826.61388852\n",
      "Iteration 421, loss = 765.59426932\n",
      "Iteration 395, loss = 831.19160360\n",
      "Iteration 414, loss = 818.71527725\n",
      "Iteration 422, loss = 824.75440198\n",
      "Iteration 328, loss = 861.17192832\n",
      "Iteration 428, loss = 812.91297097\n",
      "Iteration 396, loss = 830.31094500\n",
      "Iteration 398, loss = 827.47765277\n",
      "Iteration 415, loss = 777.84032292\n",
      "Iteration 422, loss = 763.44183918\n",
      "Iteration 415, loss = 817.55194982\n",
      "Iteration 397, loss = 831.36504283\n",
      "Iteration 423, loss = 823.94543118\n",
      "Iteration 329, loss = 858.90199257\n",
      "Iteration 429, loss = 812.07414193\n",
      "Iteration 416, loss = 777.95988454\n",
      "Iteration 399, loss = 824.80413811\n",
      "Iteration 423, loss = 763.68938227\n",
      "Iteration 416, loss = 818.67382483\n",
      "Iteration 424, loss = 824.13137473\n",
      "Iteration 398, loss = 833.73364310\n",
      "Iteration 430, loss = 812.39688832\n",
      "Iteration 330, loss = 860.16730647\n",
      "Iteration 400, loss = 825.01082495\n",
      "Iteration 417, loss = 776.96159198\n",
      "Iteration 424, loss = 762.86348601\n",
      "Iteration 417, loss = 818.09263116\n",
      "Iteration 399, loss = 829.46542626\n",
      "Iteration 425, loss = 823.78896102\n",
      "Iteration 431, loss = 812.23229132\n",
      "Iteration 331, loss = 859.03997870\n",
      "Iteration 418, loss = 777.60269295\n",
      "Iteration 401, loss = 823.87525932\n",
      "Iteration 425, loss = 763.01966579\n",
      "Iteration 418, loss = 817.82235815\n",
      "Iteration 400, loss = 830.07880315\n",
      "Iteration 426, loss = 824.36279855\n",
      "Iteration 332, loss = 859.66403053\n",
      "Iteration 432, loss = 810.96549404\n",
      "Iteration 419, loss = 777.72934476\n",
      "Iteration 402, loss = 822.45136777\n",
      "Iteration 426, loss = 763.20492297\n",
      "Iteration 419, loss = 818.30519854\n",
      "Iteration 401, loss = 829.11443627\n",
      "Iteration 427, loss = 821.39705791\n",
      "Iteration 433, loss = 811.08482571\n",
      "Iteration 333, loss = 857.55802618\n",
      "Iteration 420, loss = 777.42607011\n",
      "Iteration 403, loss = 824.00475301\n",
      "Iteration 420, loss = 817.40969066\n",
      "Iteration 427, loss = 763.11425649\n",
      "Iteration 402, loss = 828.64183428\n",
      "Iteration 428, loss = 823.51354311\n",
      "Iteration 334, loss = 860.15365302\n",
      "Iteration 434, loss = 810.92897746\n",
      "Iteration 421, loss = 777.88509235\n",
      "Iteration 404, loss = 823.95519133\n",
      "Iteration 421, loss = 818.71085296\n",
      "Iteration 428, loss = 762.30686694\n",
      "Iteration 403, loss = 828.67008029\n",
      "Iteration 429, loss = 822.81391764\n",
      "Iteration 422, loss = 775.20551330\n",
      "Iteration 335, loss = 858.76583699\n",
      "Iteration 435, loss = 810.86127497\n",
      "Iteration 405, loss = 823.16596440\n",
      "Iteration 429, loss = 762.96675189\n",
      "Iteration 422, loss = 816.20473556\n",
      "Iteration 404, loss = 829.85653496\n",
      "Iteration 423, loss = 774.83214323\n",
      "Iteration 430, loss = 824.15705236\n",
      "Iteration 436, loss = 810.36916659\n",
      "Iteration 336, loss = 858.14279350\n",
      "Iteration 406, loss = 821.90825983\n",
      "Iteration 430, loss = 762.47232226\n",
      "Iteration 423, loss = 815.41115250\n",
      "Iteration 405, loss = 827.93393852\n",
      "Iteration 431, loss = 823.61511789\n",
      "Iteration 424, loss = 776.49247957\n",
      "Iteration 437, loss = 810.98468226\n",
      "Iteration 337, loss = 856.91974725\n",
      "Iteration 407, loss = 820.95519088\n",
      "Iteration 431, loss = 761.11613084\n",
      "Iteration 424, loss = 814.39675903\n",
      "Iteration 406, loss = 827.76688448\n",
      "Iteration 432, loss = 821.81535583\n",
      "Iteration 425, loss = 775.38236191\n",
      "Iteration 438, loss = 810.07306621\n",
      "Iteration 338, loss = 856.92717027\n",
      "Iteration 408, loss = 820.69122317\n",
      "Iteration 432, loss = 763.99676564\n",
      "Iteration 407, loss = 827.33700455\n",
      "Iteration 426, loss = 774.74032280\n",
      "Iteration 425, loss = 815.27162903\n",
      "Iteration 339, loss = 855.55370942\n",
      "Iteration 433, loss = 822.27699991\n",
      "Iteration 439, loss = 809.88860169\n",
      "Iteration 409, loss = 820.65928586\n",
      "Iteration 433, loss = 760.38603447\n",
      "Iteration 408, loss = 825.03723816\n",
      "Iteration 427, loss = 775.17509734\n",
      "Iteration 426, loss = 814.80731058\n",
      "Iteration 434, loss = 822.24601454\n",
      "Iteration 440, loss = 810.77725959\n",
      "Iteration 340, loss = 855.60022852\n",
      "Iteration 410, loss = 819.44232853\n",
      "Iteration 409, loss = 826.69443835\n",
      "Iteration 434, loss = 760.78323568\n",
      "Iteration 428, loss = 774.48399225\n",
      "Iteration 427, loss = 815.34044613\n",
      "Iteration 341, loss = 856.01264771\n",
      "Iteration 441, loss = 808.96275553\n",
      "Iteration 435, loss = 821.10504358\n",
      "Iteration 411, loss = 822.06921489\n",
      "Iteration 435, loss = 761.28236891\n",
      "Iteration 410, loss = 824.70509164\n",
      "Iteration 429, loss = 774.15994784\n",
      "Iteration 428, loss = 814.25444693\n",
      "Iteration 436, loss = 820.72925838\n",
      "Iteration 442, loss = 809.50265884\n",
      "Iteration 342, loss = 855.02241551\n",
      "Iteration 412, loss = 821.26874480\n",
      "Iteration 436, loss = 758.73075574\n",
      "Iteration 411, loss = 827.91119978\n",
      "Iteration 430, loss = 774.96125429\n",
      "Iteration 429, loss = 813.50086860\n",
      "Iteration 443, loss = 809.15709651\n",
      "Iteration 437, loss = 820.65269611\n",
      "Iteration 343, loss = 854.34005861\n",
      "Iteration 413, loss = 819.14069755\n",
      "Iteration 437, loss = 762.51268096\n",
      "Iteration 431, loss = 773.90910813\n",
      "Iteration 412, loss = 826.38228704\n",
      "Iteration 430, loss = 814.74478018\n",
      "Iteration 444, loss = 808.19524507\n",
      "Iteration 344, loss = 855.03872880\n",
      "Iteration 438, loss = 820.21850818\n",
      "Iteration 414, loss = 816.76412350\n",
      "Iteration 438, loss = 760.12043463\n",
      "Iteration 432, loss = 776.08447187\n",
      "Iteration 413, loss = 824.33024928\n",
      "Iteration 431, loss = 813.68928926\n",
      "Iteration 445, loss = 807.66958459\n",
      "Iteration 345, loss = 853.20327892\n",
      "Iteration 439, loss = 821.18913478\n",
      "Iteration 415, loss = 819.76193676\n",
      "Iteration 433, loss = 773.92179735\n",
      "Iteration 439, loss = 756.08036940\n",
      "Iteration 414, loss = 823.14216168\n",
      "Iteration 432, loss = 815.63070396\n",
      "Iteration 346, loss = 850.64937203\n",
      "Iteration 446, loss = 808.49546804\n",
      "Iteration 440, loss = 821.69694511\n",
      "Iteration 416, loss = 819.86465322\n",
      "Iteration 434, loss = 772.55061329\n",
      "Iteration 440, loss = 758.86963475\n",
      "Iteration 415, loss = 824.95788572\n",
      "Iteration 433, loss = 811.77113518\n",
      "Iteration 347, loss = 853.35914799\n",
      "Iteration 447, loss = 808.43804932\n",
      "Iteration 441, loss = 820.10054588\n",
      "Iteration 417, loss = 819.04193404\n",
      "Iteration 435, loss = 774.17199441\n",
      "Iteration 416, loss = 825.20700067\n",
      "Iteration 441, loss = 760.15443523\n",
      "Iteration 434, loss = 812.12121439\n",
      "Iteration 348, loss = 851.69123469\n",
      "Iteration 448, loss = 807.29762926\n",
      "Iteration 442, loss = 821.12940652\n",
      "Iteration 418, loss = 818.79287715\n",
      "Iteration 436, loss = 772.38121569\n",
      "Iteration 417, loss = 823.80571647\n",
      "Iteration 442, loss = 758.73681068\n",
      "Iteration 435, loss = 812.51862589\n",
      "Iteration 449, loss = 807.53650475\n",
      "Iteration 349, loss = 852.52925603\n",
      "Iteration 443, loss = 819.30800303\n",
      "Iteration 419, loss = 819.62532121\n",
      "Iteration 418, loss = 824.75860039\n",
      "Iteration 437, loss = 772.85846182\n",
      "Iteration 443, loss = 760.44674847\n",
      "Iteration 436, loss = 809.56801150\n",
      "Iteration 450, loss = 806.66626764\n",
      "Iteration 350, loss = 851.54445889\n",
      "Iteration 444, loss = 819.57598321\n",
      "Iteration 420, loss = 817.81003124\n",
      "Iteration 419, loss = 824.81780534\n",
      "Iteration 438, loss = 773.17634345\n",
      "Iteration 437, loss = 811.46743073\n",
      "Iteration 444, loss = 759.26196482\n",
      "Iteration 351, loss = 851.06601759\n",
      "Iteration 451, loss = 806.86365154\n",
      "Iteration 445, loss = 819.02366481\n",
      "Iteration 421, loss = 820.11395127\n",
      "Iteration 420, loss = 822.72054565\n",
      "Iteration 439, loss = 771.54695983\n",
      "Iteration 445, loss = 757.94119134\n",
      "Iteration 452, loss = 807.27439069\n",
      "Iteration 352, loss = 851.93072010\n",
      "Iteration 438, loss = 810.96427646\n",
      "Iteration 446, loss = 818.15078220\n",
      "Iteration 421, loss = 825.46030199\n",
      "Iteration 422, loss = 816.76834467\n",
      "Iteration 446, loss = 758.90803152\n",
      "Iteration 440, loss = 770.01716930\n",
      "Iteration 439, loss = 808.13925079\n",
      "Iteration 353, loss = 850.74712424\n",
      "Iteration 453, loss = 806.92592346\n",
      "Iteration 447, loss = 819.73097206\n",
      "Iteration 422, loss = 821.98906904\n",
      "Iteration 447, loss = 758.53733840\n",
      "Iteration 423, loss = 816.63636884\n",
      "Iteration 441, loss = 772.87846198\n",
      "Iteration 440, loss = 808.34697659\n",
      "Iteration 354, loss = 850.02753714\n",
      "Iteration 454, loss = 806.09694152\n",
      "Iteration 448, loss = 818.22366804\n",
      "Iteration 423, loss = 821.63954152\n",
      "Iteration 448, loss = 758.50864720\n",
      "Iteration 424, loss = 817.47875348\n",
      "Iteration 442, loss = 772.23645260\n",
      "Iteration 441, loss = 811.12347191\n",
      "Iteration 449, loss = 817.87207125\n",
      "Iteration 455, loss = 806.25135277\n",
      "Iteration 355, loss = 850.20137736\n",
      "Iteration 424, loss = 822.08680348\n",
      "Iteration 449, loss = 759.45122533\n",
      "Iteration 425, loss = 816.88336713\n",
      "Iteration 443, loss = 772.98093619\n",
      "Iteration 442, loss = 809.02196643\n",
      "Iteration 425, loss = 821.42637308\n",
      "Iteration 456, loss = 804.98656174\n",
      "Iteration 450, loss = 817.08068774\n",
      "Iteration 450, loss = 759.01770114\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 356, loss = 849.04720341\n",
      "Iteration 426, loss = 815.83506005\n",
      "Iteration 444, loss = 772.18233841\n",
      "Iteration 443, loss = 810.08082375\n",
      "Iteration 457, loss = 805.16816741\n",
      "Iteration 426, loss = 821.63479541\n",
      "Iteration 451, loss = 817.64220901\n",
      "Iteration 357, loss = 848.04172504\n",
      "Iteration 427, loss = 815.97622671\n",
      "Iteration 445, loss = 771.11616647\n",
      "Iteration 1, loss = 11562.33615222\n",
      "Iteration 444, loss = 808.51316019\n",
      "Iteration 458, loss = 806.29066632\n",
      "Iteration 427, loss = 821.98392593\n",
      "Iteration 452, loss = 818.34670061\n",
      "Iteration 358, loss = 848.99725473\n",
      "Iteration 428, loss = 816.09647916\n",
      "Iteration 446, loss = 767.24807461\n",
      "Iteration 2, loss = 10329.49226993\n",
      "Iteration 445, loss = 807.83770186\n",
      "Iteration 459, loss = 803.85166494\n",
      "Iteration 428, loss = 820.34676192\n",
      "Iteration 453, loss = 818.48197660\n",
      "Iteration 359, loss = 850.19922669\n",
      "Iteration 447, loss = 771.23794556\n",
      "Iteration 429, loss = 814.73676441\n",
      "Iteration 3, loss = 9657.33761297\n",
      "Iteration 446, loss = 806.63667509\n",
      "Iteration 460, loss = 804.77181068\n",
      "Iteration 454, loss = 817.46314298\n",
      "Iteration 360, loss = 846.42837906\n",
      "Iteration 448, loss = 770.31725988\n",
      "Iteration 430, loss = 814.59171636\n",
      "Iteration 429, loss = 822.48702486\n",
      "Iteration 4, loss = 9028.43411186\n",
      "Iteration 447, loss = 808.98891853Iteration 461, loss = 803.80566755\n",
      "\n",
      "Iteration 455, loss = 816.05997817\n",
      "Iteration 361, loss = 847.68614680\n",
      "Iteration 449, loss = 771.53323490\n",
      "Iteration 430, loss = 820.18028197\n",
      "Iteration 431, loss = 813.49929882\n",
      "Iteration 462, loss = 804.97922707\n",
      "Iteration 5, loss = 8466.08201439\n",
      "Iteration 448, loss = 806.97424043\n",
      "Iteration 456, loss = 815.24447547\n",
      "Iteration 362, loss = 847.00850722\n",
      "Iteration 450, loss = 771.92221568\n",
      "Iteration 431, loss = 818.92889379\n",
      "Iteration 432, loss = 816.68170063\n",
      "Iteration 463, loss = 804.68514457\n",
      "Iteration 6, loss = 7984.57085172\n",
      "Iteration 449, loss = 809.81364496\n",
      "Iteration 363, loss = 847.08283939\n",
      "Iteration 451, loss = 769.83112544\n",
      "Iteration 432, loss = 821.70599462\n",
      "Iteration 457, loss = 816.56258828\n",
      "Iteration 464, loss = 800.40310502\n",
      "Iteration 433, loss = 813.86040058\n",
      "Iteration 450, loss = 807.70490606\n",
      "Iteration 7, loss = 7561.08537249\n",
      "Iteration 433, loss = 820.16733127\n",
      "Iteration 452, loss = 769.95174547\n",
      "Iteration 364, loss = 846.27707495\n",
      "Iteration 434, loss = 814.61643468\n",
      "Iteration 465, loss = 802.76475083\n",
      "Iteration 458, loss = 817.60358569\n",
      "Iteration 8, loss = 7183.11606382\n",
      "Iteration 451, loss = 807.30157045\n",
      "Iteration 453, loss = 770.71644786\n",
      "Iteration 434, loss = 820.20786588\n",
      "Iteration 365, loss = 845.33328404\n",
      "Iteration 466, loss = 801.92516250\n",
      "Iteration 435, loss = 813.94010263\n",
      "Iteration 9, loss = 6844.52372921\n",
      "Iteration 452, loss = 807.01489859\n",
      "Iteration 459, loss = 815.37400151\n",
      "Iteration 454, loss = 768.80204001\n",
      "Iteration 366, loss = 845.97684831\n",
      "Iteration 435, loss = 819.48293494\n",
      "Iteration 467, loss = 801.23876555\n",
      "Iteration 436, loss = 812.38927486\n",
      "Iteration 10, loss = 6532.89870186\n",
      "Iteration 453, loss = 807.08445765\n",
      "Iteration 455, loss = 769.38717546\n",
      "Iteration 460, loss = 815.71679102\n",
      "Iteration 436, loss = 818.29362809\n",
      "Iteration 367, loss = 844.39659452\n",
      "Iteration 468, loss = 802.50600780\n",
      "Iteration 437, loss = 812.78256252\n",
      "Iteration 11, loss = 6245.33883182\n",
      "Iteration 454, loss = 805.17328199\n",
      "Iteration 456, loss = 769.56750291\n",
      "Iteration 461, loss = 814.03522076\n",
      "Iteration 437, loss = 819.72452324\n",
      "Iteration 368, loss = 846.06913883\n",
      "Iteration 469, loss = 803.44329628\n",
      "Iteration 12, loss = 5978.52830131\n",
      "Iteration 455, loss = 805.20807857\n",
      "Iteration 438, loss = 813.76816479\n",
      "Iteration 457, loss = 769.10067432\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 462, loss = 816.10915594\n",
      "Iteration 438, loss = 819.02466993\n",
      "Iteration 369, loss = 844.89341295\n",
      "Iteration 470, loss = 800.53978726\n",
      "Iteration 456, loss = 806.14963751\n",
      "Iteration 439, loss = 811.76623341\n",
      "Iteration 13, loss = 5730.37380303\n",
      "Iteration 463, loss = 814.87980979\n",
      "Iteration 439, loss = 816.98054824\n",
      "Iteration 1, loss = 11487.71390167\n",
      "Iteration 370, loss = 844.49762354\n",
      "Iteration 471, loss = 802.29335843\n",
      "Iteration 14, loss = 5499.68245546\n",
      "Iteration 457, loss = 805.02116875\n",
      "Iteration 440, loss = 809.94471399\n",
      "Iteration 464, loss = 811.99950132\n",
      "Iteration 2, loss = 10251.18304249\n",
      "Iteration 472, loss = 799.93561938\n",
      "Iteration 371, loss = 841.08105947\n",
      "Iteration 458, loss = 804.83967592\n",
      "Iteration 441, loss = 813.73090619\n",
      "Iteration 440, loss = 815.10845970\n",
      "Iteration 15, loss = 5285.91888231\n",
      "Iteration 465, loss = 813.55882379\n",
      "Iteration 3, loss = 9576.25411805\n",
      "Iteration 459, loss = 804.86174249\n",
      "Iteration 372, loss = 844.81123132\n",
      "Iteration 473, loss = 802.15763920\n",
      "Iteration 442, loss = 811.64993072\n",
      "Iteration 441, loss = 819.10709595\n",
      "Iteration 16, loss = 5089.02042889\n",
      "Iteration 466, loss = 812.57995258\n",
      "Iteration 4, loss = 8947.38829447\n",
      "Iteration 474, loss = 799.62610150\n",
      "Iteration 460, loss = 804.75101696\n",
      "Iteration 373, loss = 842.18335471\n",
      "Iteration 17, loss = 4905.10246928\n",
      "Iteration 442, loss = 817.49942449\n",
      "Iteration 443, loss = 812.72529216\n",
      "Iteration 467, loss = 813.68330455\n",
      "Iteration 5, loss = 8384.53009856\n",
      "Iteration 475, loss = 801.47754341\n",
      "Iteration 461, loss = 803.42694750\n",
      "Iteration 443, loss = 817.76645489\n",
      "Iteration 374, loss = 840.95937336\n",
      "Iteration 18, loss = 4733.69919542\n",
      "Iteration 444, loss = 810.27743686\n",
      "Iteration 468, loss = 812.92517038\n",
      "Iteration 6, loss = 7904.20214519\n",
      "Iteration 462, loss = 803.84149479\n",
      "Iteration 476, loss = 801.06672444\n",
      "Iteration 444, loss = 815.09700508\n",
      "Iteration 375, loss = 842.47138317\n",
      "Iteration 19, loss = 4575.19344315\n",
      "Iteration 445, loss = 810.13146235\n",
      "Iteration 469, loss = 814.15316587\n",
      "Iteration 463, loss = 802.11050901\n",
      "Iteration 7, loss = 7482.84291747\n",
      "Iteration 376, loss = 839.83347449\n",
      "Iteration 477, loss = 800.44468030\n",
      "Iteration 20, loss = 4425.18016197\n",
      "Iteration 445, loss = 816.81107071\n",
      "Iteration 446, loss = 807.29037630\n",
      "Iteration 470, loss = 810.19084330\n",
      "Iteration 8, loss = 7106.08406464\n",
      "Iteration 478, loss = 800.38524721\n",
      "Iteration 464, loss = 802.93295708\n",
      "Iteration 377, loss = 842.77667338\n",
      "Iteration 21, loss = 4284.71477810\n",
      "Iteration 447, loss = 811.89397223\n",
      "Iteration 446, loss = 812.28960770\n",
      "Iteration 471, loss = 813.06701454\n",
      "Iteration 479, loss = 800.40361952\n",
      "Iteration 9, loss = 6767.48749113\n",
      "Iteration 465, loss = 803.91336165\n",
      "Iteration 378, loss = 840.13462961\n",
      "Iteration 22, loss = 4152.28295471\n",
      "Iteration 448, loss = 809.35220106\n",
      "Iteration 447, loss = 817.93700815\n",
      "Iteration 472, loss = 812.68239875\n",
      "Iteration 10, loss = 6456.82186900\n",
      "Iteration 480, loss = 800.16690319\n",
      "Iteration 466, loss = 801.91107972\n",
      "Iteration 379, loss = 839.25107036\n",
      "Iteration 23, loss = 4027.26289480\n",
      "Iteration 449, loss = 810.63854073\n",
      "Iteration 448, loss = 814.85581185\n",
      "Iteration 473, loss = 812.99040969\n",
      "Iteration 11, loss = 6171.87027276\n",
      "Iteration 380, loss = 841.53530911\n",
      "Iteration 481, loss = 800.01632317\n",
      "Iteration 467, loss = 801.38023917\n",
      "Iteration 24, loss = 3908.66377929\n",
      "Iteration 450, loss = 809.82480652\n",
      "Iteration 449, loss = 816.04775020\n",
      "Iteration 474, loss = 811.23486339\n",
      "Iteration 12, loss = 5908.90233981\n",
      "Iteration 381, loss = 838.90356403\n",
      "Iteration 482, loss = 800.07335378\n",
      "Iteration 468, loss = 799.09841582\n",
      "Iteration 451, loss = 809.11584165\n",
      "Iteration 25, loss = 3796.36545877\n",
      "Iteration 450, loss = 814.47359240\n",
      "Iteration 475, loss = 813.85371445\n",
      "Iteration 13, loss = 5663.31326457\n",
      "Iteration 382, loss = 839.10955005\n",
      "Iteration 469, loss = 802.02623802\n",
      "Iteration 483, loss = 799.16458801\n",
      "Iteration 26, loss = 3689.41376091\n",
      "Iteration 452, loss = 808.32308637\n",
      "Iteration 476, loss = 811.39784997\n",
      "Iteration 451, loss = 815.05042558\n",
      "Iteration 14, loss = 5435.55677105\n",
      "Iteration 470, loss = 801.23664767\n",
      "Iteration 484, loss = 797.01951951\n",
      "Iteration 383, loss = 839.35128639\n",
      "Iteration 27, loss = 3587.26154257\n",
      "Iteration 453, loss = 810.02795753\n",
      "Iteration 477, loss = 812.92376571\n",
      "Iteration 452, loss = 812.84694273\n",
      "Iteration 15, loss = 5225.81250230\n",
      "Iteration 471, loss = 800.46954566\n",
      "Iteration 384, loss = 837.86933036\n",
      "Iteration 485, loss = 800.12358794\n",
      "Iteration 28, loss = 3490.78644337\n",
      "Iteration 454, loss = 808.55008957\n",
      "Iteration 453, loss = 815.30062443\n",
      "Iteration 478, loss = 811.09981922\n",
      "Iteration 16, loss = 5033.13741935\n",
      "Iteration 385, loss = 838.83119901\n",
      "Iteration 29, loss = 3397.58078167\n",
      "Iteration 472, loss = 800.87660338\n",
      "Iteration 479, loss = 811.72058266\n",
      "Iteration 486, loss = 798.86683687\n",
      "Iteration 454, loss = 813.13676737\n",
      "Iteration 455, loss = 808.33455166\n",
      "Iteration 17, loss = 4852.54498944\n",
      "Iteration 386, loss = 838.59434944\n",
      "Iteration 30, loss = 3308.68382965\n",
      "Iteration 480, loss = 811.32615986\n",
      "Iteration 473, loss = 799.84912002\n",
      "Iteration 455, loss = 813.61748494\n",
      "Iteration 487, loss = 796.93463907\n",
      "Iteration 456, loss = 808.71603064\n",
      "Iteration 18, loss = 4683.15021691\n",
      "Iteration 387, loss = 837.47370450\n",
      "Iteration 456, loss = 814.97034476\n",
      "Iteration 31, loss = 3223.24010994\n",
      "Iteration 474, loss = 799.20823436\n",
      "Iteration 481, loss = 811.72586360\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 488, loss = 798.03787349\n",
      "Iteration 457, loss = 807.46282503\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 4526.18207868\n",
      "Iteration 388, loss = 837.12344445\n",
      "Iteration 475, loss = 798.60772696\n",
      "Iteration 32, loss = 3141.96336284\n",
      "Iteration 489, loss = 798.04639564\n",
      "Iteration 457, loss = 813.03018116\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 9388.49937711\n",
      "Iteration 20, loss = 4378.93661767\n",
      "Iteration 389, loss = 838.34929315\n",
      "Iteration 1, loss = 9755.80633276\n",
      "Iteration 33, loss = 3062.80582187\n",
      "Iteration 476, loss = 799.33021414\n",
      "Iteration 490, loss = 797.62479011\n",
      "Iteration 21, loss = 4240.06377833\n",
      "Iteration 390, loss = 837.32320274\n",
      "Iteration 2, loss = 6947.00245765\n",
      "Iteration 1, loss = 9523.87473239\n",
      "Iteration 2, loss = 7242.60241342\n",
      "Iteration 34, loss = 2987.96126702\n",
      "Iteration 477, loss = 798.91502413\n",
      "Iteration 491, loss = 797.41449298\n",
      "Iteration 22, loss = 4109.50009986\n",
      "Iteration 391, loss = 834.88132236\n",
      "Iteration 478, loss = 797.56935728\n",
      "Iteration 3, loss = 5725.01896344\n",
      "Iteration 35, loss = 2916.35630134\n",
      "Iteration 2, loss = 6999.40297084\n",
      "Iteration 492, loss = 795.30875593\n",
      "Iteration 23, loss = 3986.55578113\n",
      "Iteration 3, loss = 5971.20569670\n",
      "Iteration 392, loss = 835.01984589\n",
      "Iteration 493, loss = 798.71358236\n",
      "Iteration 479, loss = 799.56566802\n",
      "Iteration 24, loss = 3869.86793807\n",
      "Iteration 36, loss = 2846.96211377\n",
      "Iteration 3, loss = 5733.43867197\n",
      "Iteration 4, loss = 4904.97021097\n",
      "Iteration 4, loss = 5117.81771521\n",
      "Iteration 393, loss = 834.59106737\n",
      "Iteration 494, loss = 795.53026546\n",
      "Iteration 480, loss = 797.10191971\n",
      "Iteration 25, loss = 3759.54541952\n",
      "Iteration 37, loss = 2780.02682655\n",
      "Iteration 394, loss = 835.16740163\n",
      "Iteration 4, loss = 4891.08035523\n",
      "Iteration 5, loss = 4310.12431032\n",
      "Iteration 5, loss = 4486.12027132\n",
      "Iteration 495, loss = 797.09391789\n",
      "Iteration 481, loss = 798.42937874\n",
      "Iteration 26, loss = 3655.30338572\n",
      "Iteration 38, loss = 2717.55919718\n",
      "Iteration 395, loss = 835.94115579\n",
      "Iteration 5, loss = 4270.22552063\n",
      "Iteration 496, loss = 796.63899237\n",
      "Iteration 6, loss = 3823.44142662\n",
      "Iteration 27, loss = 3555.60281351\n",
      "Iteration 482, loss = 797.36615874\n",
      "Iteration 39, loss = 2657.03109468\n",
      "Iteration 6, loss = 3976.08931167\n",
      "Iteration 396, loss = 834.31396357\n",
      "Iteration 497, loss = 797.16475031\n",
      "Iteration 483, loss = 797.75365103\n",
      "Iteration 6, loss = 3773.06758854\n",
      "Iteration 28, loss = 3460.32686376\n",
      "Iteration 40, loss = 2599.37193758\n",
      "Iteration 7, loss = 3435.94684570\n",
      "Iteration 397, loss = 837.01957214\n",
      "Iteration 7, loss = 3577.03223176\n",
      "Iteration 498, loss = 797.64663225\n",
      "Iteration 29, loss = 3369.02055847\n",
      "Iteration 41, loss = 2543.03652702\n",
      "Iteration 484, loss = 796.03914121\n",
      "Iteration 7, loss = 3357.48742883\n",
      "Iteration 398, loss = 837.17956698\n",
      "Iteration 8, loss = 3092.16080538\n",
      "Iteration 8, loss = 3216.03418459\n",
      "Iteration 30, loss = 3282.29391491\n",
      "Iteration 499, loss = 797.10005992\n",
      "Iteration 42, loss = 2491.27827267\n",
      "Iteration 485, loss = 797.34660897\n",
      "Iteration 399, loss = 833.97322645\n",
      "Iteration 8, loss = 3014.95683999\n",
      "Iteration 500, loss = 794.52790104\n",
      "Iteration 31, loss = 3198.59106670\n",
      "Iteration 9, loss = 2827.59156919\n",
      "Iteration 43, loss = 2441.07866175\n",
      "Iteration 9, loss = 2930.13172736\n",
      "Iteration 486, loss = 796.13028929\n",
      "Iteration 400, loss = 834.85045806\n",
      "Iteration 501, loss = 795.51599264\n",
      "Iteration 9, loss = 2736.86598108\n",
      "Iteration 44, loss = 2392.99752513\n",
      "Iteration 32, loss = 3118.62301199\n",
      "Iteration 487, loss = 796.90808484\n",
      "Iteration 10, loss = 2607.11531645\n",
      "Iteration 401, loss = 833.44369699\n",
      "Iteration 10, loss = 2683.83334208\n",
      "Iteration 33, loss = 3040.96498342\n",
      "Iteration 45, loss = 2347.34164148\n",
      "Iteration 502, loss = 795.80143965\n",
      "Iteration 10, loss = 2492.44530449\n",
      "Iteration 488, loss = 795.94230798\n",
      "Iteration 402, loss = 832.96278029\n",
      "Iteration 11, loss = 2407.23534506\n",
      "Iteration 34, loss = 2968.34555283\n",
      "Iteration 11, loss = 2474.28139812\n",
      "Iteration 503, loss = 794.03010772\n",
      "Iteration 46, loss = 2304.28414840\n",
      "Iteration 489, loss = 795.05072926\n",
      "Iteration 11, loss = 2289.65453338\n",
      "Iteration 403, loss = 832.97432853\n",
      "Iteration 35, loss = 2898.31432010\n",
      "Iteration 12, loss = 2260.32004634\n",
      "Iteration 504, loss = 793.26956932\n",
      "Iteration 47, loss = 2262.68815139\n",
      "Iteration 12, loss = 2304.10027559\n",
      "Iteration 490, loss = 796.89571984\n",
      "Iteration 404, loss = 834.27758225\n",
      "Iteration 36, loss = 2831.53497898\n",
      "Iteration 12, loss = 2113.92883578\n",
      "Iteration 505, loss = 794.60146160\n",
      "Iteration 48, loss = 2223.33561910\n",
      "Iteration 13, loss = 2093.86207958\n",
      "Iteration 491, loss = 794.25716584\n",
      "Iteration 405, loss = 832.71419223\n",
      "Iteration 13, loss = 2164.82693259\n",
      "Iteration 37, loss = 2766.66160851\n",
      "Iteration 506, loss = 793.55471204\n",
      "Iteration 492, loss = 795.59198681\n",
      "Iteration 406, loss = 832.04348932\n",
      "Iteration 49, loss = 2184.65790323\n",
      "Iteration 13, loss = 1958.90827713\n",
      "Iteration 14, loss = 1985.72556740\n",
      "Iteration 38, loss = 2705.96492592\n",
      "Iteration 14, loss = 2033.18981567\n",
      "Iteration 507, loss = 793.56706668\n",
      "Iteration 50, loss = 2149.18915235\n",
      "Iteration 493, loss = 794.83998270\n",
      "Iteration 407, loss = 831.20562873\n",
      "Iteration 39, loss = 2647.43997784\n",
      "Iteration 15, loss = 1874.37210589\n",
      "Iteration 14, loss = 1868.59882600\n",
      "Iteration 508, loss = 791.85502276\n",
      "Iteration 15, loss = 1909.33073014\n",
      "Iteration 408, loss = 830.05506425\n",
      "Iteration 51, loss = 2114.81768538\n",
      "Iteration 494, loss = 795.19566330\n",
      "Iteration 40, loss = 2591.40533449\n",
      "Iteration 16, loss = 1804.13651464\n",
      "Iteration 409, loss = 829.79602272\n",
      "Iteration 15, loss = 1744.15227532\n",
      "Iteration 509, loss = 793.47727961\n",
      "Iteration 52, loss = 2081.74983602\n",
      "Iteration 495, loss = 795.07836266\n",
      "Iteration 16, loss = 1824.02789920\n",
      "Iteration 41, loss = 2537.41849794\n",
      "Iteration 410, loss = 828.91295390\n",
      "Iteration 510, loss = 793.50779898\n",
      "Iteration 17, loss = 1713.80713884\n",
      "Iteration 53, loss = 2049.79763894\n",
      "Iteration 496, loss = 795.23861686\n",
      "Iteration 16, loss = 1658.60703983\n",
      "Iteration 42, loss = 2486.90708206\n",
      "Iteration 17, loss = 1733.71587199\n",
      "Iteration 411, loss = 831.26122836\n",
      "Iteration 511, loss = 793.78508838\n",
      "Iteration 497, loss = 795.02003927\n",
      "Iteration 54, loss = 2020.01793109\n",
      "Iteration 18, loss = 1627.50626317\n",
      "Iteration 43, loss = 2438.27989936\n",
      "Iteration 17, loss = 1572.62395883\n",
      "Iteration 412, loss = 829.95875728\n",
      "Iteration 18, loss = 1669.72964242\n",
      "Iteration 55, loss = 1990.76928859\n",
      "Iteration 512, loss = 794.52411006\n",
      "Iteration 498, loss = 793.61317344\n",
      "Iteration 19, loss = 1594.38955442\n",
      "Iteration 44, loss = 2391.79721964\n",
      "Iteration 413, loss = 828.82816967\n",
      "Iteration 18, loss = 1526.02626463\n",
      "Iteration 56, loss = 1961.57099806\n",
      "Iteration 513, loss = 795.19350150\n",
      "Iteration 499, loss = 793.94570900\n",
      "Iteration 19, loss = 1583.92320846\n",
      "Iteration 414, loss = 827.85307789\n",
      "Iteration 45, loss = 2346.98997824\n",
      "Iteration 57, loss = 1934.09939625\n",
      "Iteration 20, loss = 1537.31705135\n",
      "Iteration 500, loss = 793.04126361\n",
      "Iteration 514, loss = 792.56045110\n",
      "Iteration 19, loss = 1458.28966722\n",
      "Iteration 46, loss = 2304.44017853\n",
      "Iteration 20, loss = 1519.84027994\n",
      "Iteration 415, loss = 828.91684037\n",
      "Iteration 58, loss = 1907.47785956\n",
      "Iteration 501, loss = 796.25685355\n",
      "Iteration 515, loss = 795.55824693\n",
      "Iteration 21, loss = 1479.17193248\n",
      "Iteration 20, loss = 1381.47865101\n",
      "Iteration 416, loss = 828.67460786\n",
      "Iteration 47, loss = 2262.91308522\n",
      "Iteration 59, loss = 1882.19450711\n",
      "Iteration 21, loss = 1509.42805658\n",
      "Iteration 502, loss = 791.65026466\n",
      "Iteration 516, loss = 792.25603019\n",
      "Iteration 417, loss = 827.73796793\n",
      "Iteration 48, loss = 2223.38054611\n",
      "Iteration 22, loss = 1455.99431861\n",
      "Iteration 60, loss = 1857.53121420\n",
      "Iteration 21, loss = 1362.33493192\n",
      "Iteration 503, loss = 793.48369855\n",
      "Iteration 517, loss = 791.34252641\n",
      "Iteration 22, loss = 1455.10090864\n",
      "Iteration 418, loss = 827.76193238\n",
      "Iteration 49, loss = 2185.48128811\n",
      "Iteration 61, loss = 1833.54188645\n",
      "Iteration 504, loss = 791.60867779\n",
      "Iteration 23, loss = 1380.34780413\n",
      "Iteration 22, loss = 1297.48441759\n",
      "Iteration 518, loss = 793.16190284\n",
      "Iteration 419, loss = 828.98955789\n",
      "Iteration 62, loss = 1809.88927524\n",
      "Iteration 50, loss = 2150.34788896\n",
      "Iteration 23, loss = 1453.68561617\n",
      "Iteration 505, loss = 790.74072931\n",
      "Iteration 519, loss = 792.09223187\n",
      "Iteration 23, loss = 1258.03980413\n",
      "Iteration 420, loss = 825.87258411\n",
      "Iteration 24, loss = 1362.45749528\n",
      "Iteration 63, loss = 1786.76107179\n",
      "Iteration 51, loss = 2116.39187521\n",
      "Iteration 506, loss = 792.28525745\n",
      "Iteration 24, loss = 1351.10385731\n",
      "Iteration 520, loss = 792.49567268\n",
      "Iteration 421, loss = 827.12691672\n",
      "Iteration 52, loss = 2083.88550501\n",
      "Iteration 24, loss = 1245.78656517\n",
      "Iteration 64, loss = 1765.22601017\n",
      "Iteration 25, loss = 1343.59676908\n",
      "Iteration 507, loss = 790.21961941\n",
      "Iteration 521, loss = 793.11496849\n",
      "Iteration 25, loss = 1325.20118632\n",
      "Iteration 422, loss = 823.79084676\n",
      "Iteration 65, loss = 1744.20903515\n",
      "Iteration 53, loss = 2052.90674894\n",
      "Iteration 25, loss = 1201.59030009\n",
      "Iteration 508, loss = 791.26405126\n",
      "Iteration 522, loss = 792.97330355\n",
      "Iteration 26, loss = 1312.59163948\n",
      "Iteration 26, loss = 1281.82778869\n",
      "Iteration 423, loss = 824.26647232\n",
      "Iteration 54, loss = 2023.98164874\n",
      "Iteration 66, loss = 1724.51031058\n",
      "Iteration 509, loss = 790.49525333\n",
      "Iteration 523, loss = 791.59028193\n",
      "Iteration 26, loss = 1176.57521949\n",
      "Iteration 424, loss = 824.20468124\n",
      "Iteration 27, loss = 1323.26650884\n",
      "Iteration 55, loss = 1996.02248684\n",
      "Iteration 67, loss = 1704.24529711\n",
      "Iteration 27, loss = 1294.33314500\n",
      "Iteration 524, loss = 792.34379381\n",
      "Iteration 510, loss = 789.54625583\n",
      "Iteration 27, loss = 1192.14341056\n",
      "Iteration 56, loss = 1968.34683249\n",
      "Iteration 425, loss = 822.79474470\n",
      "Iteration 68, loss = 1685.81139391\n",
      "Iteration 28, loss = 1267.71229754\n",
      "Iteration 525, loss = 791.71253724\n",
      "Iteration 511, loss = 790.72962490\n",
      "Iteration 28, loss = 1256.91624344\n",
      "Iteration 426, loss = 823.84972544\n",
      "Iteration 57, loss = 1942.05410820\n",
      "Iteration 28, loss = 1104.95140459\n",
      "Iteration 69, loss = 1667.12495939\n",
      "Iteration 526, loss = 790.29150368\n",
      "Iteration 512, loss = 790.58250551\n",
      "Iteration 29, loss = 1270.33558346\n",
      "Iteration 58, loss = 1916.35030177\n",
      "Iteration 427, loss = 823.20911572\n",
      "Iteration 29, loss = 1220.73315995\n",
      "Iteration 70, loss = 1649.44432372\n",
      "Iteration 527, loss = 789.98709773\n",
      "Iteration 513, loss = 786.88269930\n",
      "Iteration 29, loss = 1104.86464234\n",
      "Iteration 30, loss = 1204.27293845\n",
      "Iteration 59, loss = 1892.48473517\n",
      "Iteration 428, loss = 822.75902166\n",
      "Iteration 71, loss = 1632.89187280\n",
      "Iteration 528, loss = 791.21298940\n",
      "Iteration 30, loss = 1200.19305964\n",
      "Iteration 514, loss = 790.04249355\n",
      "Iteration 30, loss = 1109.75218026\n",
      "Iteration 60, loss = 1869.23835232\n",
      "Iteration 429, loss = 823.53163518\n",
      "Iteration 31, loss = 1167.31644818\n",
      "Iteration 529, loss = 791.01710977\n",
      "Iteration 72, loss = 1616.75095987\n",
      "Iteration 515, loss = 788.68100065\n",
      "Iteration 31, loss = 1191.70013455\n",
      "Iteration 61, loss = 1846.75963363\n",
      "Iteration 430, loss = 822.41234040\n",
      "Iteration 31, loss = 1095.46660715\n",
      "Iteration 516, loss = 789.79478376\n",
      "Iteration 73, loss = 1600.46781184\n",
      "Iteration 530, loss = 789.01031849\n",
      "Iteration 32, loss = 1142.36792595\n",
      "Iteration 62, loss = 1824.67948125\n",
      "Iteration 431, loss = 821.69833401\n",
      "Iteration 32, loss = 1183.91046650\n",
      "Iteration 32, loss = 1101.09818926\n",
      "Iteration 74, loss = 1584.56003815\n",
      "Iteration 517, loss = 788.89237169\n",
      "Iteration 531, loss = 789.68896020\n",
      "Iteration 63, loss = 1802.58532124\n",
      "Iteration 432, loss = 823.07723672\n",
      "Iteration 33, loss = 1151.50894568\n",
      "Iteration 33, loss = 1162.30249808\n",
      "Iteration 75, loss = 1568.79805850\n",
      "Iteration 518, loss = 789.53458603\n",
      "Iteration 33, loss = 1025.96297038\n",
      "Iteration 532, loss = 791.63577769\n",
      "Iteration 64, loss = 1781.74391916\n",
      "Iteration 433, loss = 821.83052554\n",
      "Iteration 76, loss = 1553.01442410\n",
      "Iteration 519, loss = 787.84365410\n",
      "Iteration 34, loss = 1125.88947447\n",
      "Iteration 34, loss = 1177.73923716\n",
      "Iteration 533, loss = 789.54359489\n",
      "Iteration 34, loss = 1031.83155585\n",
      "Iteration 65, loss = 1761.07326944\n",
      "Iteration 77, loss = 1536.77530545\n",
      "Iteration 434, loss = 822.05381126\n",
      "Iteration 520, loss = 787.29646775\n",
      "Iteration 534, loss = 790.28523845\n",
      "Iteration 35, loss = 1141.93792642\n",
      "Iteration 78, loss = 1523.08912355\n",
      "Iteration 435, loss = 821.16471561\n",
      "Iteration 35, loss = 1022.30554223\n",
      "Iteration 66, loss = 1741.53145726\n",
      "Iteration 35, loss = 1160.22518682\n",
      "Iteration 521, loss = 788.65138241\n",
      "Iteration 79, loss = 1509.03383112\n",
      "Iteration 535, loss = 789.49184699\n",
      "Iteration 36, loss = 1116.26265224\n",
      "Iteration 436, loss = 820.60763277\n",
      "Iteration 67, loss = 1721.42966133\n",
      "Iteration 36, loss = 1029.32432445\n",
      "Iteration 522, loss = 787.93661179\n",
      "Iteration 36, loss = 1108.25990470\n",
      "Iteration 80, loss = 1494.46750846\n",
      "Iteration 536, loss = 789.60968609\n",
      "Iteration 68, loss = 1703.24880453Iteration 437, loss = 821.42350119\n",
      "\n",
      "Iteration 37, loss = 1076.40156101\n",
      "Iteration 523, loss = 788.34801338\n",
      "Iteration 81, loss = 1480.65830196\n",
      "Iteration 537, loss = 788.46654288\n",
      "Iteration 37, loss = 1100.70490326\n",
      "Iteration 37, loss = 1037.48463867\n",
      "Iteration 69, loss = 1684.19988509\n",
      "Iteration 438, loss = 821.33081679\n",
      "Iteration 524, loss = 785.98724792\n",
      "Iteration 38, loss = 1089.27537501\n",
      "Iteration 538, loss = 789.01302699\n",
      "Iteration 82, loss = 1467.21018683\n",
      "Iteration 70, loss = 1666.15377188\n",
      "Iteration 439, loss = 818.90208852\n",
      "Iteration 38, loss = 1091.94280127\n",
      "Iteration 525, loss = 786.85593675\n",
      "Iteration 38, loss = 1000.86223098\n",
      "Iteration 71, loss = 1648.75294408\n",
      "Iteration 539, loss = 789.46028230\n",
      "Iteration 83, loss = 1454.50398970\n",
      "Iteration 39, loss = 1114.02889351\n",
      "Iteration 440, loss = 817.24832550\n",
      "Iteration 526, loss = 787.36372877\n",
      "Iteration 39, loss = 1102.38280066\n",
      "Iteration 39, loss = 998.20716898\n",
      "Iteration 72, loss = 1632.10368864\n",
      "Iteration 84, loss = 1441.44106175\n",
      "Iteration 540, loss = 788.79923628\n",
      "Iteration 441, loss = 821.65101993\n",
      "Iteration 527, loss = 786.10728454\n",
      "Iteration 40, loss = 1077.39858421\n",
      "Iteration 40, loss = 1102.08826618\n",
      "Iteration 541, loss = 787.63974176\n",
      "Iteration 73, loss = 1615.79649687\n",
      "Iteration 40, loss = 1017.67061337\n",
      "Iteration 85, loss = 1428.74243636\n",
      "Iteration 528, loss = 786.87071233\n",
      "Iteration 442, loss = 819.04931932\n",
      "Iteration 41, loss = 1067.69315332\n",
      "Iteration 542, loss = 787.23621590\n",
      "Iteration 74, loss = 1600.07566258\n",
      "Iteration 41, loss = 1077.10647564\n",
      "Iteration 86, loss = 1417.87959266\n",
      "Iteration 529, loss = 786.19168452\n",
      "Iteration 443, loss = 819.21367513\n",
      "Iteration 41, loss = 1033.61455945\n",
      "Iteration 75, loss = 1584.08496077\n",
      "Iteration 543, loss = 787.71530967\n",
      "Iteration 42, loss = 1051.87598490\n",
      "Iteration 87, loss = 1405.46109922\n",
      "Iteration 42, loss = 1114.03291947\n",
      "Iteration 530, loss = 785.88292963\n",
      "Iteration 444, loss = 817.85384176\n",
      "Iteration 76, loss = 1568.57810850\n",
      "Iteration 544, loss = 787.77540005\n",
      "Iteration 42, loss = 978.54170518\n",
      "Iteration 43, loss = 1047.89808407\n",
      "Iteration 531, loss = 785.47359969\n",
      "Iteration 88, loss = 1393.96483776\n",
      "Iteration 445, loss = 819.52878502\n",
      "Iteration 43, loss = 1085.74416235\n",
      "Iteration 77, loss = 1553.09186098\n",
      "Iteration 43, loss = 983.52346363\n",
      "Iteration 545, loss = 788.96789721\n",
      "Iteration 532, loss = 784.93927142\n",
      "Iteration 89, loss = 1383.74604687\n",
      "Iteration 446, loss = 815.20011614\n",
      "Iteration 44, loss = 1049.99458816\n",
      "Iteration 78, loss = 1539.22552584\n",
      "Iteration 546, loss = 786.84991191\n",
      "Iteration 44, loss = 978.80115006\n",
      "Iteration 44, loss = 1062.35008387\n",
      "Iteration 90, loss = 1372.99973784\n",
      "Iteration 533, loss = 784.39288445\n",
      "Iteration 447, loss = 820.76829833\n",
      "Iteration 79, loss = 1524.73313906\n",
      "Iteration 45, loss = 1067.99964239\n",
      "Iteration 547, loss = 788.08930738\n",
      "Iteration 45, loss = 1018.07412419\n",
      "Iteration 91, loss = 1363.07536953\n",
      "Iteration 534, loss = 785.54861281\n",
      "Iteration 45, loss = 1094.18675502\n",
      "Iteration 448, loss = 817.92064028\n",
      "Iteration 80, loss = 1509.61745884\n",
      "Iteration 548, loss = 789.07800588\n",
      "Iteration 46, loss = 1046.30677026\n",
      "Iteration 92, loss = 1352.30381631\n",
      "Iteration 535, loss = 785.19357951\n",
      "Iteration 46, loss = 977.38259594\n",
      "Iteration 449, loss = 818.36912027\n",
      "Iteration 81, loss = 1494.74704370\n",
      "Iteration 46, loss = 1069.90800331\n",
      "Iteration 549, loss = 787.15166584\n",
      "Iteration 93, loss = 1342.96853407\n",
      "Iteration 536, loss = 780.90175341\n",
      "Iteration 82, loss = 1480.66836669\n",
      "Iteration 47, loss = 1065.29385041\n",
      "Iteration 450, loss = 817.12088946\n",
      "Iteration 47, loss = 952.40872240\n",
      "Iteration 550, loss = 788.02238020\n",
      "Iteration 47, loss = 1034.43413684\n",
      "Iteration 94, loss = 1333.54700210\n",
      "Iteration 451, loss = 816.16371503\n",
      "Iteration 83, loss = 1467.64753739\n",
      "Iteration 537, loss = 786.24631430\n",
      "Iteration 48, loss = 1024.74359880\n",
      "Iteration 551, loss = 786.80011390\n",
      "Iteration 48, loss = 958.37905102\n",
      "Iteration 95, loss = 1324.30405627\n",
      "Iteration 48, loss = 1050.67382399\n",
      "Iteration 538, loss = 783.89700172\n",
      "Iteration 84, loss = 1454.08628446\n",
      "Iteration 452, loss = 816.14734086\n",
      "Iteration 552, loss = 785.99462016\n",
      "Iteration 49, loss = 999.14461364\n",
      "Iteration 49, loss = 985.53333275\n",
      "Iteration 96, loss = 1315.60828106\n",
      "Iteration 85, loss = 1441.86761799\n",
      "Iteration 539, loss = 783.15488027\n",
      "Iteration 453, loss = 817.96710390\n",
      "Iteration 49, loss = 1028.48496840\n",
      "Iteration 553, loss = 787.45447432\n",
      "Iteration 86, loss = 1430.64243604\n",
      "Iteration 97, loss = 1306.94872205\n",
      "Iteration 50, loss = 1083.70848296\n",
      "Iteration 540, loss = 782.98666216\n",
      "Iteration 454, loss = 815.21663275\n",
      "Iteration 50, loss = 955.93073191\n",
      "Iteration 554, loss = 787.46652549\n",
      "Iteration 50, loss = 1034.50661658\n",
      "Iteration 98, loss = 1299.10182673\n",
      "Iteration 87, loss = 1418.30254296\n",
      "Iteration 455, loss = 815.84088206\n",
      "Iteration 541, loss = 783.30123342\n",
      "Iteration 51, loss = 1016.16452876\n",
      "Iteration 555, loss = 786.55589628\n",
      "Iteration 51, loss = 978.56711392\n",
      "Iteration 51, loss = 1051.35827497\n",
      "Iteration 99, loss = 1290.22544245\n",
      "Iteration 88, loss = 1406.59333661\n",
      "Iteration 456, loss = 816.29579529\n",
      "Iteration 542, loss = 782.80743985\n",
      "Iteration 52, loss = 1010.57029115\n",
      "Iteration 556, loss = 786.28829223\n",
      "Iteration 89, loss = 1395.62556769\n",
      "Iteration 100, loss = 1282.89939051\n",
      "Iteration 52, loss = 997.07286241\n",
      "Iteration 457, loss = 815.49994180\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 52, loss = 990.34910851\n",
      "Iteration 543, loss = 783.94095620\n",
      "Iteration 557, loss = 783.57934748\n",
      "Iteration 53, loss = 984.16969499\n",
      "Iteration 90, loss = 1385.59291064\n",
      "Iteration 101, loss = 1274.31488689\n",
      "Iteration 544, loss = 783.46026529\n",
      "Iteration 558, loss = 786.05857382\n",
      "Iteration 53, loss = 941.12990486\n",
      "Iteration 53, loss = 1012.37691332\n",
      "Iteration 1, loss = 9801.07971667\n",
      "Iteration 91, loss = 1374.96754367\n",
      "Iteration 102, loss = 1266.06835748\n",
      "Iteration 54, loss = 1045.84149641\n",
      "Iteration 545, loss = 780.58134714\n",
      "Iteration 559, loss = 785.57624906\n",
      "Iteration 54, loss = 1046.47699956\n",
      "Iteration 54, loss = 941.78692970\n",
      "Iteration 92, loss = 1363.88721318\n",
      "Iteration 2, loss = 7265.09186357\n",
      "Iteration 103, loss = 1259.18597856\n",
      "Iteration 560, loss = 784.36765171\n",
      "Iteration 55, loss = 1006.51940769\n",
      "Iteration 546, loss = 783.52754142\n",
      "Iteration 93, loss = 1353.79196959\n",
      "Iteration 104, loss = 1250.67000303\n",
      "Iteration 55, loss = 1087.76497945\n",
      "Iteration 55, loss = 961.20555906\n",
      "Iteration 561, loss = 787.57281111\n",
      "Iteration 3, loss = 5991.63353463\n",
      "Iteration 547, loss = 782.38375180\n",
      "Iteration 56, loss = 1028.78966454\n",
      "Iteration 105, loss = 1243.92523728\n",
      "Iteration 94, loss = 1343.51346245\n",
      "Iteration 56, loss = 975.97321505\n",
      "Iteration 562, loss = 787.14889769\n",
      "Iteration 56, loss = 1042.50699990\n",
      "Iteration 548, loss = 781.88675295\n",
      "Iteration 57, loss = 1059.69690820\n",
      "Iteration 4, loss = 5141.39972952\n",
      "Iteration 95, loss = 1333.98730388\n",
      "Iteration 106, loss = 1235.62992993\n",
      "Iteration 563, loss = 783.11065863\n",
      "Iteration 549, loss = 781.28817037\n",
      "Iteration 57, loss = 1085.08218377\n",
      "Iteration 57, loss = 985.08117637\n",
      "Iteration 96, loss = 1324.33294235\n",
      "Iteration 107, loss = 1228.46487484\n",
      "Iteration 58, loss = 1073.60743800\n",
      "Iteration 5, loss = 4501.49081569\n",
      "Iteration 564, loss = 785.24985826\n",
      "Iteration 550, loss = 781.64446510\n",
      "Iteration 108, loss = 1220.23557746\n",
      "Iteration 58, loss = 971.58011703\n",
      "Iteration 97, loss = 1315.25425797\n",
      "Iteration 58, loss = 972.92266063\n",
      "Iteration 551, loss = 782.26643642\n",
      "Iteration 565, loss = 785.38836008\n",
      "Iteration 59, loss = 1019.90049007\n",
      "Iteration 6, loss = 3988.67443965\n",
      "Iteration 109, loss = 1213.20660529\n",
      "Iteration 98, loss = 1305.81497503\n",
      "Iteration 552, loss = 779.99676064\n",
      "Iteration 59, loss = 1004.29422670\n",
      "Iteration 566, loss = 784.48369899\n",
      "Iteration 59, loss = 958.18694148\n",
      "Iteration 7, loss = 3565.22810497\n",
      "Iteration 60, loss = 1011.82008730\n",
      "Iteration 110, loss = 1207.76616760\n",
      "Iteration 553, loss = 781.08573112\n",
      "Iteration 99, loss = 1295.71220139\n",
      "Iteration 567, loss = 784.76333820\n",
      "Iteration 60, loss = 1020.45808019\n",
      "Iteration 60, loss = 948.10889218\n",
      "Iteration 8, loss = 3221.40606509\n",
      "Iteration 111, loss = 1200.63613077\n",
      "Iteration 554, loss = 779.27808379\n",
      "Iteration 100, loss = 1287.69577918\n",
      "Iteration 61, loss = 981.75608247\n",
      "Iteration 568, loss = 784.38706302\n",
      "Iteration 555, loss = 780.62430795\n",
      "Iteration 61, loss = 924.72186153\n",
      "Iteration 112, loss = 1194.58117306\n",
      "Iteration 61, loss = 1044.83052954\n",
      "Iteration 101, loss = 1278.17051194\n",
      "Iteration 569, loss = 783.59126446\n",
      "Iteration 9, loss = 2928.20321537\n",
      "Iteration 62, loss = 1000.25586833\n",
      "Iteration 556, loss = 781.24038497\n",
      "Iteration 113, loss = 1188.60008904\n",
      "Iteration 102, loss = 1270.06635343\n",
      "Iteration 62, loss = 986.40253354\n",
      "Iteration 570, loss = 782.86106775\n",
      "Iteration 62, loss = 1013.97484388\n",
      "Iteration 10, loss = 2680.11873723\n",
      "Iteration 63, loss = 1014.55320468\n",
      "Iteration 114, loss = 1182.38813390\n",
      "Iteration 557, loss = 778.86222580\n",
      "Iteration 103, loss = 1261.99678481\n",
      "Iteration 571, loss = 784.33210916\n",
      "Iteration 63, loss = 970.98235452\n",
      "Iteration 63, loss = 1048.40965706\n",
      "Iteration 115, loss = 1176.45284511\n",
      "Iteration 558, loss = 780.98977308\n",
      "Iteration 104, loss = 1254.48760847\n",
      "Iteration 11, loss = 2454.48365218\n",
      "Iteration 572, loss = 784.35764260\n",
      "Iteration 64, loss = 1025.35674187\n",
      "Iteration 64, loss = 971.99227569\n",
      "Iteration 559, loss = 778.27780670\n",
      "Iteration 116, loss = 1170.21776715\n",
      "Iteration 64, loss = 1018.53664087\n",
      "Iteration 105, loss = 1248.02992927\n",
      "Iteration 573, loss = 784.33746162\n",
      "Iteration 12, loss = 2275.78039851\n",
      "Iteration 65, loss = 1011.00758569\n",
      "Iteration 117, loss = 1163.56687498\n",
      "Iteration 65, loss = 930.10755597\n",
      "Iteration 574, loss = 783.55414055\n",
      "Iteration 106, loss = 1240.23892455\n",
      "Iteration 65, loss = 986.53036946\n",
      "Iteration 560, loss = 779.59742110\n",
      "Iteration 13, loss = 2143.83690475\n",
      "Iteration 66, loss = 994.60818071\n",
      "Iteration 575, loss = 784.60861537\n",
      "Iteration 118, loss = 1158.30430299\n",
      "Iteration 107, loss = 1232.52996884\n",
      "Iteration 66, loss = 939.84036385\n",
      "Iteration 561, loss = 778.48136923\n",
      "Iteration 66, loss = 995.63860601\n",
      "Iteration 576, loss = 783.09388007\n",
      "Iteration 14, loss = 2006.76384469\n",
      "Iteration 119, loss = 1153.81780300\n",
      "Iteration 67, loss = 979.52610142\n",
      "Iteration 108, loss = 1225.54078383\n",
      "Iteration 562, loss = 779.39651643\n",
      "Iteration 67, loss = 901.65231703\n",
      "Iteration 67, loss = 997.23973948\n",
      "Iteration 577, loss = 783.46378869\n",
      "Iteration 120, loss = 1150.06275124\n",
      "Iteration 109, loss = 1218.27043587\n",
      "Iteration 15, loss = 1899.24476380\n",
      "Iteration 563, loss = 780.26636243\n",
      "Iteration 68, loss = 968.39761680\n",
      "Iteration 68, loss = 889.71407187\n",
      "Iteration 578, loss = 782.28957577\n",
      "Iteration 68, loss = 1011.95446186\n",
      "Iteration 110, loss = 1212.17416084\n",
      "Iteration 121, loss = 1144.42473618\n",
      "Iteration 16, loss = 1805.12089812\n",
      "Iteration 564, loss = 775.60942282\n",
      "Iteration 69, loss = 965.08142259\n",
      "Iteration 579, loss = 781.46029358\n",
      "Iteration 122, loss = 1138.89193780\n",
      "Iteration 69, loss = 948.16610131\n",
      "Iteration 111, loss = 1205.04390801\n",
      "Iteration 69, loss = 1011.83084124\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 565, loss = 780.11895571\n",
      "Iteration 17, loss = 1705.60017011\n",
      "Iteration 580, loss = 781.88696059\n",
      "Iteration 112, loss = 1199.26039981\n",
      "Iteration 123, loss = 1134.24448100\n",
      "Iteration 70, loss = 997.32977335\n",
      "Iteration 70, loss = 928.59359876\n",
      "Iteration 566, loss = 779.08650655\n",
      "Iteration 581, loss = 783.66819506\n",
      "Iteration 1, loss = 9658.37858743\n",
      "Iteration 113, loss = 1193.40321013\n",
      "Iteration 18, loss = 1653.73369446\n",
      "Iteration 124, loss = 1128.97249442\n",
      "Iteration 71, loss = 1008.84408210\n",
      "Iteration 567, loss = 775.88720918\n",
      "Iteration 71, loss = 941.06962577\n",
      "Iteration 114, loss = 1188.09219261\n",
      "Iteration 582, loss = 783.11412453\n",
      "Iteration 125, loss = 1124.96857523\n",
      "Iteration 19, loss = 1569.91632004\n",
      "Iteration 2, loss = 7124.41517355\n",
      "Iteration 568, loss = 780.42775672\n",
      "Iteration 72, loss = 987.93861727\n",
      "Iteration 583, loss = 781.03341764\n",
      "Iteration 72, loss = 933.70777041\n",
      "Iteration 115, loss = 1182.12873711\n",
      "Iteration 126, loss = 1119.70433989\n",
      "Iteration 569, loss = 777.08287216\n",
      "Iteration 20, loss = 1502.33030174\n",
      "Iteration 73, loss = 982.37441673\n",
      "Iteration 3, loss = 5848.30837969\n",
      "Iteration 584, loss = 781.68183134\n",
      "Iteration 127, loss = 1115.40745311\n",
      "Iteration 116, loss = 1176.03915567\n",
      "Iteration 73, loss = 897.18176287\n",
      "Iteration 570, loss = 778.28218536\n",
      "Iteration 585, loss = 783.12888922\n",
      "Iteration 21, loss = 1464.72936668\n",
      "Iteration 128, loss = 1112.33096938\n",
      "Iteration 74, loss = 1024.31736010\n",
      "Iteration 117, loss = 1168.68775926\n",
      "Iteration 4, loss = 5005.61205297\n",
      "Iteration 74, loss = 894.53087466\n",
      "Iteration 571, loss = 777.97800627\n",
      "Iteration 586, loss = 781.43162856\n",
      "Iteration 129, loss = 1107.62816111\n",
      "Iteration 118, loss = 1164.27490352\n",
      "Iteration 75, loss = 969.46582381\n",
      "Iteration 22, loss = 1458.74873332\n",
      "Iteration 5, loss = 4373.80438811\n",
      "Iteration 572, loss = 776.88697661\n",
      "Iteration 75, loss = 923.40498613\n",
      "Iteration 130, loss = 1102.79719602\n",
      "Iteration 587, loss = 781.76296732\n",
      "Iteration 119, loss = 1159.81569729\n",
      "Iteration 76, loss = 949.75707228\n",
      "Iteration 573, loss = 777.36186912\n",
      "Iteration 23, loss = 1383.14761674\n",
      "Iteration 6, loss = 3879.62061647\n",
      "Iteration 131, loss = 1099.58178784\n",
      "Iteration 588, loss = 780.83215874\n",
      "Iteration 76, loss = 944.42248266\n",
      "Iteration 120, loss = 1155.17182670\n",
      "Iteration 574, loss = 776.64102902\n",
      "Iteration 132, loss = 1095.60865151\n",
      "Iteration 77, loss = 978.78440756\n",
      "Iteration 589, loss = 782.07348693\n",
      "Iteration 24, loss = 1350.23097412\n",
      "Iteration 7, loss = 3457.68094457\n",
      "Iteration 121, loss = 1149.79346669\n",
      "Iteration 77, loss = 909.08373383\n",
      "Iteration 575, loss = 776.57949828\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 133, loss = 1091.43480570\n",
      "Iteration 590, loss = 782.21624374\n",
      "Iteration 122, loss = 1144.29783868\n",
      "Iteration 78, loss = 976.09648057\n",
      "Iteration 8, loss = 3118.11682845\n",
      "Iteration 25, loss = 1326.56327025\n",
      "Iteration 78, loss = 905.99277645\n",
      "Iteration 134, loss = 1086.99880185\n",
      "Iteration 123, loss = 1139.69135422\n",
      "Iteration 591, loss = 780.60672332\n",
      "Iteration 1, loss = 9587.10070740\n",
      "Iteration 79, loss = 947.39531961\n",
      "Iteration 9, loss = 2828.34871641\n",
      "Iteration 135, loss = 1083.83695888\n",
      "Iteration 124, loss = 1134.60572370\n",
      "Iteration 26, loss = 1285.63651223\n",
      "Iteration 592, loss = 779.19767865\n",
      "Iteration 79, loss = 894.42350877\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 2, loss = 7070.04032141\n",
      "Iteration 136, loss = 1080.29310169\n",
      "Iteration 80, loss = 989.96486390\n",
      "Iteration 125, loss = 1130.43488670\n",
      "Iteration 593, loss = 781.30385933\n",
      "Iteration 10, loss = 2598.24476615\n",
      "Iteration 27, loss = 1289.40917869\n",
      "Iteration 3, loss = 5803.71115858\n",
      "Iteration 594, loss = 780.99209983\n",
      "Iteration 126, loss = 1125.26706944\n",
      "Iteration 1, loss = 9662.75664351\n",
      "Iteration 137, loss = 1076.43571839\n",
      "Iteration 81, loss = 1016.94975477\n",
      "Iteration 11, loss = 2376.80407489\n",
      "Iteration 28, loss = 1235.72306565\n",
      "Iteration 595, loss = 780.94046003\n",
      "Iteration 127, loss = 1120.84135470\n",
      "Iteration 138, loss = 1073.32243266\n",
      "Iteration 4, loss = 4979.35905924\n",
      "Iteration 2, loss = 7120.13282411\n",
      "Iteration 82, loss = 921.41204705\n",
      "Iteration 12, loss = 2210.78308325\n",
      "Iteration 29, loss = 1218.14117619\n",
      "Iteration 596, loss = 778.50521079\n",
      "Iteration 128, loss = 1117.02631661\n",
      "Iteration 139, loss = 1070.02339261\n",
      "Iteration 5, loss = 4359.63860148\n",
      "Iteration 3, loss = 5843.83364394\n",
      "Iteration 83, loss = 938.64201496\n",
      "Iteration 597, loss = 780.17127130\n",
      "Iteration 13, loss = 2042.10697323\n",
      "Iteration 129, loss = 1112.21819893\n",
      "Iteration 30, loss = 1190.33222482\n",
      "Iteration 140, loss = 1067.01040530\n",
      "Iteration 4, loss = 4999.07444373\n",
      "Iteration 6, loss = 3875.24121457\n",
      "Iteration 130, loss = 1107.08854547\n",
      "Iteration 598, loss = 782.14767257\n",
      "Iteration 84, loss = 971.58019158\n",
      "Iteration 14, loss = 1942.06865351\n",
      "Iteration 141, loss = 1062.38050922\n",
      "Iteration 31, loss = 1196.15811117\n",
      "Iteration 131, loss = 1103.38044585\n",
      "Iteration 599, loss = 780.39401353\n",
      "Iteration 5, loss = 4358.91500325\n",
      "Iteration 142, loss = 1059.40115640\n",
      "Iteration 15, loss = 1837.35755668\n",
      "Iteration 7, loss = 3472.32395555\n",
      "Iteration 85, loss = 988.30261555\n",
      "Iteration 600, loss = 780.85564945\n",
      "Iteration 132, loss = 1100.16234184\n",
      "Iteration 32, loss = 1172.92928917\n",
      "Iteration 143, loss = 1057.62114254\n",
      "Iteration 6, loss = 3858.60494839\n",
      "Iteration 16, loss = 1719.94709943\n",
      "Iteration 8, loss = 3124.03117586\n",
      "Iteration 86, loss = 944.65393187\n",
      "Iteration 133, loss = 1095.88520673\n",
      "Iteration 601, loss = 780.38661141\n",
      "Iteration 144, loss = 1052.15288102\n",
      "Iteration 33, loss = 1139.16040358\n",
      "Iteration 17, loss = 1644.91140879\n",
      "Iteration 7, loss = 3448.29752704\n",
      "Iteration 134, loss = 1090.59054111\n",
      "Iteration 602, loss = 777.64525477\n",
      "Iteration 9, loss = 2837.32907947\n",
      "Iteration 87, loss = 961.24855628\n",
      "Iteration 145, loss = 1050.14130242\n",
      "Iteration 34, loss = 1111.74907562\n",
      "Iteration 603, loss = 777.85810530\n",
      "Iteration 18, loss = 1619.82580572\n",
      "Iteration 135, loss = 1088.07976087\n",
      "Iteration 8, loss = 3102.16923428\n",
      "Iteration 146, loss = 1046.94467860\n",
      "Iteration 88, loss = 994.80627376\n",
      "Iteration 10, loss = 2603.54018242\n",
      "Iteration 604, loss = 778.07519126\n",
      "Iteration 136, loss = 1083.04156201\n",
      "Iteration 35, loss = 1167.36955565\n",
      "Iteration 19, loss = 1611.26331921\n",
      "Iteration 9, loss = 2810.94964016\n",
      "Iteration 147, loss = 1044.18404199\n",
      "Iteration 89, loss = 934.42474724\n",
      "Iteration 11, loss = 2402.99569319\n",
      "Iteration 137, loss = 1080.33750166\n",
      "Iteration 605, loss = 779.61302997\n",
      "Iteration 148, loss = 1041.92840209\n",
      "Iteration 36, loss = 1078.88232758\n",
      "Iteration 20, loss = 1477.96291495\n",
      "Iteration 10, loss = 2573.84864300\n",
      "Iteration 138, loss = 1076.00777054\n",
      "Iteration 90, loss = 926.25173333\n",
      "Iteration 606, loss = 778.67109714\n",
      "Iteration 12, loss = 2220.29839848\n",
      "Iteration 149, loss = 1038.00305608\n",
      "Iteration 37, loss = 1129.36086305\n",
      "Iteration 21, loss = 1415.89820279\n",
      "Iteration 139, loss = 1070.96547975\n",
      "Iteration 11, loss = 2370.44987618\n",
      "Iteration 607, loss = 780.46038853\n",
      "Iteration 91, loss = 985.53724654\n",
      "Iteration 150, loss = 1036.39400789\n",
      "Iteration 13, loss = 2091.70958988\n",
      "Iteration 38, loss = 1125.64724599\n",
      "Iteration 140, loss = 1067.75145772\n",
      "Iteration 608, loss = 778.87183824\n",
      "Iteration 22, loss = 1337.34782553\n",
      "Iteration 12, loss = 2182.93980741\n",
      "Iteration 151, loss = 1033.30962152\n",
      "Iteration 92, loss = 967.63377882\n",
      "Iteration 14, loss = 1953.42826441\n",
      "Iteration 609, loss = 779.43938916\n",
      "Iteration 141, loss = 1063.08019470\n",
      "Iteration 39, loss = 1109.48204010\n",
      "Iteration 23, loss = 1289.05339175\n",
      "Iteration 13, loss = 2060.98520058\n",
      "Iteration 152, loss = 1029.92810026\n",
      "Iteration 93, loss = 939.96251457\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 610, loss = 779.31035678\n",
      "Iteration 142, loss = 1060.29272707\n",
      "Iteration 15, loss = 1861.08264086\n",
      "Iteration 40, loss = 1109.82031433\n",
      "Iteration 153, loss = 1028.38130870\n",
      "Iteration 14, loss = 1936.86541237\n",
      "Iteration 24, loss = 1318.12801167\n",
      "Iteration 611, loss = 777.57466301\n",
      "Iteration 143, loss = 1057.01348808\n",
      "Iteration 1, loss = 9640.80649618\n",
      "Iteration 16, loss = 1758.47830346\n",
      "Iteration 154, loss = 1025.16254079\n",
      "Iteration 41, loss = 1093.33588115\n",
      "Iteration 15, loss = 1842.41333704\n",
      "Iteration 144, loss = 1051.17798910\n",
      "Iteration 612, loss = 779.88243645\n",
      "Iteration 25, loss = 1313.50512366\n",
      "Iteration 155, loss = 1023.78683123\n",
      "Iteration 2, loss = 7114.16759223\n",
      "Iteration 17, loss = 1683.06663109\n",
      "Iteration 145, loss = 1047.59242996\n",
      "Iteration 613, loss = 778.77814827\n",
      "Iteration 16, loss = 1732.45487439\n",
      "Iteration 42, loss = 1110.00002421\n",
      "Iteration 26, loss = 1216.18261771\n",
      "Iteration 156, loss = 1021.54990884\n",
      "Iteration 3, loss = 5846.54994137\n",
      "Iteration 146, loss = 1043.18587919\n",
      "Iteration 614, loss = 777.38010655\n",
      "Iteration 18, loss = 1620.94567982\n",
      "Iteration 17, loss = 1668.08024191\n",
      "Iteration 43, loss = 1092.07246298\n",
      "Iteration 157, loss = 1018.84853396\n",
      "Iteration 27, loss = 1187.43476893\n",
      "Iteration 147, loss = 1040.59992259\n",
      "Iteration 615, loss = 778.05488111\n",
      "Iteration 4, loss = 5013.73689913\n",
      "Iteration 18, loss = 1582.01253716\n",
      "Iteration 19, loss = 1556.90743331\n",
      "Iteration 44, loss = 1146.23992058\n",
      "Iteration 158, loss = 1015.78427849\n",
      "Iteration 148, loss = 1037.30044473\n",
      "Iteration 28, loss = 1185.69100431\n",
      "Iteration 616, loss = 778.31364734\n",
      "Iteration 5, loss = 4393.45141217\n",
      "Iteration 19, loss = 1532.52024050\n",
      "Iteration 45, loss = 1109.32410216\n",
      "Iteration 159, loss = 1014.36739716\n",
      "Iteration 149, loss = 1032.35518073\n",
      "Iteration 20, loss = 1498.63892129\n",
      "Iteration 617, loss = 777.88749088\n",
      "Iteration 29, loss = 1160.78904907\n",
      "Iteration 6, loss = 3895.52430616\n",
      "Iteration 150, loss = 1031.78198850\n",
      "Iteration 20, loss = 1489.53506563\n",
      "Iteration 160, loss = 1009.97991243\n",
      "Iteration 46, loss = 1096.69401961\n",
      "Iteration 618, loss = 777.56125195\n",
      "Iteration 21, loss = 1440.03168658\n",
      "Iteration 30, loss = 1118.65707172\n",
      "Iteration 7, loss = 3487.45581151\n",
      "Iteration 151, loss = 1027.43673889\n",
      "Iteration 161, loss = 1007.82970879\n",
      "Iteration 619, loss = 777.46733911\n",
      "Iteration 21, loss = 1411.06274365\n",
      "Iteration 22, loss = 1412.89389468\n",
      "Iteration 47, loss = 1081.33269071\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 152, loss = 1023.87193048\n",
      "Iteration 31, loss = 1109.12702885\n",
      "Iteration 8, loss = 3157.28255605\n",
      "Iteration 162, loss = 1004.35678426\n",
      "Iteration 620, loss = 776.27584116\n",
      "Iteration 22, loss = 1369.65723337\n",
      "Iteration 23, loss = 1363.62465629\n",
      "Iteration 1, loss = 9706.82169470\n",
      "Iteration 153, loss = 1020.48531679\n",
      "Iteration 163, loss = 1001.50032362\n",
      "Iteration 621, loss = 776.44039755\n",
      "Iteration 32, loss = 1143.13970576\n",
      "Iteration 9, loss = 2880.61070295\n",
      "Iteration 23, loss = 1334.20893051\n",
      "Iteration 154, loss = 1017.87204403\n",
      "Iteration 2, loss = 7174.43788031\n",
      "Iteration 24, loss = 1328.16598616\n",
      "Iteration 622, loss = 776.09057674\n",
      "Iteration 164, loss = 1000.19872036\n",
      "Iteration 33, loss = 1070.02117064\n",
      "Iteration 10, loss = 2630.27607267\n",
      "Iteration 24, loss = 1299.96254018\n",
      "Iteration 155, loss = 1015.71427704\n",
      "Iteration 623, loss = 779.33392380\n",
      "Iteration 165, loss = 997.35582720\n",
      "Iteration 3, loss = 5910.82574032\n",
      "Iteration 25, loss = 1272.84262368\n",
      "Iteration 34, loss = 1053.35135940\n",
      "Iteration 156, loss = 1010.73051911\n",
      "Iteration 11, loss = 2431.79804006\n",
      "Iteration 166, loss = 996.00946681\n",
      "Iteration 624, loss = 776.91868955\n",
      "Iteration 25, loss = 1255.71265186\n",
      "Iteration 4, loss = 5058.04204796\n",
      "Iteration 26, loss = 1267.08876331\n",
      "Iteration 157, loss = 1007.98406684\n",
      "Iteration 625, loss = 777.20198244\n",
      "Iteration 167, loss = 993.15972991\n",
      "Iteration 35, loss = 1051.17356362\n",
      "Iteration 26, loss = 1247.65159076\n",
      "Iteration 12, loss = 2244.01950586\n",
      "Iteration 5, loss = 4416.69491050\n",
      "Iteration 27, loss = 1248.73476700\n",
      "Iteration 626, loss = 776.84586280\n",
      "Iteration 158, loss = 1004.77255464\n",
      "Iteration 168, loss = 992.42161556\n",
      "Iteration 36, loss = 1070.33123341\n",
      "Iteration 27, loss = 1230.35503259\n",
      "Iteration 13, loss = 2109.31239447\n",
      "Iteration 627, loss = 776.99171741\n",
      "Iteration 159, loss = 1002.59494230\n",
      "Iteration 6, loss = 3917.71185547\n",
      "Iteration 28, loss = 1190.88808577\n",
      "Iteration 169, loss = 990.56608405\n",
      "Iteration 37, loss = 1030.29762501\n",
      "Iteration 14, loss = 1981.87385248\n",
      "Iteration 28, loss = 1183.84723655\n",
      "Iteration 160, loss = 999.55730617\n",
      "Iteration 628, loss = 779.46501329\n",
      "Iteration 170, loss = 987.17518661\n",
      "Iteration 7, loss = 3501.55306001\n",
      "Iteration 29, loss = 1232.04281865\n",
      "Iteration 161, loss = 997.38888696\n",
      "Iteration 38, loss = 1031.33240673\n",
      "Iteration 171, loss = 986.47078135\n",
      "Iteration 629, loss = 776.68788807\n",
      "Iteration 29, loss = 1202.42489406\n",
      "Iteration 15, loss = 1875.85669417\n",
      "Iteration 8, loss = 3151.82892034\n",
      "Iteration 30, loss = 1178.92838348\n",
      "Iteration 162, loss = 994.78681622\n",
      "Iteration 172, loss = 983.91646534\n",
      "Iteration 630, loss = 778.77540788\n",
      "Iteration 39, loss = 1031.91545761\n",
      "Iteration 16, loss = 1798.82558140\n",
      "Iteration 30, loss = 1184.87848835\n",
      "Iteration 163, loss = 991.89815101\n",
      "Iteration 9, loss = 2864.49068445\n",
      "Iteration 173, loss = 982.29084734\n",
      "Iteration 31, loss = 1144.40620867\n",
      "Iteration 631, loss = 776.25187057\n",
      "Iteration 40, loss = 1005.54478307\n",
      "Iteration 17, loss = 1739.24473579\n",
      "Iteration 31, loss = 1143.76487926\n",
      "Iteration 164, loss = 989.02372291\n",
      "Iteration 174, loss = 980.65052439\n",
      "Iteration 632, loss = 776.72413296\n",
      "Iteration 10, loss = 2630.96951802\n",
      "Iteration 32, loss = 1155.76901290\n",
      "Iteration 41, loss = 1034.51390176\n",
      "Iteration 165, loss = 986.48127025\n",
      "Iteration 18, loss = 1640.60807305\n",
      "Iteration 175, loss = 978.68567946\n",
      "Iteration 32, loss = 1125.90729917\n",
      "Iteration 633, loss = 775.82942960\n",
      "Iteration 11, loss = 2422.43268370\n",
      "Iteration 33, loss = 1109.19993674\n",
      "Iteration 166, loss = 984.17737421\n",
      "Iteration 176, loss = 976.74233044\n",
      "Iteration 42, loss = 1010.72254789\n",
      "Iteration 634, loss = 775.78684045\n",
      "Iteration 19, loss = 1578.08309363\n",
      "Iteration 33, loss = 1122.73648618\n",
      "Iteration 34, loss = 1154.13238229\n",
      "Iteration 167, loss = 982.49245004\n",
      "Iteration 12, loss = 2250.85585096\n",
      "Iteration 177, loss = 972.46902551\n",
      "Iteration 635, loss = 776.82796528\n",
      "Iteration 43, loss = 998.64946582\n",
      "Iteration 20, loss = 1509.23991031\n",
      "Iteration 34, loss = 1122.62245689\n",
      "Iteration 168, loss = 980.75310596\n",
      "Iteration 636, loss = 775.42821676\n",
      "Iteration 35, loss = 1136.35018400\n",
      "Iteration 178, loss = 971.06710917\n",
      "Iteration 13, loss = 2093.47209322\n",
      "Iteration 44, loss = 1001.91120805\n",
      "Iteration 21, loss = 1490.89680091\n",
      "Iteration 637, loss = 775.90763133\n",
      "Iteration 169, loss = 978.26648797\n",
      "Iteration 35, loss = 1148.35964063\n",
      "Iteration 179, loss = 970.06417473\n",
      "Iteration 36, loss = 1083.14804114\n",
      "Iteration 14, loss = 1963.75712718\n",
      "Iteration 638, loss = 775.32689724\n",
      "Iteration 170, loss = 974.84984832\n",
      "Iteration 45, loss = 968.76769196\n",
      "Iteration 22, loss = 1435.00640614\n",
      "Iteration 180, loss = 967.24478324\n",
      "Iteration 36, loss = 1086.76708880\n",
      "Iteration 639, loss = 775.38197301\n",
      "Iteration 37, loss = 1083.74713606\n",
      "Iteration 171, loss = 972.50519447\n",
      "Iteration 15, loss = 1857.93273361\n",
      "Iteration 181, loss = 965.04341882\n",
      "Iteration 46, loss = 975.32620034\n",
      "Iteration 23, loss = 1374.00197219\n",
      "Iteration 640, loss = 775.83954424\n",
      "Iteration 37, loss = 1072.85809639\n",
      "Iteration 172, loss = 970.61556454\n",
      "Iteration 38, loss = 1090.51067248\n",
      "Iteration 16, loss = 1761.10721907\n",
      "Iteration 182, loss = 963.86790877\n",
      "Iteration 641, loss = 775.58655878\n",
      "Iteration 47, loss = 986.00697720\n",
      "Iteration 173, loss = 968.63449343\n",
      "Iteration 24, loss = 1349.80876892\n",
      "Iteration 38, loss = 1145.15160172\n",
      "Iteration 183, loss = 963.67964319\n",
      "Iteration 39, loss = 1069.58475638\n",
      "Iteration 642, loss = 774.81384224\n",
      "Iteration 17, loss = 1686.69892911\n",
      "Iteration 174, loss = 966.73125257\n",
      "Iteration 48, loss = 968.16252358\n",
      "Iteration 25, loss = 1310.20766049\n",
      "Iteration 39, loss = 1071.68310037\n",
      "Iteration 184, loss = 961.20966174\n",
      "Iteration 643, loss = 775.66455297\n",
      "Iteration 40, loss = 1044.98781446\n",
      "Iteration 175, loss = 964.44929430\n",
      "Iteration 18, loss = 1614.02568442\n",
      "Iteration 49, loss = 1004.63966701\n",
      "Iteration 185, loss = 956.59542310\n",
      "Iteration 26, loss = 1273.79370467\n",
      "Iteration 40, loss = 1089.89575527\n",
      "Iteration 644, loss = 775.03471084\n",
      "Iteration 176, loss = 962.22467936\n",
      "Iteration 41, loss = 1073.29913940\n",
      "Iteration 19, loss = 1545.24716987\n",
      "Iteration 186, loss = 958.74678761\n",
      "Iteration 50, loss = 974.72754741\n",
      "Iteration 645, loss = 773.08824787\n",
      "Iteration 27, loss = 1284.58982743\n",
      "Iteration 177, loss = 960.05850932\n",
      "Iteration 41, loss = 1060.12240769\n",
      "Iteration 42, loss = 1084.89303678\n",
      "Iteration 187, loss = 956.33396979\n",
      "Iteration 20, loss = 1503.28152205\n",
      "Iteration 646, loss = 774.97719997\n",
      "Iteration 178, loss = 958.94448223\n",
      "Iteration 51, loss = 965.92292827\n",
      "Iteration 42, loss = 1030.16594972\n",
      "Iteration 28, loss = 1330.73325244\n",
      "Iteration 188, loss = 954.80101353\n",
      "Iteration 647, loss = 773.54753661\n",
      "Iteration 43, loss = 1068.45465972\n",
      "Iteration 179, loss = 957.20443618\n",
      "Iteration 21, loss = 1459.65056709\n",
      "Iteration 52, loss = 992.80822139\n",
      "Iteration 29, loss = 1221.19717464\n",
      "Iteration 43, loss = 1018.31014016\n",
      "Iteration 189, loss = 953.87991289\n",
      "Iteration 648, loss = 774.56470037\n",
      "Iteration 180, loss = 953.63697469\n",
      "Iteration 44, loss = 1068.79735115\n",
      "Iteration 22, loss = 1398.03954750\n",
      "Iteration 53, loss = 953.63908060\n",
      "Iteration 30, loss = 1212.48609647\n",
      "Iteration 190, loss = 953.14168904\n",
      "Iteration 44, loss = 1026.97913345\n",
      "Iteration 649, loss = 773.53454361\n",
      "Iteration 181, loss = 950.50583152\n",
      "Iteration 45, loss = 1089.98330107\n",
      "Iteration 23, loss = 1319.68950216\n",
      "Iteration 54, loss = 959.27238992\n",
      "Iteration 191, loss = 950.43751459\n",
      "Iteration 650, loss = 773.36715708\n",
      "Iteration 45, loss = 1019.52491950\n",
      "Iteration 182, loss = 948.65562803\n",
      "Iteration 31, loss = 1181.58462262\n",
      "Iteration 46, loss = 1036.22177894\n",
      "Iteration 651, loss = 776.15388447\n",
      "Iteration 24, loss = 1327.32566380\n",
      "Iteration 192, loss = 949.63104689\n",
      "Iteration 183, loss = 948.08786676\n",
      "Iteration 55, loss = 951.88583025\n",
      "Iteration 46, loss = 1074.23978764\n",
      "Iteration 32, loss = 1184.67435418\n",
      "Iteration 652, loss = 775.38783119\n",
      "Iteration 193, loss = 948.22368547\n",
      "Iteration 47, loss = 1034.36171895\n",
      "Iteration 184, loss = 944.85897007\n",
      "Iteration 25, loss = 1279.87666647\n",
      "Iteration 56, loss = 962.86678637\n",
      "Iteration 47, loss = 1082.83537470\n",
      "Iteration 194, loss = 946.78666132\n",
      "Iteration 653, loss = 773.77440767\n",
      "Iteration 33, loss = 1150.29613028\n",
      "Iteration 185, loss = 941.98084368\n",
      "Iteration 48, loss = 1024.48245887\n",
      "Iteration 26, loss = 1250.57095430\n",
      "Iteration 48, loss = 1019.34700514\n",
      "Iteration 57, loss = 999.99134179\n",
      "Iteration 654, loss = 773.42627051\n",
      "Iteration 186, loss = 942.88343046\n",
      "Iteration 195, loss = 946.30604619\n",
      "Iteration 34, loss = 1130.63631249\n",
      "Iteration 49, loss = 1063.76649723\n",
      "Iteration 27, loss = 1215.70009531\n",
      "Iteration 655, loss = 774.60469734\n",
      "Iteration 58, loss = 926.90081752\n",
      "Iteration 196, loss = 943.25777964\n",
      "Iteration 187, loss = 939.56267949\n",
      "Iteration 49, loss = 1094.38140537\n",
      "Iteration 35, loss = 1095.11018801\n",
      "Iteration 656, loss = 772.29851939\n",
      "Iteration 50, loss = 1022.12975559\n",
      "Iteration 188, loss = 938.54960280\n",
      "Iteration 28, loss = 1195.66203325\n",
      "Iteration 197, loss = 944.36532915\n",
      "Iteration 59, loss = 960.21372363\n",
      "Iteration 50, loss = 1037.21772917\n",
      "Iteration 36, loss = 1189.08826199\n",
      "Iteration 657, loss = 772.82338561\n",
      "Iteration 189, loss = 937.66430989\n",
      "Iteration 198, loss = 942.87910512\n",
      "Iteration 51, loss = 1041.66453329\n",
      "Iteration 29, loss = 1191.32449525\n",
      "Iteration 60, loss = 970.41271622\n",
      "Iteration 51, loss = 1015.65622220\n",
      "Iteration 658, loss = 772.61445580\n",
      "Iteration 190, loss = 936.36699565\n",
      "Iteration 199, loss = 941.59705822\n",
      "Iteration 37, loss = 1123.11809070\n",
      "Iteration 52, loss = 1024.48283254\n",
      "Iteration 659, loss = 773.08902241\n",
      "Iteration 30, loss = 1172.59518069\n",
      "Iteration 61, loss = 973.59189693\n",
      "Iteration 191, loss = 933.87880473\n",
      "Iteration 52, loss = 1018.00809670\n",
      "Iteration 200, loss = 939.73491988\n",
      "Iteration 38, loss = 1128.10437325\n",
      "Iteration 660, loss = 773.42406952\n",
      "Iteration 53, loss = 1017.73754408\n",
      "Iteration 192, loss = 932.04005365\n",
      "Iteration 31, loss = 1178.08983818\n",
      "Iteration 53, loss = 960.27583500\n",
      "Iteration 62, loss = 933.25263085\n",
      "Iteration 201, loss = 938.85091090\n",
      "Iteration 661, loss = 773.55972924\n",
      "Iteration 39, loss = 1096.06864027\n",
      "Iteration 193, loss = 931.88875732\n",
      "Iteration 54, loss = 1039.60900079\n",
      "Iteration 32, loss = 1165.92613184\n",
      "Iteration 202, loss = 938.27365838\n",
      "Iteration 63, loss = 920.94730377\n",
      "Iteration 54, loss = 1012.54799194\n",
      "Iteration 662, loss = 773.14653297\n",
      "Iteration 194, loss = 929.50663160\n",
      "Iteration 40, loss = 1079.39630094\n",
      "Iteration 203, loss = 936.28664088\n",
      "Iteration 55, loss = 1015.13082738\n",
      "Iteration 33, loss = 1113.84010918\n",
      "Iteration 663, loss = 771.77096357\n",
      "Iteration 195, loss = 929.14732732\n",
      "Iteration 55, loss = 1050.80971786\n",
      "Iteration 64, loss = 908.18208645\n",
      "Iteration 204, loss = 935.10397253\n",
      "Iteration 41, loss = 1122.07028091\n",
      "Iteration 664, loss = 773.26610978\n",
      "Iteration 196, loss = 926.83907088\n",
      "Iteration 56, loss = 1033.84445159\n",
      "Iteration 34, loss = 1106.45190522\n",
      "Iteration 65, loss = 935.65227405\n",
      "Iteration 56, loss = 1059.19462937\n",
      "Iteration 205, loss = 935.39292595\n",
      "Iteration 665, loss = 771.23206007\n",
      "Iteration 197, loss = 925.95105218\n",
      "Iteration 42, loss = 1088.04631966\n",
      "Iteration 57, loss = 1007.93500898\n",
      "Iteration 35, loss = 1112.98744273\n",
      "Iteration 206, loss = 933.92823258\n",
      "Iteration 66, loss = 975.40325297\n",
      "Iteration 57, loss = 1044.46000670\n",
      "Iteration 666, loss = 772.94704118\n",
      "Iteration 198, loss = 924.79224087\n",
      "Iteration 43, loss = 1050.14835625\n",
      "Iteration 207, loss = 932.49476442\n",
      "Iteration 58, loss = 1014.77857262\n",
      "Iteration 36, loss = 1116.25032892\n",
      "Iteration 667, loss = 772.69745934\n",
      "Iteration 58, loss = 1027.80817172\n",
      "Iteration 67, loss = 932.55735352\n",
      "Iteration 199, loss = 923.57373623\n",
      "Iteration 208, loss = 931.31154190\n",
      "Iteration 44, loss = 1084.15441126\n",
      "Iteration 668, loss = 771.96792907\n",
      "Iteration 59, loss = 1023.71232732\n",
      "Iteration 200, loss = 921.65991028\n",
      "Iteration 37, loss = 1116.94561842\n",
      "Iteration 59, loss = 1055.67630253\n",
      "Iteration 68, loss = 907.08479716\n",
      "Iteration 209, loss = 929.43401688\n",
      "Iteration 669, loss = 772.40786527\n",
      "Iteration 45, loss = 1046.38677890\n",
      "Iteration 201, loss = 921.23576511\n",
      "Iteration 60, loss = 1000.72336607\n",
      "Iteration 38, loss = 1056.56530275\n",
      "Iteration 60, loss = 968.95480514\n",
      "Iteration 210, loss = 927.88990366\n",
      "Iteration 69, loss = 880.77513294\n",
      "Iteration 670, loss = 771.46273160\n",
      "Iteration 202, loss = 918.18271099\n",
      "Iteration 46, loss = 1046.24449988\n",
      "Iteration 211, loss = 928.49964849\n",
      "Iteration 61, loss = 984.99630996\n",
      "Iteration 39, loss = 1064.60467741\n",
      "Iteration 61, loss = 1019.05694752\n",
      "Iteration 671, loss = 771.00208401\n",
      "Iteration 70, loss = 946.40018474\n",
      "Iteration 203, loss = 917.92932878\n",
      "Iteration 47, loss = 1035.84517001\n",
      "Iteration 212, loss = 925.95122484\n",
      "Iteration 672, loss = 771.87819498\n",
      "Iteration 62, loss = 1046.15480347\n",
      "Iteration 40, loss = 1066.38940216\n",
      "Iteration 204, loss = 916.46795844\n",
      "Iteration 62, loss = 996.90147023\n",
      "Iteration 71, loss = 921.64896026\n",
      "Iteration 48, loss = 1022.49361813\n",
      "Iteration 213, loss = 927.26168050\n",
      "Iteration 673, loss = 772.58981882\n",
      "Iteration 63, loss = 1030.22014985\n",
      "Iteration 205, loss = 917.69979449\n",
      "Iteration 41, loss = 1108.34607287\n",
      "Iteration 63, loss = 1021.85223172\n",
      "Iteration 72, loss = 952.60030398\n",
      "Iteration 214, loss = 924.61769748\n",
      "Iteration 674, loss = 772.93491246\n",
      "Iteration 49, loss = 1048.09480525\n",
      "Iteration 206, loss = 915.84018323\n",
      "Iteration 64, loss = 987.15427021\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 42, loss = 1094.13406369\n",
      "Iteration 215, loss = 922.66773727\n",
      "Iteration 64, loss = 1015.61916662\n",
      "Iteration 73, loss = 927.23879483\n",
      "Iteration 675, loss = 771.43904595\n",
      "Iteration 207, loss = 913.52567485\n",
      "Iteration 50, loss = 1085.53587779\n",
      "Iteration 43, loss = 1062.83336733\n",
      "Iteration 216, loss = 922.55744606\n",
      "Iteration 1, loss = 9633.86793480\n",
      "Iteration 65, loss = 973.22452033\n",
      "Iteration 676, loss = 771.44492488\n",
      "Iteration 208, loss = 913.62072029\n",
      "Iteration 74, loss = 922.99942495\n",
      "Iteration 51, loss = 1072.64080023\n",
      "Iteration 217, loss = 920.95813193\n",
      "Iteration 44, loss = 1038.45561535\n",
      "Iteration 677, loss = 770.03093165\n",
      "Iteration 209, loss = 911.41702567\n",
      "Iteration 66, loss = 956.78729650\n",
      "Iteration 2, loss = 7110.37119342\n",
      "Iteration 75, loss = 920.54982861\n",
      "Iteration 218, loss = 920.75016769\n",
      "Iteration 52, loss = 1012.79274334\n",
      "Iteration 678, loss = 772.66547863\n",
      "Iteration 210, loss = 909.56899543\n",
      "Iteration 45, loss = 1070.65766169\n",
      "Iteration 67, loss = 982.07962798\n",
      "Iteration 219, loss = 918.76657227\n",
      "Iteration 3, loss = 5850.28438865\n",
      "Iteration 76, loss = 914.42435028\n",
      "Iteration 679, loss = 770.77399644\n",
      "Iteration 53, loss = 1036.25780432\n",
      "Iteration 211, loss = 909.11227592\n",
      "Iteration 46, loss = 1009.40663661\n",
      "Iteration 220, loss = 918.29106045\n",
      "Iteration 680, loss = 771.81880203\n",
      "Iteration 68, loss = 990.33219220\n",
      "Iteration 4, loss = 5012.45218997\n",
      "Iteration 212, loss = 905.83787088\n",
      "Iteration 77, loss = 891.18215911\n",
      "Iteration 54, loss = 1052.02401846\n",
      "Iteration 221, loss = 916.40295071\n",
      "Iteration 47, loss = 1023.67816816\n",
      "Iteration 681, loss = 771.61957062\n",
      "Iteration 213, loss = 905.31336146\n",
      "Iteration 5, loss = 4389.76204365\n",
      "Iteration 69, loss = 985.31304909\n",
      "Iteration 78, loss = 945.65259735\n",
      "Iteration 222, loss = 915.27801368\n",
      "Iteration 55, loss = 1022.03587952\n",
      "Iteration 682, loss = 771.57602129\n",
      "Iteration 214, loss = 904.04331455\n",
      "Iteration 48, loss = 1034.71946267\n",
      "Iteration 223, loss = 911.41888422\n",
      "Iteration 6, loss = 3892.14080610\n",
      "Iteration 70, loss = 977.81208352\n",
      "Iteration 79, loss = 899.04617312\n",
      "Iteration 683, loss = 770.38618315\n",
      "Iteration 56, loss = 1035.36033132\n",
      "Iteration 215, loss = 901.31364379\n",
      "Iteration 49, loss = 1065.61680431\n",
      "Iteration 224, loss = 912.96022123\n",
      "Iteration 684, loss = 770.15720329\n",
      "Iteration 7, loss = 3483.11162509\n",
      "Iteration 216, loss = 902.49997484\n",
      "Iteration 71, loss = 973.90046241\n",
      "Iteration 80, loss = 934.76303438\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 57, loss = 1042.74383630\n",
      "Iteration 225, loss = 912.87873902\n",
      "Iteration 50, loss = 1041.93904309\n",
      "Iteration 685, loss = 771.69647544\n",
      "Iteration 217, loss = 899.64409678\n",
      "Iteration 8, loss = 3156.80938745\n",
      "Iteration 72, loss = 995.56537696\n",
      "Iteration 58, loss = 1031.47177566\n",
      "Iteration 226, loss = 909.49524735\n",
      "Iteration 1, loss = 11356.54704272\n",
      "Iteration 686, loss = 772.06571090\n",
      "Iteration 218, loss = 898.89541967\n",
      "Iteration 51, loss = 1035.49202230\n",
      "Iteration 227, loss = 909.70904711\n",
      "Iteration 9, loss = 2851.27639522\n",
      "Iteration 73, loss = 954.35024782\n",
      "Iteration 687, loss = 770.99501418\n",
      "Iteration 59, loss = 1089.02452501\n",
      "Iteration 2, loss = 10682.82046490\n",
      "Iteration 219, loss = 897.41904864\n",
      "Iteration 52, loss = 1074.03580157\n",
      "Iteration 228, loss = 908.94846173\n",
      "Iteration 688, loss = 770.47176803\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 10, loss = 2616.11535891\n",
      "Iteration 74, loss = 976.88107485\n",
      "Iteration 220, loss = 897.70206060\n",
      "Iteration 60, loss = 970.54371816\n",
      "Iteration 3, loss = 10179.43712913\n",
      "Iteration 229, loss = 906.21179657\n",
      "Iteration 53, loss = 1045.77773167\n",
      "Iteration 221, loss = 895.92416761\n",
      "Iteration 75, loss = 1014.75370062\n",
      "Iteration 11, loss = 2418.95795300\n",
      "Iteration 1, loss = 11754.74306340\n",
      "Iteration 61, loss = 992.94208138\n",
      "Iteration 230, loss = 905.51565894\n",
      "Iteration 4, loss = 9705.58336261\n",
      "Iteration 222, loss = 894.67919505\n",
      "Iteration 54, loss = 992.15366909\n",
      "Iteration 231, loss = 903.94729118\n",
      "Iteration 76, loss = 1028.22946525\n",
      "Iteration 12, loss = 2241.93931419\n",
      "Iteration 2, loss = 11068.99400445\n",
      "Iteration 62, loss = 1004.44972151\n",
      "Iteration 5, loss = 9294.27412150\n",
      "Iteration 223, loss = 892.85233583\n",
      "Iteration 55, loss = 1027.08716585\n",
      "Iteration 232, loss = 904.42154383\n",
      "Iteration 77, loss = 963.87465180\n",
      "Iteration 13, loss = 2116.60692550\n",
      "Iteration 3, loss = 10554.83215561\n",
      "Iteration 224, loss = 892.65943721\n",
      "Iteration 63, loss = 987.25424536\n",
      "Iteration 6, loss = 8916.52966803\n",
      "Iteration 233, loss = 904.29319477\n",
      "Iteration 56, loss = 991.72836395\n",
      "Iteration 225, loss = 892.68748397\n",
      "Iteration 78, loss = 953.07015751\n",
      "Iteration 14, loss = 1977.13085061\n",
      "Iteration 4, loss = 10074.81924344\n",
      "Iteration 64, loss = 993.98270037\n",
      "Iteration 234, loss = 904.20066118\n",
      "Iteration 7, loss = 8587.07553666\n",
      "Iteration 57, loss = 988.22289386\n",
      "Iteration 226, loss = 889.65898153\n",
      "Iteration 79, loss = 968.11177453\n",
      "Iteration 15, loss = 1865.93813718\n",
      "Iteration 235, loss = 902.07400400\n",
      "Iteration 5, loss = 9656.10335400\n",
      "Iteration 65, loss = 993.94111233\n",
      "Iteration 227, loss = 888.69771615\n",
      "Iteration 8, loss = 8293.93777889\n",
      "Iteration 58, loss = 1014.03826812\n",
      "Iteration 236, loss = 901.08916102\n",
      "Iteration 80, loss = 941.26285042\n",
      "Iteration 16, loss = 1766.52866323\n",
      "Iteration 228, loss = 889.26486484\n",
      "Iteration 6, loss = 9269.57034745\n",
      "Iteration 66, loss = 959.12370591\n",
      "Iteration 9, loss = 8022.09937864\n",
      "Iteration 59, loss = 1011.71316584\n",
      "Iteration 237, loss = 899.83772528\n",
      "Iteration 229, loss = 886.68782276\n",
      "Iteration 81, loss = 1020.37634490\n",
      "Iteration 17, loss = 1705.56716284\n",
      "Iteration 67, loss = 988.00087186\n",
      "Iteration 7, loss = 8932.03899963\n",
      "Iteration 10, loss = 7768.34350961\n",
      "Iteration 60, loss = 975.29014523\n",
      "Iteration 238, loss = 900.08245165\n",
      "Iteration 230, loss = 886.24208828\n",
      "Iteration 82, loss = 1020.31336976\n",
      "Iteration 18, loss = 1646.12453778\n",
      "Iteration 8, loss = 8631.32901505\n",
      "Iteration 68, loss = 1005.80670396\n",
      "Iteration 239, loss = 899.30448959\n",
      "Iteration 231, loss = 884.67584751\n",
      "Iteration 61, loss = 1005.35857010\n",
      "Iteration 11, loss = 7532.09752809\n",
      "Iteration 83, loss = 990.27687190\n",
      "Iteration 19, loss = 1568.53974810\n",
      "Iteration 9, loss = 8351.96110928\n",
      "Iteration 240, loss = 896.67267365\n",
      "Iteration 69, loss = 1002.73944407\n",
      "Iteration 232, loss = 884.54237901\n",
      "Iteration 62, loss = 1046.53723760\n",
      "Iteration 12, loss = 7310.07789493\n",
      "Iteration 241, loss = 896.55391938\n",
      "Iteration 84, loss = 975.91874211\n",
      "Iteration 233, loss = 884.73369455\n",
      "Iteration 20, loss = 1500.38221557\n",
      "Iteration 10, loss = 8091.43527396\n",
      "Iteration 70, loss = 991.33159968\n",
      "Iteration 63, loss = 940.18093834\n",
      "Iteration 13, loss = 7101.24862743\n",
      "Iteration 242, loss = 897.47369512\n",
      "Iteration 234, loss = 884.17945539\n",
      "Iteration 85, loss = 1009.93847112\n",
      "Iteration 21, loss = 1474.22786898\n",
      "Iteration 11, loss = 7848.34706774\n",
      "Iteration 71, loss = 1079.08377223\n",
      "Iteration 243, loss = 896.35484982\n",
      "Iteration 14, loss = 6903.91943796\n",
      "Iteration 235, loss = 882.59670464\n",
      "Iteration 64, loss = 1000.84589434\n",
      "Iteration 86, loss = 1034.62331141\n",
      "Iteration 12, loss = 7620.19890609\n",
      "Iteration 22, loss = 1392.32180006\n",
      "Iteration 72, loss = 1024.50867611\n",
      "Iteration 244, loss = 894.40532396\n",
      "Iteration 236, loss = 880.73408530\n",
      "Iteration 15, loss = 6715.66720263\n",
      "Iteration 65, loss = 984.22036540\n",
      "Iteration 245, loss = 891.89051270\n",
      "Iteration 87, loss = 943.25945420\n",
      "Iteration 23, loss = 1367.17198343\n",
      "Iteration 13, loss = 7404.93345914\n",
      "Iteration 73, loss = 1020.50894594\n",
      "Iteration 237, loss = 880.53177538\n",
      "Iteration 66, loss = 948.10456298\n",
      "Iteration 16, loss = 6536.83437625\n",
      "Iteration 246, loss = 894.75385328\n",
      "Iteration 238, loss = 880.04247619\n",
      "Iteration 24, loss = 1340.40973124\n",
      "Iteration 88, loss = 947.85328292\n",
      "Iteration 14, loss = 7200.91513074\n",
      "Iteration 74, loss = 988.63669165\n",
      "Iteration 67, loss = 984.56176433\n",
      "Iteration 247, loss = 891.43309524\n",
      "Iteration 17, loss = 6366.56082218\n",
      "Iteration 239, loss = 879.15118141\n",
      "Iteration 25, loss = 1287.66999304\n",
      "Iteration 89, loss = 919.73138805\n",
      "Iteration 15, loss = 7006.51679112\n",
      "Iteration 75, loss = 991.53588356\n",
      "Iteration 248, loss = 893.64185929\n",
      "Iteration 68, loss = 989.72708779\n",
      "Iteration 240, loss = 877.51103336\n",
      "Iteration 18, loss = 6206.20350518\n",
      "Iteration 249, loss = 890.10375124\n",
      "Iteration 90, loss = 933.64240223\n",
      "Iteration 26, loss = 1278.61927526\n",
      "Iteration 76, loss = 994.01592692\n",
      "Iteration 16, loss = 6821.83754061\n",
      "Iteration 241, loss = 877.14467240\n",
      "Iteration 69, loss = 966.69134859\n",
      "Iteration 19, loss = 6052.45234805\n",
      "Iteration 250, loss = 888.11609141\n",
      "Iteration 242, loss = 875.57476923\n",
      "Iteration 17, loss = 6645.79433487\n",
      "Iteration 91, loss = 914.98287981\n",
      "Iteration 77, loss = 985.42314016\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 1237.38572532\n",
      "Iteration 70, loss = 977.29054060\n",
      "Iteration 20, loss = 5905.52670273\n",
      "Iteration 251, loss = 889.55260024\n",
      "Iteration 243, loss = 875.12086685\n",
      "Iteration 18, loss = 6479.25650435\n",
      "Iteration 28, loss = 1188.55813005\n",
      "Iteration 92, loss = 1095.67491013\n",
      "Iteration 252, loss = 890.35356693\n",
      "Iteration 1, loss = 11473.90085532\n",
      "Iteration 71, loss = 977.97462037\n",
      "Iteration 21, loss = 5765.25963052\n",
      "Iteration 244, loss = 872.75977381\n",
      "Iteration 19, loss = 6320.37677690\n",
      "Iteration 253, loss = 887.24149431\n",
      "Iteration 29, loss = 1202.59611701\n",
      "Iteration 245, loss = 871.83251098\n",
      "Iteration 93, loss = 988.25698763\n",
      "Iteration 72, loss = 956.47040824\n",
      "Iteration 2, loss = 10778.58295139\n",
      "Iteration 22, loss = 5630.79114383\n",
      "Iteration 20, loss = 6169.12407402\n",
      "Iteration 254, loss = 887.42835052\n",
      "Iteration 246, loss = 871.84546641\n",
      "Iteration 30, loss = 1137.99750814\n",
      "Iteration 94, loss = 1003.37999358\n",
      "Iteration 3, loss = 10264.59335504\n",
      "Iteration 73, loss = 985.78181939\n",
      "Iteration 23, loss = 5502.86183110\n",
      "Iteration 255, loss = 886.32648967\n",
      "Iteration 247, loss = 869.34550821\n",
      "Iteration 21, loss = 6024.66493761\n",
      "Iteration 31, loss = 1197.45203039\n",
      "Iteration 95, loss = 982.44953536\n",
      "Iteration 74, loss = 934.77312220\n",
      "Iteration 4, loss = 9787.77220923\n",
      "Iteration 256, loss = 886.08962038\n",
      "Iteration 24, loss = 5382.17136604\n",
      "Iteration 248, loss = 870.37189971\n",
      "Iteration 22, loss = 5886.28639481\n",
      "Iteration 32, loss = 1137.94972807\n",
      "Iteration 257, loss = 885.04592156\n",
      "Iteration 96, loss = 974.31911992\n",
      "Iteration 249, loss = 866.90057098\n",
      "Iteration 5, loss = 9370.26451581\n",
      "Iteration 75, loss = 979.71628593\n",
      "Iteration 25, loss = 5264.51823414\n",
      "Iteration 23, loss = 5753.83007091\n",
      "Iteration 258, loss = 884.70513214\n",
      "Iteration 33, loss = 1152.89648093\n",
      "Iteration 250, loss = 865.69699468\n",
      "Iteration 97, loss = 978.45985544\n",
      "Iteration 6, loss = 8987.80519090\n",
      "Iteration 26, loss = 5150.55120587\n",
      "Iteration 76, loss = 944.07247097\n",
      "Iteration 259, loss = 883.04290188\n",
      "Iteration 251, loss = 865.42881695\n",
      "Iteration 24, loss = 5629.27732062\n",
      "Iteration 34, loss = 1075.32252789\n",
      "Iteration 98, loss = 972.03282205\n",
      "Iteration 27, loss = 5041.74295362\n",
      "Iteration 7, loss = 8653.01513348\n",
      "Iteration 77, loss = 974.28453234\n",
      "Iteration 252, loss = 864.99166719\n",
      "Iteration 260, loss = 883.04870348\n",
      "Iteration 25, loss = 5507.59326354\n",
      "Iteration 35, loss = 1060.00828624\n",
      "Iteration 99, loss = 957.82999698\n",
      "Iteration 28, loss = 4938.36536445\n",
      "Iteration 8, loss = 8353.82385795\n",
      "Iteration 261, loss = 880.68761888\n",
      "Iteration 253, loss = 862.79620217\n",
      "Iteration 78, loss = 966.75613209\n",
      "Iteration 26, loss = 5390.71548827\n",
      "Iteration 36, loss = 1129.67710291\n",
      "Iteration 262, loss = 881.92922898\n",
      "Iteration 100, loss = 988.49133642\n",
      "Iteration 254, loss = 862.95353413\n",
      "Iteration 9, loss = 8075.69316197\n",
      "Iteration 29, loss = 4838.64008407\n",
      "Iteration 79, loss = 928.85684425\n",
      "Iteration 27, loss = 5278.91359376\n",
      "Iteration 263, loss = 880.71830200\n",
      "Iteration 255, loss = 861.38313148\n",
      "Iteration 37, loss = 1032.79563676\n",
      "Iteration 101, loss = 1024.27702374\n",
      "Iteration 30, loss = 4743.76194601\n",
      "Iteration 10, loss = 7817.97004866\n",
      "Iteration 80, loss = 923.84139830\n",
      "Iteration 264, loss = 880.43620750\n",
      "Iteration 256, loss = 860.58086706\n",
      "Iteration 28, loss = 5172.26544456\n",
      "Iteration 38, loss = 1055.45359624\n",
      "Iteration 102, loss = 993.83354023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 7577.18248853\n",
      "Iteration 31, loss = 4651.93366985\n",
      "Iteration 81, loss = 928.92114593\n",
      "Iteration 257, loss = 858.61513509\n",
      "Iteration 265, loss = 879.59753681\n",
      "Iteration 29, loss = 5068.72060171\n",
      "Iteration 39, loss = 1033.24209679\n",
      "Iteration 258, loss = 858.83957756\n",
      "Iteration 1, loss = 11764.16687310\n",
      "Iteration 12, loss = 7351.19493027\n",
      "Iteration 266, loss = 879.89587383\n",
      "Iteration 32, loss = 4564.76373525\n",
      "Iteration 82, loss = 988.99352572\n",
      "Iteration 30, loss = 4970.03292559\n",
      "Iteration 40, loss = 1044.12140043\n",
      "Iteration 259, loss = 858.25823033\n",
      "Iteration 267, loss = 876.61118980\n",
      "Iteration 2, loss = 11069.35603256\n",
      "Iteration 13, loss = 7138.35483902\n",
      "Iteration 33, loss = 4481.15233745\n",
      "Iteration 83, loss = 948.08326891\n",
      "Iteration 31, loss = 4874.53193229\n",
      "Iteration 260, loss = 857.30097002\n",
      "Iteration 268, loss = 878.38202163\n",
      "Iteration 41, loss = 1012.65875996\n",
      "Iteration 3, loss = 10553.44014918\n",
      "Iteration 34, loss = 4398.98786058\n",
      "Iteration 14, loss = 6936.95247902\n",
      "Iteration 84, loss = 908.44900790\n",
      "Iteration 261, loss = 855.62290265\n",
      "Iteration 269, loss = 876.44124275\n",
      "Iteration 32, loss = 4783.58635830\n",
      "Iteration 42, loss = 1054.70406150\n",
      "Iteration 4, loss = 10075.81086558\n",
      "Iteration 15, loss = 6745.18522942\n",
      "Iteration 35, loss = 4319.97805418\n",
      "Iteration 262, loss = 856.72804310\n",
      "Iteration 270, loss = 876.64791528\n",
      "Iteration 85, loss = 983.37443958\n",
      "Iteration 33, loss = 4696.46187257\n",
      "Iteration 43, loss = 1044.93820363\n",
      "Iteration 263, loss = 854.97570130\n",
      "Iteration 5, loss = 9657.42245139\n",
      "Iteration 271, loss = 875.93567752\n",
      "Iteration 36, loss = 4241.93402393\n",
      "Iteration 16, loss = 6562.70736149\n",
      "Iteration 86, loss = 967.24498394\n",
      "Iteration 34, loss = 4610.74830007\n",
      "Iteration 264, loss = 854.73375423\n",
      "Iteration 44, loss = 1056.36735163\n",
      "Iteration 272, loss = 875.24210086\n",
      "Iteration 6, loss = 9272.77136686\n",
      "Iteration 37, loss = 4167.37959905\n",
      "Iteration 17, loss = 6389.72558546\n",
      "Iteration 87, loss = 967.45632218\n",
      "Iteration 265, loss = 853.73533982\n",
      "Iteration 35, loss = 4527.68683877\n",
      "Iteration 273, loss = 873.68644479\n",
      "Iteration 45, loss = 1054.93042910\n",
      "Iteration 7, loss = 8936.47560525\n",
      "Iteration 38, loss = 4095.84471205\n",
      "Iteration 18, loss = 6224.71599869\n",
      "Iteration 266, loss = 852.87765531\n",
      "Iteration 88, loss = 943.94056098\n",
      "Iteration 274, loss = 871.97371293\n",
      "Iteration 36, loss = 4446.39285244\n",
      "Iteration 46, loss = 1027.37193818\n",
      "Iteration 267, loss = 850.42792310\n",
      "Iteration 8, loss = 8636.21401346\n",
      "Iteration 39, loss = 4025.89648846\n",
      "Iteration 19, loss = 6066.68878153\n",
      "Iteration 275, loss = 871.41051875\n",
      "Iteration 89, loss = 953.48888581\n",
      "Iteration 37, loss = 4368.26250482\n",
      "Iteration 268, loss = 852.28102735\n",
      "Iteration 47, loss = 1026.31439373\n",
      "Iteration 9, loss = 8357.00829767\n",
      "Iteration 276, loss = 870.96355898\n",
      "Iteration 20, loss = 5916.05112099\n",
      "Iteration 40, loss = 3957.53701814\n",
      "Iteration 90, loss = 959.80609252\n",
      "Iteration 269, loss = 849.67449014\n",
      "Iteration 38, loss = 4292.93502565\n",
      "Iteration 48, loss = 976.50777088\n",
      "Iteration 277, loss = 868.82313934\n",
      "Iteration 10, loss = 8097.79906509\n",
      "Iteration 41, loss = 3891.62124423\n",
      "Iteration 21, loss = 5772.55683564\n",
      "Iteration 91, loss = 1009.46674897\n",
      "Iteration 270, loss = 850.69342358\n",
      "Iteration 39, loss = 4219.88163006\n",
      "Iteration 278, loss = 868.50327431\n",
      "Iteration 49, loss = 1002.74516948\n",
      "Iteration 11, loss = 7855.64587491\n",
      "Iteration 271, loss = 849.09112973\n",
      "Iteration 42, loss = 3829.20949793\n",
      "Iteration 92, loss = 964.47406626\n",
      "Iteration 22, loss = 5635.02832397\n",
      "Iteration 279, loss = 868.48863040\n",
      "Iteration 40, loss = 4148.59602989\n",
      "Iteration 50, loss = 970.08439941\n",
      "Iteration 272, loss = 849.08804939\n",
      "Iteration 12, loss = 7628.28690975\n",
      "Iteration 93, loss = 991.18867540\n",
      "Iteration 43, loss = 3768.66894210\n",
      "Iteration 23, loss = 5504.14014990\n",
      "Iteration 280, loss = 867.90671568\n",
      "Iteration 41, loss = 4079.50759095\n",
      "Iteration 273, loss = 848.24730526\n",
      "Iteration 51, loss = 1016.73624795\n",
      "Iteration 13, loss = 7413.88795347\n",
      "Iteration 281, loss = 865.74682246\n",
      "Iteration 94, loss = 922.18162116\n",
      "Iteration 24, loss = 5378.03078683\n",
      "Iteration 44, loss = 3709.28195882\n",
      "Iteration 274, loss = 847.36884950\n",
      "Iteration 42, loss = 4013.05600374\n",
      "Iteration 52, loss = 1018.77028217\n",
      "Iteration 282, loss = 865.01701597\n",
      "Iteration 14, loss = 7211.29483262\n",
      "Iteration 95, loss = 928.87867199\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 275, loss = 846.70509720\n",
      "Iteration 45, loss = 3653.02368494\n",
      "Iteration 25, loss = 5255.92516985\n",
      "Iteration 43, loss = 3948.89688805\n",
      "Iteration 283, loss = 867.86254130\n",
      "Iteration 53, loss = 938.12175061\n",
      "Iteration 276, loss = 846.15445547\n",
      "Iteration 15, loss = 7019.17174746\n",
      "Iteration 46, loss = 3597.56505775\n",
      "Iteration 26, loss = 5139.14696748\n",
      "Iteration 1, loss = 11608.51366430\n",
      "Iteration 284, loss = 863.53011548\n",
      "Iteration 44, loss = 3886.06296739\n",
      "Iteration 277, loss = 845.47924908\n",
      "Iteration 54, loss = 966.60992608\n",
      "Iteration 16, loss = 6836.70286325\n",
      "Iteration 47, loss = 3544.33608508\n",
      "Iteration 27, loss = 5027.43978391\n",
      "Iteration 285, loss = 864.52972123\n",
      "Iteration 278, loss = 842.30337501\n",
      "Iteration 2, loss = 10916.16048571\n",
      "Iteration 45, loss = 3826.57055915\n",
      "Iteration 55, loss = 960.51343662\n",
      "Iteration 286, loss = 862.62034304\n",
      "Iteration 17, loss = 6663.10739654\n",
      "Iteration 279, loss = 843.38598951\n",
      "Iteration 48, loss = 3490.80864213\n",
      "Iteration 28, loss = 4922.20459511\n",
      "Iteration 3, loss = 10398.53725875\n",
      "Iteration 46, loss = 3767.56069102\n",
      "Iteration 56, loss = 942.75147821\n",
      "Iteration 287, loss = 862.89345713\n",
      "Iteration 280, loss = 842.66732015\n",
      "Iteration 18, loss = 6497.46616762\n",
      "Iteration 29, loss = 4821.25651769\n",
      "Iteration 49, loss = 3438.58059247\n",
      "Iteration 4, loss = 9922.08546610\n",
      "Iteration 47, loss = 3711.51531416\n",
      "Iteration 288, loss = 863.43921497\n",
      "Iteration 281, loss = 841.44044247\n",
      "Iteration 57, loss = 949.23398513\n",
      "Iteration 19, loss = 6338.01729344\n",
      "Iteration 30, loss = 4723.13496847\n",
      "Iteration 50, loss = 3388.91477257\n",
      "Iteration 289, loss = 862.21710119\n",
      "Iteration 5, loss = 9505.00960501\n",
      "Iteration 282, loss = 840.95459906\n",
      "Iteration 48, loss = 3654.35648251\n",
      "Iteration 58, loss = 925.81034802\n",
      "Iteration 290, loss = 861.37042034\n",
      "Iteration 20, loss = 6185.79520459\n",
      "Iteration 283, loss = 841.66814966\n",
      "Iteration 51, loss = 3339.73100012\n",
      "Iteration 31, loss = 4629.80360862\n",
      "Iteration 6, loss = 9121.84366061\n",
      "Iteration 49, loss = 3599.01254161\n",
      "Iteration 59, loss = 1008.62556267\n",
      "Iteration 291, loss = 860.81803954\n",
      "Iteration 284, loss = 838.94637217\n",
      "Iteration 52, loss = 3291.20442773\n",
      "Iteration 21, loss = 6040.88413219\n",
      "Iteration 32, loss = 4539.18371406\n",
      "Iteration 7, loss = 8786.11793245\n",
      "Iteration 50, loss = 3546.48976375\n",
      "Iteration 60, loss = 937.44520709\n",
      "Iteration 292, loss = 860.03956085\n",
      "Iteration 285, loss = 838.83783963\n",
      "Iteration 53, loss = 3245.75790377\n",
      "Iteration 22, loss = 5901.85514506\n",
      "Iteration 33, loss = 4450.83501264\n",
      "Iteration 8, loss = 8485.97805301\n",
      "Iteration 293, loss = 860.49934693\n",
      "Iteration 51, loss = 3493.81491898\n",
      "Iteration 286, loss = 837.88005289\n",
      "Iteration 61, loss = 975.88770309\n",
      "Iteration 54, loss = 3201.21420389\n",
      "Iteration 23, loss = 5769.99027494\n",
      "Iteration 34, loss = 4367.86525888\n",
      "Iteration 294, loss = 858.68952334\n",
      "Iteration 287, loss = 837.64928284\n",
      "Iteration 9, loss = 8206.76985248\n",
      "Iteration 52, loss = 3443.18777000\n",
      "Iteration 62, loss = 988.69651195\n",
      "Iteration 288, loss = 839.26713859\n",
      "Iteration 295, loss = 858.32070531\n",
      "Iteration 55, loss = 3158.39026372\n",
      "Iteration 24, loss = 5643.12188735\n",
      "Iteration 35, loss = 4284.38430836\n",
      "Iteration 10, loss = 7947.47065031\n",
      "Iteration 53, loss = 3394.08237055\n",
      "Iteration 63, loss = 957.36527467\n",
      "Iteration 289, loss = 834.92625914\n",
      "Iteration 296, loss = 858.16861079\n",
      "Iteration 56, loss = 3114.83022173\n",
      "Iteration 25, loss = 5519.74056871\n",
      "Iteration 36, loss = 4204.92561563\n",
      "Iteration 11, loss = 7704.39995241\n",
      "Iteration 54, loss = 3347.01988805\n",
      "Iteration 290, loss = 837.60723330\n",
      "Iteration 297, loss = 856.79561119\n",
      "Iteration 64, loss = 924.09594349\n",
      "Iteration 57, loss = 3073.94786216\n",
      "Iteration 26, loss = 5402.10283428\n",
      "Iteration 37, loss = 4127.65059010\n",
      "Iteration 291, loss = 835.26471643\n",
      "Iteration 12, loss = 7476.19110585\n",
      "Iteration 298, loss = 856.07520814\n",
      "Iteration 55, loss = 3301.69460399\n",
      "Iteration 65, loss = 945.85436382\n",
      "Iteration 292, loss = 833.63466227\n",
      "Iteration 58, loss = 3033.81508357\n",
      "Iteration 299, loss = 853.43996718\n",
      "Iteration 27, loss = 5289.18390315\n",
      "Iteration 38, loss = 4051.26727323\n",
      "Iteration 13, loss = 7260.68889037\n",
      "Iteration 56, loss = 3255.98187650\n",
      "Iteration 66, loss = 941.50959317\n",
      "Iteration 293, loss = 833.33772194\n",
      "Iteration 300, loss = 854.65808317\n",
      "Iteration 28, loss = 5182.90261026\n",
      "Iteration 59, loss = 2995.68692254\n",
      "Iteration 39, loss = 3979.78354167\n",
      "Iteration 14, loss = 7057.04119052\n",
      "Iteration 57, loss = 3213.01956175\n",
      "Iteration 294, loss = 832.81678550\n",
      "Iteration 67, loss = 979.76721634\n",
      "Iteration 301, loss = 854.80682277\n",
      "Iteration 29, loss = 5080.51314030\n",
      "Iteration 60, loss = 2956.51952439\n",
      "Iteration 40, loss = 3909.39222185\n",
      "Iteration 295, loss = 833.28239624\n",
      "Iteration 15, loss = 6863.91579352\n",
      "Iteration 58, loss = 3170.38353918\n",
      "Iteration 302, loss = 854.36808972\n",
      "Iteration 68, loss = 957.79379324\n",
      "Iteration 296, loss = 831.41071918\n",
      "Iteration 30, loss = 4981.08174458\n",
      "Iteration 61, loss = 2918.89163994\n",
      "Iteration 41, loss = 3842.10090881\n",
      "Iteration 16, loss = 6680.20231048\n",
      "Iteration 59, loss = 3128.90387696\n",
      "Iteration 303, loss = 854.21228233\n",
      "Iteration 69, loss = 936.77463524\n",
      "Iteration 297, loss = 829.68323238\n",
      "Iteration 31, loss = 4886.54196798\n",
      "Iteration 62, loss = 2881.79901401\n",
      "Iteration 42, loss = 3777.30155177\n",
      "Iteration 304, loss = 852.01214497\n",
      "Iteration 60, loss = 3086.67497791\n",
      "Iteration 17, loss = 6506.00144646\n",
      "Iteration 70, loss = 958.86794191\n",
      "Iteration 298, loss = 828.48209432\n",
      "Iteration 305, loss = 853.53843570\n",
      "Iteration 32, loss = 4794.69932138\n",
      "Iteration 63, loss = 2846.32756734\n",
      "Iteration 43, loss = 3712.23090078\n",
      "Iteration 299, loss = 826.48124901\n",
      "Iteration 61, loss = 3046.80207199\n",
      "Iteration 18, loss = 6340.12631732\n",
      "Iteration 71, loss = 901.37062109\n",
      "Iteration 306, loss = 852.47957712\n",
      "Iteration 33, loss = 4705.38965775\n",
      "Iteration 300, loss = 827.14744350\n",
      "Iteration 64, loss = 2811.65091098\n",
      "Iteration 44, loss = 3651.30126237\n",
      "Iteration 62, loss = 3007.01535846\n",
      "Iteration 19, loss = 6181.00178595\n",
      "Iteration 72, loss = 898.74143876\n",
      "Iteration 307, loss = 851.87184546\n",
      "Iteration 301, loss = 825.03740789\n",
      "Iteration 65, loss = 2777.53914674\n",
      "Iteration 34, loss = 4621.43125613\n",
      "Iteration 45, loss = 3589.32601694\n",
      "Iteration 63, loss = 2969.30562064\n",
      "Iteration 308, loss = 852.01220983\n",
      "Iteration 20, loss = 6028.72883185\n",
      "Iteration 73, loss = 964.76741520\n",
      "Iteration 302, loss = 825.90017579\n",
      "Iteration 66, loss = 2745.43644995\n",
      "Iteration 35, loss = 4536.71315024\n",
      "Iteration 46, loss = 3530.58448770\n",
      "Iteration 309, loss = 849.58069963\n",
      "Iteration 64, loss = 2932.43192499\n",
      "Iteration 74, loss = 945.46457583\n",
      "Iteration 21, loss = 5883.12306141\n",
      "Iteration 303, loss = 824.67179325\n",
      "Iteration 67, loss = 2713.84975035\n",
      "Iteration 310, loss = 850.94528019\n",
      "Iteration 36, loss = 4455.99273477\n",
      "Iteration 47, loss = 3473.70029893\n",
      "Iteration 304, loss = 822.29544773\n",
      "Iteration 65, loss = 2896.02209654\n",
      "Iteration 22, loss = 5744.01369544\n",
      "Iteration 75, loss = 918.12970047\n",
      "Iteration 311, loss = 848.85045643\n",
      "Iteration 68, loss = 2683.59041575\n",
      "Iteration 305, loss = 825.50020191\n",
      "Iteration 37, loss = 4377.38131191\n",
      "Iteration 48, loss = 3418.42392978\n",
      "Iteration 66, loss = 2861.24200350\n",
      "Iteration 23, loss = 5612.27822888\n",
      "Iteration 76, loss = 932.82819276\n",
      "Iteration 312, loss = 849.49760818\n",
      "Iteration 306, loss = 822.76027612\n",
      "Iteration 69, loss = 2654.85336476\n",
      "Iteration 38, loss = 4300.13264950\n",
      "Iteration 49, loss = 3364.72640055\n",
      "Iteration 67, loss = 2828.30688546\n",
      "Iteration 313, loss = 849.09646395\n",
      "Iteration 24, loss = 5485.46033920\n",
      "Iteration 77, loss = 912.25918648\n",
      "Iteration 307, loss = 821.26428006\n",
      "Iteration 39, loss = 4226.37884898\n",
      "Iteration 70, loss = 2623.75949633\n",
      "Iteration 50, loss = 3311.04762738\n",
      "Iteration 314, loss = 849.44341492\n",
      "Iteration 308, loss = 821.43751884\n",
      "Iteration 68, loss = 2794.68971175\n",
      "Iteration 25, loss = 5362.58098458\n",
      "Iteration 78, loss = 899.43938487\n",
      "Iteration 315, loss = 850.19425174\n",
      "Iteration 40, loss = 4153.60282501\n",
      "Iteration 309, loss = 817.24384724\n",
      "Iteration 51, loss = 3260.93962293\n",
      "Iteration 71, loss = 2595.52724944\n",
      "Iteration 69, loss = 2762.25099642\n",
      "Iteration 26, loss = 5245.73962055\n",
      "Iteration 79, loss = 946.21407931\n",
      "Iteration 316, loss = 847.63876217\n",
      "Iteration 310, loss = 821.86485361\n",
      "Iteration 41, loss = 4085.15021787\n",
      "Iteration 52, loss = 3209.44176336\n",
      "Iteration 72, loss = 2568.18150095\n",
      "Iteration 70, loss = 2730.02191252\n",
      "Iteration 27, loss = 5133.81510511\n",
      "Iteration 80, loss = 922.79379238\n",
      "Iteration 317, loss = 846.48506565\n",
      "Iteration 311, loss = 820.19069276\n",
      "Iteration 42, loss = 4017.88017698\n",
      "Iteration 53, loss = 3163.39554469\n",
      "Iteration 73, loss = 2540.44283539\n",
      "Iteration 318, loss = 847.54975403\n",
      "Iteration 312, loss = 818.92006734\n",
      "Iteration 71, loss = 2699.32044894\n",
      "Iteration 28, loss = 5028.03333963\n",
      "Iteration 81, loss = 937.32066408\n",
      "Iteration 43, loss = 3951.15304285\n",
      "Iteration 54, loss = 3116.32349080\n",
      "Iteration 313, loss = 818.30698031\n",
      "Iteration 319, loss = 846.39414669\n",
      "Iteration 74, loss = 2513.56428028\n",
      "Iteration 72, loss = 2669.34100959\n",
      "Iteration 29, loss = 4926.17577977\n",
      "Iteration 82, loss = 959.78427025\n",
      "Iteration 314, loss = 818.95977531\n",
      "Iteration 320, loss = 845.56396371\n",
      "Iteration 44, loss = 3888.54189069\n",
      "Iteration 55, loss = 3070.82323754\n",
      "Iteration 75, loss = 2485.76554669\n",
      "Iteration 73, loss = 2640.40724858\n",
      "Iteration 30, loss = 4827.71547481\n",
      "Iteration 83, loss = 923.97816482\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 315, loss = 818.67097439\n",
      "Iteration 321, loss = 844.59782141\n",
      "Iteration 45, loss = 3825.91455396\n",
      "Iteration 76, loss = 2461.96317425\n",
      "Iteration 56, loss = 3026.64469910\n",
      "Iteration 316, loss = 818.15419078\n",
      "Iteration 74, loss = 2610.48367540\n",
      "Iteration 322, loss = 844.98784976\n",
      "Iteration 31, loss = 4733.73511875\n",
      "Iteration 1, loss = 11522.67407861\n",
      "Iteration 77, loss = 2436.30858804\n",
      "Iteration 46, loss = 3766.50030209\n",
      "Iteration 317, loss = 815.04422420\n",
      "Iteration 57, loss = 2982.39268131\n",
      "Iteration 323, loss = 842.54465969\n",
      "Iteration 32, loss = 4642.85868990\n",
      "Iteration 75, loss = 2580.91445464\n",
      "Iteration 2, loss = 10831.53172602\n",
      "Iteration 318, loss = 816.40797929\n",
      "Iteration 78, loss = 2410.82722661\n",
      "Iteration 324, loss = 843.15127445\n",
      "Iteration 47, loss = 3708.67220019\n",
      "Iteration 58, loss = 2940.20545255\n",
      "Iteration 76, loss = 2555.45275117\n",
      "Iteration 33, loss = 4554.67999887\n",
      "Iteration 319, loss = 814.53652137\n",
      "Iteration 3, loss = 10316.52265988\n",
      "Iteration 325, loss = 843.77641459\n",
      "Iteration 79, loss = 2386.24765553\n",
      "Iteration 48, loss = 3652.85402780\n",
      "Iteration 59, loss = 2898.64098323\n",
      "Iteration 77, loss = 2526.63077334\n",
      "Iteration 34, loss = 4470.88679041\n",
      "Iteration 320, loss = 815.16906518\n",
      "Iteration 326, loss = 842.76943797\n",
      "Iteration 4, loss = 9840.56109436\n",
      "Iteration 80, loss = 2363.23993617\n",
      "Iteration 49, loss = 3598.44575779\n",
      "Iteration 60, loss = 2858.15255559\n",
      "Iteration 321, loss = 813.44475024\n",
      "Iteration 327, loss = 842.46274502\n",
      "Iteration 78, loss = 2499.88402510\n",
      "Iteration 35, loss = 4388.29376479\n",
      "Iteration 5, loss = 9424.49201194\n",
      "Iteration 81, loss = 2342.21157728\n",
      "Iteration 50, loss = 3544.61227139\n",
      "Iteration 322, loss = 813.24616289\n",
      "Iteration 61, loss = 2819.34548804\n",
      "Iteration 328, loss = 841.23584895\n",
      "Iteration 79, loss = 2474.13575987\n",
      "Iteration 36, loss = 4308.24088409\n",
      "Iteration 6, loss = 9043.94804347\n",
      "Iteration 82, loss = 2316.97743903\n",
      "Iteration 323, loss = 811.57199753\n",
      "Iteration 329, loss = 840.42469217\n",
      "Iteration 51, loss = 3491.86479250\n",
      "Iteration 62, loss = 2779.94448944\n",
      "Iteration 80, loss = 2449.09305160\n",
      "Iteration 37, loss = 4230.58710639\n",
      "Iteration 324, loss = 812.16761562\n",
      "Iteration 330, loss = 840.20452886\n",
      "Iteration 7, loss = 8711.24014958\n",
      "Iteration 83, loss = 2297.11010728\n",
      "Iteration 52, loss = 3439.83120274\n",
      "Iteration 63, loss = 2743.34948969\n",
      "Iteration 81, loss = 2425.77190559\n",
      "Iteration 325, loss = 811.71268572\n",
      "Iteration 38, loss = 4154.51546556\n",
      "Iteration 331, loss = 839.96421608\n",
      "Iteration 84, loss = 2275.04346211\n",
      "Iteration 8, loss = 8413.68717289\n",
      "Iteration 53, loss = 3391.70675786\n",
      "Iteration 326, loss = 811.94504538\n",
      "Iteration 64, loss = 2707.23348265\n",
      "Iteration 332, loss = 839.18129877\n",
      "Iteration 82, loss = 2399.54198813\n",
      "Iteration 39, loss = 4081.31604010\n",
      "Iteration 85, loss = 2255.17673861\n",
      "Iteration 327, loss = 811.43681602\n",
      "Iteration 9, loss = 8137.91996339\n",
      "Iteration 333, loss = 837.31333120\n",
      "Iteration 83, loss = 2377.31463792\n",
      "Iteration 54, loss = 3342.43053613\n",
      "Iteration 40, loss = 4009.48501984\n",
      "Iteration 65, loss = 2671.36703996\n",
      "Iteration 328, loss = 810.59246019\n",
      "Iteration 86, loss = 2233.23967069\n",
      "Iteration 334, loss = 838.97475319\n",
      "Iteration 10, loss = 7881.11386117\n",
      "Iteration 84, loss = 2353.62818250\n",
      "Iteration 55, loss = 3295.80833574\n",
      "Iteration 329, loss = 809.74252741\n",
      "Iteration 41, loss = 3941.70924065\n",
      "Iteration 66, loss = 2638.10585134\n",
      "Iteration 335, loss = 837.87999653\n",
      "Iteration 87, loss = 2213.05024175\n",
      "Iteration 330, loss = 808.78495276\n",
      "Iteration 85, loss = 2332.57005933\n",
      "Iteration 11, loss = 7639.97896630\n",
      "Iteration 56, loss = 3249.17874643\n",
      "Iteration 42, loss = 3875.58341993\n",
      "Iteration 67, loss = 2602.37488820\n",
      "Iteration 336, loss = 837.46463407\n",
      "Iteration 88, loss = 2193.50256740\n",
      "Iteration 331, loss = 808.82837403\n",
      "Iteration 86, loss = 2308.79470711\n",
      "Iteration 12, loss = 7414.10702942\n",
      "Iteration 57, loss = 3203.24882683\n",
      "Iteration 337, loss = 837.58943458\n",
      "Iteration 43, loss = 3810.81712437\n",
      "Iteration 68, loss = 2570.78984513\n",
      "Iteration 332, loss = 809.33062147\n",
      "Iteration 89, loss = 2174.30117721\n",
      "Iteration 338, loss = 836.71857218\n",
      "Iteration 87, loss = 2286.71220711\n",
      "Iteration 58, loss = 3160.04315242\n",
      "Iteration 13, loss = 7201.33918814\n",
      "Iteration 44, loss = 3750.15571354\n",
      "Iteration 333, loss = 807.39467762\n",
      "Iteration 69, loss = 2539.39696747\n",
      "Iteration 339, loss = 835.46399228\n",
      "Iteration 90, loss = 2154.07079502\n",
      "Iteration 88, loss = 2265.32893227\n",
      "Iteration 334, loss = 807.29769410\n",
      "Iteration 59, loss = 3116.99143120\n",
      "Iteration 14, loss = 7000.05366638\n",
      "Iteration 45, loss = 3688.30692923\n",
      "Iteration 70, loss = 2508.73565989\n",
      "Iteration 340, loss = 835.79213192\n",
      "Iteration 91, loss = 2135.72760270\n",
      "Iteration 335, loss = 806.63290185\n",
      "Iteration 60, loss = 3074.20168572\n",
      "Iteration 89, loss = 2243.58383482\n",
      "Iteration 15, loss = 6810.00186522\n",
      "Iteration 46, loss = 3630.14832370\n",
      "Iteration 341, loss = 835.85049604\n",
      "Iteration 71, loss = 2477.15829782\n",
      "Iteration 336, loss = 806.74452801\n",
      "Iteration 92, loss = 2116.09015047\n",
      "Iteration 61, loss = 3034.36002913\n",
      "Iteration 90, loss = 2223.30471996\n",
      "Iteration 342, loss = 835.34016983\n",
      "Iteration 47, loss = 3571.79096143\n",
      "Iteration 16, loss = 6628.47576644\n",
      "Iteration 337, loss = 806.30474280\n",
      "Iteration 72, loss = 2447.97750131\n",
      "Iteration 93, loss = 2096.83280663\n",
      "Iteration 343, loss = 833.78818874\n",
      "Iteration 91, loss = 2202.70469152\n",
      "Iteration 62, loss = 2993.58461204\n",
      "Iteration 338, loss = 806.17527856\n",
      "Iteration 17, loss = 6455.99446002\n",
      "Iteration 48, loss = 3517.83932387\n",
      "Iteration 73, loss = 2419.45848855\n",
      "Iteration 344, loss = 834.15887373\n",
      "Iteration 94, loss = 2079.70171389\n",
      "Iteration 92, loss = 2182.07896871\n",
      "Iteration 339, loss = 802.48381862\n",
      "Iteration 63, loss = 2955.86728273\n",
      "Iteration 18, loss = 6292.01435769\n",
      "Iteration 74, loss = 2390.30473863\n",
      "Iteration 49, loss = 3464.74968931\n",
      "Iteration 345, loss = 833.53101510\n",
      "Iteration 340, loss = 805.12094434\n",
      "Iteration 95, loss = 2060.23555739\n",
      "Iteration 93, loss = 2161.83909119\n",
      "Iteration 64, loss = 2918.42520417\n",
      "Iteration 19, loss = 6134.52886297\n",
      "Iteration 346, loss = 831.93929737\n",
      "Iteration 75, loss = 2361.35122955\n",
      "Iteration 341, loss = 805.64033277\n",
      "Iteration 50, loss = 3411.58195033\n",
      "Iteration 96, loss = 2043.63194764\n",
      "Iteration 65, loss = 2882.12442620\n",
      "Iteration 94, loss = 2143.52749475\n",
      "Iteration 347, loss = 833.72961536\n",
      "Iteration 20, loss = 5984.09617501\n",
      "Iteration 342, loss = 805.29951992\n",
      "Iteration 76, loss = 2335.26646314\n",
      "Iteration 51, loss = 3360.91470027\n",
      "Iteration 97, loss = 2024.85006987\n",
      "Iteration 66, loss = 2847.43403801\n",
      "Iteration 95, loss = 2123.80510594\n",
      "Iteration 348, loss = 832.04288907\n",
      "Iteration 343, loss = 802.68290879\n",
      "Iteration 21, loss = 5840.12268315\n",
      "Iteration 77, loss = 2308.35260222\n",
      "Iteration 52, loss = 3310.59802611\n",
      "Iteration 349, loss = 832.74753452\n",
      "Iteration 98, loss = 2010.27556301\n",
      "Iteration 67, loss = 2810.53773198\n",
      "Iteration 96, loss = 2105.68680257\n",
      "Iteration 344, loss = 803.14111537\n",
      "Iteration 22, loss = 5702.56277295\n",
      "Iteration 78, loss = 2280.58999602\n",
      "Iteration 350, loss = 830.89939724\n",
      "Iteration 53, loss = 3262.72059607\n",
      "Iteration 99, loss = 1990.52179966\n",
      "Iteration 68, loss = 2777.69238522\n",
      "Iteration 97, loss = 2085.21543984\n",
      "Iteration 345, loss = 803.01550407\n",
      "Iteration 351, loss = 829.63804311\n",
      "Iteration 23, loss = 5572.49983755\n",
      "Iteration 79, loss = 2256.00565947\n",
      "Iteration 54, loss = 3215.26688086\n",
      "Iteration 346, loss = 799.26305248\n",
      "Iteration 100, loss = 1974.95681207\n",
      "Iteration 69, loss = 2744.37241132\n",
      "Iteration 98, loss = 2070.27302055\n",
      "Iteration 352, loss = 830.98334390\n",
      "Iteration 24, loss = 5447.51626706\n",
      "Iteration 80, loss = 2231.65669237\n",
      "Iteration 347, loss = 804.11513264\n",
      "Iteration 55, loss = 3168.84544020\n",
      "Iteration 101, loss = 1958.46839726\n",
      "Iteration 70, loss = 2713.63817841\n",
      "Iteration 353, loss = 830.61003582\n",
      "Iteration 99, loss = 2050.49728412\n",
      "Iteration 348, loss = 800.84266990\n",
      "Iteration 81, loss = 2205.30119574\n",
      "Iteration 25, loss = 5327.23393437\n",
      "Iteration 56, loss = 3123.15211120\n",
      "Iteration 354, loss = 830.11826946\n",
      "Iteration 102, loss = 1942.82437238\n",
      "Iteration 71, loss = 2680.57601206\n",
      "Iteration 349, loss = 802.16429438\n",
      "Iteration 100, loss = 2031.87103181\n",
      "Iteration 82, loss = 2182.43341735\n",
      "Iteration 26, loss = 5212.33948945\n",
      "Iteration 355, loss = 828.84259637\n",
      "Iteration 57, loss = 3078.57522422\n",
      "Iteration 350, loss = 800.65148670\n",
      "Iteration 103, loss = 1925.27535316\n",
      "Iteration 72, loss = 2650.34803042\n",
      "Iteration 101, loss = 2013.31869225\n",
      "Iteration 356, loss = 829.88991322\n",
      "Iteration 83, loss = 2159.50424372\n",
      "Iteration 351, loss = 798.71457577\n",
      "Iteration 27, loss = 5102.42825665\n",
      "Iteration 58, loss = 3036.37205973\n",
      "Iteration 104, loss = 1912.89552163\n",
      "Iteration 73, loss = 2620.38713691\n",
      "Iteration 102, loss = 1996.07777083\n",
      "Iteration 357, loss = 828.58913205\n",
      "Iteration 352, loss = 802.08240844\n",
      "Iteration 84, loss = 2137.82747997\n",
      "Iteration 28, loss = 4998.26480761\n",
      "Iteration 59, loss = 2994.01382675\n",
      "Iteration 105, loss = 1899.89267014\n",
      "Iteration 74, loss = 2591.76494644\n",
      "Iteration 353, loss = 800.16946551\n",
      "Iteration 358, loss = 827.76802754\n",
      "Iteration 103, loss = 1978.21445445\n",
      "Iteration 85, loss = 2115.56123817\n",
      "Iteration 29, loss = 4898.19825395\n",
      "Iteration 354, loss = 800.05281913\n",
      "Iteration 60, loss = 2953.06422934\n",
      "Iteration 359, loss = 829.31391743\n",
      "Iteration 106, loss = 1883.21653028\n",
      "Iteration 75, loss = 2562.10356239\n",
      "Iteration 104, loss = 1964.77733055\n",
      "Iteration 86, loss = 2089.62328074\n",
      "Iteration 355, loss = 798.22435313\n",
      "Iteration 30, loss = 4802.16896292\n",
      "Iteration 360, loss = 827.13852898\n",
      "Iteration 61, loss = 2913.90239673\n",
      "Iteration 107, loss = 1868.32903958\n",
      "Iteration 76, loss = 2534.67327073\n",
      "Iteration 105, loss = 1948.70723754\n",
      "Iteration 356, loss = 799.41945961\n",
      "Iteration 87, loss = 2071.15323391\n",
      "Iteration 361, loss = 827.23611198\n",
      "Iteration 31, loss = 4709.94595650\n",
      "Iteration 62, loss = 2874.24204054\n",
      "Iteration 108, loss = 1855.51252069\n",
      "Iteration 357, loss = 798.08502730\n",
      "Iteration 77, loss = 2507.28828078\n",
      "Iteration 106, loss = 1930.78629102\n",
      "Iteration 362, loss = 827.15747208\n",
      "Iteration 88, loss = 2050.85541406\n",
      "Iteration 32, loss = 4621.05538670\n",
      "Iteration 63, loss = 2837.93742387\n",
      "Iteration 358, loss = 797.23554333\n",
      "Iteration 363, loss = 826.10863356\n",
      "Iteration 109, loss = 1843.18534270\n",
      "Iteration 78, loss = 2479.29455983\n",
      "Iteration 107, loss = 1915.14656611\n",
      "Iteration 89, loss = 2028.63583149\n",
      "Iteration 33, loss = 4535.39782001\n",
      "Iteration 64, loss = 2802.30044931\n",
      "Iteration 364, loss = 825.46753824\n",
      "Iteration 359, loss = 798.09963915\n",
      "Iteration 110, loss = 1827.53435703\n",
      "Iteration 108, loss = 1903.20807198\n",
      "Iteration 79, loss = 2453.67095083\n",
      "Iteration 90, loss = 2010.12857771\n",
      "Iteration 34, loss = 4453.66658659\n",
      "Iteration 360, loss = 796.82137272\n",
      "Iteration 365, loss = 825.39929043\n",
      "Iteration 65, loss = 2767.55536970\n",
      "Iteration 111, loss = 1815.70990754\n",
      "Iteration 109, loss = 1885.21350328\n",
      "Iteration 80, loss = 2428.62018377\n",
      "Iteration 91, loss = 1988.46231782\n",
      "Iteration 361, loss = 796.64902354\n",
      "Iteration 366, loss = 825.22147491\n",
      "Iteration 35, loss = 4373.23065675\n",
      "Iteration 112, loss = 1798.62742690\n",
      "Iteration 66, loss = 2735.11648877\n",
      "Iteration 110, loss = 1869.11842757\n",
      "Iteration 362, loss = 795.72492644\n",
      "Iteration 81, loss = 2402.32727836\n",
      "Iteration 367, loss = 825.14038320\n",
      "Iteration 92, loss = 1971.48589935\n",
      "Iteration 36, loss = 4295.90382324\n",
      "Iteration 363, loss = 794.77912424\n",
      "Iteration 368, loss = 825.90925204\n",
      "Iteration 113, loss = 1789.88305036\n",
      "Iteration 67, loss = 2700.33062613\n",
      "Iteration 82, loss = 2377.63822773\n",
      "Iteration 93, loss = 1951.35929554\n",
      "Iteration 111, loss = 1859.00264331\n",
      "Iteration 37, loss = 4219.76381744\n",
      "Iteration 364, loss = 794.52161767\n",
      "Iteration 369, loss = 823.87300626\n",
      "Iteration 114, loss = 1778.04620973\n",
      "Iteration 68, loss = 2668.03467263\n",
      "Iteration 83, loss = 2354.49183850\n",
      "Iteration 94, loss = 1931.31546908\n",
      "Iteration 112, loss = 1838.36596257\n",
      "Iteration 365, loss = 795.07892776\n",
      "Iteration 370, loss = 824.21280691\n",
      "Iteration 38, loss = 4146.73194209\n",
      "Iteration 115, loss = 1764.44820152\n",
      "Iteration 69, loss = 2636.52488738\n",
      "Iteration 84, loss = 2331.82858701\n",
      "Iteration 366, loss = 795.07260232\n",
      "Iteration 95, loss = 1914.47641253\n",
      "Iteration 113, loss = 1828.96833401\n",
      "Iteration 371, loss = 821.00733934\n",
      "Iteration 39, loss = 4075.11225013\n",
      "Iteration 70, loss = 2605.52575333\n",
      "Iteration 116, loss = 1752.23920437\n",
      "Iteration 367, loss = 795.16958337\n",
      "Iteration 85, loss = 2307.96552016\n",
      "Iteration 372, loss = 824.73257161\n",
      "Iteration 96, loss = 1895.18982314\n",
      "Iteration 114, loss = 1813.40263153\n",
      "Iteration 368, loss = 795.26210814\n",
      "Iteration 40, loss = 4004.90681747\n",
      "Iteration 71, loss = 2573.57218560\n",
      "Iteration 373, loss = 822.15802510\n",
      "Iteration 117, loss = 1740.58270203\n",
      "Iteration 86, loss = 2282.46021192\n",
      "Iteration 97, loss = 1877.24848065\n",
      "Iteration 115, loss = 1798.45573322\n",
      "Iteration 369, loss = 793.28372431\n",
      "Iteration 41, loss = 3938.83720458\n",
      "Iteration 374, loss = 820.78470526\n",
      "Iteration 72, loss = 2544.98964736\n",
      "Iteration 118, loss = 1730.20734756\n",
      "Iteration 87, loss = 2263.41549754\n",
      "Iteration 116, loss = 1786.47215490\n",
      "Iteration 98, loss = 1861.77814176Iteration 370, loss = 793.55665560\n",
      "\n",
      "Iteration 375, loss = 824.01163567\n",
      "Iteration 42, loss = 3874.10554850\n",
      "Iteration 73, loss = 2516.02847606\n",
      "Iteration 119, loss = 1718.59678243\n",
      "Iteration 371, loss = 789.94896097\n",
      "Iteration 88, loss = 2241.44424888\n",
      "Iteration 117, loss = 1773.70488176\n",
      "Iteration 99, loss = 1844.11727731\n",
      "Iteration 376, loss = 820.62396937\n",
      "Iteration 372, loss = 793.57791272\n",
      "Iteration 43, loss = 3811.20045710\n",
      "Iteration 120, loss = 1706.77728668\n",
      "Iteration 74, loss = 2487.06124129\n",
      "Iteration 89, loss = 2219.13632216\n",
      "Iteration 377, loss = 821.35697184\n",
      "Iteration 100, loss = 1826.57100976\n",
      "Iteration 118, loss = 1760.62380181\n",
      "Iteration 373, loss = 791.14268956\n",
      "Iteration 44, loss = 3750.00379340\n",
      "Iteration 121, loss = 1693.96536069\n",
      "Iteration 75, loss = 2459.33320976\n",
      "Iteration 378, loss = 820.18551170\n",
      "Iteration 101, loss = 1811.42615393\n",
      "Iteration 90, loss = 2198.41241288\n",
      "Iteration 119, loss = 1751.24763697\n",
      "Iteration 374, loss = 792.28361435\n",
      "Iteration 45, loss = 3689.76760055\n",
      "Iteration 379, loss = 820.26363454\n",
      "Iteration 76, loss = 2432.39326551\n",
      "Iteration 122, loss = 1681.44133460\n",
      "Iteration 102, loss = 1795.21198820\n",
      "Iteration 375, loss = 792.21143078\n",
      "Iteration 91, loss = 2176.26432781\n",
      "Iteration 120, loss = 1737.64103920\n",
      "Iteration 380, loss = 821.79918628\n",
      "Iteration 46, loss = 3633.58139715\n",
      "Iteration 376, loss = 789.68796669\n",
      "Iteration 77, loss = 2407.17865186\n",
      "Iteration 123, loss = 1673.00691178\n",
      "Iteration 103, loss = 1778.35424544\n",
      "Iteration 92, loss = 2157.90082257\n",
      "Iteration 121, loss = 1723.89736271\n",
      "Iteration 381, loss = 820.08819989\n",
      "Iteration 377, loss = 792.05995266\n",
      "Iteration 47, loss = 3578.18776464\n",
      "Iteration 78, loss = 2379.60201685\n",
      "Iteration 124, loss = 1658.77077153\n",
      "Iteration 104, loss = 1762.59355597\n",
      "Iteration 93, loss = 2135.61049316\n",
      "Iteration 382, loss = 819.50576387\n",
      "Iteration 122, loss = 1710.27719636\n",
      "Iteration 378, loss = 789.28787992\n",
      "Iteration 48, loss = 3524.61780062\n",
      "Iteration 79, loss = 2354.62819774\n",
      "Iteration 383, loss = 818.60310209\n",
      "Iteration 125, loss = 1652.36695202\n",
      "Iteration 105, loss = 1747.69458590\n",
      "Iteration 379, loss = 790.44088993\n",
      "Iteration 94, loss = 2114.88450858\n",
      "Iteration 123, loss = 1699.23362555\n",
      "Iteration 49, loss = 3471.64446148\n",
      "Iteration 384, loss = 818.50424358\n",
      "Iteration 80, loss = 2330.18159233\n",
      "Iteration 380, loss = 791.34430490\n",
      "Iteration 126, loss = 1637.24686524\n",
      "Iteration 106, loss = 1734.48933615\n",
      "Iteration 95, loss = 2094.80421259\n",
      "Iteration 124, loss = 1684.81217105\n",
      "Iteration 385, loss = 819.32992450\n",
      "Iteration 381, loss = 788.45458683\n",
      "Iteration 50, loss = 3419.90679671\n",
      "Iteration 81, loss = 2304.27620306\n",
      "Iteration 127, loss = 1630.07016431\n",
      "Iteration 107, loss = 1720.30976827\n",
      "Iteration 96, loss = 2075.18394518\n",
      "Iteration 125, loss = 1678.35690970\n",
      "Iteration 382, loss = 789.47710537\n",
      "Iteration 386, loss = 818.80821508\n",
      "Iteration 51, loss = 3368.56560939\n",
      "Iteration 82, loss = 2281.45124870\n",
      "Iteration 97, loss = 2054.44483723\n",
      "Iteration 128, loss = 1616.88268493\n",
      "Iteration 108, loss = 1704.35527270\n",
      "Iteration 383, loss = 788.27777922\n",
      "Iteration 387, loss = 816.90020511\n",
      "Iteration 126, loss = 1660.77558562\n",
      "Iteration 52, loss = 3319.61052555\n",
      "Iteration 83, loss = 2258.80851387\n",
      "Iteration 384, loss = 788.59704868\n",
      "Iteration 129, loss = 1607.69333899\n",
      "Iteration 388, loss = 818.63987932\n",
      "Iteration 109, loss = 1689.52792865\n",
      "Iteration 98, loss = 2038.93302803\n",
      "Iteration 127, loss = 1652.95851958\n",
      "Iteration 385, loss = 788.99084394\n",
      "Iteration 84, loss = 2236.28482642\n",
      "Iteration 389, loss = 816.86476480\n",
      "Iteration 53, loss = 3271.53819273\n",
      "Iteration 130, loss = 1598.11112865\n",
      "Iteration 110, loss = 1675.07426064\n",
      "Iteration 99, loss = 2020.65424651\n",
      "Iteration 128, loss = 1639.04765220\n",
      "Iteration 386, loss = 787.32765166\n",
      "Iteration 390, loss = 818.64218646\n",
      "Iteration 54, loss = 3224.77193715\n",
      "Iteration 85, loss = 2212.87712636\n",
      "Iteration 131, loss = 1589.80607973\n",
      "Iteration 111, loss = 1662.74435075\n",
      "Iteration 100, loss = 2002.62925596\n",
      "Iteration 129, loss = 1630.62751452\n",
      "Iteration 387, loss = 786.15215540\n",
      "Iteration 391, loss = 814.03993456\n",
      "Iteration 55, loss = 3179.14479844\n",
      "Iteration 86, loss = 2188.30343973\n",
      "Iteration 132, loss = 1582.23483228\n",
      "Iteration 112, loss = 1650.86745462\n",
      "Iteration 388, loss = 787.44720983\n",
      "Iteration 101, loss = 1984.45628211\n",
      "Iteration 392, loss = 816.10599257\n",
      "Iteration 130, loss = 1617.39493754\n",
      "Iteration 56, loss = 3134.76336679\n",
      "Iteration 87, loss = 2169.77189968\n",
      "Iteration 133, loss = 1568.72863344\n",
      "Iteration 393, loss = 814.93203886\n",
      "Iteration 389, loss = 786.01684506\n",
      "Iteration 113, loss = 1635.90742413\n",
      "Iteration 102, loss = 1967.52505869\n",
      "Iteration 131, loss = 1610.25239308\n",
      "Iteration 394, loss = 815.60556518\n",
      "Iteration 390, loss = 786.71482544\n",
      "Iteration 57, loss = 3091.51275523\n",
      "Iteration 88, loss = 2148.35618419\n",
      "Iteration 134, loss = 1558.91307396\n",
      "Iteration 114, loss = 1624.37629496\n",
      "Iteration 103, loss = 1951.56840235\n",
      "Iteration 132, loss = 1601.23220603\n",
      "Iteration 395, loss = 816.18225865\n",
      "Iteration 391, loss = 782.58523052\n",
      "Iteration 89, loss = 2127.40114057\n",
      "Iteration 58, loss = 3050.40655328\n",
      "Iteration 135, loss = 1551.03232038\n",
      "Iteration 115, loss = 1612.97134276\n",
      "Iteration 104, loss = 1933.68627744\n",
      "Iteration 396, loss = 814.12812191\n",
      "Iteration 133, loss = 1588.60929179\n",
      "Iteration 392, loss = 784.93636730\n",
      "Iteration 59, loss = 3008.64168422\n",
      "Iteration 136, loss = 1543.49730796\n",
      "Iteration 90, loss = 2108.10334605\n",
      "Iteration 116, loss = 1599.23827850\n",
      "Iteration 105, loss = 1918.83592671\n",
      "Iteration 397, loss = 816.19517796\n",
      "Iteration 393, loss = 785.16915052\n",
      "Iteration 134, loss = 1577.18112249\n",
      "Iteration 137, loss = 1533.34704780\n",
      "Iteration 398, loss = 817.30529695\n",
      "Iteration 91, loss = 2086.08481295\n",
      "Iteration 117, loss = 1586.98430773\n",
      "Iteration 60, loss = 2966.82469682\n",
      "Iteration 394, loss = 783.87725977\n",
      "Iteration 106, loss = 1905.18412199\n",
      "Iteration 135, loss = 1566.70714579\n",
      "Iteration 399, loss = 813.37972172\n",
      "Iteration 395, loss = 783.12805810\n",
      "Iteration 138, loss = 1525.92688827\n",
      "Iteration 118, loss = 1576.62160638\n",
      "Iteration 92, loss = 2069.90966096\n",
      "Iteration 61, loss = 2929.67023470\n",
      "Iteration 107, loss = 1887.98021368\n",
      "Iteration 136, loss = 1559.46579906\n",
      "Iteration 400, loss = 814.75927473\n",
      "Iteration 396, loss = 782.20675751\n",
      "Iteration 108, loss = 1873.37711501\n",
      "Iteration 139, loss = 1517.15338227\n",
      "Iteration 119, loss = 1563.61945972\n",
      "Iteration 93, loss = 2048.32282297\n",
      "Iteration 62, loss = 2890.85976112\n",
      "Iteration 397, loss = 784.62509007\n",
      "Iteration 401, loss = 812.96118675\n",
      "Iteration 137, loss = 1549.55066570\n",
      "Iteration 109, loss = 1857.05181260\n",
      "Iteration 140, loss = 1509.02945136\n",
      "Iteration 94, loss = 2028.38826094\n",
      "Iteration 120, loss = 1553.09372935\n",
      "Iteration 63, loss = 2854.33423475\n",
      "Iteration 398, loss = 784.96084832\n",
      "Iteration 402, loss = 813.46487710\n",
      "Iteration 138, loss = 1543.14749516\n",
      "Iteration 110, loss = 1842.53963125\n",
      "Iteration 399, loss = 782.11396384\n",
      "Iteration 95, loss = 2011.76102086\n",
      "Iteration 141, loss = 1500.69052096\n",
      "Iteration 121, loss = 1543.33340196\n",
      "Iteration 403, loss = 812.45517852\n",
      "Iteration 64, loss = 2819.30370301\n",
      "Iteration 139, loss = 1530.20450375\n",
      "Iteration 400, loss = 782.87517280\n",
      "Iteration 404, loss = 813.16275173\n",
      "Iteration 96, loss = 1992.02341239\n",
      "Iteration 111, loss = 1827.65976435\n",
      "Iteration 142, loss = 1491.81856322\n",
      "Iteration 122, loss = 1529.89211339\n",
      "Iteration 65, loss = 2784.06511228\n",
      "Iteration 401, loss = 781.48900998\n",
      "Iteration 405, loss = 812.29505861\n",
      "Iteration 140, loss = 1522.59541436\n",
      "Iteration 143, loss = 1487.28578194\n",
      "Iteration 112, loss = 1818.71735012Iteration 97, loss = 1973.81806112\n",
      "\n",
      "Iteration 123, loss = 1519.55494747\n",
      "Iteration 402, loss = 782.43869036\n",
      "Iteration 66, loss = 2750.84486997\n",
      "Iteration 406, loss = 811.93425787\n",
      "Iteration 141, loss = 1513.97442491\n",
      "Iteration 144, loss = 1472.53406304\n",
      "Iteration 113, loss = 1800.57818121\n",
      "Iteration 124, loss = 1509.29184172\n",
      "Iteration 98, loss = 1958.18701463\n",
      "Iteration 403, loss = 780.67727132\n",
      "Iteration 407, loss = 811.65685475\n",
      "Iteration 67, loss = 2717.47707898\n",
      "Iteration 145, loss = 1466.89474000\n",
      "Iteration 142, loss = 1504.56700591\n",
      "Iteration 404, loss = 782.65245925\n",
      "Iteration 114, loss = 1787.72945274\n",
      "Iteration 125, loss = 1498.00273941\n",
      "Iteration 408, loss = 809.69512080\n",
      "Iteration 99, loss = 1942.02444914\n",
      "Iteration 68, loss = 2687.25983899\n",
      "Iteration 405, loss = 779.46706832\n",
      "Iteration 146, loss = 1459.91030068\n",
      "Iteration 409, loss = 810.95327150\n",
      "Iteration 143, loss = 1498.72341230\n",
      "Iteration 115, loss = 1775.56769470\n",
      "Iteration 126, loss = 1490.77541966\n",
      "Iteration 100, loss = 1922.91232488\n",
      "Iteration 406, loss = 780.32362702\n",
      "Iteration 410, loss = 810.24968485\n",
      "Iteration 147, loss = 1455.98366885\n",
      "Iteration 69, loss = 2655.79951148\n",
      "Iteration 144, loss = 1486.65048743\n",
      "Iteration 116, loss = 1760.39332083\n",
      "Iteration 127, loss = 1480.36048399\n",
      "Iteration 101, loss = 1906.93518432\n",
      "Iteration 407, loss = 779.88170439\n",
      "Iteration 411, loss = 811.15576478\n",
      "Iteration 148, loss = 1445.45242602\n",
      "Iteration 70, loss = 2627.47445779\n",
      "Iteration 145, loss = 1480.34679021\n",
      "Iteration 117, loss = 1747.09759264\n",
      "Iteration 408, loss = 779.40652271\n",
      "Iteration 128, loss = 1469.83106454\n",
      "Iteration 102, loss = 1890.80157942\n",
      "Iteration 412, loss = 809.74739623\n",
      "Iteration 149, loss = 1434.14872423\n",
      "Iteration 409, loss = 779.32857792\n",
      "Iteration 71, loss = 2595.83770515\n",
      "Iteration 146, loss = 1471.96490992\n",
      "Iteration 118, loss = 1737.62605488\n",
      "Iteration 129, loss = 1459.69632802\n",
      "Iteration 413, loss = 809.22173559\n",
      "Iteration 103, loss = 1877.67622610\n",
      "Iteration 410, loss = 779.81745419\n",
      "Iteration 150, loss = 1433.53413308\n",
      "Iteration 72, loss = 2568.30771159\n",
      "Iteration 414, loss = 809.87763715\n",
      "Iteration 147, loss = 1465.10334363\n",
      "Iteration 119, loss = 1722.62101103\n",
      "Iteration 130, loss = 1447.63329138\n",
      "Iteration 104, loss = 1857.51782095\n",
      "Iteration 411, loss = 778.79045049\n",
      "Iteration 151, loss = 1423.51785015\n",
      "Iteration 415, loss = 809.63511691\n",
      "Iteration 73, loss = 2538.21681675\n",
      "Iteration 120, loss = 1711.50595051\n",
      "Iteration 148, loss = 1454.44714832\n",
      "Iteration 412, loss = 777.16598867\n",
      "Iteration 131, loss = 1443.18329606\n",
      "Iteration 105, loss = 1843.51496305\n",
      "Iteration 416, loss = 808.40398863\n",
      "Iteration 152, loss = 1418.18322064\n",
      "Iteration 413, loss = 778.35093248\n",
      "Iteration 74, loss = 2509.61207213\n",
      "Iteration 149, loss = 1445.97976523\n",
      "Iteration 121, loss = 1698.72688156\n",
      "Iteration 132, loss = 1433.08071181\n",
      "Iteration 106, loss = 1829.98462915\n",
      "Iteration 417, loss = 808.49236375\n",
      "Iteration 153, loss = 1406.82962210\n",
      "Iteration 414, loss = 778.02373156\n",
      "Iteration 75, loss = 2481.95391099\n",
      "Iteration 150, loss = 1442.39800177\n",
      "Iteration 418, loss = 808.37599667\n",
      "Iteration 122, loss = 1687.36822114\n",
      "Iteration 107, loss = 1815.66584753\n",
      "Iteration 133, loss = 1422.30898788\n",
      "Iteration 415, loss = 777.89198501\n",
      "Iteration 154, loss = 1403.06008350\n",
      "Iteration 419, loss = 809.64930025\n",
      "Iteration 76, loss = 2456.07782625\n",
      "Iteration 151, loss = 1432.02187202\n",
      "Iteration 123, loss = 1672.14633776\n",
      "Iteration 416, loss = 775.59191037\n",
      "Iteration 108, loss = 1800.86507916\n",
      "Iteration 134, loss = 1408.97196060\n",
      "Iteration 420, loss = 806.79269058\n",
      "Iteration 155, loss = 1396.49308152\n",
      "Iteration 77, loss = 2429.32973441\n",
      "Iteration 152, loss = 1427.34865582\n",
      "Iteration 417, loss = 776.99130384\n",
      "Iteration 124, loss = 1666.12691243\n",
      "Iteration 109, loss = 1785.32992927\n",
      "Iteration 135, loss = 1407.06997915\n",
      "Iteration 421, loss = 808.30924726\n",
      "Iteration 418, loss = 776.64832226\n",
      "Iteration 156, loss = 1388.03943028\n",
      "Iteration 153, loss = 1414.11793321\n",
      "Iteration 78, loss = 2403.21770932\n",
      "Iteration 125, loss = 1650.56270481\n",
      "Iteration 110, loss = 1771.45057416\n",
      "Iteration 422, loss = 806.64325223\n",
      "Iteration 136, loss = 1395.35470266\n",
      "Iteration 419, loss = 776.83892798\n",
      "Iteration 154, loss = 1410.15077785\n",
      "Iteration 79, loss = 2378.03021786\n",
      "Iteration 423, loss = 807.09343468\n",
      "Iteration 157, loss = 1386.03481328\n",
      "Iteration 126, loss = 1638.01605258\n",
      "Iteration 420, loss = 775.03713612\n",
      "Iteration 137, loss = 1387.91837242\n",
      "Iteration 111, loss = 1757.33587659\n",
      "Iteration 424, loss = 806.77359154\n",
      "Iteration 155, loss = 1400.97510860\n",
      "Iteration 80, loss = 2353.33912931\n",
      "Iteration 421, loss = 775.52353409\n",
      "Iteration 127, loss = 1631.67892555\n",
      "Iteration 158, loss = 1374.61129434\n",
      "Iteration 138, loss = 1379.96082172\n",
      "Iteration 112, loss = 1744.78285367\n",
      "Iteration 425, loss = 805.96285226\n",
      "Iteration 422, loss = 776.03307217\n",
      "Iteration 81, loss = 2329.59222899\n",
      "Iteration 128, loss = 1619.60555076\n",
      "Iteration 156, loss = 1394.20366088\n",
      "Iteration 159, loss = 1368.53206190\n",
      "Iteration 426, loss = 804.88253499\n",
      "Iteration 113, loss = 1730.60401700\n",
      "Iteration 139, loss = 1372.62712628\n",
      "Iteration 423, loss = 774.96646240\n",
      "Iteration 82, loss = 2304.38511797\n",
      "Iteration 129, loss = 1607.19296746\n",
      "Iteration 157, loss = 1389.82003000\n",
      "Iteration 427, loss = 806.36451300\n",
      "Iteration 160, loss = 1365.96964588\n",
      "Iteration 424, loss = 775.18590911\n",
      "Iteration 140, loss = 1363.60896148\n",
      "Iteration 114, loss = 1720.02973409\n",
      "Iteration 428, loss = 805.76050073\n",
      "Iteration 83, loss = 2283.22719490\n",
      "Iteration 130, loss = 1598.84670245\n",
      "Iteration 425, loss = 774.99713072\n",
      "Iteration 161, loss = 1355.86608518\n",
      "Iteration 158, loss = 1379.29204030\n",
      "Iteration 115, loss = 1708.10559724Iteration 141, loss = 1356.06755902\n",
      "\n",
      "Iteration 429, loss = 804.62692051\n",
      "Iteration 426, loss = 773.70306428\n",
      "Iteration 84, loss = 2261.31679481\n",
      "Iteration 131, loss = 1588.04588850\n",
      "Iteration 162, loss = 1347.56227040\n",
      "Iteration 159, loss = 1370.94465207\n",
      "Iteration 116, loss = 1693.46066720\n",
      "Iteration 142, loss = 1350.75273506\n",
      "Iteration 430, loss = 804.16208911\n",
      "Iteration 427, loss = 773.20805599\n",
      "Iteration 132, loss = 1577.57065075\n",
      "Iteration 85, loss = 2237.34848142\n",
      "Iteration 163, loss = 1343.70289822\n",
      "Iteration 431, loss = 804.99918400\n",
      "Iteration 117, loss = 1681.28870699\n",
      "Iteration 160, loss = 1366.17026928\n",
      "Iteration 428, loss = 773.25128288\n",
      "Iteration 143, loss = 1343.87078501\n",
      "Iteration 86, loss = 2215.46541753\n",
      "Iteration 133, loss = 1568.93654728\n",
      "Iteration 432, loss = 804.96395139\n",
      "Iteration 164, loss = 1339.24577499\n",
      "Iteration 429, loss = 772.85818004\n",
      "Iteration 118, loss = 1670.25030920\n",
      "Iteration 161, loss = 1355.38336590\n",
      "Iteration 144, loss = 1332.99335161\n",
      "Iteration 433, loss = 804.38997725\n",
      "Iteration 87, loss = 2196.77860499\n",
      "Iteration 134, loss = 1556.29888592\n",
      "Iteration 430, loss = 771.95611844\n",
      "Iteration 165, loss = 1333.53822376\n",
      "Iteration 119, loss = 1654.42459273\n",
      "Iteration 162, loss = 1350.75468542\n",
      "Iteration 434, loss = 803.93384455\n",
      "Iteration 145, loss = 1325.07945175\n",
      "Iteration 88, loss = 2176.28903465\n",
      "Iteration 135, loss = 1553.44107020\n",
      "Iteration 431, loss = 772.29102977\n",
      "Iteration 166, loss = 1325.41287145\n",
      "Iteration 163, loss = 1342.75052837\n",
      "Iteration 435, loss = 803.16600973\n",
      "Iteration 120, loss = 1645.93595177\n",
      "Iteration 146, loss = 1318.61959452\n",
      "Iteration 432, loss = 772.65034607\n",
      "Iteration 89, loss = 2155.48707912\n",
      "Iteration 136, loss = 1538.98917720\n",
      "Iteration 436, loss = 803.16887374\n",
      "Iteration 167, loss = 1320.95631755\n",
      "Iteration 121, loss = 1633.67888912\n",
      "Iteration 164, loss = 1338.45124923\n",
      "Iteration 147, loss = 1312.27473087\n",
      "Iteration 433, loss = 771.63654098\n",
      "Iteration 90, loss = 2137.43642455\n",
      "Iteration 137, loss = 1530.72133939\n",
      "Iteration 437, loss = 803.44888732\n",
      "Iteration 122, loss = 1619.43460155\n",
      "Iteration 168, loss = 1315.29125705\n",
      "Iteration 165, loss = 1332.56147439\n",
      "Iteration 434, loss = 772.21821272\n",
      "Iteration 148, loss = 1305.86095852\n",
      "Iteration 438, loss = 803.59607498\n",
      "Iteration 138, loss = 1523.06005925\n",
      "Iteration 91, loss = 2115.81264336\n",
      "Iteration 435, loss = 771.25833028\n",
      "Iteration 123, loss = 1611.42239491\n",
      "Iteration 169, loss = 1306.76574991\n",
      "Iteration 166, loss = 1325.78134367\n",
      "Iteration 149, loss = 1298.22497720\n",
      "Iteration 439, loss = 801.48883675\n",
      "Iteration 436, loss = 771.12909383\n",
      "Iteration 139, loss = 1515.25349862\n",
      "Iteration 92, loss = 2100.51340652\n",
      "Iteration 167, loss = 1319.47794452\n",
      "Iteration 124, loss = 1600.04589881\n",
      "Iteration 440, loss = 801.60468991\n",
      "Iteration 170, loss = 1306.11521846\n",
      "Iteration 150, loss = 1285.63832056\n",
      "Iteration 437, loss = 772.15855560\n",
      "Iteration 140, loss = 1505.62305881\n",
      "Iteration 93, loss = 2079.48133720\n",
      "Iteration 125, loss = 1589.38995314\n",
      "Iteration 168, loss = 1315.97133145\n",
      "Iteration 441, loss = 804.04206148\n",
      "Iteration 438, loss = 770.45253930\n",
      "Iteration 171, loss = 1297.75925239\n",
      "Iteration 151, loss = 1280.51149815\n",
      "Iteration 141, loss = 1497.94566127\n",
      "Iteration 94, loss = 2061.37475767\n",
      "Iteration 442, loss = 802.04409321\n",
      "Iteration 169, loss = 1307.50517196\n",
      "Iteration 126, loss = 1575.20884022\n",
      "Iteration 439, loss = 770.00852774\n",
      "Iteration 172, loss = 1293.92985336\n",
      "Iteration 152, loss = 1274.28178112\n",
      "Iteration 443, loss = 802.71414863\n",
      "Iteration 440, loss = 768.88689816\n",
      "Iteration 95, loss = 2042.85928584\n",
      "Iteration 142, loss = 1489.24949423\n",
      "Iteration 127, loss = 1568.12159675\n",
      "Iteration 170, loss = 1304.25561186\n",
      "Iteration 173, loss = 1286.61028883\n",
      "Iteration 444, loss = 800.63708540\n",
      "Iteration 153, loss = 1266.78260210\n",
      "Iteration 441, loss = 771.94689919\n",
      "Iteration 128, loss = 1557.56332100\n",
      "Iteration 96, loss = 2025.39691977\n",
      "Iteration 143, loss = 1480.38691045\n",
      "Iteration 171, loss = 1297.05168019\n",
      "Iteration 174, loss = 1287.38013472\n",
      "Iteration 445, loss = 802.13828225\n",
      "Iteration 442, loss = 769.83267017\n",
      "Iteration 154, loss = 1258.93587716\n",
      "Iteration 129, loss = 1545.61820374\n",
      "Iteration 144, loss = 1471.85218377\n",
      "Iteration 97, loss = 2006.22175938\n",
      "Iteration 172, loss = 1290.82893747\n",
      "Iteration 443, loss = 769.49708067\n",
      "Iteration 446, loss = 798.40414180\n",
      "Iteration 175, loss = 1274.37992443\n",
      "Iteration 155, loss = 1250.85876724\n",
      "Iteration 130, loss = 1539.48447675\n",
      "Iteration 145, loss = 1462.78403350\n",
      "Iteration 447, loss = 803.10937013\n",
      "Iteration 444, loss = 768.56446235\n",
      "Iteration 173, loss = 1287.55421118\n",
      "Iteration 98, loss = 1990.13494074\n",
      "Iteration 176, loss = 1273.33870961\n",
      "Iteration 156, loss = 1249.48320581\n",
      "Iteration 131, loss = 1526.31831471\n",
      "Iteration 445, loss = 768.64701843\n",
      "Iteration 448, loss = 800.95161707\n",
      "Iteration 146, loss = 1455.14482807\n",
      "Iteration 174, loss = 1280.47147179\n",
      "Iteration 99, loss = 1974.10431101\n",
      "Iteration 177, loss = 1268.68287189\n",
      "Iteration 449, loss = 800.59121332\n",
      "Iteration 446, loss = 766.56876067\n",
      "Iteration 157, loss = 1242.26797330\n",
      "Iteration 132, loss = 1519.94188372\n",
      "Iteration 147, loss = 1450.60015518\n",
      "Iteration 100, loss = 1956.61711757\n",
      "Iteration 175, loss = 1271.18232985\n",
      "Iteration 178, loss = 1258.97346731\n",
      "Iteration 450, loss = 799.74006765\n",
      "Iteration 447, loss = 769.11529924\n",
      "Iteration 158, loss = 1232.41648726\n",
      "Iteration 133, loss = 1508.39174699\n",
      "Iteration 148, loss = 1438.69538670\n",
      "Iteration 451, loss = 799.46634080\n",
      "Iteration 448, loss = 767.68259481\n",
      "Iteration 101, loss = 1939.51039023\n",
      "Iteration 176, loss = 1272.29373195\n",
      "Iteration 179, loss = 1255.50749718\n",
      "Iteration 134, loss = 1498.40954117\n",
      "Iteration 159, loss = 1229.87201961\n",
      "Iteration 149, loss = 1430.04277906\n",
      "Iteration 449, loss = 767.55041348\n",
      "Iteration 452, loss = 799.09666283\n",
      "Iteration 177, loss = 1267.86618858\n",
      "Iteration 102, loss = 1921.62984496\n",
      "Iteration 180, loss = 1251.86328005\n",
      "Iteration 135, loss = 1491.00366900\n",
      "Iteration 450, loss = 767.39235843\n",
      "Iteration 160, loss = 1218.87397787\n",
      "Iteration 453, loss = 800.75461242\n",
      "Iteration 150, loss = 1418.19104894\n",
      "Iteration 103, loss = 1905.59569556\n",
      "Iteration 178, loss = 1259.56652832\n",
      "Iteration 451, loss = 767.03173861\n",
      "Iteration 181, loss = 1241.74737559\n",
      "Iteration 136, loss = 1482.47121072\n",
      "Iteration 454, loss = 798.38402292\n",
      "Iteration 161, loss = 1208.17931348\n",
      "Iteration 151, loss = 1412.78542944\n",
      "Iteration 452, loss = 767.21659662\n",
      "Iteration 179, loss = 1253.00703291\n",
      "Iteration 104, loss = 1888.76169012\n",
      "Iteration 455, loss = 798.69388278\n",
      "Iteration 182, loss = 1242.89345755\n",
      "Iteration 137, loss = 1470.72257076\n",
      "Iteration 162, loss = 1213.27884955\n",
      "Iteration 152, loss = 1410.36490802\n",
      "Iteration 453, loss = 768.10320353\n",
      "Iteration 180, loss = 1251.99779433\n",
      "Iteration 456, loss = 799.65407488\n",
      "Iteration 105, loss = 1873.93776209\n",
      "Iteration 183, loss = 1237.99535646\n",
      "Iteration 138, loss = 1460.26138908\n",
      "Iteration 163, loss = 1205.34313255\n",
      "Iteration 454, loss = 765.38231270\n",
      "Iteration 153, loss = 1395.59692492\n",
      "Iteration 457, loss = 798.92561353\n",
      "Iteration 106, loss = 1859.99218711\n",
      "Iteration 181, loss = 1241.01824378\n",
      "Iteration 455, loss = 766.33937656\n",
      "Iteration 164, loss = 1199.02996894\n",
      "Iteration 139, loss = 1452.18118318\n",
      "Iteration 184, loss = 1237.95702880\n",
      "Iteration 458, loss = 797.19537450\n",
      "Iteration 154, loss = 1391.29189200\n",
      "Iteration 456, loss = 766.36326068\n",
      "Iteration 107, loss = 1848.41550925\n",
      "Iteration 165, loss = 1192.55746329\n",
      "Iteration 182, loss = 1238.57457587\n",
      "Iteration 185, loss = 1224.64110310\n",
      "Iteration 140, loss = 1441.03291981\n",
      "Iteration 459, loss = 798.93557241\n",
      "Iteration 155, loss = 1385.71083201\n",
      "Iteration 457, loss = 765.78617681\n",
      "Iteration 108, loss = 1831.10378645\n",
      "Iteration 183, loss = 1235.55681959\n",
      "Iteration 460, loss = 798.01384587\n",
      "Iteration 166, loss = 1188.54748856\n",
      "Iteration 141, loss = 1432.89808422\n",
      "Iteration 186, loss = 1221.27600945\n",
      "Iteration 156, loss = 1376.43512466\n",
      "Iteration 458, loss = 763.97563526\n",
      "Iteration 461, loss = 797.99054883\n",
      "Iteration 109, loss = 1816.03743878\n",
      "Iteration 184, loss = 1233.16647869\n",
      "Iteration 142, loss = 1424.67350146\n",
      "Iteration 167, loss = 1182.92748084\n",
      "Iteration 187, loss = 1218.60506102\n",
      "Iteration 459, loss = 766.12839142\n",
      "Iteration 157, loss = 1368.20398340\n",
      "Iteration 462, loss = 797.34548329\n",
      "Iteration 168, loss = 1178.65262977\n",
      "Iteration 110, loss = 1800.96298982\n",
      "Iteration 143, loss = 1413.91709246\n",
      "Iteration 460, loss = 764.22076508\n",
      "Iteration 185, loss = 1226.05707897\n",
      "Iteration 188, loss = 1217.21595389\n",
      "Iteration 463, loss = 795.65179299\n",
      "Iteration 158, loss = 1360.85636958\n",
      "Iteration 461, loss = 765.28735202\n",
      "Iteration 186, loss = 1221.21479755\n",
      "Iteration 169, loss = 1170.34022417\n",
      "Iteration 111, loss = 1787.41135086\n",
      "Iteration 144, loss = 1406.80630815\n",
      "Iteration 464, loss = 795.61465950\n",
      "Iteration 189, loss = 1208.23367976\n",
      "Iteration 159, loss = 1358.48851428\n",
      "Iteration 462, loss = 764.31449778\n",
      "Iteration 145, loss = 1395.79848441\n",
      "Iteration 170, loss = 1166.56509870\n",
      "Iteration 465, loss = 797.13194421\n",
      "Iteration 187, loss = 1217.47152393\n",
      "Iteration 112, loss = 1773.02946754\n",
      "Iteration 190, loss = 1202.32639770\n",
      "Iteration 160, loss = 1346.13458939\n",
      "Iteration 463, loss = 762.36034013\n",
      "Iteration 466, loss = 797.22966445\n",
      "Iteration 146, loss = 1387.22789553\n",
      "Iteration 171, loss = 1160.00787198\n",
      "Iteration 188, loss = 1214.03876281\n",
      "Iteration 191, loss = 1203.29334684\n",
      "Iteration 113, loss = 1757.72422519\n",
      "Iteration 464, loss = 763.09858762\n",
      "Iteration 161, loss = 1336.33497672\n",
      "Iteration 467, loss = 796.56232613\n",
      "Iteration 147, loss = 1386.24708584\n",
      "Iteration 465, loss = 762.64463106\n",
      "Iteration 189, loss = 1207.31726435\n",
      "Iteration 192, loss = 1198.83304887\n",
      "Iteration 172, loss = 1156.39545130\n",
      "Iteration 468, loss = 795.50691948\n",
      "Iteration 114, loss = 1745.83471672\n",
      "Iteration 162, loss = 1334.92804531\n",
      "Iteration 466, loss = 763.69947823\n",
      "Iteration 469, loss = 795.24984493\n",
      "Iteration 148, loss = 1373.03804547\n",
      "Iteration 190, loss = 1199.48893160\n",
      "Iteration 173, loss = 1153.28372623\n",
      "Iteration 193, loss = 1190.68026393\n",
      "Iteration 115, loss = 1735.72960034\n",
      "Iteration 163, loss = 1329.67106029\n",
      "Iteration 467, loss = 763.13921713\n",
      "Iteration 470, loss = 796.77098024\n",
      "Iteration 149, loss = 1362.28921171\n",
      "Iteration 191, loss = 1199.46870918\n",
      "Iteration 194, loss = 1194.84040888\n",
      "Iteration 174, loss = 1142.72103757\n",
      "Iteration 116, loss = 1723.10003862\n",
      "Iteration 468, loss = 761.94298324\n",
      "Iteration 164, loss = 1324.22715897\n",
      "Iteration 471, loss = 795.10271628\n",
      "Iteration 150, loss = 1356.97180106\n",
      "Iteration 192, loss = 1190.72900460\n",
      "Iteration 175, loss = 1142.99520754\n",
      "Iteration 469, loss = 761.99007505\n",
      "Iteration 195, loss = 1185.44491814\n",
      "Iteration 117, loss = 1709.86715119\n",
      "Iteration 472, loss = 795.44699216\n",
      "Iteration 165, loss = 1316.62793213\n",
      "Iteration 470, loss = 763.50646447\n",
      "Iteration 151, loss = 1345.19110771\n",
      "Iteration 193, loss = 1191.53485251\n",
      "Iteration 176, loss = 1139.84057417\n",
      "Iteration 473, loss = 796.08057120\n",
      "Iteration 196, loss = 1172.76789676\n",
      "Iteration 118, loss = 1700.36461500\n",
      "Iteration 166, loss = 1307.72555733\n",
      "Iteration 471, loss = 761.06282372\n",
      "Iteration 474, loss = 794.31129032\n",
      "Iteration 152, loss = 1341.99079826\n",
      "Iteration 194, loss = 1188.67785102\n",
      "Iteration 197, loss = 1177.99702395\n",
      "Iteration 177, loss = 1127.99601137\n",
      "Iteration 119, loss = 1682.54468504\n",
      "Iteration 167, loss = 1308.80799531\n",
      "Iteration 472, loss = 762.11099067\n",
      "Iteration 475, loss = 795.40206560\n",
      "Iteration 153, loss = 1333.90987987\n",
      "Iteration 195, loss = 1182.16966638\n",
      "Iteration 198, loss = 1172.06169347\n",
      "Iteration 178, loss = 1125.65575576\n",
      "Iteration 120, loss = 1676.35830796\n",
      "Iteration 473, loss = 762.11870119\n",
      "Iteration 476, loss = 793.22827004\n",
      "Iteration 168, loss = 1299.25446031\n",
      "Iteration 154, loss = 1325.61321445\n",
      "Iteration 474, loss = 760.96182781\n",
      "Iteration 196, loss = 1170.15781010\n",
      "Iteration 179, loss = 1124.73091318\n",
      "Iteration 199, loss = 1169.59261141\n",
      "Iteration 121, loss = 1665.07139303\n",
      "Iteration 477, loss = 793.51104189\n",
      "Iteration 169, loss = 1289.56686387\n",
      "Iteration 475, loss = 760.92101906\n",
      "Iteration 155, loss = 1317.93244793\n",
      "Iteration 197, loss = 1170.87790812\n",
      "Iteration 478, loss = 795.64998994\n",
      "Iteration 180, loss = 1118.76496851\n",
      "Iteration 200, loss = 1167.44870649\n",
      "Iteration 122, loss = 1651.98389338\n",
      "Iteration 170, loss = 1283.81127555\n",
      "Iteration 476, loss = 758.98564048\n",
      "Iteration 479, loss = 793.78339455\n",
      "Iteration 198, loss = 1167.22915285\n",
      "Iteration 156, loss = 1308.99540767\n",
      "Iteration 181, loss = 1114.29337281\n",
      "Iteration 201, loss = 1160.79198113\n",
      "Iteration 123, loss = 1642.91153020\n",
      "Iteration 171, loss = 1278.60781127\n",
      "Iteration 477, loss = 759.78256278\n",
      "Iteration 480, loss = 793.84476201\n",
      "Iteration 157, loss = 1305.32634486\n",
      "Iteration 199, loss = 1162.80887259\n",
      "Iteration 182, loss = 1107.88871490\n",
      "Iteration 202, loss = 1156.06650680\n",
      "Iteration 124, loss = 1631.06411233\n",
      "Iteration 478, loss = 761.29405730\n",
      "Iteration 481, loss = 792.74074957\n",
      "Iteration 172, loss = 1271.14153103\n",
      "Iteration 200, loss = 1160.47315262\n",
      "Iteration 158, loss = 1293.82497295\n",
      "Iteration 183, loss = 1106.44418424\n",
      "Iteration 203, loss = 1158.17059702\n",
      "Iteration 479, loss = 760.56998422\n",
      "Iteration 125, loss = 1621.40256451\n",
      "Iteration 482, loss = 793.01793431\n",
      "Iteration 173, loss = 1269.84145018\n",
      "Iteration 201, loss = 1158.61945487\n",
      "Iteration 159, loss = 1292.58329401\n",
      "Iteration 483, loss = 792.55585090\n",
      "Iteration 480, loss = 758.64176377\n",
      "Iteration 184, loss = 1104.21262984\n",
      "Iteration 204, loss = 1150.84129305\n",
      "Iteration 126, loss = 1608.77080564\n",
      "Iteration 174, loss = 1262.86827645\n",
      "Iteration 481, loss = 759.48940670\n",
      "Iteration 484, loss = 792.45558346\n",
      "Iteration 202, loss = 1152.26090751\n",
      "Iteration 160, loss = 1280.44939146\n",
      "Iteration 185, loss = 1103.70450380\n",
      "Iteration 205, loss = 1141.63449618\n",
      "Iteration 127, loss = 1600.41267184\n",
      "Iteration 482, loss = 758.29029340\n",
      "Iteration 175, loss = 1259.34722603\n",
      "Iteration 485, loss = 792.36051898\n",
      "Iteration 161, loss = 1273.43368704\n",
      "Iteration 203, loss = 1154.49084265\n",
      "Iteration 186, loss = 1091.50396615\n",
      "Iteration 206, loss = 1144.01836793\n",
      "Iteration 128, loss = 1589.98267826\n",
      "Iteration 483, loss = 757.56437017\n",
      "Iteration 176, loss = 1254.55345597\n",
      "Iteration 486, loss = 793.44998166\n",
      "Iteration 484, loss = 759.19091608\n",
      "Iteration 187, loss = 1091.55600954\n",
      "Iteration 204, loss = 1144.26311439\n",
      "Iteration 162, loss = 1269.17399986\n",
      "Iteration 129, loss = 1579.00860317\n",
      "Iteration 487, loss = 791.73430669\n",
      "Iteration 207, loss = 1142.57988304\n",
      "Iteration 177, loss = 1244.33212635\n",
      "Iteration 485, loss = 758.09082115\n",
      "Iteration 488, loss = 792.34167225\n",
      "Iteration 205, loss = 1143.25921860\n",
      "Iteration 188, loss = 1082.96726612\n",
      "Iteration 163, loss = 1265.87877138\n",
      "Iteration 130, loss = 1571.90830460\n",
      "Iteration 208, loss = 1136.17246083\n",
      "Iteration 178, loss = 1240.85110818\n",
      "Iteration 486, loss = 757.96742908\n",
      "Iteration 489, loss = 790.68492395\n",
      "Iteration 206, loss = 1138.70928149\n",
      "Iteration 164, loss = 1255.60016289\n",
      "Iteration 189, loss = 1081.60541987\n",
      "Iteration 131, loss = 1561.72628315\n",
      "Iteration 487, loss = 758.04118462\n",
      "Iteration 209, loss = 1133.74495114\n",
      "Iteration 179, loss = 1239.93122016\n",
      "Iteration 490, loss = 789.94141658\n",
      "Iteration 207, loss = 1136.74298918\n",
      "Iteration 190, loss = 1080.95909804\n",
      "Iteration 165, loss = 1253.23809386\n",
      "Iteration 132, loss = 1551.58557949\n",
      "Iteration 488, loss = 757.42703620\n",
      "Iteration 491, loss = 790.96091767\n",
      "Iteration 210, loss = 1131.00480458\n",
      "Iteration 180, loss = 1234.78835876\n",
      "Iteration 489, loss = 757.40539367\n",
      "Iteration 191, loss = 1077.44223518\n",
      "Iteration 166, loss = 1245.09778747\n",
      "Iteration 133, loss = 1544.57679132\n",
      "Iteration 492, loss = 789.85606438\n",
      "Iteration 208, loss = 1133.81263332\n",
      "Iteration 181, loss = 1225.75411118\n",
      "Iteration 211, loss = 1129.21574906\n",
      "Iteration 490, loss = 755.70663867\n",
      "Iteration 192, loss = 1070.50233975\n",
      "Iteration 493, loss = 790.41168921\n",
      "Iteration 167, loss = 1243.92748428\n",
      "Iteration 134, loss = 1533.81735544\n",
      "Iteration 209, loss = 1129.27274138\n",
      "Iteration 182, loss = 1221.41151316\n",
      "Iteration 212, loss = 1122.48959900\n",
      "Iteration 491, loss = 757.12671654\n",
      "Iteration 494, loss = 792.07477869\n",
      "Iteration 135, loss = 1523.83738571\n",
      "Iteration 193, loss = 1068.58462478\n",
      "Iteration 492, loss = 756.01989484\n",
      "Iteration 168, loss = 1240.97103534\n",
      "Iteration 210, loss = 1125.95289612\n",
      "Iteration 213, loss = 1125.01653781\n",
      "Iteration 495, loss = 789.89365676\n",
      "Iteration 183, loss = 1218.12532723\n",
      "Iteration 493, loss = 755.99169306\n",
      "Iteration 136, loss = 1516.96165925\n",
      "Iteration 194, loss = 1065.67697242\n",
      "Iteration 211, loss = 1128.77541721\n",
      "Iteration 169, loss = 1228.75429330\n",
      "Iteration 496, loss = 790.76942651\n",
      "Iteration 214, loss = 1106.86515868\n",
      "Iteration 184, loss = 1215.83033833\n",
      "Iteration 494, loss = 757.13137402\n",
      "Iteration 137, loss = 1506.56414944\n",
      "Iteration 195, loss = 1058.89861096\n",
      "Iteration 497, loss = 791.09389514\n",
      "Iteration 212, loss = 1121.76782111\n",
      "Iteration 170, loss = 1224.47964096\n",
      "Iteration 495, loss = 755.91173411\n",
      "Iteration 215, loss = 1119.21233273\n",
      "Iteration 185, loss = 1211.86339465\n",
      "Iteration 138, loss = 1498.32086699\n",
      "Iteration 498, loss = 790.02689700\n",
      "Iteration 196, loss = 1059.91402490\n",
      "Iteration 213, loss = 1118.92000078\n",
      "Iteration 496, loss = 756.23727730\n",
      "Iteration 171, loss = 1217.34057204\n",
      "Iteration 216, loss = 1112.05063815\n",
      "Iteration 186, loss = 1203.39168336\n",
      "Iteration 499, loss = 789.62624026\n",
      "Iteration 139, loss = 1492.20493498\n",
      "Iteration 497, loss = 756.07870987\n",
      "Iteration 197, loss = 1049.20684424\n",
      "Iteration 214, loss = 1108.03470275\n",
      "Iteration 172, loss = 1210.21813970\n",
      "Iteration 187, loss = 1200.90881013\n",
      "Iteration 217, loss = 1106.70649441\n",
      "Iteration 500, loss = 789.84133065\n",
      "Iteration 140, loss = 1480.94925163\n",
      "Iteration 498, loss = 755.85659437\n",
      "Iteration 198, loss = 1048.98205985\n",
      "Iteration 173, loss = 1209.58868982\n",
      "Iteration 215, loss = 1110.82751412\n",
      "Iteration 501, loss = 790.14860212\n",
      "Iteration 188, loss = 1191.27866446\n",
      "Iteration 499, loss = 755.25011351\n",
      "Iteration 218, loss = 1101.48825792\n",
      "Iteration 141, loss = 1471.80188137\n",
      "Iteration 199, loss = 1044.48885306\n",
      "Iteration 174, loss = 1203.09950173\n",
      "Iteration 502, loss = 789.10105677\n",
      "Iteration 216, loss = 1108.41354535\n",
      "Iteration 500, loss = 754.87206592\n",
      "Iteration 189, loss = 1186.77242831\n",
      "Iteration 219, loss = 1100.93116531\n",
      "Iteration 142, loss = 1462.86359648\n",
      "Iteration 503, loss = 788.99231255\n",
      "Iteration 501, loss = 755.13371208\n",
      "Iteration 175, loss = 1199.67705749\n",
      "Iteration 217, loss = 1105.49126802\n",
      "Iteration 200, loss = 1043.18289186\n",
      "Iteration 190, loss = 1188.72301054\n",
      "Iteration 220, loss = 1092.01419784\n",
      "Iteration 143, loss = 1454.36147736\n",
      "Iteration 504, loss = 788.31610380\n",
      "Iteration 502, loss = 753.83770156\n",
      "Iteration 176, loss = 1196.10300819\n",
      "Iteration 218, loss = 1100.61504068\n",
      "Iteration 201, loss = 1039.67669034\n",
      "Iteration 191, loss = 1180.19472004\n",
      "Iteration 221, loss = 1097.73474716\n",
      "Iteration 505, loss = 789.37139646\n",
      "Iteration 144, loss = 1445.58836002\n",
      "Iteration 503, loss = 754.39512029\n",
      "Iteration 177, loss = 1183.81283033\n",
      "Iteration 219, loss = 1097.26043136\n",
      "Iteration 202, loss = 1037.90341062\n",
      "Iteration 506, loss = 787.92769004\n",
      "Iteration 192, loss = 1177.53463422\n",
      "Iteration 222, loss = 1091.33211951\n",
      "Iteration 145, loss = 1437.06659774\n",
      "Iteration 504, loss = 753.19980789\n",
      "Iteration 203, loss = 1028.80723885\n",
      "Iteration 178, loss = 1183.52179611\n",
      "Iteration 220, loss = 1088.92395050\n",
      "Iteration 507, loss = 789.54345944\n",
      "Iteration 193, loss = 1173.36920534\n",
      "Iteration 505, loss = 753.52314373\n",
      "Iteration 223, loss = 1082.87333226\n",
      "Iteration 146, loss = 1431.10086808\n",
      "Iteration 508, loss = 788.39260641\n",
      "Iteration 204, loss = 1029.91182673\n",
      "Iteration 221, loss = 1093.77343070\n",
      "Iteration 179, loss = 1178.80380183\n",
      "Iteration 506, loss = 753.62161590\n",
      "Iteration 194, loss = 1170.31276850\n",
      "Iteration 224, loss = 1087.18503528\n",
      "Iteration 147, loss = 1423.92108564\n",
      "Iteration 509, loss = 787.71485027\n",
      "Iteration 222, loss = 1087.75184905\n",
      "Iteration 507, loss = 755.09760324\n",
      "Iteration 205, loss = 1028.64313205\n",
      "Iteration 180, loss = 1172.54901171\n",
      "Iteration 195, loss = 1164.19078774\n",
      "Iteration 225, loss = 1087.18859845\n",
      "Iteration 510, loss = 787.17491739\n",
      "Iteration 148, loss = 1414.79488971\n",
      "Iteration 508, loss = 753.92722179\n",
      "Iteration 223, loss = 1085.02159119\n",
      "Iteration 206, loss = 1018.23351434\n",
      "Iteration 196, loss = 1163.78308099\n",
      "Iteration 511, loss = 787.82733757\n",
      "Iteration 181, loss = 1164.43258161\n",
      "Iteration 226, loss = 1077.21051624\n",
      "Iteration 509, loss = 752.43148023\n",
      "Iteration 149, loss = 1405.86094885\n",
      "Iteration 224, loss = 1084.08505502\n",
      "Iteration 207, loss = 1017.00141170\n",
      "Iteration 512, loss = 788.29683530\n",
      "Iteration 197, loss = 1154.98832944\n",
      "Iteration 510, loss = 752.36473792\n",
      "Iteration 182, loss = 1168.33722375\n",
      "Iteration 227, loss = 1076.05917878\n",
      "Iteration 150, loss = 1396.89157353\n",
      "Iteration 513, loss = 786.71223183\n",
      "Iteration 511, loss = 752.81681687\n",
      "Iteration 225, loss = 1081.95521000\n",
      "Iteration 208, loss = 1013.80017396\n",
      "Iteration 198, loss = 1152.50943121\n",
      "Iteration 228, loss = 1077.20047345\n",
      "Iteration 183, loss = 1158.30556830\n",
      "Iteration 514, loss = 787.57338851\n",
      "Iteration 151, loss = 1388.65061531\n",
      "Iteration 512, loss = 753.03719467\n",
      "Iteration 226, loss = 1077.08791795\n",
      "Iteration 209, loss = 1013.94447223\n",
      "Iteration 199, loss = 1145.40740358\n",
      "Iteration 229, loss = 1070.62049940\n",
      "Iteration 184, loss = 1157.66287339\n",
      "Iteration 515, loss = 784.73596968\n",
      "Iteration 513, loss = 752.08600733\n",
      "Iteration 152, loss = 1383.62403595\n",
      "Iteration 227, loss = 1074.27987598\n",
      "Iteration 200, loss = 1145.99166991\n",
      "Iteration 210, loss = 1010.85194788\n",
      "Iteration 230, loss = 1071.43237631\n",
      "Iteration 516, loss = 787.11569073\n",
      "Iteration 185, loss = 1155.70213082\n",
      "Iteration 514, loss = 751.65302652\n",
      "Iteration 153, loss = 1377.78567209\n",
      "Iteration 228, loss = 1076.21448754\n",
      "Iteration 517, loss = 786.79459244\n",
      "Iteration 211, loss = 1005.63895607\n",
      "Iteration 515, loss = 751.33499000\n",
      "Iteration 201, loss = 1142.18600095\n",
      "Iteration 231, loss = 1068.10204214\n",
      "Iteration 186, loss = 1149.62981322\n",
      "Iteration 154, loss = 1369.79770445\n",
      "Iteration 229, loss = 1067.56292311\n",
      "Iteration 516, loss = 752.94970776\n",
      "Iteration 518, loss = 785.70843872\n",
      "Iteration 212, loss = 1003.70565506\n",
      "Iteration 202, loss = 1138.08866916\n",
      "Iteration 232, loss = 1062.70773171\n",
      "Iteration 187, loss = 1145.13507602\n",
      "Iteration 155, loss = 1365.13789720\n",
      "Iteration 517, loss = 751.78308977\n",
      "Iteration 519, loss = 784.86849285\n",
      "Iteration 230, loss = 1071.56160043\n",
      "Iteration 203, loss = 1132.43491689\n",
      "Iteration 213, loss = 1002.37699503\n",
      "Iteration 233, loss = 1062.28734877\n",
      "Iteration 188, loss = 1133.29342256\n",
      "Iteration 518, loss = 751.34827446\n",
      "Iteration 520, loss = 785.01161909\n",
      "Iteration 156, loss = 1355.14646045\n",
      "Iteration 231, loss = 1062.86847123\n",
      "Iteration 204, loss = 1127.26161027\n",
      "Iteration 214, loss = 1004.84928416\n",
      "Iteration 234, loss = 1058.65765850\n",
      "Iteration 519, loss = 751.51349113\n",
      "Iteration 521, loss = 786.66245690\n",
      "Iteration 189, loss = 1135.00082268\n",
      "Iteration 157, loss = 1354.36611448\n",
      "Iteration 232, loss = 1061.30866089\n",
      "Iteration 520, loss = 750.02264867\n",
      "Iteration 205, loss = 1127.32627176\n",
      "Iteration 522, loss = 786.26099754\n",
      "Iteration 235, loss = 1053.76183313\n",
      "Iteration 190, loss = 1137.93300976\n",
      "Iteration 158, loss = 1341.23797588\n",
      "Iteration 215, loss = 998.07713477\n",
      "Iteration 521, loss = 751.28573670\n",
      "Iteration 523, loss = 784.87313806\n",
      "Iteration 233, loss = 1060.11370466\n",
      "Iteration 206, loss = 1116.00971425\n",
      "Iteration 236, loss = 1054.25051584\n",
      "Iteration 191, loss = 1129.80108928\n",
      "Iteration 159, loss = 1340.12275800\n",
      "Iteration 216, loss = 995.49897818\n",
      "Iteration 522, loss = 750.91244620\n",
      "Iteration 524, loss = 784.44370190\n",
      "Iteration 234, loss = 1055.61336078\n",
      "Iteration 207, loss = 1113.99181219\n",
      "Iteration 525, loss = 784.35382945\n",
      "Iteration 237, loss = 1054.57675263\n",
      "Iteration 523, loss = 750.34854603\n",
      "Iteration 192, loss = 1118.75138227\n",
      "Iteration 160, loss = 1330.54495264\n",
      "Iteration 217, loss = 991.93591232\n",
      "Iteration 235, loss = 1051.62420581\n",
      "Iteration 526, loss = 784.52873535\n",
      "Iteration 524, loss = 749.99891197\n",
      "Iteration 208, loss = 1112.68109371\n",
      "Iteration 238, loss = 1048.25318125\n",
      "Iteration 193, loss = 1116.43024646\n",
      "Iteration 161, loss = 1320.21087025\n",
      "Iteration 218, loss = 994.39549050\n",
      "Iteration 527, loss = 784.86781211\n",
      "Iteration 525, loss = 748.41907662\n",
      "Iteration 236, loss = 1051.63467220\n",
      "Iteration 209, loss = 1111.46171019\n",
      "Iteration 239, loss = 1048.88318885\n",
      "Iteration 194, loss = 1116.65680812\n",
      "Iteration 162, loss = 1314.76960436\n",
      "Iteration 528, loss = 783.89662809\n",
      "Iteration 526, loss = 748.79638266\n",
      "Iteration 237, loss = 1049.68442602\n",
      "Iteration 219, loss = 991.26756643\n",
      "Iteration 210, loss = 1105.38151959\n",
      "Iteration 240, loss = 1044.59530682\n",
      "Iteration 195, loss = 1112.80464667\n",
      "Iteration 527, loss = 750.31540831\n",
      "Iteration 529, loss = 784.49277920\n",
      "Iteration 163, loss = 1313.90967675\n",
      "Iteration 238, loss = 1049.29636394\n",
      "Iteration 220, loss = 986.42497929\n",
      "Iteration 211, loss = 1105.57527141\n",
      "Iteration 530, loss = 786.37134991\n",
      "Iteration 528, loss = 749.26778402\n",
      "Iteration 241, loss = 1041.10329447\n",
      "Iteration 196, loss = 1104.39238701\n",
      "Iteration 164, loss = 1302.80188358\n",
      "Iteration 239, loss = 1044.70313981\n",
      "Iteration 221, loss = 981.84108318\n",
      "Iteration 529, loss = 748.17640006\n",
      "Iteration 531, loss = 785.01155527\n",
      "Iteration 212, loss = 1100.60249375\n",
      "Iteration 197, loss = 1100.55274345\n",
      "Iteration 165, loss = 1302.97386798\n",
      "Iteration 242, loss = 1039.97207331\n",
      "Iteration 240, loss = 1042.33109837\n",
      "Iteration 222, loss = 979.25166117\n",
      "Iteration 532, loss = 782.46787854\n",
      "Iteration 530, loss = 750.35813411\n",
      "Iteration 213, loss = 1097.79735662\n",
      "Iteration 198, loss = 1097.90329993\n",
      "Iteration 533, loss = 783.71531464\n",
      "Iteration 166, loss = 1293.78180309\n",
      "Iteration 243, loss = 1038.74695541\n",
      "Iteration 241, loss = 1038.94658257\n",
      "Iteration 223, loss = 977.35020982\n",
      "Iteration 531, loss = 748.91929775\n",
      "Iteration 214, loss = 1103.44202457\n",
      "Iteration 199, loss = 1089.14349871\n",
      "Iteration 534, loss = 783.61938512\n",
      "Iteration 532, loss = 748.53949541\n",
      "Iteration 244, loss = 1038.89181933\n",
      "Iteration 167, loss = 1289.66562459\n",
      "Iteration 242, loss = 1037.18620866\n",
      "Iteration 224, loss = 973.34607151\n",
      "Iteration 535, loss = 782.53678903\n",
      "Iteration 215, loss = 1095.23004972\n",
      "Iteration 533, loss = 748.97954003\n",
      "Iteration 200, loss = 1088.94549529\n",
      "Iteration 245, loss = 1029.97158973\n",
      "Iteration 168, loss = 1286.29553779\n",
      "Iteration 243, loss = 1034.82142614\n",
      "Iteration 225, loss = 979.64443651\n",
      "Iteration 536, loss = 784.52007261\n",
      "Iteration 534, loss = 748.47638431\n",
      "Iteration 216, loss = 1091.56565098\n",
      "Iteration 201, loss = 1085.29004032\n",
      "Iteration 246, loss = 1032.66435911\n",
      "Iteration 169, loss = 1274.80601919\n",
      "Iteration 226, loss = 971.15685492\n",
      "Iteration 244, loss = 1028.67894697\n",
      "Iteration 535, loss = 747.66372577\n",
      "Iteration 537, loss = 782.52444112\n",
      "Iteration 217, loss = 1083.49438998\n",
      "Iteration 202, loss = 1083.74128803\n",
      "Iteration 247, loss = 1029.68118478\n",
      "Iteration 536, loss = 748.47137793\n",
      "Iteration 170, loss = 1273.03639516\n",
      "Iteration 227, loss = 965.68256399\n",
      "Iteration 245, loss = 1033.80000321\n",
      "Iteration 538, loss = 783.00752079\n",
      "Iteration 218, loss = 1084.22915112\n",
      "Iteration 537, loss = 747.63930333\n",
      "Iteration 248, loss = 1029.27065539\n",
      "Iteration 203, loss = 1078.42310961\n",
      "Iteration 539, loss = 782.36308471\n",
      "Iteration 171, loss = 1265.44767830\n",
      "Iteration 228, loss = 966.19944521\n",
      "Iteration 246, loss = 1029.20960784\n",
      "Iteration 219, loss = 1086.88745226\n",
      "Iteration 538, loss = 747.94629115\n",
      "Iteration 540, loss = 783.25082761\n",
      "Iteration 249, loss = 1023.59321871\n",
      "Iteration 204, loss = 1074.79277004\n",
      "Iteration 172, loss = 1259.61706936\n",
      "Iteration 229, loss = 963.09486282\n",
      "Iteration 247, loss = 1023.31278295\n",
      "Iteration 539, loss = 747.92594659\n",
      "Iteration 541, loss = 780.91040366\n",
      "Iteration 220, loss = 1080.76738236\n",
      "Iteration 250, loss = 1026.14733496\n",
      "Iteration 540, loss = 747.82629901\n",
      "Iteration 205, loss = 1073.38807925\n",
      "Iteration 173, loss = 1255.19000428\n",
      "Iteration 248, loss = 1022.48962290\n",
      "Iteration 230, loss = 960.80587763\n",
      "Iteration 542, loss = 782.08291940\n",
      "Iteration 221, loss = 1072.69475381\n",
      "Iteration 541, loss = 745.43665952\n",
      "Iteration 251, loss = 1022.55358183\n",
      "Iteration 206, loss = 1063.46130722\n",
      "Iteration 543, loss = 781.79692397\n",
      "Iteration 249, loss = 1017.68262507\n",
      "Iteration 174, loss = 1252.76193129\n",
      "Iteration 231, loss = 959.48294117\n",
      "Iteration 542, loss = 747.80259308\n",
      "Iteration 222, loss = 1070.19798688\n",
      "Iteration 544, loss = 782.73582163\n",
      "Iteration 207, loss = 1060.71660104\n",
      "Iteration 252, loss = 1018.43009617\n",
      "Iteration 232, loss = 956.90275617\n",
      "Iteration 175, loss = 1245.91261036\n",
      "Iteration 250, loss = 1023.63736994\n",
      "Iteration 543, loss = 745.52727048\n",
      "Iteration 545, loss = 780.49484984\n",
      "Iteration 208, loss = 1061.13380538\n",
      "Iteration 223, loss = 1073.06439068\n",
      "Iteration 253, loss = 1014.50699571\n",
      "Iteration 233, loss = 955.58193126\n",
      "Iteration 251, loss = 1017.00746168\n",
      "Iteration 544, loss = 747.88435214\n",
      "Iteration 176, loss = 1242.56750348\n",
      "Iteration 546, loss = 780.68823018\n",
      "Iteration 224, loss = 1065.59623614\n",
      "Iteration 254, loss = 1015.38032158\n",
      "Iteration 545, loss = 745.49342706\n",
      "Iteration 209, loss = 1057.52151324\n",
      "Iteration 252, loss = 1012.49014420\n",
      "Iteration 234, loss = 952.66032146\n",
      "Iteration 547, loss = 780.85430478\n",
      "Iteration 177, loss = 1237.03361006\n",
      "Iteration 546, loss = 745.82459253\n",
      "Iteration 225, loss = 1069.01798580\n",
      "Iteration 255, loss = 1013.88035122\n",
      "Iteration 210, loss = 1054.72620208\n",
      "Iteration 548, loss = 781.00001745\n",
      "Iteration 235, loss = 947.22851525\n",
      "Iteration 253, loss = 1012.32994686\n",
      "Iteration 178, loss = 1232.62595034\n",
      "Iteration 547, loss = 745.39140412\n",
      "Iteration 256, loss = 1007.83596160\n",
      "Iteration 226, loss = 1062.32996767\n",
      "Iteration 549, loss = 781.24954660\n",
      "Iteration 211, loss = 1050.62605991\n",
      "Iteration 254, loss = 1009.52487551\n",
      "Iteration 236, loss = 948.28952199\n",
      "Iteration 179, loss = 1229.64314432\n",
      "Iteration 548, loss = 745.32458245\n",
      "Iteration 550, loss = 781.98215118\n",
      "Iteration 257, loss = 1008.03985697\n",
      "Iteration 227, loss = 1058.18484289\n",
      "Iteration 212, loss = 1050.39740759\n",
      "Iteration 549, loss = 744.88478869\n",
      "Iteration 255, loss = 1008.56884725\n",
      "Iteration 237, loss = 948.18934008\n",
      "Iteration 180, loss = 1218.26385689\n",
      "Iteration 551, loss = 780.58989156\n",
      "Iteration 258, loss = 1004.49627482\n",
      "Iteration 550, loss = 745.94685754\n",
      "Iteration 228, loss = 1057.76020419\n",
      "Iteration 213, loss = 1046.76660366\n",
      "Iteration 256, loss = 1007.83017099\n",
      "Iteration 238, loss = 945.36362984\n",
      "Iteration 552, loss = 779.28814557\n",
      "Iteration 181, loss = 1214.53776320\n",
      "Iteration 551, loss = 745.97957512\n",
      "Iteration 229, loss = 1049.84508975\n",
      "Iteration 259, loss = 1000.31975443\n",
      "Iteration 214, loss = 1043.65570136\n",
      "Iteration 553, loss = 779.47066580\n",
      "Iteration 257, loss = 1005.69128627\n",
      "Iteration 239, loss = 939.81189357\n",
      "Iteration 182, loss = 1222.09451978\n",
      "Iteration 552, loss = 742.14192974\n",
      "Iteration 230, loss = 1054.14735867\n",
      "Iteration 554, loss = 779.83591194\n",
      "Iteration 260, loss = 1001.13179567\n",
      "Iteration 553, loss = 743.62026853\n",
      "Iteration 215, loss = 1046.90926263\n",
      "Iteration 258, loss = 1001.46956414\n",
      "Iteration 240, loss = 943.46625705\n",
      "Iteration 183, loss = 1206.99005535\n",
      "Iteration 555, loss = 779.68336142\n",
      "Iteration 231, loss = 1050.48191711Iteration 554, loss = 743.19079944\n",
      "\n",
      "Iteration 261, loss = 999.67669368\n",
      "Iteration 216, loss = 1036.52826428\n",
      "Iteration 259, loss = 999.12636434\n",
      "Iteration 241, loss = 937.17461366\n",
      "Iteration 184, loss = 1204.69423088\n",
      "Iteration 556, loss = 780.54582582\n",
      "Iteration 555, loss = 743.85662042\n",
      "Iteration 232, loss = 1045.07108067\n",
      "Iteration 262, loss = 992.66871238\n",
      "Iteration 217, loss = 1033.99261554\n",
      "Iteration 260, loss = 997.66343458\n",
      "Iteration 242, loss = 937.75028289\n",
      "Iteration 557, loss = 779.45664248\n",
      "Iteration 185, loss = 1199.71311406\n",
      "Iteration 556, loss = 743.94878425\n",
      "Iteration 233, loss = 1046.66012466\n",
      "Iteration 263, loss = 995.93899884\n",
      "Iteration 218, loss = 1030.46546967\n",
      "Iteration 558, loss = 778.34226481\n",
      "Iteration 261, loss = 993.88950296\n",
      "Iteration 557, loss = 743.57054679\n",
      "Iteration 243, loss = 935.57803148\n",
      "Iteration 186, loss = 1195.60939357\n",
      "Iteration 234, loss = 1043.85841172\n",
      "Iteration 264, loss = 1000.73354701\n",
      "Iteration 558, loss = 743.83961938\n",
      "Iteration 559, loss = 779.37151314\n",
      "Iteration 219, loss = 1030.18233529\n",
      "Iteration 262, loss = 992.70195915\n",
      "Iteration 244, loss = 930.19115377\n",
      "Iteration 187, loss = 1189.21504738\n",
      "Iteration 559, loss = 741.23384800\n",
      "Iteration 235, loss = 1038.86247092\n",
      "Iteration 560, loss = 778.66382502\n",
      "Iteration 265, loss = 990.64180926\n",
      "Iteration 220, loss = 1025.59036247\n",
      "Iteration 245, loss = 930.81851325\n",
      "Iteration 188, loss = 1179.01834233\n",
      "Iteration 263, loss = 992.10103179\n",
      "Iteration 560, loss = 741.96528359\n",
      "Iteration 561, loss = 779.20745551\n",
      "Iteration 236, loss = 1038.40043702\n",
      "Iteration 266, loss = 992.28847158\n",
      "Iteration 221, loss = 1019.77161885\n",
      "Iteration 246, loss = 925.73256432\n",
      "Iteration 561, loss = 742.83307192\n",
      "Iteration 189, loss = 1186.44146415\n",
      "Iteration 264, loss = 991.80732897\n",
      "Iteration 562, loss = 779.40405650\n",
      "Iteration 237, loss = 1034.47718160\n",
      "Iteration 267, loss = 988.59376454\n",
      "Iteration 222, loss = 1016.20231772\n",
      "Iteration 562, loss = 743.05773320\n",
      "Iteration 247, loss = 928.83999194\n",
      "Iteration 190, loss = 1179.94776927\n",
      "Iteration 563, loss = 776.77410134\n",
      "Iteration 265, loss = 987.53644251\n",
      "Iteration 238, loss = 1034.46799350\n",
      "Iteration 268, loss = 983.99824363\n",
      "Iteration 563, loss = 738.48779152\n",
      "Iteration 223, loss = 1017.62236539\n",
      "Iteration 248, loss = 927.15518170\n",
      "Iteration 564, loss = 777.54628364\n",
      "Iteration 191, loss = 1178.43487635\n",
      "Iteration 266, loss = 988.44947688\n",
      "Iteration 564, loss = 741.87473361\n",
      "Iteration 269, loss = 984.69908318Iteration 239, loss = 1028.37933826\n",
      "\n",
      "Iteration 224, loss = 1012.24078834\n",
      "Iteration 565, loss = 779.28557290\n",
      "Iteration 249, loss = 921.86615367\n",
      "Iteration 192, loss = 1168.49661500\n",
      "Iteration 267, loss = 984.09004993\n",
      "Iteration 565, loss = 742.23483270\n",
      "Iteration 566, loss = 778.54639236\n",
      "Iteration 240, loss = 1031.61961795\n",
      "Iteration 225, loss = 1009.61987347\n",
      "Iteration 270, loss = 988.08998586\n",
      "Iteration 250, loss = 916.93769829\n",
      "Iteration 566, loss = 741.21204521\n",
      "Iteration 193, loss = 1167.13829876\n",
      "Iteration 268, loss = 983.35519240\n",
      "Iteration 567, loss = 776.37267252\n",
      "Iteration 251, loss = 929.17653851\n",
      "Iteration 241, loss = 1026.55767649\n",
      "Iteration 226, loss = 1008.79841897\n",
      "Iteration 271, loss = 980.41507850\n",
      "Iteration 567, loss = 740.62810380\n",
      "Iteration 568, loss = 778.67375871\n",
      "Iteration 194, loss = 1163.85279923\n",
      "Iteration 269, loss = 981.76915583\n",
      "Iteration 252, loss = 915.23803076\n",
      "Iteration 242, loss = 1023.28528960\n",
      "Iteration 227, loss = 1005.40184148\n",
      "Iteration 568, loss = 739.97138867\n",
      "Iteration 272, loss = 975.40288837\n",
      "Iteration 569, loss = 777.17793788\n",
      "Iteration 195, loss = 1162.72756403\n",
      "Iteration 270, loss = 982.11501532\n",
      "Iteration 569, loss = 740.63880015\n",
      "Iteration 253, loss = 920.00610020\n",
      "Iteration 243, loss = 1024.04934939\n",
      "Iteration 228, loss = 1003.81654848\n",
      "Iteration 570, loss = 776.96565939\n",
      "Iteration 273, loss = 987.21785489\n",
      "Iteration 196, loss = 1155.07205271\n",
      "Iteration 570, loss = 739.34648389\n",
      "Iteration 271, loss = 980.41217639\n",
      "Iteration 254, loss = 915.00449178\n",
      "Iteration 571, loss = 778.89782668\n",
      "Iteration 244, loss = 1021.36064801\n",
      "Iteration 229, loss = 996.10007847\n",
      "Iteration 274, loss = 978.15839038\n",
      "Iteration 197, loss = 1149.52106593\n",
      "Iteration 571, loss = 742.86532609\n",
      "Iteration 272, loss = 975.76557214\n",
      "Iteration 572, loss = 777.27063167\n",
      "Iteration 255, loss = 916.26592234\n",
      "Iteration 245, loss = 1018.07694337\n",
      "Iteration 230, loss = 999.25192893\n",
      "Iteration 572, loss = 739.18043760\n",
      "Iteration 275, loss = 975.67590040\n",
      "Iteration 198, loss = 1146.97272873\n",
      "Iteration 573, loss = 776.97631367\n",
      "Iteration 273, loss = 981.79607850\n",
      "Iteration 573, loss = 740.70295908\n",
      "Iteration 256, loss = 911.06348698\n",
      "Iteration 246, loss = 1013.09650128\n",
      "Iteration 231, loss = 994.86921152\n",
      "Iteration 276, loss = 971.38178534\n",
      "Iteration 199, loss = 1140.44025499\n",
      "Iteration 574, loss = 777.63109211\n",
      "Iteration 574, loss = 739.12669502\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 274, loss = 976.42148256\n",
      "Iteration 247, loss = 1015.18916849\n",
      "Iteration 257, loss = 914.81493486\n",
      "Iteration 232, loss = 990.39336274\n",
      "Iteration 277, loss = 969.45369708\n",
      "Iteration 575, loss = 777.21259457\n",
      "Iteration 200, loss = 1139.99924537\n",
      "Iteration 275, loss = 971.46254733\n",
      "Iteration 248, loss = 1012.91163290\n",
      "Iteration 576, loss = 777.21134538\n",
      "Iteration 233, loss = 991.27563628\n",
      "Iteration 258, loss = 906.79844332\n",
      "Iteration 1, loss = 11607.43301934\n",
      "Iteration 278, loss = 977.19468673\n",
      "Iteration 201, loss = 1138.92371512\n",
      "Iteration 276, loss = 972.56883260\n",
      "Iteration 577, loss = 775.74954052\n",
      "Iteration 249, loss = 1012.55124068\n",
      "Iteration 234, loss = 986.24349586\n",
      "Iteration 259, loss = 911.65966077\n",
      "Iteration 279, loss = 974.20177587\n",
      "Iteration 2, loss = 10913.45794694\n",
      "Iteration 202, loss = 1135.19004826\n",
      "Iteration 578, loss = 776.74203469\n",
      "Iteration 277, loss = 968.71319599\n",
      "Iteration 250, loss = 1001.96358177\n",
      "Iteration 235, loss = 985.80129983\n",
      "Iteration 260, loss = 905.81658101\n",
      "Iteration 280, loss = 967.01239237\n",
      "Iteration 3, loss = 10397.15599007\n",
      "Iteration 203, loss = 1127.65304489\n",
      "Iteration 579, loss = 776.98304558\n",
      "Iteration 278, loss = 971.54020147\n",
      "Iteration 251, loss = 1014.21983269\n",
      "Iteration 236, loss = 982.85108695\n",
      "Iteration 261, loss = 905.54949467\n",
      "Iteration 580, loss = 778.42623143\n",
      "Iteration 4, loss = 9917.68681979\n",
      "Iteration 281, loss = 964.63832788\n",
      "Iteration 204, loss = 1124.69636101\n",
      "Iteration 279, loss = 970.88118212\n",
      "Iteration 237, loss = 977.88531269\n",
      "Iteration 252, loss = 1000.27315420\n",
      "Iteration 581, loss = 776.13596765\n",
      "Iteration 262, loss = 905.20045703\n",
      "Iteration 5, loss = 9498.17143342\n",
      "Iteration 282, loss = 967.71109249\n",
      "Iteration 205, loss = 1127.74849718\n",
      "Iteration 280, loss = 965.13315384\n",
      "Iteration 582, loss = 776.79703907\n",
      "Iteration 238, loss = 978.47702282\n",
      "Iteration 253, loss = 1008.90420838\n",
      "Iteration 263, loss = 904.34849009\n",
      "Iteration 283, loss = 962.08442458\n",
      "Iteration 6, loss = 9114.84149799\n",
      "Iteration 206, loss = 1116.20181792\n",
      "Iteration 583, loss = 775.66816775\n",
      "Iteration 281, loss = 962.22596514\n",
      "Iteration 239, loss = 973.99076650\n",
      "Iteration 254, loss = 1001.43784456\n",
      "Iteration 264, loss = 902.07401500\n",
      "Iteration 284, loss = 966.39683009\n",
      "Iteration 7, loss = 8779.92480922\n",
      "Iteration 584, loss = 776.40530470\n",
      "Iteration 207, loss = 1121.24895257\n",
      "Iteration 282, loss = 957.88159836\n",
      "Iteration 240, loss = 974.44121650\n",
      "Iteration 255, loss = 1002.21149921\n",
      "Iteration 265, loss = 899.48060576\n",
      "Iteration 285, loss = 963.49201373\n",
      "Iteration 585, loss = 773.22654533\n",
      "Iteration 8, loss = 8479.36183033\n",
      "Iteration 208, loss = 1112.93359249\n",
      "Iteration 241, loss = 973.09571682\n",
      "Iteration 283, loss = 962.02004522\n",
      "Iteration 256, loss = 996.10512101\n",
      "Iteration 586, loss = 777.82941283\n",
      "Iteration 286, loss = 959.14593978\n",
      "Iteration 266, loss = 896.49013429\n",
      "Iteration 9, loss = 8200.82490906\n",
      "Iteration 209, loss = 1109.70521465\n",
      "Iteration 242, loss = 967.15928070\n",
      "Iteration 587, loss = 776.68202304\n",
      "Iteration 284, loss = 957.39884630\n",
      "Iteration 257, loss = 999.91089001\n",
      "Iteration 267, loss = 897.83382631\n",
      "Iteration 287, loss = 960.58596803\n",
      "Iteration 10, loss = 7941.05183750\n",
      "Iteration 210, loss = 1105.61096783\n",
      "Iteration 588, loss = 772.69406907\n",
      "Iteration 243, loss = 968.18278510\n",
      "Iteration 285, loss = 956.86390906\n",
      "Iteration 258, loss = 991.16119588\n",
      "Iteration 288, loss = 960.61696516\n",
      "Iteration 268, loss = 900.97347833\n",
      "Iteration 11, loss = 7696.42845560\n",
      "Iteration 589, loss = 775.73336338\n",
      "Iteration 211, loss = 1099.71250063\n",
      "Iteration 244, loss = 965.03238672\n",
      "Iteration 259, loss = 994.02431879\n",
      "Iteration 286, loss = 953.28629544\n",
      "Iteration 289, loss = 959.81439453\n",
      "Iteration 269, loss = 892.84604195\n",
      "Iteration 590, loss = 774.86911784\n",
      "Iteration 12, loss = 7467.47036154\n",
      "Iteration 212, loss = 1101.43237343\n",
      "Iteration 260, loss = 991.90143579\n",
      "Iteration 245, loss = 961.83210748\n",
      "Iteration 290, loss = 951.47160266\n",
      "Iteration 591, loss = 775.18690756\n",
      "Iteration 270, loss = 892.03434592\n",
      "Iteration 287, loss = 958.28642545\n",
      "Iteration 13, loss = 7251.35308326\n",
      "Iteration 213, loss = 1098.58236050\n",
      "Iteration 246, loss = 960.05313826\n",
      "Iteration 592, loss = 773.85436871\n",
      "Iteration 261, loss = 990.77684075\n",
      "Iteration 291, loss = 954.17255281\n",
      "Iteration 271, loss = 889.58493766\n",
      "Iteration 288, loss = 956.14433342\n",
      "Iteration 14, loss = 7047.31037227\n",
      "Iteration 593, loss = 773.18466329\n",
      "Iteration 214, loss = 1093.89727216\n",
      "Iteration 247, loss = 960.72844543\n",
      "Iteration 262, loss = 987.02875072\n",
      "Iteration 292, loss = 952.53813971\n",
      "Iteration 289, loss = 946.96043113\n",
      "Iteration 272, loss = 888.48921486\n",
      "Iteration 594, loss = 774.79861181\n",
      "Iteration 15, loss = 6854.49167420\n",
      "Iteration 215, loss = 1096.41708709\n",
      "Iteration 263, loss = 988.86108595\n",
      "Iteration 248, loss = 953.07651675\n",
      "Iteration 293, loss = 956.14139906\n",
      "Iteration 290, loss = 945.84301333\n",
      "Iteration 273, loss = 884.54546944\n",
      "Iteration 595, loss = 773.95625919\n",
      "Iteration 16, loss = 6670.63503698\n",
      "Iteration 216, loss = 1092.35907108\n",
      "Iteration 249, loss = 956.61652372\n",
      "Iteration 264, loss = 983.08960367\n",
      "Iteration 596, loss = 774.65017226\n",
      "Iteration 294, loss = 949.84820957\n",
      "Iteration 291, loss = 946.84797707\n",
      "Iteration 274, loss = 888.84934532\n",
      "Iteration 17, loss = 6496.29210288\n",
      "Iteration 597, loss = 773.57713759\n",
      "Iteration 250, loss = 949.10928556\n",
      "Iteration 217, loss = 1087.66078062\n",
      "Iteration 265, loss = 986.38497160\n",
      "Iteration 295, loss = 951.54389731\n",
      "Iteration 275, loss = 882.08067797\n",
      "Iteration 292, loss = 946.86437680\n",
      "Iteration 598, loss = 772.88543277\n",
      "Iteration 18, loss = 6330.49820992\n",
      "Iteration 251, loss = 955.43173534\n",
      "Iteration 218, loss = 1084.68568620\n",
      "Iteration 266, loss = 981.97866459\n",
      "Iteration 296, loss = 947.29789845\n",
      "Iteration 276, loss = 884.09906102\n",
      "Iteration 599, loss = 774.81583466\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 293, loss = 945.21197913\n",
      "Iteration 19, loss = 6172.05476764\n",
      "Iteration 252, loss = 946.08955901\n",
      "Iteration 219, loss = 1081.58926472\n",
      "Iteration 267, loss = 977.47383247\n",
      "Iteration 297, loss = 946.92596085\n",
      "Iteration 277, loss = 885.29520121\n",
      "Iteration 294, loss = 942.49267836\n",
      "Iteration 1, loss = 11578.99618391\n",
      "Iteration 20, loss = 6020.33640457\n",
      "Iteration 253, loss = 954.29960227\n",
      "Iteration 220, loss = 1082.95482345\n",
      "Iteration 268, loss = 984.17444635\n",
      "Iteration 298, loss = 947.50951210\n",
      "Iteration 278, loss = 879.37688714\n",
      "Iteration 295, loss = 940.34629223\n",
      "Iteration 2, loss = 10885.52876169\n",
      "Iteration 21, loss = 5875.13118983\n",
      "Iteration 254, loss = 940.56272741\n",
      "Iteration 221, loss = 1078.00248588\n",
      "Iteration 269, loss = 976.00375963\n",
      "Iteration 299, loss = 944.84301649\n",
      "Iteration 279, loss = 881.01297046\n",
      "Iteration 296, loss = 940.59534847\n",
      "Iteration 3, loss = 10376.00231746\n",
      "Iteration 22, loss = 5736.20198257\n",
      "Iteration 255, loss = 946.16894936\n",
      "Iteration 222, loss = 1072.14347176\n",
      "Iteration 270, loss = 975.94955492\n",
      "Iteration 300, loss = 942.45936206\n",
      "Iteration 280, loss = 877.34952852\n",
      "Iteration 297, loss = 940.47617273\n",
      "Iteration 4, loss = 9897.01745437\n",
      "Iteration 23, loss = 5603.27932441\n",
      "Iteration 256, loss = 941.09657602\n",
      "Iteration 223, loss = 1072.42271027\n",
      "Iteration 271, loss = 970.49559120\n",
      "Iteration 301, loss = 941.99274320\n",
      "Iteration 281, loss = 876.80590042\n",
      "Iteration 5, loss = 9480.15004644\n",
      "Iteration 298, loss = 937.97468579\n",
      "Iteration 24, loss = 5475.22067683\n",
      "Iteration 257, loss = 939.32838747\n",
      "Iteration 272, loss = 975.27098064\n",
      "Iteration 224, loss = 1067.11138858\n",
      "Iteration 302, loss = 941.57321225\n",
      "Iteration 282, loss = 876.26100819\n",
      "Iteration 299, loss = 932.72671127\n",
      "Iteration 6, loss = 9097.45195257\n",
      "Iteration 25, loss = 5352.13204220\n",
      "Iteration 258, loss = 929.74804144\n",
      "Iteration 225, loss = 1066.06508900\n",
      "Iteration 273, loss = 970.80350297\n",
      "Iteration 303, loss = 936.60721746\n",
      "Iteration 300, loss = 934.50040719\n",
      "Iteration 283, loss = 873.49509304\n",
      "Iteration 7, loss = 8763.03768639\n",
      "Iteration 26, loss = 5235.50010205\n",
      "Iteration 259, loss = 933.83923558\n",
      "Iteration 304, loss = 938.71158898\n",
      "Iteration 274, loss = 972.63118218\n",
      "Iteration 226, loss = 1065.07965194\n",
      "Iteration 8, loss = 8463.73090894\n",
      "Iteration 284, loss = 871.81412133\n",
      "Iteration 301, loss = 931.69636831\n",
      "Iteration 27, loss = 5123.42369458\n",
      "Iteration 260, loss = 932.82082169\n",
      "Iteration 305, loss = 935.55092755\n",
      "Iteration 227, loss = 1068.35066286\n",
      "Iteration 275, loss = 967.61440516\n",
      "Iteration 285, loss = 870.72141841\n",
      "Iteration 9, loss = 8187.24117540\n",
      "Iteration 302, loss = 933.74527483\n",
      "Iteration 28, loss = 5017.17184818\n",
      "Iteration 306, loss = 932.59520979\n",
      "Iteration 261, loss = 931.09206889\n",
      "Iteration 228, loss = 1063.10856343\n",
      "Iteration 276, loss = 969.48221252\n",
      "Iteration 286, loss = 867.84989665\n",
      "Iteration 303, loss = 933.65606290\n",
      "Iteration 29, loss = 4913.95609982\n",
      "Iteration 10, loss = 7929.68641715\n",
      "Iteration 307, loss = 931.81909962\n",
      "Iteration 262, loss = 930.25461395\n",
      "Iteration 277, loss = 969.83555125\n",
      "Iteration 229, loss = 1057.83131822\n",
      "Iteration 304, loss = 928.40024407\n",
      "Iteration 287, loss = 871.40307599\n",
      "Iteration 308, loss = 937.42054778\n",
      "Iteration 263, loss = 929.22865274\n",
      "Iteration 278, loss = 960.07934740\n",
      "Iteration 11, loss = 7687.52871858\n",
      "Iteration 30, loss = 4815.07511034\n",
      "Iteration 230, loss = 1054.44410583\n",
      "Iteration 288, loss = 867.47083118\n",
      "Iteration 305, loss = 929.19828131\n",
      "Iteration 264, loss = 923.18053664\n",
      "Iteration 309, loss = 932.76623905\n",
      "Iteration 12, loss = 7461.39725426\n",
      "Iteration 279, loss = 962.12812907\n",
      "Iteration 231, loss = 1054.69411155\n",
      "Iteration 31, loss = 4720.51483517\n",
      "Iteration 289, loss = 860.85232962\n",
      "Iteration 306, loss = 928.27691655\n",
      "Iteration 265, loss = 925.13852234\n",
      "Iteration 310, loss = 927.67030173\n",
      "Iteration 13, loss = 7248.08762231\n",
      "Iteration 280, loss = 961.06973111\n",
      "Iteration 32, loss = 4628.56992864\n",
      "Iteration 232, loss = 1048.53507070\n",
      "Iteration 290, loss = 868.78085268\n",
      "Iteration 307, loss = 926.17740627\n",
      "Iteration 311, loss = 927.43045776\n",
      "Iteration 266, loss = 921.33944743\n",
      "Iteration 14, loss = 7046.77812587\n",
      "Iteration 281, loss = 958.25510518\n",
      "Iteration 233, loss = 1056.77965484\n",
      "Iteration 33, loss = 4540.09905391\n",
      "Iteration 291, loss = 866.34803871\n",
      "Iteration 308, loss = 927.67208416\n",
      "Iteration 312, loss = 923.71034207\n",
      "Iteration 15, loss = 6856.83503565\n",
      "Iteration 267, loss = 919.47600108\n",
      "Iteration 282, loss = 958.59541778\n",
      "Iteration 34, loss = 4455.98080574\n",
      "Iteration 234, loss = 1047.42646763\n",
      "Iteration 309, loss = 923.97254224\n",
      "Iteration 292, loss = 867.36675254\n",
      "Iteration 313, loss = 923.86709262\n",
      "Iteration 268, loss = 921.05060324\n",
      "Iteration 16, loss = 6675.31606713\n",
      "Iteration 283, loss = 959.38563631\n",
      "Iteration 35, loss = 4373.08476904\n",
      "Iteration 235, loss = 1045.42826816\n",
      "Iteration 310, loss = 925.67767895\n",
      "Iteration 293, loss = 860.53992312\n",
      "Iteration 314, loss = 920.59114263\n",
      "Iteration 269, loss = 912.60038002\n",
      "Iteration 17, loss = 6502.21626038\n",
      "Iteration 284, loss = 955.80029535\n",
      "Iteration 36, loss = 4293.51119301\n",
      "Iteration 236, loss = 1040.38873254\n",
      "Iteration 311, loss = 921.81599830\n",
      "Iteration 294, loss = 863.05386067\n",
      "Iteration 315, loss = 929.19186241\n",
      "Iteration 270, loss = 908.59565185\n",
      "Iteration 285, loss = 955.10291700\n",
      "Iteration 18, loss = 6337.74831839\n",
      "Iteration 37, loss = 4216.08532634\n",
      "Iteration 237, loss = 1039.52236345\n",
      "Iteration 312, loss = 915.80680716\n",
      "Iteration 295, loss = 858.98178319\n",
      "Iteration 316, loss = 922.12011115\n",
      "Iteration 271, loss = 902.91186464\n",
      "Iteration 286, loss = 952.43749234\n",
      "Iteration 19, loss = 6180.51932856\n",
      "Iteration 38, loss = 4140.24147652\n",
      "Iteration 238, loss = 1036.54078928\n",
      "Iteration 313, loss = 918.62094566\n",
      "Iteration 296, loss = 860.12391228\n",
      "Iteration 317, loss = 919.37455189\n",
      "Iteration 287, loss = 953.32917981\n",
      "Iteration 272, loss = 911.04456847\n",
      "Iteration 20, loss = 6030.64551999\n",
      "Iteration 39, loss = 4067.90582135\n",
      "Iteration 239, loss = 1029.52967280\n",
      "Iteration 314, loss = 915.29926939\n",
      "Iteration 297, loss = 855.88686673\n",
      "Iteration 318, loss = 918.48989777\n",
      "Iteration 273, loss = 908.12103498\n",
      "Iteration 288, loss = 950.78484501\n",
      "Iteration 21, loss = 5886.95258622\n",
      "Iteration 40, loss = 3996.94560101\n",
      "Iteration 240, loss = 1031.05448724\n",
      "Iteration 315, loss = 920.31960296\n",
      "Iteration 298, loss = 862.44048109\n",
      "Iteration 319, loss = 915.87247614\n",
      "Iteration 274, loss = 909.47917245\n",
      "Iteration 289, loss = 944.92405567\n",
      "Iteration 22, loss = 5748.56534526\n",
      "Iteration 41, loss = 3929.27177532\n",
      "Iteration 241, loss = 1027.62461320\n",
      "Iteration 316, loss = 915.18992945\n",
      "Iteration 299, loss = 852.86469831\n",
      "Iteration 320, loss = 913.18946903\n",
      "Iteration 275, loss = 903.28523670\n",
      "Iteration 290, loss = 948.42054937\n",
      "Iteration 42, loss = 3861.79288794\n",
      "Iteration 242, loss = 1026.04103274\n",
      "Iteration 23, loss = 5617.72013586\n",
      "Iteration 300, loss = 857.20973030\n",
      "Iteration 317, loss = 912.71812401\n",
      "Iteration 321, loss = 922.15947479\n",
      "Iteration 276, loss = 903.10077543\n",
      "Iteration 291, loss = 947.13389096\n",
      "Iteration 43, loss = 3796.06951666\n",
      "Iteration 243, loss = 1028.51730727\n",
      "Iteration 24, loss = 5492.51348913\n",
      "Iteration 301, loss = 854.12905036\n",
      "Iteration 318, loss = 910.50528835\n",
      "Iteration 322, loss = 915.81622683\n",
      "Iteration 277, loss = 906.12949823\n",
      "Iteration 292, loss = 949.15182082\n",
      "Iteration 44, loss = 3735.28564556\n",
      "Iteration 25, loss = 5371.64906535\n",
      "Iteration 244, loss = 1020.80712633\n",
      "Iteration 302, loss = 852.89274800\n",
      "Iteration 319, loss = 913.25633451\n",
      "Iteration 323, loss = 907.09813580\n",
      "Iteration 45, loss = 3673.53098725\n",
      "Iteration 278, loss = 899.31834357\n",
      "Iteration 293, loss = 937.80051105\n",
      "Iteration 26, loss = 5257.56456780\n",
      "Iteration 245, loss = 1018.12980428\n",
      "Iteration 320, loss = 906.37985662\n",
      "Iteration 303, loss = 850.87293537\n",
      "Iteration 324, loss = 912.14980730\n",
      "Iteration 279, loss = 902.25163732\n",
      "Iteration 46, loss = 3615.42836779\n",
      "Iteration 294, loss = 944.32070981\n",
      "Iteration 246, loss = 1015.68925774\n",
      "Iteration 27, loss = 5147.86561271\n",
      "Iteration 321, loss = 913.83212393\n",
      "Iteration 304, loss = 850.42577144\n",
      "Iteration 325, loss = 907.57828279\n",
      "Iteration 280, loss = 894.46412478\n",
      "Iteration 47, loss = 3558.08601043\n",
      "Iteration 295, loss = 940.54164046\n",
      "Iteration 247, loss = 1017.78122052\n",
      "Iteration 28, loss = 5042.67286981\n",
      "Iteration 322, loss = 912.42410708\n",
      "Iteration 305, loss = 852.37044782\n",
      "Iteration 48, loss = 3503.51980448\n",
      "Iteration 281, loss = 895.82458660\n",
      "Iteration 326, loss = 904.35058994\n",
      "Iteration 296, loss = 940.73000668\n",
      "Iteration 248, loss = 1016.15967348\n",
      "Iteration 29, loss = 4942.30408121\n",
      "Iteration 323, loss = 904.79735857\n",
      "Iteration 306, loss = 849.83246830\n",
      "Iteration 49, loss = 3449.16703690\n",
      "Iteration 282, loss = 890.70037974\n",
      "Iteration 327, loss = 909.95769699\n",
      "Iteration 297, loss = 939.88800312\n",
      "Iteration 249, loss = 1012.59229093\n",
      "Iteration 324, loss = 903.22097239\n",
      "Iteration 30, loss = 4845.16851876\n",
      "Iteration 307, loss = 847.73432077\n",
      "Iteration 298, loss = 941.15388234\n",
      "Iteration 283, loss = 893.11302252\n",
      "Iteration 50, loss = 3396.47311727\n",
      "Iteration 328, loss = 907.65544985\n",
      "Iteration 250, loss = 1002.90822815\n",
      "Iteration 325, loss = 906.70800638\n",
      "Iteration 31, loss = 4752.63647839\n",
      "Iteration 308, loss = 844.95802424\n",
      "Iteration 299, loss = 934.05393508\n",
      "Iteration 284, loss = 887.30138598\n",
      "Iteration 51, loss = 3343.83259567\n",
      "Iteration 251, loss = 1011.37428474\n",
      "Iteration 329, loss = 906.46803533\n",
      "Iteration 326, loss = 904.49528252\n",
      "Iteration 32, loss = 4662.71950981\n",
      "Iteration 309, loss = 847.56191483\n",
      "Iteration 285, loss = 887.00038503\n",
      "Iteration 300, loss = 934.78021609\n",
      "Iteration 52, loss = 3293.19179125\n",
      "Iteration 252, loss = 1004.20288974\n",
      "Iteration 330, loss = 904.13082437\n",
      "Iteration 327, loss = 909.51911530\n",
      "Iteration 33, loss = 4575.76438274\n",
      "Iteration 310, loss = 845.24009260\n",
      "Iteration 286, loss = 884.18564561\n",
      "Iteration 301, loss = 933.30463554\n",
      "Iteration 53, loss = 3243.55140295\n",
      "Iteration 253, loss = 1012.02204290\n",
      "Iteration 331, loss = 901.48772752\n",
      "Iteration 328, loss = 902.69833560\n",
      "Iteration 34, loss = 4492.95942775\n",
      "Iteration 311, loss = 843.75635023\n",
      "Iteration 54, loss = 3196.88062780\n",
      "Iteration 287, loss = 887.34409412\n",
      "Iteration 302, loss = 929.73314334\n",
      "Iteration 332, loss = 897.47618259\n",
      "Iteration 254, loss = 998.63574818\n",
      "Iteration 329, loss = 901.79484976\n",
      "Iteration 35, loss = 4411.57915775\n",
      "Iteration 312, loss = 845.10430448\n",
      "Iteration 55, loss = 3151.00890955\n",
      "Iteration 288, loss = 886.94932885\n",
      "Iteration 303, loss = 931.06626857\n",
      "Iteration 333, loss = 901.92029247\n",
      "Iteration 255, loss = 1003.33046497\n",
      "Iteration 330, loss = 902.33896719\n",
      "Iteration 36, loss = 4332.92087436Iteration 313, loss = 842.46686984\n",
      "\n",
      "Iteration 56, loss = 3106.24100774\n",
      "Iteration 289, loss = 881.47018833\n",
      "Iteration 304, loss = 929.61384343\n",
      "Iteration 334, loss = 903.33386502\n",
      "Iteration 256, loss = 998.02099655\n",
      "Iteration 331, loss = 900.03986663\n",
      "Iteration 314, loss = 841.87360301\n",
      "Iteration 37, loss = 4254.92574979\n",
      "Iteration 57, loss = 3061.59303091\n",
      "Iteration 290, loss = 877.63656046\n",
      "Iteration 305, loss = 929.00811235\n",
      "Iteration 335, loss = 891.73971156\n",
      "Iteration 257, loss = 998.55668929\n",
      "Iteration 332, loss = 889.99205021\n",
      "Iteration 315, loss = 842.79802014\n",
      "Iteration 38, loss = 4180.66001407\n",
      "Iteration 58, loss = 3020.88343267\n",
      "Iteration 291, loss = 879.76963954\n",
      "Iteration 306, loss = 929.45330079\n",
      "Iteration 258, loss = 993.78879255\n",
      "Iteration 336, loss = 903.85214718\n",
      "Iteration 333, loss = 900.61107579\n",
      "Iteration 316, loss = 839.37542595\n",
      "Iteration 39, loss = 4109.30490915\n",
      "Iteration 59, loss = 2977.63594593\n",
      "Iteration 292, loss = 880.72131780\n",
      "Iteration 259, loss = 992.82587269\n",
      "Iteration 307, loss = 925.08287794\n",
      "Iteration 337, loss = 895.52929292\n",
      "Iteration 334, loss = 899.16149028\n",
      "Iteration 317, loss = 835.45363955\n",
      "Iteration 40, loss = 4039.80737356\n",
      "Iteration 60, loss = 2936.31297225\n",
      "Iteration 293, loss = 876.22000716\n",
      "Iteration 260, loss = 992.65068443\n",
      "Iteration 308, loss = 921.27105345\n",
      "Iteration 338, loss = 891.25239467\n",
      "Iteration 335, loss = 895.09592496\n",
      "Iteration 318, loss = 836.69227198\n",
      "Iteration 61, loss = 2897.81256936\n",
      "Iteration 41, loss = 3974.05760891\n",
      "Iteration 261, loss = 986.15098602\n",
      "Iteration 309, loss = 921.30994543\n",
      "Iteration 294, loss = 872.50752157\n",
      "Iteration 339, loss = 891.68901958\n",
      "Iteration 336, loss = 899.28752979\n",
      "Iteration 319, loss = 835.75175336\n",
      "Iteration 62, loss = 2858.53954449\n",
      "Iteration 42, loss = 3908.75145510\n",
      "Iteration 262, loss = 991.09239548\n",
      "Iteration 310, loss = 923.92239797\n",
      "Iteration 295, loss = 873.85542015\n",
      "Iteration 340, loss = 890.96644930\n",
      "Iteration 337, loss = 892.30831941\n",
      "Iteration 320, loss = 834.30816128\n",
      "Iteration 63, loss = 2821.83071473\n",
      "Iteration 43, loss = 3846.04406974\n",
      "Iteration 296, loss = 879.61076407\n",
      "Iteration 311, loss = 920.51073557\n",
      "Iteration 341, loss = 893.21634406\n",
      "Iteration 263, loss = 989.52915617\n",
      "Iteration 321, loss = 836.26095073\n",
      "Iteration 338, loss = 894.74150388\n",
      "Iteration 64, loss = 2785.93899832\n",
      "Iteration 44, loss = 3785.84910605\n",
      "Iteration 297, loss = 872.85640579\n",
      "Iteration 312, loss = 919.39962033\n",
      "Iteration 342, loss = 896.08600480\n",
      "Iteration 264, loss = 986.64012418\n",
      "Iteration 322, loss = 838.02104609\n",
      "Iteration 339, loss = 889.04845564\n",
      "Iteration 65, loss = 2750.28168879\n",
      "Iteration 298, loss = 871.77282470\n",
      "Iteration 45, loss = 3726.00891769\n",
      "Iteration 343, loss = 889.70351874\n",
      "Iteration 313, loss = 916.04344770\n",
      "Iteration 265, loss = 984.12947104\n",
      "Iteration 323, loss = 833.58624330\n",
      "Iteration 340, loss = 894.83650283\n",
      "Iteration 66, loss = 2716.83244692\n",
      "Iteration 299, loss = 868.84035870\n",
      "Iteration 344, loss = 883.79842405\n",
      "Iteration 46, loss = 3668.79014942\n",
      "Iteration 314, loss = 915.23304255\n",
      "Iteration 266, loss = 984.56979904\n",
      "Iteration 341, loss = 894.97325289\n",
      "Iteration 324, loss = 835.07670161\n",
      "Iteration 300, loss = 872.35868723\n",
      "Iteration 345, loss = 888.92996161\n",
      "Iteration 67, loss = 2683.26267792\n",
      "Iteration 47, loss = 3613.20627010\n",
      "Iteration 315, loss = 920.25609036\n",
      "Iteration 267, loss = 981.37725575\n",
      "Iteration 342, loss = 896.48063703\n",
      "Iteration 325, loss = 832.09991387\n",
      "Iteration 346, loss = 884.53270109\n",
      "Iteration 301, loss = 867.46879228\n",
      "Iteration 68, loss = 2651.01551761\n",
      "Iteration 48, loss = 3560.19925837\n",
      "Iteration 316, loss = 917.46568619\n",
      "Iteration 268, loss = 983.98979666\n",
      "Iteration 343, loss = 891.31530273\n",
      "Iteration 326, loss = 831.30598764\n",
      "Iteration 302, loss = 865.24457296\n",
      "Iteration 69, loss = 2620.56846198\n",
      "Iteration 347, loss = 885.91231506\n",
      "Iteration 317, loss = 912.85889782\n",
      "Iteration 49, loss = 3507.01495515\n",
      "Iteration 269, loss = 979.26983396\n",
      "Iteration 344, loss = 879.87716485\n",
      "Iteration 327, loss = 831.91767060\n",
      "Iteration 70, loss = 2590.46292010\n",
      "Iteration 348, loss = 882.59348227\n",
      "Iteration 303, loss = 871.25561171\n",
      "Iteration 318, loss = 908.16244057\n",
      "Iteration 50, loss = 3455.39312822\n",
      "Iteration 270, loss = 975.42809237\n",
      "Iteration 345, loss = 888.32166060\n",
      "Iteration 71, loss = 2559.61518862\n",
      "Iteration 349, loss = 882.68010635\n",
      "Iteration 328, loss = 832.21767928\n",
      "Iteration 304, loss = 860.75828523\n",
      "Iteration 319, loss = 908.41864824\n",
      "Iteration 51, loss = 3403.60766637\n",
      "Iteration 271, loss = 973.38375638\n",
      "Iteration 346, loss = 886.95928065\n",
      "Iteration 72, loss = 2530.99544885\n",
      "Iteration 350, loss = 884.93463480\n",
      "Iteration 305, loss = 866.14947696\n",
      "Iteration 329, loss = 830.93194017\n",
      "Iteration 320, loss = 909.69450039\n",
      "Iteration 52, loss = 3353.64422240\n",
      "Iteration 351, loss = 882.30134248\n",
      "Iteration 347, loss = 891.24801534\n",
      "Iteration 73, loss = 2501.77000495\n",
      "Iteration 272, loss = 975.43613621\n",
      "Iteration 306, loss = 866.76722550\n",
      "Iteration 330, loss = 828.58456151\n",
      "Iteration 321, loss = 908.73205897\n",
      "Iteration 53, loss = 3304.59042337\n",
      "Iteration 348, loss = 882.87520223\n",
      "Iteration 273, loss = 971.41004468\n",
      "Iteration 352, loss = 882.41874928\n",
      "Iteration 74, loss = 2474.17587012\n",
      "Iteration 307, loss = 857.60556357\n",
      "Iteration 322, loss = 905.80428455\n",
      "Iteration 331, loss = 833.77107454\n",
      "Iteration 54, loss = 3258.74210860\n",
      "Iteration 353, loss = 884.74196129\n",
      "Iteration 349, loss = 887.27449875\n",
      "Iteration 75, loss = 2446.39956040\n",
      "Iteration 274, loss = 979.55242977\n",
      "Iteration 332, loss = 826.91612329\n",
      "Iteration 308, loss = 856.86863472\n",
      "Iteration 323, loss = 903.10903998\n",
      "Iteration 55, loss = 3213.96734607\n",
      "Iteration 354, loss = 878.03422179\n",
      "Iteration 350, loss = 884.00215071\n",
      "Iteration 76, loss = 2419.83463880\n",
      "Iteration 275, loss = 968.36817536\n",
      "Iteration 333, loss = 829.55053945\n",
      "Iteration 309, loss = 856.82885728\n",
      "Iteration 324, loss = 909.56369998\n",
      "Iteration 56, loss = 3169.00399297\n",
      "Iteration 351, loss = 882.62607066\n",
      "Iteration 355, loss = 877.94590234\n",
      "Iteration 276, loss = 967.82785216\n",
      "Iteration 334, loss = 827.48301805\n",
      "Iteration 77, loss = 2394.10442396\n",
      "Iteration 310, loss = 858.99737791\n",
      "Iteration 325, loss = 904.16624892\n",
      "Iteration 57, loss = 3125.85152644\n",
      "Iteration 352, loss = 880.90709921\n",
      "Iteration 277, loss = 975.71415602\n",
      "Iteration 356, loss = 878.20751873\n",
      "Iteration 78, loss = 2368.72387751\n",
      "Iteration 335, loss = 825.08216462\n",
      "Iteration 326, loss = 904.83413820\n",
      "Iteration 311, loss = 858.76959497\n",
      "Iteration 58, loss = 3084.15742004\n",
      "Iteration 353, loss = 883.63120134\n",
      "Iteration 278, loss = 966.71366085\n",
      "Iteration 357, loss = 872.32608866\n",
      "Iteration 336, loss = 830.56169684\n",
      "Iteration 79, loss = 2342.67335816\n",
      "Iteration 327, loss = 902.49732811\n",
      "Iteration 59, loss = 3043.12712906\n",
      "Iteration 354, loss = 877.30884452\n",
      "Iteration 312, loss = 857.52846567\n",
      "Iteration 279, loss = 971.81916922\n",
      "Iteration 358, loss = 877.73424018\n",
      "Iteration 80, loss = 2318.22317787\n",
      "Iteration 337, loss = 825.59545262\n",
      "Iteration 328, loss = 901.34306522\n",
      "Iteration 60, loss = 3003.01314646\n",
      "Iteration 355, loss = 880.61924670\n",
      "Iteration 280, loss = 963.09082777\n",
      "Iteration 313, loss = 855.89266162\n",
      "Iteration 338, loss = 823.66936311\n",
      "Iteration 359, loss = 881.94980594\n",
      "Iteration 81, loss = 2293.88989770\n",
      "Iteration 329, loss = 907.09821201\n",
      "Iteration 356, loss = 879.09844475\n",
      "Iteration 61, loss = 2965.51747449\n",
      "Iteration 314, loss = 851.37436590\n",
      "Iteration 281, loss = 963.99565577\n",
      "Iteration 339, loss = 826.91716992\n",
      "Iteration 360, loss = 873.22355028\n",
      "Iteration 82, loss = 2270.34975673\n",
      "Iteration 330, loss = 897.94381715\n",
      "Iteration 357, loss = 875.50139943\n",
      "Iteration 62, loss = 2926.80597548\n",
      "Iteration 315, loss = 855.31464277\n",
      "Iteration 282, loss = 961.43674939\n",
      "Iteration 83, loss = 2248.05996146\n",
      "Iteration 361, loss = 879.07896654\n",
      "Iteration 340, loss = 821.79037365\n",
      "Iteration 331, loss = 897.39828150\n",
      "Iteration 358, loss = 879.44903531\n",
      "Iteration 316, loss = 852.84596051\n",
      "Iteration 63, loss = 2889.58677898\n",
      "Iteration 283, loss = 960.06410348\n",
      "Iteration 84, loss = 2225.84778036\n",
      "Iteration 341, loss = 821.96518251\n",
      "Iteration 362, loss = 875.03998381\n",
      "Iteration 332, loss = 894.67686449\n",
      "Iteration 359, loss = 872.81131560\n",
      "Iteration 284, loss = 958.54258583\n",
      "Iteration 317, loss = 848.35700715\n",
      "Iteration 363, loss = 872.36517208\n",
      "Iteration 64, loss = 2854.54332708\n",
      "Iteration 85, loss = 2202.69165892\n",
      "Iteration 342, loss = 821.14671319\n",
      "Iteration 333, loss = 893.25327395\n",
      "Iteration 360, loss = 874.66904431\n",
      "Iteration 285, loss = 955.64906359\n",
      "Iteration 65, loss = 2819.71401384\n",
      "Iteration 318, loss = 847.13867494\n",
      "Iteration 364, loss = 869.80494118\n",
      "Iteration 86, loss = 2180.47126726\n",
      "Iteration 343, loss = 823.05787134\n",
      "Iteration 334, loss = 895.53722623\n",
      "Iteration 361, loss = 875.54250446\n",
      "Iteration 66, loss = 2787.17690076\n",
      "Iteration 286, loss = 953.87801032\n",
      "Iteration 365, loss = 872.06549953\n",
      "Iteration 319, loss = 845.04207173\n",
      "Iteration 87, loss = 2160.97462863\n",
      "Iteration 344, loss = 815.37109965\n",
      "Iteration 335, loss = 897.09972304\n",
      "Iteration 362, loss = 871.07783850\n",
      "Iteration 287, loss = 958.21994677\n",
      "Iteration 67, loss = 2753.73147991\n",
      "Iteration 320, loss = 849.09527577\n",
      "Iteration 88, loss = 2139.77801545\n",
      "Iteration 366, loss = 868.53117249\n",
      "Iteration 345, loss = 821.52511674\n",
      "Iteration 336, loss = 897.82560634\n",
      "Iteration 363, loss = 876.44054263\n",
      "Iteration 68, loss = 2721.18753967\n",
      "Iteration 288, loss = 956.68656552\n",
      "Iteration 321, loss = 847.26574211\n",
      "Iteration 367, loss = 870.62361806\n",
      "Iteration 89, loss = 2119.69926441\n",
      "Iteration 346, loss = 819.67508933\n",
      "Iteration 337, loss = 891.16785419\n",
      "Iteration 364, loss = 869.49480288\n",
      "Iteration 90, loss = 2100.74724363\n",
      "Iteration 368, loss = 876.07909488\n",
      "Iteration 69, loss = 2690.42394178\n",
      "Iteration 289, loss = 952.55493460\n",
      "Iteration 322, loss = 846.24490069\n",
      "Iteration 347, loss = 817.20036737\n",
      "Iteration 338, loss = 889.95310651\n",
      "Iteration 365, loss = 871.78292401\n",
      "Iteration 91, loss = 2078.36726744\n",
      "Iteration 369, loss = 869.52409012\n",
      "Iteration 70, loss = 2660.26791871\n",
      "Iteration 323, loss = 843.02487268\n",
      "Iteration 348, loss = 818.11566607\n",
      "Iteration 290, loss = 947.50162688\n",
      "Iteration 339, loss = 888.50733912\n",
      "Iteration 366, loss = 867.27190593\n",
      "Iteration 92, loss = 2061.46254589\n",
      "Iteration 370, loss = 863.99543981\n",
      "Iteration 71, loss = 2629.94834565\n",
      "Iteration 291, loss = 955.57485699\n",
      "Iteration 324, loss = 844.59200114\n",
      "Iteration 349, loss = 817.20580553\n",
      "Iteration 340, loss = 885.71924079\n",
      "Iteration 367, loss = 870.84420469\n",
      "Iteration 93, loss = 2041.67108680\n",
      "Iteration 371, loss = 867.52232113\n",
      "Iteration 72, loss = 2600.60688101\n",
      "Iteration 325, loss = 840.85179225\n",
      "Iteration 292, loss = 948.07714916\n",
      "Iteration 350, loss = 820.28553777\n",
      "Iteration 341, loss = 886.79006543\n",
      "Iteration 368, loss = 868.66115129\n",
      "Iteration 372, loss = 866.63245862\n",
      "Iteration 94, loss = 2022.63811101\n",
      "Iteration 293, loss = 949.88240393\n",
      "Iteration 73, loss = 2571.78342942\n",
      "Iteration 351, loss = 814.61238478\n",
      "Iteration 326, loss = 840.41403922\n",
      "Iteration 342, loss = 888.63849877\n",
      "Iteration 369, loss = 867.59382288\n",
      "Iteration 373, loss = 861.21068386\n",
      "Iteration 95, loss = 2004.00533038\n",
      "Iteration 294, loss = 943.86557503\n",
      "Iteration 74, loss = 2544.11038072\n",
      "Iteration 343, loss = 886.83001188\n",
      "Iteration 327, loss = 841.93864151\n",
      "Iteration 352, loss = 819.87300153\n",
      "Iteration 370, loss = 861.43322220\n",
      "Iteration 374, loss = 866.51154325\n",
      "Iteration 96, loss = 1986.49324867\n",
      "Iteration 75, loss = 2515.41107970\n",
      "Iteration 295, loss = 941.57107473\n",
      "Iteration 344, loss = 886.61340773\n",
      "Iteration 328, loss = 842.93890170\n",
      "Iteration 353, loss = 813.64687040\n",
      "Iteration 371, loss = 862.35890634\n",
      "Iteration 375, loss = 868.75066355\n",
      "Iteration 97, loss = 1969.09233468\n",
      "Iteration 76, loss = 2488.07404562\n",
      "Iteration 296, loss = 951.76199805\n",
      "Iteration 329, loss = 840.86860870\n",
      "Iteration 345, loss = 883.96995744\n",
      "Iteration 354, loss = 815.90239051\n",
      "Iteration 372, loss = 863.86203226\n",
      "Iteration 376, loss = 864.80399518\n",
      "Iteration 98, loss = 1952.56190872\n",
      "Iteration 77, loss = 2462.26925064\n",
      "Iteration 297, loss = 938.14052871\n",
      "Iteration 330, loss = 837.69177885\n",
      "Iteration 346, loss = 884.06395520\n",
      "Iteration 355, loss = 816.65238422\n",
      "Iteration 373, loss = 861.24040050\n",
      "Iteration 377, loss = 867.23305905\n",
      "Iteration 99, loss = 1934.67387361\n",
      "Iteration 78, loss = 2436.06943191\n",
      "Iteration 331, loss = 838.30230281\n",
      "Iteration 298, loss = 942.75698877\n",
      "Iteration 347, loss = 879.57821290\n",
      "Iteration 356, loss = 813.71405116\n",
      "Iteration 378, loss = 862.34920658\n",
      "Iteration 374, loss = 862.33128389\n",
      "Iteration 100, loss = 1918.90108428\n",
      "Iteration 79, loss = 2410.41092387\n",
      "Iteration 332, loss = 839.32856938\n",
      "Iteration 299, loss = 937.28475624\n",
      "Iteration 348, loss = 880.53137534\n",
      "Iteration 357, loss = 813.99987483\n",
      "Iteration 379, loss = 862.66713524\n",
      "Iteration 375, loss = 861.02953699\n",
      "Iteration 101, loss = 1902.46717500\n",
      "Iteration 80, loss = 2384.88582608\n",
      "Iteration 333, loss = 835.98936917\n",
      "Iteration 300, loss = 940.25099130\n",
      "Iteration 349, loss = 877.94200471\n",
      "Iteration 358, loss = 809.13534230\n",
      "Iteration 380, loss = 857.26932113\n",
      "Iteration 376, loss = 859.59469526\n",
      "Iteration 102, loss = 1884.07378510\n",
      "Iteration 81, loss = 2360.09293673\n",
      "Iteration 334, loss = 836.21964249\n",
      "Iteration 301, loss = 932.91179689\n",
      "Iteration 350, loss = 881.62693642\n",
      "Iteration 359, loss = 812.02635325\n",
      "Iteration 381, loss = 856.96518611\n",
      "Iteration 377, loss = 865.26290836\n",
      "Iteration 103, loss = 1870.33152592\n",
      "Iteration 82, loss = 2337.29781348\n",
      "Iteration 335, loss = 833.69204108\n",
      "Iteration 302, loss = 933.84948928\n",
      "Iteration 351, loss = 871.73439337\n",
      "Iteration 360, loss = 809.61340300\n",
      "Iteration 382, loss = 867.49866351\n",
      "Iteration 378, loss = 858.75146591\n",
      "Iteration 104, loss = 1852.01062367\n",
      "Iteration 336, loss = 839.42414673\n",
      "Iteration 83, loss = 2315.70669632\n",
      "Iteration 352, loss = 879.45675548\n",
      "Iteration 303, loss = 937.01780763\n",
      "Iteration 361, loss = 811.63909453\n",
      "Iteration 383, loss = 857.65198000\n",
      "Iteration 379, loss = 865.62123394\n",
      "Iteration 105, loss = 1837.75340565\n",
      "Iteration 337, loss = 828.37040525\n",
      "Iteration 353, loss = 873.04596357\n",
      "Iteration 84, loss = 2294.01852605\n",
      "Iteration 304, loss = 927.51040318\n",
      "Iteration 362, loss = 813.26116474\n",
      "Iteration 384, loss = 858.13681393\n",
      "Iteration 380, loss = 849.28684065\n",
      "Iteration 106, loss = 1822.62142514\n",
      "Iteration 354, loss = 876.26175328\n",
      "Iteration 338, loss = 832.23805484\n",
      "Iteration 85, loss = 2269.83912233\n",
      "Iteration 305, loss = 935.45130000\n",
      "Iteration 363, loss = 810.51955002\n",
      "Iteration 385, loss = 857.63703848\n",
      "Iteration 381, loss = 861.03158931\n",
      "Iteration 107, loss = 1810.48479781\n",
      "Iteration 339, loss = 830.20578287\n",
      "Iteration 355, loss = 874.63106974\n",
      "Iteration 86, loss = 2247.67334116\n",
      "Iteration 306, loss = 930.28141945\n",
      "Iteration 364, loss = 808.60716081\n",
      "Iteration 386, loss = 862.88892009\n",
      "Iteration 382, loss = 863.22550307\n",
      "Iteration 108, loss = 1793.50133996\n",
      "Iteration 356, loss = 870.87947892\n",
      "Iteration 340, loss = 828.31363470\n",
      "Iteration 87, loss = 2227.52677833\n",
      "Iteration 307, loss = 926.59839307\n",
      "Iteration 365, loss = 809.29996542\n",
      "Iteration 387, loss = 855.18763394\n",
      "Iteration 383, loss = 854.36267411\n",
      "Iteration 109, loss = 1779.34660789\n",
      "Iteration 357, loss = 870.37714467\n",
      "Iteration 88, loss = 2206.87830018\n",
      "Iteration 308, loss = 922.38421536\n",
      "Iteration 366, loss = 809.30471488\n",
      "Iteration 341, loss = 827.78213579\n",
      "Iteration 388, loss = 855.65823204\n",
      "Iteration 384, loss = 855.38396508\n",
      "Iteration 110, loss = 1765.37227759\n",
      "Iteration 358, loss = 870.74850538\n",
      "Iteration 309, loss = 925.03099634\n",
      "Iteration 367, loss = 806.18873780\n",
      "Iteration 89, loss = 2186.33838747\n",
      "Iteration 342, loss = 831.25870029\n",
      "Iteration 389, loss = 859.84019455\n",
      "Iteration 385, loss = 858.31566346\n",
      "Iteration 111, loss = 1750.04081067\n",
      "Iteration 359, loss = 868.30872851\n",
      "Iteration 368, loss = 805.39017217\n",
      "Iteration 343, loss = 828.81575008\n",
      "Iteration 310, loss = 926.18305545\n",
      "Iteration 90, loss = 2166.32001083\n",
      "Iteration 386, loss = 858.23176428\n",
      "Iteration 390, loss = 852.70412011\n",
      "Iteration 112, loss = 1736.48441163\n",
      "Iteration 360, loss = 869.88463528\n",
      "Iteration 369, loss = 804.91133262\n",
      "Iteration 311, loss = 921.46202570\n",
      "Iteration 344, loss = 827.07780043\n",
      "Iteration 91, loss = 2143.88898937\n",
      "Iteration 387, loss = 853.23710992\n",
      "Iteration 391, loss = 855.74429922\n",
      "Iteration 113, loss = 1726.00015429\n",
      "Iteration 361, loss = 871.32238840\n",
      "Iteration 370, loss = 812.12943072\n",
      "Iteration 312, loss = 926.67880447\n",
      "Iteration 345, loss = 824.40980828\n",
      "Iteration 92, loss = 2128.80893027\n",
      "Iteration 392, loss = 851.70836464\n",
      "Iteration 388, loss = 854.05945637\n",
      "Iteration 114, loss = 1711.81024841\n",
      "Iteration 371, loss = 802.65175368\n",
      "Iteration 362, loss = 867.08045301\n",
      "Iteration 346, loss = 824.09947358\n",
      "Iteration 313, loss = 926.25351172\n",
      "Iteration 93, loss = 2107.34580886\n",
      "Iteration 389, loss = 857.37269425\n",
      "Iteration 393, loss = 849.50932477\n",
      "Iteration 115, loss = 1701.48938456\n",
      "Iteration 372, loss = 804.07472851\n",
      "Iteration 363, loss = 871.40246108\n",
      "Iteration 347, loss = 826.52358542\n",
      "Iteration 314, loss = 920.04611853\n",
      "Iteration 94, loss = 2088.47927330\n",
      "Iteration 390, loss = 848.25939902\n",
      "Iteration 394, loss = 852.88191105\n",
      "Iteration 116, loss = 1691.21781007\n",
      "Iteration 373, loss = 804.70072200\n",
      "Iteration 364, loss = 866.88655270\n",
      "Iteration 315, loss = 924.06160326\n",
      "Iteration 95, loss = 2069.44990938\n",
      "Iteration 348, loss = 825.33597240\n",
      "Iteration 395, loss = 849.44647415\n",
      "Iteration 391, loss = 851.71998222\n",
      "Iteration 117, loss = 1675.95600025\n",
      "Iteration 374, loss = 809.97186404\n",
      "Iteration 365, loss = 866.80791126\n",
      "Iteration 316, loss = 918.64768967\n",
      "Iteration 96, loss = 2050.63876999\n",
      "Iteration 349, loss = 824.77391655\n",
      "Iteration 392, loss = 849.33037645\n",
      "Iteration 396, loss = 854.37244028\n",
      "Iteration 118, loss = 1664.80202929\n",
      "Iteration 375, loss = 802.87591025\n",
      "Iteration 366, loss = 869.34970273\n",
      "Iteration 317, loss = 914.94751831\n",
      "Iteration 97, loss = 2033.27222935\n",
      "Iteration 350, loss = 825.49596590\n",
      "Iteration 393, loss = 846.39648217\n",
      "Iteration 397, loss = 852.58558258\n",
      "Iteration 119, loss = 1650.73938098\n",
      "Iteration 376, loss = 800.81937058\n",
      "Iteration 367, loss = 864.15162611\n",
      "Iteration 318, loss = 918.24310346\n",
      "Iteration 351, loss = 816.24069154\n",
      "Iteration 98, loss = 2016.13212671\n",
      "Iteration 394, loss = 847.72951158\n",
      "Iteration 398, loss = 848.21814129\n",
      "Iteration 120, loss = 1642.72907533\n",
      "Iteration 377, loss = 802.65438954\n",
      "Iteration 368, loss = 864.69945609\n",
      "Iteration 319, loss = 914.62305314\n",
      "Iteration 352, loss = 827.60732335\n",
      "Iteration 99, loss = 1999.78350674\n",
      "Iteration 399, loss = 850.03305368\n",
      "Iteration 395, loss = 847.67344584\n",
      "Iteration 378, loss = 801.19434977\n",
      "Iteration 121, loss = 1630.34549253\n",
      "Iteration 369, loss = 865.12954174\n",
      "Iteration 320, loss = 918.37562072\n",
      "Iteration 353, loss = 817.28426141\n",
      "Iteration 100, loss = 1985.03451496\n",
      "Iteration 400, loss = 845.05948580\n",
      "Iteration 396, loss = 850.67734094\n",
      "Iteration 379, loss = 801.65288719\n",
      "Iteration 122, loss = 1617.25291250\n",
      "Iteration 321, loss = 912.76587623\n",
      "Iteration 370, loss = 867.19330583\n",
      "Iteration 354, loss = 814.65560191\n",
      "Iteration 101, loss = 1967.64835235\n",
      "Iteration 401, loss = 851.52522677\n",
      "Iteration 380, loss = 802.66747578\n",
      "Iteration 397, loss = 845.98756931\n",
      "Iteration 123, loss = 1609.85309019\n",
      "Iteration 322, loss = 914.22565473\n",
      "Iteration 371, loss = 861.63433984\n",
      "Iteration 402, loss = 848.75477633\n",
      "Iteration 102, loss = 1949.07023449\n",
      "Iteration 355, loss = 816.29037470\n",
      "Iteration 398, loss = 844.49082727\n",
      "Iteration 381, loss = 800.70143880\n",
      "Iteration 124, loss = 1601.51760802\n",
      "Iteration 323, loss = 909.78557271\n",
      "Iteration 372, loss = 857.88688968\n",
      "Iteration 403, loss = 845.80813995\n",
      "Iteration 103, loss = 1936.05425025\n",
      "Iteration 356, loss = 819.69126856\n",
      "Iteration 382, loss = 801.13576014\n",
      "Iteration 399, loss = 850.26724441\n",
      "Iteration 125, loss = 1587.06909106\n",
      "Iteration 324, loss = 910.34745786\n",
      "Iteration 373, loss = 861.93848910\n",
      "Iteration 404, loss = 852.60352699\n",
      "Iteration 104, loss = 1918.69632059\n",
      "Iteration 357, loss = 816.01726122\n",
      "Iteration 383, loss = 800.66751542\n",
      "Iteration 400, loss = 838.54603079\n",
      "Iteration 126, loss = 1573.95583386\n",
      "Iteration 325, loss = 912.76688504\n",
      "Iteration 374, loss = 858.77423919\n",
      "Iteration 405, loss = 847.41431595\n",
      "Iteration 358, loss = 814.49047860\n",
      "Iteration 105, loss = 1903.91164220\n",
      "Iteration 384, loss = 797.74740881\n",
      "Iteration 401, loss = 842.99352229\n",
      "Iteration 127, loss = 1563.89605230\n",
      "Iteration 326, loss = 903.67112215\n",
      "Iteration 375, loss = 854.30153415\n",
      "Iteration 406, loss = 846.88200463\n",
      "Iteration 359, loss = 815.48799118\n",
      "Iteration 106, loss = 1888.29235172\n",
      "Iteration 385, loss = 798.57047465\n",
      "Iteration 402, loss = 844.11067629\n",
      "Iteration 128, loss = 1556.03999306\n",
      "Iteration 327, loss = 908.35814074\n",
      "Iteration 376, loss = 858.08373336\n",
      "Iteration 407, loss = 846.76014053\n",
      "Iteration 360, loss = 813.19882861\n",
      "Iteration 107, loss = 1876.78257102\n",
      "Iteration 386, loss = 795.40340385\n",
      "Iteration 403, loss = 842.38750066\n",
      "Iteration 129, loss = 1543.86046017\n",
      "Iteration 328, loss = 907.87754681\n",
      "Iteration 377, loss = 855.57869522\n",
      "Iteration 408, loss = 842.45739032\n",
      "Iteration 361, loss = 814.79436241\n",
      "Iteration 108, loss = 1861.15268861\n",
      "Iteration 387, loss = 797.62764195\n",
      "Iteration 130, loss = 1536.36651803\n",
      "Iteration 404, loss = 844.87735994\n",
      "Iteration 329, loss = 908.10836882\n",
      "Iteration 378, loss = 853.53885111\n",
      "Iteration 409, loss = 850.71457533\n",
      "Iteration 362, loss = 809.60632724\n",
      "Iteration 388, loss = 797.01619552\n",
      "Iteration 109, loss = 1846.25519836\n",
      "Iteration 131, loss = 1524.63880830\n",
      "Iteration 405, loss = 838.20287397\n",
      "Iteration 330, loss = 903.55664339\n",
      "Iteration 379, loss = 854.94588673\n",
      "Iteration 410, loss = 841.94974030\n",
      "Iteration 363, loss = 814.14090374\n",
      "Iteration 389, loss = 798.01496606\n",
      "Iteration 132, loss = 1514.85687536\n",
      "Iteration 110, loss = 1831.20988604\n",
      "Iteration 406, loss = 845.92305707\n",
      "Iteration 331, loss = 902.94038740\n",
      "Iteration 380, loss = 853.76340880\n",
      "Iteration 411, loss = 846.99297733\n",
      "Iteration 364, loss = 811.82222935\n",
      "Iteration 390, loss = 798.77584438\n",
      "Iteration 133, loss = 1506.20367853\n",
      "Iteration 111, loss = 1819.47309477\n",
      "Iteration 407, loss = 841.51704373\n",
      "Iteration 332, loss = 913.01877241\n",
      "Iteration 381, loss = 857.12346432\n",
      "Iteration 412, loss = 841.44136538\n",
      "Iteration 391, loss = 795.35296431\n",
      "Iteration 365, loss = 806.05196451\n",
      "Iteration 134, loss = 1498.03014826\n",
      "Iteration 112, loss = 1802.76898804\n",
      "Iteration 408, loss = 840.61683686\n",
      "Iteration 333, loss = 902.79676308\n",
      "Iteration 382, loss = 854.62054365\n",
      "Iteration 413, loss = 845.94380110\n",
      "Iteration 392, loss = 795.57888645\n",
      "Iteration 135, loss = 1484.69518306\n",
      "Iteration 366, loss = 809.49116833\n",
      "Iteration 113, loss = 1797.07303851\n",
      "Iteration 409, loss = 839.04783893\n",
      "Iteration 334, loss = 902.25105467\n",
      "Iteration 383, loss = 854.10749178\n",
      "Iteration 414, loss = 841.79196764\n",
      "Iteration 393, loss = 792.37008758\n",
      "Iteration 136, loss = 1480.15948814\n",
      "Iteration 367, loss = 807.77041094\n",
      "Iteration 410, loss = 838.45664125\n",
      "Iteration 114, loss = 1776.88224072\n",
      "Iteration 335, loss = 901.01776813Iteration 384, loss = 855.68573963\n",
      "\n",
      "Iteration 415, loss = 836.77392023\n",
      "Iteration 394, loss = 798.36573500\n",
      "Iteration 368, loss = 802.79275651\n",
      "Iteration 137, loss = 1471.88132834\n",
      "Iteration 411, loss = 841.44186771\n",
      "Iteration 115, loss = 1769.18959745\n",
      "Iteration 336, loss = 902.14599850\n",
      "Iteration 385, loss = 849.25890011\n",
      "Iteration 416, loss = 848.15148459\n",
      "Iteration 369, loss = 813.48818632Iteration 395, loss = 796.81460218\n",
      "\n",
      "Iteration 138, loss = 1461.26804983\n",
      "Iteration 412, loss = 835.09563944\n",
      "Iteration 116, loss = 1755.83064828\n",
      "Iteration 386, loss = 847.79207652\n",
      "Iteration 337, loss = 898.76067537\n",
      "Iteration 417, loss = 841.43369191\n",
      "Iteration 396, loss = 792.82117569\n",
      "Iteration 370, loss = 809.94810582\n",
      "Iteration 139, loss = 1454.83683645\n",
      "Iteration 413, loss = 839.42947654\n",
      "Iteration 117, loss = 1740.94770302\n",
      "Iteration 387, loss = 847.22360964\n",
      "Iteration 338, loss = 897.27145327\n",
      "Iteration 418, loss = 839.64506680\n",
      "Iteration 140, loss = 1446.82853784\n",
      "Iteration 371, loss = 804.52324952\n",
      "Iteration 397, loss = 792.93620059\n",
      "Iteration 414, loss = 834.86528084\n",
      "Iteration 118, loss = 1731.13767679\n",
      "Iteration 388, loss = 846.53596297\n",
      "Iteration 339, loss = 896.87365911\n",
      "Iteration 419, loss = 838.86550335\n",
      "Iteration 141, loss = 1436.28093074\n",
      "Iteration 372, loss = 807.04947797\n",
      "Iteration 398, loss = 795.95497642\n",
      "Iteration 415, loss = 832.95129913\n",
      "Iteration 119, loss = 1716.45888166\n",
      "Iteration 389, loss = 848.49145472\n",
      "Iteration 340, loss = 898.87251655\n",
      "Iteration 420, loss = 836.04942954\n",
      "Iteration 142, loss = 1428.74857118\n",
      "Iteration 373, loss = 806.73071486\n",
      "Iteration 399, loss = 792.92884377\n",
      "Iteration 416, loss = 847.19450183\n",
      "Iteration 120, loss = 1706.90167902\n",
      "Iteration 390, loss = 845.48717455\n",
      "Iteration 341, loss = 895.93841144\n",
      "Iteration 143, loss = 1419.92199792\n",
      "Iteration 421, loss = 838.50704009\n",
      "Iteration 374, loss = 798.87360139\n",
      "Iteration 400, loss = 796.01386438\n",
      "Iteration 417, loss = 830.69252089\n",
      "Iteration 121, loss = 1695.14402008\n",
      "Iteration 391, loss = 849.30673093\n",
      "Iteration 342, loss = 898.60741641\n",
      "Iteration 144, loss = 1410.80256300\n",
      "Iteration 375, loss = 799.57927617\n",
      "Iteration 422, loss = 837.92488550\n",
      "Iteration 401, loss = 793.87088284\n",
      "Iteration 418, loss = 825.37612677\n",
      "Iteration 392, loss = 849.31576207\n",
      "Iteration 122, loss = 1679.22699565\n",
      "Iteration 343, loss = 895.48432432\n",
      "Iteration 145, loss = 1406.33210761\n",
      "Iteration 423, loss = 838.26648409\n",
      "Iteration 402, loss = 792.22807693\n",
      "Iteration 376, loss = 804.90826147\n",
      "Iteration 419, loss = 832.91381803\n",
      "Iteration 123, loss = 1673.14863230\n",
      "Iteration 393, loss = 846.11650652\n",
      "Iteration 344, loss = 891.08494014\n",
      "Iteration 146, loss = 1396.15341055\n",
      "Iteration 424, loss = 835.87081375\n",
      "Iteration 403, loss = 789.90635417\n",
      "Iteration 377, loss = 802.50456020\n",
      "Iteration 420, loss = 832.26579544\n",
      "Iteration 394, loss = 848.48652003\n",
      "Iteration 124, loss = 1662.68106985\n",
      "Iteration 345, loss = 893.32594301\n",
      "Iteration 425, loss = 834.64602385\n",
      "Iteration 147, loss = 1387.44825258\n",
      "Iteration 404, loss = 789.11029003\n",
      "Iteration 378, loss = 798.11717221\n",
      "Iteration 421, loss = 833.92610682\n",
      "Iteration 125, loss = 1650.17885249\n",
      "Iteration 395, loss = 850.28230949\n",
      "Iteration 426, loss = 833.78422337\n",
      "Iteration 346, loss = 891.02332483\n",
      "Iteration 148, loss = 1380.82840807\n",
      "Iteration 405, loss = 792.34452772\n",
      "Iteration 379, loss = 799.05266498\n",
      "Iteration 422, loss = 832.19955789\n",
      "Iteration 396, loss = 840.45929480\n",
      "Iteration 126, loss = 1640.16434333\n",
      "Iteration 427, loss = 834.56020692\n",
      "Iteration 347, loss = 893.68164403\n",
      "Iteration 149, loss = 1372.65910484\n",
      "Iteration 380, loss = 799.63404719\n",
      "Iteration 406, loss = 790.17262254\n",
      "Iteration 423, loss = 831.89735273\n",
      "Iteration 127, loss = 1628.78712337\n",
      "Iteration 397, loss = 845.52229487\n",
      "Iteration 348, loss = 894.06296737\n",
      "Iteration 428, loss = 832.06923412\n",
      "Iteration 150, loss = 1366.81830059\n",
      "Iteration 381, loss = 802.26089546\n",
      "Iteration 407, loss = 786.65550899\n",
      "Iteration 424, loss = 829.42099042\n",
      "Iteration 398, loss = 836.92917652\n",
      "Iteration 128, loss = 1618.62098832\n",
      "Iteration 429, loss = 836.52076373\n",
      "Iteration 349, loss = 890.36038992\n",
      "Iteration 382, loss = 794.33543986\n",
      "Iteration 151, loss = 1355.92906718\n",
      "Iteration 408, loss = 790.70561319\n",
      "Iteration 425, loss = 826.17946041\n",
      "Iteration 399, loss = 844.14112443\n",
      "Iteration 129, loss = 1607.24497773\n",
      "Iteration 383, loss = 799.06979059\n",
      "Iteration 430, loss = 833.96150266\n",
      "Iteration 350, loss = 890.84757422\n",
      "Iteration 152, loss = 1349.83602807\n",
      "Iteration 409, loss = 788.99893107\n",
      "Iteration 426, loss = 825.25924483\n",
      "Iteration 400, loss = 843.80170115\n",
      "Iteration 130, loss = 1599.62041421\n",
      "Iteration 384, loss = 796.59406009\n",
      "Iteration 351, loss = 880.72530131\n",
      "Iteration 431, loss = 829.80246565\n",
      "Iteration 410, loss = 789.02992935\n",
      "Iteration 153, loss = 1345.61402048\n",
      "Iteration 427, loss = 820.06057652\n",
      "Iteration 401, loss = 838.49624611\n",
      "Iteration 131, loss = 1588.59120310\n",
      "Iteration 385, loss = 787.09622030\n",
      "Iteration 352, loss = 895.35429987\n",
      "Iteration 432, loss = 836.52869025\n",
      "Iteration 154, loss = 1336.52224529\n",
      "Iteration 411, loss = 788.96475174\n",
      "Iteration 428, loss = 826.12334428\n",
      "Iteration 402, loss = 845.11353067\n",
      "Iteration 132, loss = 1580.92983947\n",
      "Iteration 386, loss = 792.92134269\n",
      "Iteration 353, loss = 887.27418900\n",
      "Iteration 433, loss = 835.34721999\n",
      "Iteration 155, loss = 1331.86800746\n",
      "Iteration 412, loss = 786.78918019\n",
      "Iteration 429, loss = 828.33316146\n",
      "Iteration 403, loss = 841.70467995\n",
      "Iteration 387, loss = 792.03275369\n",
      "Iteration 133, loss = 1569.81333740\n",
      "Iteration 434, loss = 827.14348230\n",
      "Iteration 354, loss = 884.16908034\n",
      "Iteration 156, loss = 1323.07500297\n",
      "Iteration 413, loss = 786.16325078\n",
      "Iteration 430, loss = 827.95468624\n",
      "Iteration 388, loss = 794.99433156\n",
      "Iteration 404, loss = 836.90960618\n",
      "Iteration 134, loss = 1560.94627699\n",
      "Iteration 355, loss = 887.42218775\n",
      "Iteration 435, loss = 835.63816786\n",
      "Iteration 157, loss = 1319.22292842\n",
      "Iteration 414, loss = 793.33497598\n",
      "Iteration 431, loss = 827.87247451\n",
      "Iteration 389, loss = 792.48908475\n",
      "Iteration 405, loss = 837.01929324\n",
      "Iteration 135, loss = 1551.38356372\n",
      "Iteration 436, loss = 829.74645175\n",
      "Iteration 356, loss = 885.80905543\n",
      "Iteration 158, loss = 1310.74907771\n",
      "Iteration 415, loss = 792.24515721\n",
      "Iteration 432, loss = 826.71531186\n",
      "Iteration 390, loss = 794.55219818\n",
      "Iteration 406, loss = 838.97276691\n",
      "Iteration 136, loss = 1542.22988071\n",
      "Iteration 437, loss = 834.06547330\n",
      "Iteration 159, loss = 1306.57753318\n",
      "Iteration 357, loss = 885.87086836\n",
      "Iteration 416, loss = 786.43757136\n",
      "Iteration 433, loss = 825.75210619\n",
      "Iteration 391, loss = 792.51416649\n",
      "Iteration 407, loss = 834.54107724\n",
      "Iteration 137, loss = 1531.08102573\n",
      "Iteration 160, loss = 1297.93720629\n",
      "Iteration 438, loss = 826.54165073\n",
      "Iteration 417, loss = 785.09965887\n",
      "Iteration 358, loss = 883.37715982\n",
      "Iteration 434, loss = 822.77431696\n",
      "Iteration 392, loss = 797.54196839\n",
      "Iteration 408, loss = 841.02480353\n",
      "Iteration 138, loss = 1523.79627426\n",
      "Iteration 161, loss = 1288.42552263\n",
      "Iteration 439, loss = 830.06043166\n",
      "Iteration 418, loss = 788.84154829\n",
      "Iteration 359, loss = 883.08789707\n",
      "Iteration 435, loss = 820.60811710\n",
      "Iteration 409, loss = 830.23812866\n",
      "Iteration 393, loss = 791.82668484\n",
      "Iteration 139, loss = 1515.59642288\n",
      "Iteration 162, loss = 1284.03901924\n",
      "Iteration 440, loss = 828.11733686\n",
      "Iteration 419, loss = 785.78621457\n",
      "Iteration 360, loss = 885.36862390\n",
      "Iteration 436, loss = 824.47093437\n",
      "Iteration 410, loss = 834.27362449\n",
      "Iteration 394, loss = 793.05627767\n",
      "Iteration 140, loss = 1509.87764402\n",
      "Iteration 441, loss = 823.43891422\n",
      "Iteration 163, loss = 1285.08468752\n",
      "Iteration 420, loss = 781.61756230\n",
      "Iteration 361, loss = 879.10297311\n",
      "Iteration 437, loss = 823.29622477\n",
      "Iteration 411, loss = 835.30259356\n",
      "Iteration 395, loss = 789.06042075\n",
      "Iteration 442, loss = 829.04966784\n",
      "Iteration 164, loss = 1278.02068093\n",
      "Iteration 141, loss = 1496.44142215\n",
      "Iteration 421, loss = 785.89442930\n",
      "Iteration 362, loss = 881.10934192\n",
      "Iteration 438, loss = 822.32560734\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 396, loss = 789.99881454\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 412, loss = 832.21146918\n",
      "Iteration 443, loss = 829.51048696\n",
      "Iteration 142, loss = 1488.98945798\n",
      "Iteration 165, loss = 1272.90933533\n",
      "Iteration 363, loss = 879.57792325\n",
      "Iteration 422, loss = 785.98969885\n",
      "Iteration 1, loss = 11656.06740026\n",
      "Iteration 444, loss = 827.06936731\n",
      "Iteration 1, loss = 11570.04383887\n",
      "Iteration 143, loss = 1481.94627543\n",
      "Iteration 413, loss = 820.52147115\n",
      "Iteration 166, loss = 1266.86213265\n",
      "Iteration 364, loss = 882.59630641\n",
      "Iteration 423, loss = 785.49130048\n",
      "Iteration 2, loss = 10963.17863920\n",
      "Iteration 445, loss = 825.71100708\n",
      "Iteration 2, loss = 10878.44223973\n",
      "Iteration 144, loss = 1472.08251675\n",
      "Iteration 414, loss = 838.47484437\n",
      "Iteration 167, loss = 1262.26353477\n",
      "Iteration 365, loss = 877.29429677\n",
      "Iteration 424, loss = 784.65909032\n",
      "Iteration 3, loss = 10450.98954474\n",
      "Iteration 446, loss = 825.17696564\n",
      "Iteration 3, loss = 10363.51702936\n",
      "Iteration 145, loss = 1465.45692603\n",
      "Iteration 168, loss = 1257.72533252\n",
      "Iteration 415, loss = 826.79717867\n",
      "Iteration 366, loss = 882.41618168\n",
      "Iteration 425, loss = 781.53928275\n",
      "Iteration 4, loss = 9974.36735122\n",
      "Iteration 447, loss = 827.64281890\n",
      "Iteration 4, loss = 9886.85256383\n",
      "Iteration 146, loss = 1457.74884414\n",
      "Iteration 416, loss = 832.34960521\n",
      "Iteration 169, loss = 1249.71281014\n",
      "Iteration 367, loss = 875.67892459\n",
      "Iteration 426, loss = 784.87025003\n",
      "Iteration 5, loss = 9557.64009816\n",
      "Iteration 5, loss = 9470.27967580\n",
      "Iteration 448, loss = 825.46764198\n",
      "Iteration 170, loss = 1245.13020291\n",
      "Iteration 417, loss = 825.13599940\n",
      "Iteration 147, loss = 1446.53488377\n",
      "Iteration 368, loss = 875.26209228\n",
      "Iteration 427, loss = 784.39596644\n",
      "Iteration 6, loss = 9173.78750099\n",
      "Iteration 6, loss = 9087.77301647\n",
      "Iteration 449, loss = 825.36529379\n",
      "Iteration 418, loss = 839.88688699\n",
      "Iteration 171, loss = 1244.12980282\n",
      "Iteration 148, loss = 1445.32230642\n",
      "Iteration 428, loss = 787.34129414\n",
      "Iteration 369, loss = 883.50564845\n",
      "Iteration 7, loss = 8836.99071063\n",
      "Iteration 7, loss = 8753.42780071\n",
      "Iteration 419, loss = 829.30577832\n",
      "Iteration 450, loss = 825.71073558\n",
      "Iteration 172, loss = 1238.23035744\n",
      "Iteration 149, loss = 1433.20233242\n",
      "Iteration 429, loss = 784.75369750\n",
      "Iteration 370, loss = 882.80729340\n",
      "Iteration 8, loss = 8536.08987325\n",
      "Iteration 8, loss = 8453.62929507\n",
      "Iteration 173, loss = 1232.21114755\n",
      "Iteration 420, loss = 826.56802130\n",
      "Iteration 451, loss = 821.24961950\n",
      "Iteration 150, loss = 1428.99585573\n",
      "Iteration 430, loss = 781.56012189\n",
      "Iteration 371, loss = 878.27562072\n",
      "Iteration 9, loss = 8258.95999768\n",
      "Iteration 174, loss = 1226.49146489\n",
      "Iteration 421, loss = 820.88342011\n",
      "Iteration 452, loss = 824.73330478\n",
      "Iteration 9, loss = 8178.07118523\n",
      "Iteration 151, loss = 1418.05062124\n",
      "Iteration 431, loss = 781.35380983\n",
      "Iteration 372, loss = 874.40325425\n",
      "Iteration 10, loss = 8000.69555087\n",
      "Iteration 422, loss = 833.72513524\n",
      "Iteration 175, loss = 1221.88573276\n",
      "Iteration 453, loss = 823.89577858\n",
      "Iteration 432, loss = 780.32009528\n",
      "Iteration 10, loss = 7921.16399863\n",
      "Iteration 152, loss = 1410.38780111\n",
      "Iteration 373, loss = 876.56935180\n",
      "Iteration 11, loss = 7757.82016072\n",
      "Iteration 423, loss = 828.60704768\n",
      "Iteration 176, loss = 1217.50905867\n",
      "Iteration 454, loss = 819.99028381\n",
      "Iteration 433, loss = 779.57323985\n",
      "Iteration 11, loss = 7679.59431735\n",
      "Iteration 153, loss = 1406.04211901\n",
      "Iteration 374, loss = 874.48428640\n",
      "Iteration 12, loss = 7530.09319704\n",
      "Iteration 424, loss = 823.33158894\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 177, loss = 1217.25938947\n",
      "Iteration 455, loss = 822.50680324\n",
      "Iteration 434, loss = 781.07988679\n",
      "Iteration 12, loss = 7452.94314341\n",
      "Iteration 154, loss = 1397.19897417\n",
      "Iteration 375, loss = 867.32721133\n",
      "Iteration 13, loss = 7315.50729572\n",
      "Iteration 456, loss = 822.30396257\n",
      "Iteration 178, loss = 1212.30124252\n",
      "Iteration 435, loss = 778.98795787\n",
      "Iteration 13, loss = 7239.41951568\n",
      "Iteration 155, loss = 1390.76650010\n",
      "Iteration 376, loss = 873.02468764\n",
      "Iteration 14, loss = 7112.62645158\n",
      "Iteration 457, loss = 822.46165467\n",
      "Iteration 1, loss = 10349.65676360\n",
      "Iteration 179, loss = 1207.36969026\n",
      "Iteration 436, loss = 781.83084804\n",
      "Iteration 14, loss = 7038.06778232\n",
      "Iteration 156, loss = 1384.49060949\n",
      "Iteration 377, loss = 867.22790066\n",
      "Iteration 15, loss = 6920.90900461\n",
      "Iteration 458, loss = 813.41597268\n",
      "Iteration 180, loss = 1199.93645356\n",
      "Iteration 437, loss = 781.00014919\n",
      "Iteration 15, loss = 6848.00625860\n",
      "Iteration 157, loss = 1377.06168563\n",
      "Iteration 378, loss = 868.54462761\n",
      "Iteration 16, loss = 6737.33007159\n",
      "Iteration 2, loss = 8476.51697416\n",
      "Iteration 181, loss = 1195.08011980\n",
      "Iteration 438, loss = 777.26166950\n",
      "Iteration 459, loss = 819.30997904\n",
      "Iteration 16, loss = 6666.22716527\n",
      "Iteration 379, loss = 868.63906606\n",
      "Iteration 158, loss = 1369.41188835\n",
      "Iteration 17, loss = 6562.79398379\n",
      "Iteration 182, loss = 1199.29105119\n",
      "Iteration 439, loss = 777.13270478\n",
      "Iteration 460, loss = 819.42909229\n",
      "Iteration 17, loss = 6493.27642727\n",
      "Iteration 380, loss = 869.30316086\n",
      "Iteration 159, loss = 1361.26418312\n",
      "Iteration 3, loss = 7383.31577194\n",
      "Iteration 18, loss = 6397.05232435\n",
      "Iteration 183, loss = 1184.99376967\n",
      "Iteration 440, loss = 777.94696295\n",
      "Iteration 461, loss = 819.84501657\n",
      "Iteration 18, loss = 6329.23777343\n",
      "Iteration 381, loss = 871.13463705\n",
      "Iteration 160, loss = 1357.20949190\n",
      "Iteration 19, loss = 6238.54501887\n",
      "Iteration 184, loss = 1185.46811533\n",
      "Iteration 441, loss = 773.77536052\n",
      "Iteration 462, loss = 818.82078364\n",
      "Iteration 19, loss = 6172.07747688\n",
      "Iteration 4, loss = 6597.95438544\n",
      "Iteration 382, loss = 863.97538167\n",
      "Iteration 161, loss = 1343.29820827\n",
      "Iteration 185, loss = 1179.30965077\n",
      "Iteration 20, loss = 6087.56179381\n",
      "Iteration 442, loss = 781.54761845\n",
      "Iteration 463, loss = 822.36599220\n",
      "Iteration 20, loss = 6022.93862078\n",
      "Iteration 383, loss = 864.69133619\n",
      "Iteration 162, loss = 1341.41513336\n",
      "Iteration 186, loss = 1173.00803413\n",
      "Iteration 21, loss = 5943.24669791\n",
      "Iteration 443, loss = 779.80827880\n",
      "Iteration 464, loss = 819.31631569\n",
      "Iteration 5, loss = 5971.55007821\n",
      "Iteration 21, loss = 5880.37308920\n",
      "Iteration 384, loss = 860.06373401\n",
      "Iteration 163, loss = 1340.45687163\n",
      "Iteration 187, loss = 1163.39483205\n",
      "Iteration 22, loss = 5803.59218761\n",
      "Iteration 444, loss = 776.47265604\n",
      "Iteration 465, loss = 821.00717843\n",
      "Iteration 22, loss = 5742.55793139\n",
      "Iteration 385, loss = 855.15738264\n",
      "Iteration 188, loss = 1158.26222004\n",
      "Iteration 164, loss = 1331.97007166\n",
      "Iteration 23, loss = 5671.86197715\n",
      "Iteration 445, loss = 773.92760354\n",
      "Iteration 6, loss = 5466.52492274\n",
      "Iteration 466, loss = 818.11335465\n",
      "Iteration 23, loss = 5612.92369116\n",
      "Iteration 386, loss = 857.27406158\n",
      "Iteration 189, loss = 1159.61892293\n",
      "Iteration 24, loss = 5545.52980907\n",
      "Iteration 446, loss = 780.79732216\n",
      "Iteration 165, loss = 1323.12525707\n",
      "Iteration 467, loss = 813.55824204\n",
      "Iteration 24, loss = 5489.06607239\n",
      "Iteration 387, loss = 861.09111049\n",
      "Iteration 190, loss = 1156.12801001\n",
      "Iteration 7, loss = 5025.59284405\n",
      "Iteration 25, loss = 5423.21104085\n",
      "Iteration 166, loss = 1326.33589238\n",
      "Iteration 447, loss = 775.05646807\n",
      "Iteration 468, loss = 819.52194166\n",
      "Iteration 25, loss = 5368.70223362\n",
      "Iteration 388, loss = 854.50758294\n",
      "Iteration 191, loss = 1159.51950805\n",
      "Iteration 26, loss = 5307.22533531\n",
      "Iteration 167, loss = 1318.06554745\n",
      "Iteration 469, loss = 816.04359175\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 448, loss = 771.83996151\n",
      "Iteration 26, loss = 5254.42356062\n",
      "Iteration 389, loss = 857.82758445\n",
      "Iteration 192, loss = 1147.80701666\n",
      "Iteration 8, loss = 4653.54066975\n",
      "Iteration 27, loss = 5196.56956892\n",
      "Iteration 168, loss = 1310.00101850\n",
      "Iteration 449, loss = 777.78501529\n",
      "Iteration 27, loss = 5145.18999249\n",
      "Iteration 390, loss = 857.79855390\n",
      "Iteration 193, loss = 1142.90262533\n",
      "Iteration 28, loss = 5089.71235607\n",
      "Iteration 450, loss = 770.12269001\n",
      "Iteration 1, loss = 10742.65970978\n",
      "Iteration 169, loss = 1302.15651167\n",
      "Iteration 28, loss = 5039.94850336\n",
      "Iteration 9, loss = 4325.16647316\n",
      "Iteration 391, loss = 861.93161162\n",
      "Iteration 194, loss = 1139.72304873\n",
      "Iteration 29, loss = 4987.13322626\n",
      "Iteration 451, loss = 775.92400216\n",
      "Iteration 170, loss = 1298.08642706\n",
      "Iteration 29, loss = 4938.66184769\n",
      "Iteration 392, loss = 861.75400121\n",
      "Iteration 195, loss = 1138.01482456\n",
      "Iteration 2, loss = 8840.20303579\n",
      "Iteration 30, loss = 4887.45502124\n",
      "Iteration 452, loss = 774.04452537\n",
      "Iteration 171, loss = 1294.82647607\n",
      "Iteration 10, loss = 4067.11102249\n",
      "Iteration 30, loss = 4840.82085555\n",
      "Iteration 393, loss = 853.80188649\n",
      "Iteration 196, loss = 1133.58089845\n",
      "Iteration 31, loss = 4791.56747996\n",
      "Iteration 172, loss = 1287.32109719\n",
      "Iteration 453, loss = 773.17658841\n",
      "Iteration 3, loss = 7722.08125134\n",
      "Iteration 394, loss = 858.61504613\n",
      "Iteration 31, loss = 4746.97365610\n",
      "Iteration 197, loss = 1126.52609073\n",
      "Iteration 32, loss = 4699.54231426\n",
      "Iteration 173, loss = 1283.40454496\n",
      "Iteration 454, loss = 774.57872965\n",
      "Iteration 11, loss = 3802.90426986\n",
      "Iteration 395, loss = 861.26784981\n",
      "Iteration 33, loss = 4610.98364186\n",
      "Iteration 198, loss = 1124.10490423\n",
      "Iteration 32, loss = 4655.75380429\n",
      "Iteration 174, loss = 1277.80891435\n",
      "Iteration 455, loss = 767.65838493\n",
      "Iteration 4, loss = 6900.85967850\n",
      "Iteration 396, loss = 847.90026554\n",
      "Iteration 34, loss = 4526.09675437\n",
      "Iteration 199, loss = 1121.06086587\n",
      "Iteration 33, loss = 4568.71362591\n",
      "Iteration 12, loss = 3557.83594135\n",
      "Iteration 175, loss = 1272.89218818\n",
      "Iteration 456, loss = 772.73308090\n",
      "Iteration 397, loss = 854.30121638\n",
      "Iteration 35, loss = 4442.97369112\n",
      "Iteration 200, loss = 1116.61901816\n",
      "Iteration 34, loss = 4484.90678474\n",
      "Iteration 5, loss = 6263.28030910\n",
      "Iteration 176, loss = 1268.72543476\n",
      "Iteration 457, loss = 770.64274087\n",
      "Iteration 398, loss = 855.49733348\n",
      "Iteration 201, loss = 1115.59823335\n",
      "Iteration 36, loss = 4363.68539834\n",
      "Iteration 13, loss = 3356.13922900\n",
      "Iteration 35, loss = 4402.86328140\n",
      "Iteration 177, loss = 1259.34997365\n",
      "Iteration 399, loss = 854.23735614\n",
      "Iteration 458, loss = 773.24244888\n",
      "Iteration 37, loss = 4284.64542717\n",
      "Iteration 202, loss = 1114.60013082\n",
      "Iteration 36, loss = 4323.98043541\n",
      "Iteration 6, loss = 5716.68725881\n",
      "Iteration 178, loss = 1257.37319407\n",
      "Iteration 14, loss = 3161.59983767\n",
      "Iteration 400, loss = 852.39170153\n",
      "Iteration 459, loss = 775.01652712\n",
      "Iteration 37, loss = 4245.48409871\n",
      "Iteration 38, loss = 4208.15868860\n",
      "Iteration 203, loss = 1105.62382613\n",
      "Iteration 179, loss = 1247.81643294\n",
      "Iteration 401, loss = 851.27923772\n",
      "Iteration 460, loss = 774.33925677\n",
      "Iteration 7, loss = 5276.14776488\n",
      "Iteration 38, loss = 4170.69387712\n",
      "Iteration 204, loss = 1102.54713104\n",
      "Iteration 39, loss = 4135.37376870\n",
      "Iteration 15, loss = 2998.94588913\n",
      "Iteration 180, loss = 1248.25666049\n",
      "Iteration 402, loss = 853.48172065\n",
      "Iteration 461, loss = 768.98244657\n",
      "Iteration 205, loss = 1103.24937157\n",
      "Iteration 40, loss = 4064.81294458\n",
      "Iteration 39, loss = 4098.16838669\n",
      "Iteration 181, loss = 1238.26421160\n",
      "Iteration 8, loss = 4889.32637048\n",
      "Iteration 403, loss = 851.25397080\n",
      "Iteration 462, loss = 774.36180797\n",
      "Iteration 41, loss = 3996.72964601\n",
      "Iteration 40, loss = 4028.13139072\n",
      "Iteration 206, loss = 1095.46706241\n",
      "Iteration 16, loss = 2880.55537299\n",
      "Iteration 182, loss = 1245.45118759\n",
      "Iteration 404, loss = 849.36954496\n",
      "Iteration 463, loss = 771.85511426\n",
      "Iteration 207, loss = 1094.20259952\n",
      "Iteration 41, loss = 3961.37740394\n",
      "Iteration 42, loss = 3929.74934819\n",
      "Iteration 9, loss = 4583.60464136\n",
      "Iteration 405, loss = 851.90235480\n",
      "Iteration 183, loss = 1227.19122620\n",
      "Iteration 464, loss = 769.94460084\n",
      "Iteration 17, loss = 2736.91577163\n",
      "Iteration 208, loss = 1086.91451018\n",
      "Iteration 42, loss = 3896.74985593\n",
      "Iteration 43, loss = 3864.91528423\n",
      "Iteration 406, loss = 854.64162960\n",
      "Iteration 184, loss = 1223.78681288\n",
      "Iteration 465, loss = 768.51918276\n",
      "Iteration 209, loss = 1087.27695189\n",
      "Iteration 43, loss = 3833.12451962\n",
      "Iteration 44, loss = 3802.43916989\n",
      "Iteration 10, loss = 4231.80961476\n",
      "Iteration 18, loss = 2601.71090878\n",
      "Iteration 407, loss = 848.20203051\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 185, loss = 1220.76461327\n",
      "Iteration 466, loss = 768.13604554\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 44, loss = 3773.28543276\n",
      "Iteration 210, loss = 1077.59779508\n",
      "Iteration 45, loss = 3741.78979547\n",
      "Iteration 186, loss = 1217.87594374\n",
      "Iteration 45, loss = 3713.23396880\n",
      "Iteration 211, loss = 1079.32060758\n",
      "Iteration 11, loss = 3969.84371642\n",
      "Iteration 46, loss = 3683.23482928\n",
      "Iteration 19, loss = 2493.64792652\n",
      "Iteration 1, loss = 10471.76084798\n",
      "Iteration 187, loss = 1209.05266961\n",
      "Iteration 1, loss = 10763.62058661\n",
      "Iteration 46, loss = 3655.20875492\n",
      "Iteration 212, loss = 1078.58591122\n",
      "Iteration 47, loss = 3626.18555281\n",
      "Iteration 12, loss = 3742.92914064\n",
      "Iteration 188, loss = 1203.36977401\n",
      "Iteration 47, loss = 3599.99422250\n",
      "Iteration 20, loss = 2419.70818192\n",
      "Iteration 48, loss = 3572.25607736\n",
      "Iteration 213, loss = 1076.29764036\n",
      "Iteration 2, loss = 8562.18797051\n",
      "Iteration 2, loss = 8853.14311097\n",
      "Iteration 189, loss = 1201.88812517\n",
      "Iteration 49, loss = 3517.97042509\n",
      "Iteration 214, loss = 1068.33611020\n",
      "Iteration 48, loss = 3545.81744319\n",
      "Iteration 13, loss = 3516.32953299\n",
      "Iteration 21, loss = 2314.64382108\n",
      "Iteration 50, loss = 3465.91795692\n",
      "Iteration 190, loss = 1199.26244401\n",
      "Iteration 215, loss = 1070.37302269\n",
      "Iteration 3, loss = 7442.82150289\n",
      "Iteration 49, loss = 3493.00284070\n",
      "Iteration 3, loss = 7730.74605978\n",
      "Iteration 191, loss = 1200.60336192\n",
      "Iteration 51, loss = 3412.63170665\n",
      "Iteration 216, loss = 1068.69570044\n",
      "Iteration 14, loss = 3318.35101684\n",
      "Iteration 50, loss = 3441.89144305\n",
      "Iteration 22, loss = 2230.91709376\n",
      "Iteration 4, loss = 6621.46492098\n",
      "Iteration 217, loss = 1064.59143446Iteration 192, loss = 1188.77901526\n",
      "\n",
      "Iteration 52, loss = 3361.43830137\n",
      "Iteration 4, loss = 6909.04127895\n",
      "Iteration 51, loss = 3390.44300789\n",
      "Iteration 193, loss = 1185.27899785\n",
      "Iteration 218, loss = 1059.69147464\n",
      "Iteration 15, loss = 3152.39318260\n",
      "Iteration 53, loss = 3310.80604281\n",
      "Iteration 23, loss = 2158.75322763\n",
      "Iteration 52, loss = 3340.64381260\n",
      "Iteration 5, loss = 5974.16922805\n",
      "Iteration 194, loss = 1182.27948404\n",
      "Iteration 219, loss = 1056.99600171\n",
      "Iteration 5, loss = 6253.48260958\n",
      "Iteration 54, loss = 3263.74215870\n",
      "Iteration 53, loss = 3290.99959267\n",
      "Iteration 16, loss = 2984.17871766\n",
      "Iteration 195, loss = 1179.43742788\n",
      "Iteration 24, loss = 2080.36432946\n",
      "Iteration 220, loss = 1058.06787135\n",
      "Iteration 55, loss = 3218.28882773\n",
      "Iteration 6, loss = 5446.40369117\n",
      "Iteration 54, loss = 3245.31992091\n",
      "Iteration 6, loss = 5727.72240720\n",
      "Iteration 196, loss = 1175.79971168\n",
      "Iteration 221, loss = 1052.75043144\n",
      "Iteration 55, loss = 3200.44117838\n",
      "Iteration 56, loss = 3172.35370220\n",
      "Iteration 17, loss = 2829.95617912\n",
      "Iteration 25, loss = 2070.36278618\n",
      "Iteration 197, loss = 1172.54764078\n",
      "Iteration 222, loss = 1054.58569964\n",
      "Iteration 7, loss = 5005.61207196\n",
      "Iteration 56, loss = 3156.12437745\n",
      "Iteration 57, loss = 3127.88491102\n",
      "Iteration 7, loss = 5296.32204208\n",
      "Iteration 198, loss = 1163.36326046\n",
      "Iteration 57, loss = 3113.62696722\n",
      "Iteration 223, loss = 1047.88403512\n",
      "Iteration 18, loss = 2703.26579189\n",
      "Iteration 26, loss = 2025.00915653\n",
      "Iteration 58, loss = 3085.09930091\n",
      "Iteration 58, loss = 3071.30208948\n",
      "Iteration 8, loss = 4627.62711107\n",
      "Iteration 199, loss = 1162.14407589\n",
      "Iteration 224, loss = 1042.93617397\n",
      "Iteration 59, loss = 3043.02158108\n",
      "Iteration 8, loss = 4875.70450185\n",
      "Iteration 59, loss = 3030.53087945\n",
      "Iteration 19, loss = 2578.25753982\n",
      "Iteration 225, loss = 1040.50236661\n",
      "Iteration 27, loss = 1955.35206769\n",
      "Iteration 200, loss = 1156.57653350\n",
      "Iteration 60, loss = 3002.42462836\n",
      "Iteration 9, loss = 4311.23761649\n",
      "Iteration 60, loss = 2990.52126398\n",
      "Iteration 226, loss = 1040.17128989\n",
      "Iteration 9, loss = 4540.80463484\n",
      "Iteration 201, loss = 1157.09244234\n",
      "Iteration 61, loss = 2963.65220835\n",
      "Iteration 28, loss = 1908.83948968\n",
      "Iteration 20, loss = 2491.72659888\n",
      "Iteration 227, loss = 1038.07961722\n",
      "Iteration 61, loss = 2952.67809258\n",
      "Iteration 202, loss = 1156.12655043\n",
      "Iteration 10, loss = 4002.53795061\n",
      "Iteration 62, loss = 2924.18032048\n",
      "Iteration 228, loss = 1038.49896654\n",
      "Iteration 62, loss = 2913.62400149\n",
      "Iteration 10, loss = 4241.28671232\n",
      "Iteration 203, loss = 1145.22458171\n",
      "Iteration 63, loss = 2886.41129841\n",
      "Iteration 29, loss = 1869.15345649\n",
      "Iteration 21, loss = 2384.80830524\n",
      "Iteration 229, loss = 1035.37463450\n",
      "Iteration 63, loss = 2877.18894933\n",
      "Iteration 11, loss = 3729.76704651\n",
      "Iteration 204, loss = 1140.45410208\n",
      "Iteration 64, loss = 2850.51158279\n",
      "Iteration 230, loss = 1030.06101408\n",
      "Iteration 64, loss = 2841.48852975\n",
      "Iteration 11, loss = 3952.59260244\n",
      "Iteration 30, loss = 1843.57765534\n",
      "Iteration 205, loss = 1144.45030652\n",
      "Iteration 22, loss = 2309.36456226\n",
      "Iteration 65, loss = 2814.26972709\n",
      "Iteration 65, loss = 2806.28052612\n",
      "Iteration 231, loss = 1030.91355046\n",
      "Iteration 12, loss = 3483.15002525\n",
      "Iteration 206, loss = 1137.34246614\n",
      "Iteration 66, loss = 2781.22139874\n",
      "Iteration 12, loss = 3729.93843772\n",
      "Iteration 232, loss = 1027.14229605\n",
      "Iteration 66, loss = 2772.24337808\n",
      "Iteration 23, loss = 2288.53751738\n",
      "Iteration 31, loss = 1834.80351178\n",
      "Iteration 207, loss = 1136.45574735\n",
      "Iteration 67, loss = 2747.71478747\n",
      "Iteration 13, loss = 3275.91067678\n",
      "Iteration 233, loss = 1031.33222362\n",
      "Iteration 67, loss = 2740.47202434\n",
      "Iteration 208, loss = 1126.95678501\n",
      "Iteration 13, loss = 3511.04146208\n",
      "Iteration 68, loss = 2714.64804940\n",
      "Iteration 24, loss = 2216.55370427\n",
      "Iteration 234, loss = 1025.87408335\n",
      "Iteration 68, loss = 2707.98772239\n",
      "Iteration 32, loss = 1796.46543054\n",
      "Iteration 209, loss = 1130.19390519\n",
      "Iteration 69, loss = 2682.51911825\n",
      "Iteration 14, loss = 3081.59131009\n",
      "Iteration 235, loss = 1023.11761596\n",
      "Iteration 69, loss = 2675.59051916\n",
      "Iteration 14, loss = 3281.79846772\n",
      "Iteration 25, loss = 2118.54265870\n",
      "Iteration 70, loss = 2651.59614426\n",
      "Iteration 210, loss = 1115.29201896\n",
      "Iteration 33, loss = 1777.21535744\n",
      "Iteration 236, loss = 1018.17586225\n",
      "Iteration 70, loss = 2645.79641739\n",
      "Iteration 15, loss = 2889.70510311\n",
      "Iteration 71, loss = 2620.50294843\n",
      "Iteration 211, loss = 1119.58136973\n",
      "Iteration 71, loss = 2614.56267185\n",
      "Iteration 237, loss = 1017.68042747\n",
      "Iteration 15, loss = 3137.78361958\n",
      "Iteration 26, loss = 2091.98057050\n",
      "Iteration 72, loss = 2590.56987507\n",
      "Iteration 34, loss = 1759.41404007\n",
      "Iteration 212, loss = 1123.07558226\n",
      "Iteration 72, loss = 2585.55855376\n",
      "Iteration 16, loss = 2751.06702517\n",
      "Iteration 238, loss = 1019.76214620\n",
      "Iteration 73, loss = 2560.27354941\n",
      "Iteration 213, loss = 1112.97968055\n",
      "Iteration 73, loss = 2555.92340719\n",
      "Iteration 16, loss = 2949.84544479\n",
      "Iteration 239, loss = 1013.13466532\n",
      "Iteration 35, loss = 1730.78802847\n",
      "Iteration 74, loss = 2531.67908489\n",
      "Iteration 214, loss = 1105.54168053\n",
      "Iteration 27, loss = 2008.36508420\n",
      "Iteration 17, loss = 2612.51187234\n",
      "Iteration 74, loss = 2528.31528454\n",
      "Iteration 240, loss = 1011.77398165\n",
      "Iteration 75, loss = 2503.19837885\n",
      "Iteration 215, loss = 1105.75664958\n",
      "Iteration 17, loss = 2825.81320119\n",
      "Iteration 75, loss = 2500.33239995\n",
      "Iteration 241, loss = 1006.30338515\n",
      "Iteration 36, loss = 1749.14232073\n",
      "Iteration 28, loss = 2116.44434984\n",
      "Iteration 76, loss = 2475.27723929\n",
      "Iteration 18, loss = 2539.25590813\n",
      "Iteration 216, loss = 1110.21859539\n",
      "Iteration 76, loss = 2473.36373086\n",
      "Iteration 242, loss = 1010.11249762\n",
      "Iteration 77, loss = 2448.18340768\n",
      "Iteration 217, loss = 1105.54677714\n",
      "Iteration 18, loss = 2682.69588651\n",
      "Iteration 77, loss = 2446.98283205\n",
      "Iteration 37, loss = 1651.96919855\n",
      "Iteration 243, loss = 1007.97202883\n",
      "Iteration 29, loss = 1996.99762160\n",
      "Iteration 19, loss = 2391.92089961\n",
      "Iteration 218, loss = 1099.16203112\n",
      "Iteration 78, loss = 2421.87235965\n",
      "Iteration 78, loss = 2420.77793480\n",
      "Iteration 244, loss = 1005.25866055\n",
      "Iteration 19, loss = 2565.88734750\n",
      "Iteration 79, loss = 2396.19134504\n",
      "Iteration 219, loss = 1098.64900377\n",
      "Iteration 38, loss = 1644.14102608\n",
      "Iteration 79, loss = 2394.93243340\n",
      "Iteration 30, loss = 1862.01190605\n",
      "Iteration 245, loss = 1003.32395592\n",
      "Iteration 20, loss = 2280.62261716\n",
      "Iteration 80, loss = 2370.24031671\n",
      "Iteration 220, loss = 1095.51152546\n",
      "Iteration 80, loss = 2370.71694225\n",
      "Iteration 246, loss = 997.39760417\n",
      "Iteration 20, loss = 2485.26610639\n",
      "Iteration 39, loss = 1630.07103432\n",
      "Iteration 81, loss = 2345.80409186\n",
      "Iteration 221, loss = 1085.16218627\n",
      "Iteration 31, loss = 1837.56667862\n",
      "Iteration 81, loss = 2347.04796569\n",
      "Iteration 21, loss = 2219.83043136\n",
      "Iteration 247, loss = 1001.38520452\n",
      "Iteration 82, loss = 2321.82471285\n",
      "Iteration 222, loss = 1088.68476533\n",
      "Iteration 82, loss = 2322.72062176\n",
      "Iteration 21, loss = 2401.75513047\n",
      "Iteration 248, loss = 999.25477946\n",
      "Iteration 40, loss = 1648.60635623\n",
      "Iteration 32, loss = 1807.45696281\n",
      "Iteration 83, loss = 2299.45887805\n",
      "Iteration 22, loss = 2140.42904736\n",
      "Iteration 223, loss = 1084.80945488\n",
      "Iteration 83, loss = 2300.45643947\n",
      "Iteration 249, loss = 997.02264243\n",
      "Iteration 84, loss = 2277.12548679\n",
      "Iteration 22, loss = 2274.08440697\n",
      "Iteration 224, loss = 1081.94897246\n",
      "Iteration 84, loss = 2277.46107823\n",
      "Iteration 41, loss = 1671.49501918\n",
      "Iteration 250, loss = 989.94975184\n",
      "Iteration 33, loss = 1777.34451507\n",
      "Iteration 85, loss = 2254.86704116\n",
      "Iteration 23, loss = 2012.82988397\n",
      "Iteration 85, loss = 2256.47843584\n",
      "Iteration 225, loss = 1073.50232176\n",
      "Iteration 251, loss = 999.32475666\n",
      "Iteration 86, loss = 2232.45056090\n",
      "Iteration 23, loss = 2199.65967814\n",
      "Iteration 42, loss = 1575.19011438\n",
      "Iteration 86, loss = 2235.07158335\n",
      "Iteration 226, loss = 1078.65703650\n",
      "Iteration 34, loss = 1864.96328624\n",
      "Iteration 252, loss = 991.35886443\n",
      "Iteration 24, loss = 2025.99014264\n",
      "Iteration 87, loss = 2212.02449916\n",
      "Iteration 87, loss = 2213.39608207\n",
      "Iteration 227, loss = 1074.42932219\n",
      "Iteration 253, loss = 994.82617436\n",
      "Iteration 24, loss = 2186.67554416\n",
      "Iteration 88, loss = 2190.42605390\n",
      "Iteration 43, loss = 1588.20683119\n",
      "Iteration 35, loss = 1775.08000661\n",
      "Iteration 88, loss = 2192.98640606\n",
      "Iteration 228, loss = 1072.91961984\n",
      "Iteration 25, loss = 1943.69120992\n",
      "Iteration 254, loss = 984.25225178\n",
      "Iteration 89, loss = 2170.57043009\n",
      "Iteration 89, loss = 2173.48856179\n",
      "Iteration 25, loss = 2096.69983194\n",
      "Iteration 229, loss = 1070.96430498\n",
      "Iteration 255, loss = 990.62860129\n",
      "Iteration 44, loss = 1577.21184713\n",
      "Iteration 90, loss = 2150.02226181\n",
      "Iteration 36, loss = 1673.76100527\n",
      "Iteration 90, loss = 2153.10445120\n",
      "Iteration 26, loss = 1845.33744742\n",
      "Iteration 230, loss = 1060.72686322\n",
      "Iteration 256, loss = 982.91721536\n",
      "Iteration 91, loss = 2128.89241690\n",
      "Iteration 91, loss = 2134.83921778\n",
      "Iteration 26, loss = 1997.01240182\n",
      "Iteration 45, loss = 1586.18958766\n",
      "Iteration 231, loss = 1065.73046893\n",
      "Iteration 92, loss = 2109.77096140\n",
      "Iteration 257, loss = 984.69001000\n",
      "Iteration 37, loss = 1621.60515586\n",
      "Iteration 27, loss = 1807.59101703\n",
      "Iteration 92, loss = 2112.79099872\n",
      "Iteration 232, loss = 1056.22561987\n",
      "Iteration 258, loss = 981.37188413\n",
      "Iteration 93, loss = 2091.74089683\n",
      "Iteration 27, loss = 1965.23067060\n",
      "Iteration 46, loss = 1515.73339329\n",
      "Iteration 93, loss = 2095.41662966\n",
      "Iteration 38, loss = 1604.62568319\n",
      "Iteration 259, loss = 982.87504347\n",
      "Iteration 233, loss = 1066.18174392\n",
      "Iteration 28, loss = 1805.08250446\n",
      "Iteration 94, loss = 2072.41290875\n",
      "Iteration 94, loss = 2076.17405998\n",
      "Iteration 260, loss = 979.46051286\n",
      "Iteration 28, loss = 1919.13726891\n",
      "Iteration 234, loss = 1056.57288459\n",
      "Iteration 47, loss = 1507.97634716\n",
      "Iteration 95, loss = 2052.87547100\n",
      "Iteration 95, loss = 2058.79872948\n",
      "Iteration 39, loss = 1670.37734389\n",
      "Iteration 29, loss = 1736.68154109\n",
      "Iteration 261, loss = 977.18232602\n",
      "Iteration 235, loss = 1054.25060977\n",
      "Iteration 96, loss = 2033.85491529\n",
      "Iteration 96, loss = 2039.13266623\n",
      "Iteration 48, loss = 1537.79568841\n",
      "Iteration 29, loss = 1881.22128996\n",
      "Iteration 262, loss = 979.80556508\n",
      "Iteration 236, loss = 1046.63934088\n",
      "Iteration 97, loss = 2017.28124990\n",
      "Iteration 40, loss = 1804.37986008\n",
      "Iteration 30, loss = 1710.73344624\n",
      "Iteration 97, loss = 2023.23224279\n",
      "Iteration 263, loss = 975.86952108\n",
      "Iteration 98, loss = 1999.18088574\n",
      "Iteration 237, loss = 1050.58002516\n",
      "Iteration 49, loss = 1510.78009858\n",
      "Iteration 30, loss = 1897.68030571\n",
      "Iteration 98, loss = 2007.27604491\n",
      "Iteration 264, loss = 972.49556441\n",
      "Iteration 41, loss = 1790.22202907\n",
      "Iteration 99, loss = 1980.45068185\n",
      "Iteration 238, loss = 1050.02464052\n",
      "Iteration 31, loss = 1653.68332905\n",
      "Iteration 99, loss = 1987.64984401\n",
      "Iteration 265, loss = 973.90855515\n",
      "Iteration 100, loss = 1965.85167298\n",
      "Iteration 239, loss = 1043.00910782\n",
      "Iteration 31, loss = 1804.15509451\n",
      "Iteration 50, loss = 1518.42232591\n",
      "Iteration 100, loss = 1974.51435392\n",
      "Iteration 42, loss = 1637.13378720\n",
      "Iteration 32, loss = 1604.68311993\n",
      "Iteration 266, loss = 970.98174768\n",
      "Iteration 101, loss = 1949.41908494\n",
      "Iteration 240, loss = 1040.69105258\n",
      "Iteration 101, loss = 1958.42487056\n",
      "Iteration 102, loss = 1930.63267607\n",
      "Iteration 32, loss = 1749.10267908\n",
      "Iteration 267, loss = 968.92550515\n",
      "Iteration 51, loss = 1476.76353731\n",
      "Iteration 241, loss = 1037.50257797\n",
      "Iteration 43, loss = 1656.84553424\n",
      "Iteration 102, loss = 1940.73571503\n",
      "Iteration 33, loss = 1568.35222443\n",
      "Iteration 103, loss = 1917.03915360\n",
      "Iteration 268, loss = 970.71870152\n",
      "Iteration 242, loss = 1029.80608473\n",
      "Iteration 103, loss = 1925.80610215\n",
      "Iteration 52, loss = 1497.02774710\n",
      "Iteration 33, loss = 1761.39029264\n",
      "Iteration 44, loss = 1664.24737757\n",
      "Iteration 104, loss = 1900.27504514\n",
      "Iteration 269, loss = 961.43024356\n",
      "Iteration 243, loss = 1033.81531616\n",
      "Iteration 34, loss = 1543.54307132\n",
      "Iteration 104, loss = 1909.15787652\n",
      "Iteration 105, loss = 1883.87091803\n",
      "Iteration 270, loss = 963.15245673\n",
      "Iteration 244, loss = 1035.09517528\n",
      "Iteration 34, loss = 1726.92898410\n",
      "Iteration 105, loss = 1892.72202792\n",
      "Iteration 45, loss = 1646.31514933\n",
      "Iteration 53, loss = 1451.11471603\n",
      "Iteration 106, loss = 1869.20353326\n",
      "Iteration 271, loss = 960.24184113\n",
      "Iteration 245, loss = 1027.82449505\n",
      "Iteration 35, loss = 1498.29320608\n",
      "Iteration 106, loss = 1877.69949440\n",
      "Iteration 107, loss = 1856.35514979\n",
      "Iteration 272, loss = 956.25517875\n",
      "Iteration 246, loss = 1021.75225416\n",
      "Iteration 35, loss = 1738.04744328\n",
      "Iteration 54, loss = 1414.94544582\n",
      "Iteration 46, loss = 1646.24994160\n",
      "Iteration 107, loss = 1865.66171812\n",
      "Iteration 108, loss = 1839.33958164\n",
      "Iteration 273, loss = 957.90039195\n",
      "Iteration 247, loss = 1030.96878819\n",
      "Iteration 36, loss = 1524.84163198\n",
      "Iteration 108, loss = 1848.75725362\n",
      "Iteration 36, loss = 1635.95149823\n",
      "Iteration 109, loss = 1825.10002004\n",
      "Iteration 274, loss = 964.61220498\n",
      "Iteration 248, loss = 1023.86196031\n",
      "Iteration 47, loss = 1600.04393534\n",
      "Iteration 55, loss = 1501.15514228\n",
      "Iteration 109, loss = 1832.96168386\n",
      "Iteration 110, loss = 1809.95724158\n",
      "Iteration 37, loss = 1500.71335087\n",
      "Iteration 249, loss = 1016.21430124\n",
      "Iteration 275, loss = 954.29200744\n",
      "Iteration 37, loss = 1708.11912230\n",
      "Iteration 110, loss = 1818.98128030\n",
      "Iteration 48, loss = 1513.93316488\n",
      "Iteration 56, loss = 1433.41039851\n",
      "Iteration 111, loss = 1797.03532196\n",
      "Iteration 250, loss = 1015.43976378\n",
      "Iteration 276, loss = 952.47779904\n",
      "Iteration 111, loss = 1805.69104315\n",
      "Iteration 38, loss = 1457.27180281\n",
      "Iteration 112, loss = 1781.18341758\n",
      "Iteration 277, loss = 959.04896213\n",
      "Iteration 251, loss = 1011.17535841\n",
      "Iteration 38, loss = 1700.38314644\n",
      "Iteration 49, loss = 1561.90336625\n",
      "Iteration 57, loss = 1320.02138502\n",
      "Iteration 112, loss = 1792.25298852\n",
      "Iteration 113, loss = 1770.82670431\n",
      "Iteration 278, loss = 951.46539906\n",
      "Iteration 252, loss = 1017.18474225\n",
      "Iteration 39, loss = 1438.17289608\n",
      "Iteration 113, loss = 1781.16190853\n",
      "Iteration 114, loss = 1753.74006420\n",
      "Iteration 39, loss = 1607.23263712\n",
      "Iteration 279, loss = 955.24543792\n",
      "Iteration 253, loss = 1018.24398755\n",
      "Iteration 50, loss = 1522.83101972\n",
      "Iteration 58, loss = 1323.27910801\n",
      "Iteration 114, loss = 1764.22106854\n",
      "Iteration 115, loss = 1742.30090158\n",
      "Iteration 40, loss = 1435.85716672\n",
      "Iteration 254, loss = 1003.62193370\n",
      "Iteration 280, loss = 952.52772005\n",
      "Iteration 115, loss = 1754.37277413\n",
      "Iteration 40, loss = 1660.41408179\n",
      "Iteration 116, loss = 1728.92293015\n",
      "Iteration 59, loss = 1429.05699215\n",
      "Iteration 51, loss = 1455.84349284\n",
      "Iteration 281, loss = 949.97758612\n",
      "Iteration 255, loss = 1008.78270208\n",
      "Iteration 116, loss = 1741.89957420\n",
      "Iteration 41, loss = 1401.72859563\n",
      "Iteration 117, loss = 1714.71251160\n",
      "Iteration 282, loss = 945.11221843\n",
      "Iteration 256, loss = 1005.53887042\n",
      "Iteration 117, loss = 1727.01963386\n",
      "Iteration 41, loss = 1617.72810916\n",
      "Iteration 52, loss = 1503.07960285\n",
      "Iteration 118, loss = 1703.14815064\n",
      "Iteration 60, loss = 1336.48091713\n",
      "Iteration 283, loss = 945.06164374\n",
      "Iteration 257, loss = 1008.05717936\n",
      "Iteration 42, loss = 1512.75819932\n",
      "Iteration 118, loss = 1712.92207555\n",
      "Iteration 119, loss = 1688.83734875\n",
      "Iteration 284, loss = 945.15793804\n",
      "Iteration 258, loss = 1001.63113232\n",
      "Iteration 42, loss = 1585.95086561\n",
      "Iteration 53, loss = 1703.50137363\n",
      "Iteration 119, loss = 1702.17231060\n",
      "Iteration 61, loss = 1489.53030762\n",
      "Iteration 120, loss = 1678.22164817\n",
      "Iteration 285, loss = 942.50804195\n",
      "Iteration 43, loss = 1389.95454845\n",
      "Iteration 259, loss = 1003.43505569\n",
      "Iteration 120, loss = 1690.06314022\n",
      "Iteration 121, loss = 1666.95101160\n",
      "Iteration 286, loss = 941.47608149\n",
      "Iteration 43, loss = 1526.67107884\n",
      "Iteration 54, loss = 1705.51854683\n",
      "Iteration 62, loss = 1316.09817113\n",
      "Iteration 260, loss = 995.78925222\n",
      "Iteration 121, loss = 1678.87898720\n",
      "Iteration 44, loss = 1364.73772938\n",
      "Iteration 122, loss = 1650.06350034\n",
      "Iteration 287, loss = 943.94006420\n",
      "Iteration 261, loss = 992.71443005\n",
      "Iteration 122, loss = 1664.06014505\n",
      "Iteration 55, loss = 1416.30188981\n",
      "Iteration 44, loss = 1533.44254086\n",
      "Iteration 123, loss = 1643.34043606\n",
      "Iteration 288, loss = 935.74309755\n",
      "Iteration 63, loss = 1440.76949490\n",
      "Iteration 45, loss = 1347.40958472\n",
      "Iteration 262, loss = 996.58312865\n",
      "Iteration 123, loss = 1653.41154167\n",
      "Iteration 124, loss = 1631.15513306\n",
      "Iteration 289, loss = 939.38348779\n",
      "Iteration 56, loss = 1392.70353718\n",
      "Iteration 263, loss = 995.43496557\n",
      "Iteration 45, loss = 1484.90034951\n",
      "Iteration 124, loss = 1645.33690449\n",
      "Iteration 125, loss = 1618.32647577\n",
      "Iteration 290, loss = 937.78027284\n",
      "Iteration 64, loss = 1357.97269408\n",
      "Iteration 46, loss = 1394.97952714\n",
      "Iteration 264, loss = 989.21066836\n",
      "Iteration 125, loss = 1631.72974834\n",
      "Iteration 291, loss = 943.10626688\n",
      "Iteration 126, loss = 1609.15802415\n",
      "Iteration 57, loss = 1353.52133320\n",
      "Iteration 46, loss = 1468.75589956\n",
      "Iteration 126, loss = 1622.48096110\n",
      "Iteration 265, loss = 988.31488194\n",
      "Iteration 65, loss = 1417.28600129\n",
      "Iteration 292, loss = 936.52402134\n",
      "Iteration 127, loss = 1596.80996002\n",
      "Iteration 47, loss = 1370.58139450\n",
      "Iteration 58, loss = 1355.96459900\n",
      "Iteration 127, loss = 1610.09324572\n",
      "Iteration 266, loss = 986.71945632\n",
      "Iteration 293, loss = 937.80576329\n",
      "Iteration 128, loss = 1585.45969132\n",
      "Iteration 47, loss = 1514.97221355\n",
      "Iteration 66, loss = 1280.00158129\n",
      "Iteration 48, loss = 1363.10429518\n",
      "Iteration 294, loss = 931.19414770\n",
      "Iteration 128, loss = 1598.14798898\n",
      "Iteration 267, loss = 988.19685190\n",
      "Iteration 129, loss = 1576.89335296\n",
      "Iteration 295, loss = 929.32291963\n",
      "Iteration 129, loss = 1589.55297633\n",
      "Iteration 59, loss = 1322.23082106\n",
      "Iteration 268, loss = 984.47679787\n",
      "Iteration 130, loss = 1568.14113867\n",
      "Iteration 48, loss = 1466.57248513\n",
      "Iteration 67, loss = 1304.21420836\n",
      "Iteration 49, loss = 1322.46069158\n",
      "Iteration 296, loss = 936.71121354\n",
      "Iteration 130, loss = 1580.49333337\n",
      "Iteration 269, loss = 978.71941639\n",
      "Iteration 131, loss = 1557.36051377\n",
      "Iteration 60, loss = 1311.21957295\n",
      "Iteration 49, loss = 1434.63782169\n",
      "Iteration 297, loss = 924.72569794\n",
      "Iteration 131, loss = 1571.22962488\n",
      "Iteration 270, loss = 981.00519116\n",
      "Iteration 132, loss = 1546.32059895\n",
      "Iteration 50, loss = 1288.52104491\n",
      "Iteration 68, loss = 1294.80286678\n",
      "Iteration 298, loss = 930.68153490\n",
      "Iteration 133, loss = 1538.39443953\n",
      "Iteration 132, loss = 1560.03131947\n",
      "Iteration 271, loss = 977.16091546\n",
      "Iteration 61, loss = 1350.54887770\n",
      "Iteration 50, loss = 1407.65481908\n",
      "Iteration 51, loss = 1332.26184636\n",
      "Iteration 69, loss = 1386.21005578\n",
      "Iteration 134, loss = 1526.79913291\n",
      "Iteration 133, loss = 1549.39011985\n",
      "Iteration 299, loss = 928.45615995\n",
      "Iteration 272, loss = 973.19934515\n",
      "Iteration 134, loss = 1541.87350982\n",
      "Iteration 300, loss = 930.02381113\n",
      "Iteration 273, loss = 977.01817486\n",
      "Iteration 135, loss = 1521.12247436\n",
      "Iteration 62, loss = 1343.80947113\n",
      "Iteration 51, loss = 1427.07718010\n",
      "Iteration 52, loss = 1300.50906925\n",
      "Iteration 70, loss = 1406.23968024\n",
      "Iteration 301, loss = 924.76597837\n",
      "Iteration 136, loss = 1511.37681978\n",
      "Iteration 274, loss = 981.11073809\n",
      "Iteration 135, loss = 1528.46493556\n",
      "Iteration 63, loss = 1398.31308147\n",
      "Iteration 52, loss = 1406.58891630\n",
      "Iteration 302, loss = 930.02927818\n",
      "Iteration 137, loss = 1499.64016749\n",
      "Iteration 275, loss = 972.22478175\n",
      "Iteration 136, loss = 1519.01020891\n",
      "Iteration 53, loss = 1280.14122582\n",
      "Iteration 71, loss = 1301.37217301\n",
      "Iteration 303, loss = 927.66671892\n",
      "Iteration 138, loss = 1492.37549840\n",
      "Iteration 276, loss = 967.21071865\n",
      "Iteration 137, loss = 1507.84165170\n",
      "Iteration 64, loss = 1311.72411457\n",
      "Iteration 304, loss = 920.02590669\n",
      "Iteration 53, loss = 1418.39015398\n",
      "Iteration 139, loss = 1483.58522512\n",
      "Iteration 54, loss = 1252.11641493\n",
      "Iteration 277, loss = 977.18389690\n",
      "Iteration 138, loss = 1500.96500404\n",
      "Iteration 72, loss = 1391.26933974\n",
      "Iteration 140, loss = 1475.51966265\n",
      "Iteration 305, loss = 927.21428769\n",
      "Iteration 278, loss = 970.60568055\n",
      "Iteration 139, loss = 1488.78872585\n",
      "Iteration 65, loss = 1262.77239021\n",
      "Iteration 54, loss = 1360.95673101\n",
      "Iteration 55, loss = 1323.30264764\n",
      "Iteration 141, loss = 1466.67983071\n",
      "Iteration 306, loss = 922.39437296\n",
      "Iteration 279, loss = 970.46606741\n",
      "Iteration 140, loss = 1479.89687063\n",
      "Iteration 73, loss = 1273.85026748\n",
      "Iteration 66, loss = 1309.86265240\n",
      "Iteration 307, loss = 922.75550086\n",
      "Iteration 142, loss = 1459.90931811\n",
      "Iteration 141, loss = 1472.35428780\n",
      "Iteration 280, loss = 968.12895829\n",
      "Iteration 55, loss = 1416.80102910\n",
      "Iteration 74, loss = 1480.64734992\n",
      "Iteration 56, loss = 1254.96240722\n",
      "Iteration 308, loss = 920.60639278\n",
      "Iteration 143, loss = 1452.25056383\n",
      "Iteration 142, loss = 1463.31348822\n",
      "Iteration 281, loss = 962.25805739\n",
      "Iteration 67, loss = 1365.39747534\n",
      "Iteration 144, loss = 1442.41896800\n",
      "Iteration 309, loss = 918.24390228\n",
      "Iteration 56, loss = 1476.59790141\n",
      "Iteration 282, loss = 956.18896374\n",
      "Iteration 143, loss = 1457.41242840\n",
      "Iteration 75, loss = 1263.41952713\n",
      "Iteration 57, loss = 1284.68838101\n",
      "Iteration 145, loss = 1431.60971325\n",
      "Iteration 310, loss = 923.39107207\n",
      "Iteration 283, loss = 958.92391699\n",
      "Iteration 68, loss = 1336.21993315\n",
      "Iteration 144, loss = 1447.96642084\n",
      "Iteration 57, loss = 1380.11519361\n",
      "Iteration 311, loss = 919.37130083\n",
      "Iteration 146, loss = 1425.75800462\n",
      "Iteration 284, loss = 961.37567159\n",
      "Iteration 145, loss = 1437.39824999\n",
      "Iteration 58, loss = 1293.36615887\n",
      "Iteration 76, loss = 1244.85754935\n",
      "Iteration 312, loss = 920.88593956\n",
      "Iteration 69, loss = 1273.05874860\n",
      "Iteration 285, loss = 957.33794331\n",
      "Iteration 147, loss = 1414.05522902\n",
      "Iteration 146, loss = 1430.36513197\n",
      "Iteration 58, loss = 1374.62731758\n",
      "Iteration 313, loss = 917.82692560\n",
      "Iteration 286, loss = 954.08500329\n",
      "Iteration 59, loss = 1272.30336945\n",
      "Iteration 148, loss = 1410.53953909\n",
      "Iteration 77, loss = 1237.30355562\n",
      "Iteration 147, loss = 1418.74620275\n",
      "Iteration 70, loss = 1272.37096576\n",
      "Iteration 314, loss = 919.07137441\n",
      "Iteration 149, loss = 1399.28778049\n",
      "Iteration 287, loss = 958.22298678\n",
      "Iteration 59, loss = 1363.82682539\n",
      "Iteration 148, loss = 1415.28013310\n",
      "Iteration 60, loss = 1314.96895681\n",
      "Iteration 78, loss = 1199.10476077\n",
      "Iteration 150, loss = 1393.16541891\n",
      "Iteration 315, loss = 915.30437075\n",
      "Iteration 288, loss = 945.79704330\n",
      "Iteration 149, loss = 1402.72002139\n",
      "Iteration 71, loss = 1211.35661148\n",
      "Iteration 316, loss = 917.21351923\n",
      "Iteration 151, loss = 1385.45967884\n",
      "Iteration 289, loss = 955.03491192\n",
      "Iteration 60, loss = 1441.40629629\n",
      "Iteration 150, loss = 1397.91696275\n",
      "Iteration 61, loss = 1304.30213584\n",
      "Iteration 79, loss = 1233.91055489\n",
      "Iteration 317, loss = 908.06156809\n",
      "Iteration 72, loss = 1327.12287243\n",
      "Iteration 152, loss = 1376.98670137\n",
      "Iteration 290, loss = 951.46500460\n",
      "Iteration 151, loss = 1387.67231027\n",
      "Iteration 318, loss = 912.04400619\n",
      "Iteration 153, loss = 1368.42201193\n",
      "Iteration 291, loss = 952.32509355\n",
      "Iteration 62, loss = 1265.93083676\n",
      "Iteration 61, loss = 1316.92541815\n",
      "Iteration 80, loss = 1183.89393394\n",
      "Iteration 152, loss = 1381.25571742\n",
      "Iteration 73, loss = 1416.97590202\n",
      "Iteration 319, loss = 906.93484810\n",
      "Iteration 154, loss = 1361.76685272\n",
      "Iteration 292, loss = 947.72596497\n",
      "Iteration 153, loss = 1368.18452241\n",
      "Iteration 62, loss = 1377.50465033\n",
      "Iteration 320, loss = 907.24052605\n",
      "Iteration 63, loss = 1200.74776197\n",
      "Iteration 155, loss = 1360.31052393\n",
      "Iteration 81, loss = 1226.27896311\n",
      "Iteration 293, loss = 957.20570199\n",
      "Iteration 154, loss = 1366.73375307\n",
      "Iteration 74, loss = 1408.36753828\n",
      "Iteration 321, loss = 904.06139828\n",
      "Iteration 156, loss = 1347.65373759\n",
      "Iteration 294, loss = 942.74127857\n",
      "Iteration 155, loss = 1362.66436137\n",
      "Iteration 63, loss = 1391.65908334\n",
      "Iteration 64, loss = 1159.49244500\n",
      "Iteration 82, loss = 1198.26644771\n",
      "Iteration 322, loss = 905.27091464\n",
      "Iteration 157, loss = 1342.64522603\n",
      "Iteration 75, loss = 1447.85955359\n",
      "Iteration 295, loss = 938.80949202\n",
      "Iteration 156, loss = 1348.53907621\n",
      "Iteration 323, loss = 901.58564780\n",
      "Iteration 158, loss = 1334.49577462\n",
      "Iteration 296, loss = 947.92154152\n",
      "Iteration 64, loss = 1353.77004228\n",
      "Iteration 157, loss = 1342.65808343\n",
      "Iteration 65, loss = 1243.89541232\n",
      "Iteration 76, loss = 1332.21429091\n",
      "Iteration 324, loss = 898.36751778\n",
      "Iteration 83, loss = 1295.22884756\n",
      "Iteration 159, loss = 1323.53633060\n",
      "Iteration 158, loss = 1336.66708436\n",
      "Iteration 297, loss = 932.57802323\n",
      "Iteration 325, loss = 903.78602349\n",
      "Iteration 160, loss = 1318.61440845\n",
      "Iteration 65, loss = 1394.68410201\n",
      "Iteration 66, loss = 1222.33306687\n",
      "Iteration 159, loss = 1326.70811547\n",
      "Iteration 77, loss = 1402.06273392\n",
      "Iteration 298, loss = 943.75886240\n",
      "Iteration 84, loss = 1295.36225037\n",
      "Iteration 326, loss = 895.95965451\n",
      "Iteration 161, loss = 1307.59351620\n",
      "Iteration 160, loss = 1321.20548323\n",
      "Iteration 299, loss = 935.64967615\n",
      "Iteration 66, loss = 1353.27936100\n",
      "Iteration 327, loss = 894.66668927\n",
      "Iteration 67, loss = 1165.58184363\n",
      "Iteration 162, loss = 1303.97601432\n",
      "Iteration 78, loss = 1274.25627961\n",
      "Iteration 161, loss = 1310.87768732\n",
      "Iteration 85, loss = 1319.10662312\n",
      "Iteration 300, loss = 940.14628239\n",
      "Iteration 328, loss = 899.19172336\n",
      "Iteration 163, loss = 1300.23357837\n",
      "Iteration 162, loss = 1306.46248174\n",
      "Iteration 67, loss = 1346.44008583\n",
      "Iteration 68, loss = 1207.41242964\n",
      "Iteration 301, loss = 932.50920247\n",
      "Iteration 79, loss = 1352.47768669\n",
      "Iteration 329, loss = 896.63025072\n",
      "Iteration 164, loss = 1291.81321997\n",
      "Iteration 86, loss = 1309.80416216\n",
      "Iteration 163, loss = 1304.23029153\n",
      "Iteration 302, loss = 935.94361990\n",
      "Iteration 165, loss = 1288.11810535\n",
      "Iteration 330, loss = 891.39430142\n",
      "Iteration 164, loss = 1295.78418393\n",
      "Iteration 69, loss = 1192.20681671\n",
      "Iteration 68, loss = 1319.52578715\n",
      "Iteration 80, loss = 1414.98119695\n",
      "Iteration 303, loss = 937.25873568\n",
      "Iteration 87, loss = 1228.96324266\n",
      "Iteration 166, loss = 1283.08284385\n",
      "Iteration 165, loss = 1289.60820534\n",
      "Iteration 331, loss = 891.92598148\n",
      "Iteration 304, loss = 929.65548540\n",
      "Iteration 70, loss = 1226.86344550\n",
      "Iteration 167, loss = 1274.99026599\n",
      "Iteration 69, loss = 1318.45391496\n",
      "Iteration 332, loss = 897.82843046\n",
      "Iteration 166, loss = 1288.36223561\n",
      "Iteration 81, loss = 1322.88798847\n",
      "Iteration 88, loss = 1251.12741195\n",
      "Iteration 305, loss = 934.76182175\n",
      "Iteration 168, loss = 1270.36957163\n",
      "Iteration 333, loss = 889.69114791\n",
      "Iteration 167, loss = 1278.04694536\n",
      "Iteration 71, loss = 1237.96686823\n",
      "Iteration 306, loss = 931.13638776\n",
      "Iteration 169, loss = 1261.91451799\n",
      "Iteration 334, loss = 888.08894020\n",
      "Iteration 70, loss = 1281.46145628\n",
      "Iteration 82, loss = 1336.06312072\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 168, loss = 1272.19853117\n",
      "Iteration 89, loss = 1393.36598752\n",
      "Iteration 307, loss = 927.30163913\n",
      "Iteration 170, loss = 1257.42171386\n",
      "Iteration 335, loss = 888.00057551\n",
      "Iteration 169, loss = 1262.59191518\n",
      "Iteration 72, loss = 1194.56404969\n",
      "Iteration 308, loss = 924.01146437\n",
      "Iteration 71, loss = 1350.59637853\n",
      "Iteration 171, loss = 1248.94543549\n",
      "Iteration 336, loss = 888.68113118\n",
      "Iteration 170, loss = 1255.44495384\n",
      "Iteration 90, loss = 1232.15416974\n",
      "Iteration 1, loss = 10620.86604814\n",
      "Iteration 309, loss = 929.55860420\n",
      "Iteration 73, loss = 1149.59562775\n",
      "Iteration 172, loss = 1246.19840985\n",
      "Iteration 171, loss = 1250.05930217\n",
      "Iteration 337, loss = 888.18397132\n",
      "Iteration 72, loss = 1263.22718252\n",
      "Iteration 310, loss = 930.52380920\n",
      "Iteration 91, loss = 1193.97712813\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 173, loss = 1238.40813311\n",
      "Iteration 172, loss = 1246.57092028\n",
      "Iteration 338, loss = 885.82003436\n",
      "Iteration 2, loss = 8706.20434511\n",
      "Iteration 74, loss = 1154.36034927\n",
      "Iteration 311, loss = 924.46509709\n",
      "Iteration 174, loss = 1231.43858255\n",
      "Iteration 173, loss = 1240.50478877\n",
      "Iteration 339, loss = 887.59543468\n",
      "Iteration 73, loss = 1267.34954260\n",
      "Iteration 3, loss = 7576.98370421\n",
      "Iteration 1, loss = 10529.12061748\n",
      "Iteration 312, loss = 925.51013562\n",
      "Iteration 174, loss = 1230.94774126\n",
      "Iteration 175, loss = 1230.03961256\n",
      "Iteration 340, loss = 880.90569656\n",
      "Iteration 75, loss = 1145.20534140\n",
      "Iteration 313, loss = 921.76857092\n",
      "Iteration 175, loss = 1226.50479535\n",
      "Iteration 176, loss = 1222.39077806\n",
      "Iteration 341, loss = 879.51857345\n",
      "Iteration 74, loss = 1275.77342386\n",
      "Iteration 4, loss = 6749.43075713\n",
      "Iteration 2, loss = 8628.10916576\n",
      "Iteration 314, loss = 920.09296457\n",
      "Iteration 176, loss = 1221.93258927\n",
      "Iteration 177, loss = 1215.97949826\n",
      "Iteration 342, loss = 882.85692638\n",
      "Iteration 76, loss = 1217.10507061\n",
      "Iteration 75, loss = 1263.33099779\n",
      "Iteration 315, loss = 925.55750033\n",
      "Iteration 177, loss = 1217.59528007\n",
      "Iteration 178, loss = 1211.42460830\n",
      "Iteration 343, loss = 882.83231993\n",
      "Iteration 3, loss = 7501.06619854\n",
      "Iteration 5, loss = 6083.82940432\n",
      "Iteration 316, loss = 923.07988088\n",
      "Iteration 179, loss = 1206.95145253\n",
      "Iteration 178, loss = 1211.02042833\n",
      "Iteration 77, loss = 1152.52409042\n",
      "Iteration 344, loss = 878.33394534\n",
      "Iteration 76, loss = 1200.09181884\n",
      "Iteration 317, loss = 917.77398571\n",
      "Iteration 4, loss = 6684.17837546\n",
      "Iteration 179, loss = 1206.65769043\n",
      "Iteration 180, loss = 1199.18258250\n",
      "Iteration 345, loss = 877.98772214\n",
      "Iteration 6, loss = 5554.95503192\n",
      "Iteration 78, loss = 1176.58882385\n",
      "Iteration 318, loss = 918.35882677\n",
      "Iteration 181, loss = 1196.41853921\n",
      "Iteration 180, loss = 1199.92326124\n",
      "Iteration 346, loss = 876.76385038\n",
      "Iteration 77, loss = 1202.31396303\n",
      "Iteration 5, loss = 6054.22551385\n",
      "Iteration 319, loss = 915.26096092\n",
      "Iteration 7, loss = 5110.52678597\n",
      "Iteration 182, loss = 1193.76379860\n",
      "Iteration 347, loss = 876.97514845\n",
      "Iteration 181, loss = 1196.76430914\n",
      "Iteration 79, loss = 1178.46193763\n",
      "Iteration 320, loss = 919.25117441\n",
      "Iteration 183, loss = 1183.93660127\n",
      "Iteration 78, loss = 1297.09497148\n",
      "Iteration 348, loss = 880.90892134\n",
      "Iteration 182, loss = 1191.92532905\n",
      "Iteration 6, loss = 5517.19340039\n",
      "Iteration 8, loss = 4730.84997156\n",
      "Iteration 321, loss = 913.17266977\n",
      "Iteration 184, loss = 1180.22033960\n",
      "Iteration 349, loss = 881.01148311\n",
      "Iteration 80, loss = 1169.72950471\n",
      "Iteration 183, loss = 1185.47774156\n",
      "Iteration 79, loss = 1216.25129041\n",
      "Iteration 322, loss = 919.34304885\n",
      "Iteration 7, loss = 5084.45455316\n",
      "Iteration 185, loss = 1175.51834316\n",
      "Iteration 350, loss = 880.51334616\n",
      "Iteration 9, loss = 4418.94561369\n",
      "Iteration 184, loss = 1180.50747665\n",
      "Iteration 323, loss = 915.70084794\n",
      "Iteration 81, loss = 1187.45025838\n",
      "Iteration 186, loss = 1172.41989008\n",
      "Iteration 351, loss = 871.57689062\n",
      "Iteration 185, loss = 1179.10717893\n",
      "Iteration 80, loss = 1212.30412799\n",
      "Iteration 8, loss = 4711.78441482\n",
      "Iteration 324, loss = 913.32030258\n",
      "Iteration 187, loss = 1163.82125423\n",
      "Iteration 10, loss = 4120.69717543\n",
      "Iteration 352, loss = 878.86207330\n",
      "Iteration 186, loss = 1171.24459029\n",
      "Iteration 82, loss = 1138.39246884\n",
      "Iteration 325, loss = 917.85916872\n",
      "Iteration 188, loss = 1160.33397008\n",
      "Iteration 353, loss = 873.75158284\n",
      "Iteration 187, loss = 1166.34665440\n",
      "Iteration 9, loss = 4368.91214849\n",
      "Iteration 81, loss = 1353.66401734\n",
      "Iteration 11, loss = 3839.43610141\n",
      "Iteration 189, loss = 1156.58946405\n",
      "Iteration 326, loss = 912.95291715\n",
      "Iteration 354, loss = 871.55332854\n",
      "Iteration 188, loss = 1167.78996012\n",
      "Iteration 83, loss = 1234.27736140\n",
      "Iteration 190, loss = 1155.28383157\n",
      "Iteration 327, loss = 913.68841549\n",
      "Iteration 355, loss = 875.54866165\n",
      "Iteration 10, loss = 4090.69348995\n",
      "Iteration 189, loss = 1163.89413476\n",
      "Iteration 82, loss = 1324.77824189\n",
      "Iteration 12, loss = 3592.87264040\n",
      "Iteration 191, loss = 1153.26866361\n",
      "Iteration 328, loss = 907.44783207\n",
      "Iteration 356, loss = 872.24674306\n",
      "Iteration 190, loss = 1156.17825742\n",
      "Iteration 84, loss = 1200.52278932\n",
      "Iteration 192, loss = 1143.03091032\n",
      "Iteration 357, loss = 871.14347839\n",
      "Iteration 83, loss = 1329.01477510\n",
      "Iteration 329, loss = 909.63130632\n",
      "Iteration 11, loss = 3824.99967275\n",
      "Iteration 191, loss = 1153.43197493\n",
      "Iteration 13, loss = 3384.08153144\n",
      "Iteration 358, loss = 869.29136868\n",
      "Iteration 193, loss = 1140.53866078\n",
      "Iteration 192, loss = 1146.86955631\n",
      "Iteration 330, loss = 908.20946784\n",
      "Iteration 85, loss = 1174.12314858\n",
      "Iteration 84, loss = 1276.63028188\n",
      "Iteration 359, loss = 878.14562418\n",
      "Iteration 12, loss = 3586.63535285\n",
      "Iteration 331, loss = 904.08598861\n",
      "Iteration 14, loss = 3190.95289587\n",
      "Iteration 194, loss = 1133.56456336\n",
      "Iteration 193, loss = 1139.17881355\n",
      "Iteration 332, loss = 905.37473473\n",
      "Iteration 360, loss = 870.47300090\n",
      "Iteration 86, loss = 1160.71971633\n",
      "Iteration 195, loss = 1132.00933109\n",
      "Iteration 194, loss = 1139.03825153\n",
      "Iteration 85, loss = 1232.08348971\n",
      "Iteration 13, loss = 3386.33374415\n",
      "Iteration 15, loss = 3002.63658400\n",
      "Iteration 333, loss = 904.75603053\n",
      "Iteration 361, loss = 868.91968489\n",
      "Iteration 196, loss = 1129.82332955\n",
      "Iteration 195, loss = 1134.36097549\n",
      "Iteration 87, loss = 1201.81677237\n",
      "Iteration 334, loss = 906.98606130\n",
      "Iteration 362, loss = 867.92215268\n",
      "Iteration 197, loss = 1124.14553917\n",
      "Iteration 16, loss = 2858.98427090\n",
      "Iteration 196, loss = 1133.04465527\n",
      "Iteration 86, loss = 1229.52312319\n",
      "Iteration 14, loss = 3199.00425252\n",
      "Iteration 335, loss = 907.56332650\n",
      "Iteration 198, loss = 1118.73361581\n",
      "Iteration 363, loss = 873.40791987\n",
      "Iteration 197, loss = 1126.86425706\n",
      "Iteration 88, loss = 1171.91555514\n",
      "Iteration 17, loss = 2688.35124968\n",
      "Iteration 364, loss = 867.22308509\n",
      "Iteration 336, loss = 900.98719676\n",
      "Iteration 199, loss = 1110.62672100\n",
      "Iteration 87, loss = 1224.93124566\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 198, loss = 1120.70187262\n",
      "Iteration 15, loss = 3012.30609066\n",
      "Iteration 365, loss = 867.20386223\n",
      "Iteration 200, loss = 1113.96465269\n",
      "Iteration 337, loss = 901.53545158\n",
      "Iteration 89, loss = 1127.39301644\n",
      "Iteration 199, loss = 1116.02492618\n",
      "Iteration 18, loss = 2600.35894283\n",
      "Iteration 366, loss = 867.60608055\n",
      "Iteration 201, loss = 1108.55329704\n",
      "Iteration 16, loss = 2891.33742962\n",
      "Iteration 338, loss = 898.55426513\n",
      "Iteration 1, loss = 10627.28878696\n",
      "Iteration 200, loss = 1113.01401248\n",
      "Iteration 90, loss = 1130.18861308\n",
      "Iteration 367, loss = 864.39592967\n",
      "Iteration 202, loss = 1106.41483233\n",
      "Iteration 339, loss = 905.16491445\n",
      "Iteration 201, loss = 1106.05078773\n",
      "Iteration 19, loss = 2452.23048593\n",
      "Iteration 17, loss = 2735.82463156\n",
      "Iteration 368, loss = 864.21069230\n",
      "Iteration 203, loss = 1097.86911830\n",
      "Iteration 340, loss = 897.09427884\n",
      "Iteration 2, loss = 8700.82439529\n",
      "Iteration 202, loss = 1106.62678286\n",
      "Iteration 91, loss = 1089.04084341\n",
      "Iteration 369, loss = 864.79520559\n",
      "Iteration 341, loss = 896.69719195\n",
      "Iteration 204, loss = 1096.61438306\n",
      "Iteration 20, loss = 2376.49892171\n",
      "Iteration 18, loss = 2652.86290078\n",
      "Iteration 370, loss = 874.68715960\n",
      "Iteration 203, loss = 1097.01069571\n",
      "Iteration 3, loss = 7564.74607642\n",
      "Iteration 342, loss = 897.14536450\n",
      "Iteration 205, loss = 1095.10038318\n",
      "Iteration 92, loss = 1164.92057785\n",
      "Iteration 371, loss = 866.23722616\n",
      "Iteration 21, loss = 2305.70869722\n",
      "Iteration 204, loss = 1098.03059584\n",
      "Iteration 206, loss = 1091.14572160\n",
      "Iteration 343, loss = 896.84530609\n",
      "Iteration 19, loss = 2500.94624390\n",
      "Iteration 372, loss = 863.44298355\n",
      "Iteration 4, loss = 6738.29833040\n",
      "Iteration 93, loss = 1137.92476463\n",
      "Iteration 205, loss = 1093.87732883\n",
      "Iteration 344, loss = 891.35526389\n",
      "Iteration 207, loss = 1087.25333148\n",
      "Iteration 373, loss = 865.05512861\n",
      "Iteration 22, loss = 2191.33908663\n",
      "Iteration 206, loss = 1089.99503743\n",
      "Iteration 345, loss = 894.86993353\n",
      "Iteration 20, loss = 2398.97593369\n",
      "Iteration 208, loss = 1082.90906845\n",
      "Iteration 374, loss = 859.86407812\n",
      "Iteration 5, loss = 6085.41761070\n",
      "Iteration 94, loss = 1080.30460253\n",
      "Iteration 23, loss = 2103.94054328\n",
      "Iteration 207, loss = 1086.35511761\n",
      "Iteration 346, loss = 887.35769706\n",
      "Iteration 209, loss = 1080.68901073\n",
      "Iteration 375, loss = 859.99695002\n",
      "Iteration 21, loss = 2305.94807060\n",
      "Iteration 208, loss = 1082.34717209\n",
      "Iteration 210, loss = 1076.42443097\n",
      "Iteration 347, loss = 894.11138684\n",
      "Iteration 95, loss = 1118.80313037\n",
      "Iteration 6, loss = 5574.22275504\n",
      "Iteration 376, loss = 863.56701320\n",
      "Iteration 24, loss = 2046.70242223\n",
      "Iteration 209, loss = 1077.21555123\n",
      "Iteration 211, loss = 1075.21671533\n",
      "Iteration 348, loss = 896.05567500\n",
      "Iteration 377, loss = 859.20438266\n",
      "Iteration 22, loss = 2218.45706786\n",
      "Iteration 210, loss = 1076.49695800\n",
      "Iteration 96, loss = 1127.86219449\n",
      "Iteration 212, loss = 1072.60135768\n",
      "Iteration 7, loss = 5116.89183061\n",
      "Iteration 349, loss = 898.03841884\n",
      "Iteration 378, loss = 859.53209081\n",
      "Iteration 25, loss = 1976.12881455\n",
      "Iteration 213, loss = 1069.46933198\n",
      "Iteration 211, loss = 1077.36978989\n",
      "Iteration 350, loss = 889.51356808\n",
      "Iteration 23, loss = 2168.30211550\n",
      "Iteration 379, loss = 859.13380090\n",
      "Iteration 97, loss = 1217.89252636\n",
      "Iteration 8, loss = 4740.84953036\n",
      "Iteration 214, loss = 1063.35372554\n",
      "Iteration 212, loss = 1071.12717003\n",
      "Iteration 26, loss = 1942.90945486\n",
      "Iteration 351, loss = 884.28687677\n",
      "Iteration 380, loss = 858.04280868\n",
      "Iteration 24, loss = 2278.79042932\n",
      "Iteration 215, loss = 1061.30140472\n",
      "Iteration 213, loss = 1065.09651079\n",
      "Iteration 352, loss = 894.23987941\n",
      "Iteration 381, loss = 864.25752336\n",
      "Iteration 98, loss = 1332.79514654\n",
      "Iteration 9, loss = 4424.64378476\n",
      "Iteration 27, loss = 1893.90769901\n",
      "Iteration 216, loss = 1064.12642300\n",
      "Iteration 214, loss = 1065.60245737\n",
      "Iteration 353, loss = 898.98313393\n",
      "Iteration 382, loss = 854.03993268\n",
      "Iteration 25, loss = 2156.90410494\n",
      "Iteration 217, loss = 1061.80139482\n",
      "Iteration 215, loss = 1057.96945679\n",
      "Iteration 354, loss = 881.18825373\n",
      "Iteration 99, loss = 1172.84766712\n",
      "Iteration 383, loss = 856.77953304\n",
      "Iteration 10, loss = 4099.14594023\n",
      "Iteration 28, loss = 1875.61372930\n",
      "Iteration 218, loss = 1058.04861584\n",
      "Iteration 355, loss = 888.35840194\n",
      "Iteration 216, loss = 1061.73125547\n",
      "Iteration 384, loss = 845.98061594\n",
      "Iteration 26, loss = 1959.64591964\n",
      "Iteration 219, loss = 1053.57156313\n",
      "Iteration 100, loss = 1278.79842883\n",
      "Iteration 11, loss = 3833.80737109\n",
      "Iteration 356, loss = 886.26731987\n",
      "Iteration 217, loss = 1053.67519448\n",
      "Iteration 385, loss = 850.16620552\n",
      "Iteration 29, loss = 1810.55491665\n",
      "Iteration 220, loss = 1055.49374957\n",
      "Iteration 357, loss = 888.34742490\n",
      "Iteration 386, loss = 855.61832504\n",
      "Iteration 218, loss = 1052.48735546\n",
      "Iteration 27, loss = 1929.17406480\n",
      "Iteration 101, loss = 1176.92842911\n",
      "Iteration 12, loss = 3623.43431947\n",
      "Iteration 221, loss = 1049.04664192\n",
      "Iteration 30, loss = 1784.19324584\n",
      "Iteration 387, loss = 847.12986126\n",
      "Iteration 358, loss = 884.27770382\n",
      "Iteration 219, loss = 1054.46004070\n",
      "Iteration 222, loss = 1051.28248159\n",
      "Iteration 220, loss = 1046.97700741\n",
      "Iteration 388, loss = 851.24390456\n",
      "Iteration 359, loss = 891.28446288\n",
      "Iteration 28, loss = 1887.75488191\n",
      "Iteration 102, loss = 1177.51335996\n",
      "Iteration 13, loss = 3417.12383226\n",
      "Iteration 223, loss = 1044.50055265\n",
      "Iteration 31, loss = 1760.23977126\n",
      "Iteration 221, loss = 1041.84601088\n",
      "Iteration 389, loss = 849.26347643\n",
      "Iteration 360, loss = 883.46849253\n",
      "Iteration 224, loss = 1041.02007612\n",
      "Iteration 222, loss = 1043.45941648\n",
      "Iteration 103, loss = 1170.34233229\n",
      "Iteration 29, loss = 1878.52785933\n",
      "Iteration 390, loss = 849.80109391\n",
      "Iteration 361, loss = 883.73683713\n",
      "Iteration 14, loss = 3209.49759937\n",
      "Iteration 32, loss = 1710.94244397\n",
      "Iteration 225, loss = 1039.77135021\n",
      "Iteration 223, loss = 1034.09712663\n",
      "Iteration 391, loss = 856.41696873\n",
      "Iteration 362, loss = 882.07390962\n",
      "Iteration 104, loss = 1111.13137578\n",
      "Iteration 226, loss = 1040.43414581\n",
      "Iteration 224, loss = 1034.56952050\n",
      "Iteration 30, loss = 1833.91676010\n",
      "Iteration 15, loss = 3004.87611446\n",
      "Iteration 392, loss = 852.53358462\n",
      "Iteration 33, loss = 1653.51636544\n",
      "Iteration 363, loss = 881.21520605\n",
      "Iteration 227, loss = 1038.29957329\n",
      "Iteration 225, loss = 1029.56110865\n",
      "Iteration 393, loss = 848.19571054\n",
      "Iteration 364, loss = 886.09755767\n",
      "Iteration 105, loss = 1061.12390845\n",
      "Iteration 31, loss = 1769.28799768\n",
      "Iteration 228, loss = 1034.52865237\n",
      "Iteration 16, loss = 2860.22864146\n",
      "Iteration 34, loss = 1641.92438244\n",
      "Iteration 394, loss = 849.57721946\n",
      "Iteration 226, loss = 1032.68032805\n",
      "Iteration 365, loss = 878.18822054\n",
      "Iteration 229, loss = 1032.42761973\n",
      "Iteration 395, loss = 849.80699665\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 106, loss = 1142.17592838\n",
      "Iteration 366, loss = 875.85190131\n",
      "Iteration 227, loss = 1028.53552392\n",
      "Iteration 32, loss = 1713.82583462\n",
      "Iteration 17, loss = 2699.47942491\n",
      "Iteration 230, loss = 1026.21442255\n",
      "Iteration 35, loss = 1619.27143695\n",
      "Iteration 367, loss = 875.96695973\n",
      "Iteration 228, loss = 1019.83751416\n",
      "Iteration 107, loss = 1137.41567650\n",
      "Iteration 1, loss = 10583.75625186\n",
      "Iteration 231, loss = 1026.62202517\n",
      "Iteration 33, loss = 1712.11668426\n",
      "Iteration 368, loss = 879.16834061\n",
      "Iteration 229, loss = 1023.41920358\n",
      "Iteration 18, loss = 2569.30281231\n",
      "Iteration 36, loss = 1660.22766572\n",
      "Iteration 232, loss = 1025.15267394\n",
      "Iteration 230, loss = 1018.34763315\n",
      "Iteration 369, loss = 881.12928707\n",
      "Iteration 108, loss = 1075.61165433\n",
      "Iteration 2, loss = 8680.44505584\n",
      "Iteration 233, loss = 1027.34336675\n",
      "Iteration 34, loss = 1728.14028948\n",
      "Iteration 19, loss = 2559.70961060\n",
      "Iteration 37, loss = 1595.76549921\n",
      "Iteration 231, loss = 1011.69004091\n",
      "Iteration 370, loss = 888.86334082\n",
      "Iteration 234, loss = 1023.36740370\n",
      "Iteration 109, loss = 1235.39517941\n",
      "Iteration 3, loss = 7560.20210544\n",
      "Iteration 232, loss = 1007.80660149\n",
      "Iteration 35, loss = 1695.79209423\n",
      "Iteration 371, loss = 885.66931435\n",
      "Iteration 20, loss = 2376.42368722\n",
      "Iteration 235, loss = 1018.76879680\n",
      "Iteration 38, loss = 1571.34578739\n",
      "Iteration 233, loss = 1012.33399549\n",
      "Iteration 236, loss = 1012.05231775\n",
      "Iteration 372, loss = 878.39420233\n",
      "Iteration 4, loss = 6743.84017809\n",
      "Iteration 21, loss = 2294.18912011\n",
      "Iteration 36, loss = 1661.54598475\n",
      "Iteration 110, loss = 1294.81635119\n",
      "Iteration 234, loss = 1009.07107423\n",
      "Iteration 237, loss = 1019.87952966\n",
      "Iteration 373, loss = 883.05825471\n",
      "Iteration 39, loss = 1562.61690208\n",
      "Iteration 238, loss = 1013.13980315\n",
      "Iteration 235, loss = 1005.37899821\n",
      "Iteration 374, loss = 874.97595859\n",
      "Iteration 37, loss = 1593.20847019\n",
      "Iteration 111, loss = 1253.16036558\n",
      "Iteration 22, loss = 2195.36677005\n",
      "Iteration 5, loss = 6123.77862776\n",
      "Iteration 40, loss = 1462.36218344\n",
      "Iteration 239, loss = 1012.04512420\n",
      "Iteration 236, loss = 998.50239798\n",
      "Iteration 375, loss = 872.73412436\n",
      "Iteration 237, loss = 999.14360403\n",
      "Iteration 240, loss = 1005.94069104\n",
      "Iteration 38, loss = 1615.70873618\n",
      "Iteration 112, loss = 1288.47205832\n",
      "Iteration 376, loss = 877.35446616\n",
      "Iteration 23, loss = 2116.55663495\n",
      "Iteration 41, loss = 1564.90402868\n",
      "Iteration 6, loss = 5566.92201304\n",
      "Iteration 241, loss = 1004.38234413\n",
      "Iteration 238, loss = 997.13783140\n",
      "Iteration 377, loss = 874.09343467\n",
      "Iteration 242, loss = 1000.34035072\n",
      "Iteration 39, loss = 1555.00236920\n",
      "Iteration 24, loss = 2055.05984406\n",
      "Iteration 239, loss = 995.58963971\n",
      "Iteration 113, loss = 1201.19493896\n",
      "Iteration 42, loss = 1425.78398634\n",
      "Iteration 378, loss = 873.56962552\n",
      "Iteration 7, loss = 5131.47243409\n",
      "Iteration 243, loss = 998.99115297\n",
      "Iteration 240, loss = 991.67820296\n",
      "Iteration 379, loss = 868.25201621\n",
      "Iteration 25, loss = 1995.70828584\n",
      "Iteration 43, loss = 1443.99171807\n",
      "Iteration 40, loss = 1524.86091483\n",
      "Iteration 114, loss = 1133.42487465\n",
      "Iteration 8, loss = 4754.28568249\n",
      "Iteration 244, loss = 998.21130601\n",
      "Iteration 241, loss = 989.43433721\n",
      "Iteration 380, loss = 879.43565023\n",
      "Iteration 245, loss = 997.25506318\n",
      "Iteration 242, loss = 989.90765839\n",
      "Iteration 381, loss = 872.69366888\n",
      "Iteration 26, loss = 1957.55031983\n",
      "Iteration 41, loss = 1536.01790141\n",
      "Iteration 44, loss = 1447.90292947\n",
      "Iteration 9, loss = 4418.72006390\n",
      "Iteration 115, loss = 1155.95215267\n",
      "Iteration 246, loss = 992.23194112\n",
      "Iteration 243, loss = 983.09390779\n",
      "Iteration 382, loss = 869.04084127\n",
      "Iteration 247, loss = 993.71368976\n",
      "Iteration 27, loss = 1933.52952231\n",
      "Iteration 244, loss = 982.04943789\n",
      "Iteration 45, loss = 1423.09027986\n",
      "Iteration 42, loss = 1542.29943661\n",
      "Iteration 10, loss = 4136.40924692\n",
      "Iteration 383, loss = 869.05458166\n",
      "Iteration 116, loss = 1163.30448879\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 248, loss = 992.81361203\n",
      "Iteration 245, loss = 982.47650474\n",
      "Iteration 384, loss = 868.94108341\n",
      "Iteration 28, loss = 1868.22532629\n",
      "Iteration 249, loss = 987.66699489\n",
      "Iteration 11, loss = 3884.03914073\n",
      "Iteration 46, loss = 1438.05268358\n",
      "Iteration 43, loss = 1585.30725295\n",
      "Iteration 246, loss = 976.63955907\n",
      "Iteration 385, loss = 862.27693301\n",
      "Iteration 250, loss = 986.56840542\n",
      "Iteration 1, loss = 10674.90537424\n",
      "Iteration 247, loss = 975.10115230\n",
      "Iteration 29, loss = 1790.93846306\n",
      "Iteration 386, loss = 865.73969019\n",
      "Iteration 47, loss = 1324.29184725\n",
      "Iteration 251, loss = 981.92137057\n",
      "Iteration 12, loss = 3643.51472017\n",
      "Iteration 44, loss = 1489.31992114\n",
      "Iteration 248, loss = 970.70403513\n",
      "Iteration 387, loss = 862.94406774\n",
      "Iteration 2, loss = 8757.53110363\n",
      "Iteration 252, loss = 981.60022789\n",
      "Iteration 30, loss = 1860.02084616\n",
      "Iteration 249, loss = 971.39015163\n",
      "Iteration 388, loss = 867.11557786\n",
      "Iteration 48, loss = 1291.08520108\n",
      "Iteration 13, loss = 3418.09931714\n",
      "Iteration 45, loss = 1452.73092785\n",
      "Iteration 253, loss = 981.85872391\n",
      "Iteration 389, loss = 865.22327171\n",
      "Iteration 3, loss = 7627.00505829\n",
      "Iteration 250, loss = 969.03054170\n",
      "Iteration 254, loss = 973.61080753\n",
      "Iteration 31, loss = 1736.37187258\n",
      "Iteration 49, loss = 1410.32846892\n",
      "Iteration 14, loss = 3233.13274171\n",
      "Iteration 390, loss = 864.51892717\n",
      "Iteration 46, loss = 1440.96946456\n",
      "Iteration 251, loss = 969.56772234\n",
      "Iteration 255, loss = 979.58165252\n",
      "Iteration 391, loss = 862.32367422\n",
      "Iteration 4, loss = 6810.21733597\n",
      "Iteration 252, loss = 962.57514061\n",
      "Iteration 32, loss = 1715.78435572\n",
      "Iteration 15, loss = 3043.60893839\n",
      "Iteration 50, loss = 1451.95603117\n",
      "Iteration 256, loss = 972.94366179\n",
      "Iteration 392, loss = 871.19962074\n",
      "Iteration 47, loss = 1457.29966929\n",
      "Iteration 253, loss = 963.72958135\n",
      "Iteration 5, loss = 6160.12405943\n",
      "Iteration 257, loss = 976.79546413\n",
      "Iteration 393, loss = 864.10524544\n",
      "Iteration 33, loss = 1718.30427170\n",
      "Iteration 254, loss = 957.15960116\n",
      "Iteration 51, loss = 1354.85374040\n",
      "Iteration 16, loss = 2929.57320449\n",
      "Iteration 258, loss = 968.41163642\n",
      "Iteration 48, loss = 1464.64972541\n",
      "Iteration 394, loss = 868.79760671\n",
      "Iteration 255, loss = 961.67404518\n",
      "Iteration 6, loss = 5629.45204128\n",
      "Iteration 259, loss = 973.09866216\n",
      "Iteration 34, loss = 1645.28901557\n",
      "Iteration 52, loss = 1479.80769318\n",
      "Iteration 395, loss = 862.54483648\n",
      "Iteration 17, loss = 2772.22958117\n",
      "Iteration 256, loss = 957.03076691\n",
      "Iteration 49, loss = 1483.11379695\n",
      "Iteration 260, loss = 967.29735045\n",
      "Iteration 396, loss = 860.89045203\n",
      "Iteration 7, loss = 5174.09004180\n",
      "Iteration 257, loss = 957.38427371\n",
      "Iteration 35, loss = 1632.54723336\n",
      "Iteration 53, loss = 1356.48813118\n",
      "Iteration 261, loss = 964.70675593\n",
      "Iteration 18, loss = 2650.63730645\n",
      "Iteration 397, loss = 860.84014116\n",
      "Iteration 50, loss = 1505.96290749\n",
      "Iteration 258, loss = 949.71951158\n",
      "Iteration 262, loss = 962.56408540\n",
      "Iteration 8, loss = 4793.45764397\n",
      "Iteration 398, loss = 861.72034708\n",
      "Iteration 36, loss = 1601.05455657\n",
      "Iteration 259, loss = 952.80793441\n",
      "Iteration 54, loss = 1291.98884735\n",
      "Iteration 263, loss = 965.04989114\n",
      "Iteration 19, loss = 2546.70565984\n",
      "Iteration 51, loss = 1535.47400384\n",
      "Iteration 399, loss = 864.58849782\n",
      "Iteration 264, loss = 961.83308318\n",
      "Iteration 260, loss = 948.80249935\n",
      "Iteration 9, loss = 4458.63117638\n",
      "Iteration 37, loss = 1588.66601141\n",
      "Iteration 55, loss = 1342.15136962\n",
      "Iteration 400, loss = 859.22195612\n",
      "Iteration 265, loss = 960.16746978\n",
      "Iteration 261, loss = 957.04802525\n",
      "Iteration 20, loss = 2443.33584272\n",
      "Iteration 52, loss = 1535.42962649\n",
      "Iteration 401, loss = 856.55874059\n",
      "Iteration 10, loss = 4166.86527845\n",
      "Iteration 266, loss = 956.30810362\n",
      "Iteration 262, loss = 947.14546406\n",
      "Iteration 38, loss = 1589.60421708\n",
      "Iteration 56, loss = 1209.02343779\n",
      "Iteration 402, loss = 863.17746009\n",
      "Iteration 21, loss = 2340.18652215\n",
      "Iteration 267, loss = 954.85864840\n",
      "Iteration 263, loss = 945.62096037\n",
      "Iteration 53, loss = 1474.69852275\n",
      "Iteration 11, loss = 3902.44842416\n",
      "Iteration 403, loss = 855.19647676\n",
      "Iteration 268, loss = 952.09351488\n",
      "Iteration 39, loss = 1500.07756942\n",
      "Iteration 264, loss = 938.96133793\n",
      "Iteration 57, loss = 1243.60052574\n",
      "Iteration 22, loss = 2240.94979463\n",
      "Iteration 54, loss = 1499.94413461\n",
      "Iteration 404, loss = 854.76589976\n",
      "Iteration 269, loss = 951.95988805\n",
      "Iteration 265, loss = 943.01491435\n",
      "Iteration 12, loss = 3646.03008452\n",
      "Iteration 40, loss = 1583.75077841\n",
      "Iteration 405, loss = 863.96786105\n",
      "Iteration 58, loss = 1245.56098232\n",
      "Iteration 270, loss = 953.54317140\n",
      "Iteration 266, loss = 938.47079054\n",
      "Iteration 23, loss = 2201.94337170\n",
      "Iteration 55, loss = 1375.14722925\n",
      "Iteration 406, loss = 864.73114217\n",
      "Iteration 271, loss = 953.42614478\n",
      "Iteration 13, loss = 3430.99944889\n",
      "Iteration 267, loss = 938.67317556\n",
      "Iteration 41, loss = 1520.27245992\n",
      "Iteration 59, loss = 1221.28278600\n",
      "Iteration 24, loss = 2114.81873152\n",
      "Iteration 272, loss = 946.43663607\n",
      "Iteration 407, loss = 854.40311509\n",
      "Iteration 56, loss = 1461.12637009\n",
      "Iteration 268, loss = 935.92397063\n",
      "Iteration 14, loss = 3243.59119960\n",
      "Iteration 273, loss = 949.88201890\n",
      "Iteration 408, loss = 858.82587033\n",
      "Iteration 269, loss = 934.97257278\n",
      "Iteration 42, loss = 1525.20574201\n",
      "Iteration 60, loss = 1230.30380200\n",
      "Iteration 25, loss = 2032.43272625\n",
      "Iteration 57, loss = 1379.06171425\n",
      "Iteration 274, loss = 946.55571073\n",
      "Iteration 409, loss = 854.73240442\n",
      "Iteration 270, loss = 936.50279663\n",
      "Iteration 15, loss = 3048.84910370\n",
      "Iteration 275, loss = 943.99850344\n",
      "Iteration 26, loss = 2108.57759568\n",
      "Iteration 43, loss = 1442.30271347\n",
      "Iteration 410, loss = 854.45344022\n",
      "Iteration 61, loss = 1206.67133917\n",
      "Iteration 271, loss = 933.63128158\n",
      "Iteration 58, loss = 1381.52130312\n",
      "Iteration 276, loss = 939.97110840\n",
      "Iteration 411, loss = 858.31089240\n",
      "Iteration 272, loss = 929.86724140\n",
      "Iteration 16, loss = 2909.74348541\n",
      "Iteration 44, loss = 1394.64531627\n",
      "Iteration 277, loss = 945.07072836\n",
      "Iteration 59, loss = 1311.99150826\n",
      "Iteration 62, loss = 1200.72164178\n",
      "Iteration 412, loss = 855.98870524\n",
      "Iteration 273, loss = 922.33375656\n",
      "Iteration 27, loss = 1964.44457661\n",
      "Iteration 278, loss = 938.16251994\n",
      "Iteration 17, loss = 2782.98976539\n",
      "Iteration 413, loss = 852.83654306\n",
      "Iteration 274, loss = 926.15960295\n",
      "Iteration 45, loss = 1442.43340444\n",
      "Iteration 60, loss = 1346.12838653\n",
      "Iteration 63, loss = 1351.13592647\n",
      "Iteration 279, loss = 947.03038466\n",
      "Iteration 28, loss = 1915.97569172\n",
      "Iteration 275, loss = 922.07761254\n",
      "Iteration 414, loss = 854.12422583\n",
      "Iteration 18, loss = 2634.96755017\n",
      "Iteration 280, loss = 940.63428376\n",
      "Iteration 46, loss = 1487.86056635\n",
      "Iteration 276, loss = 922.43638207\n",
      "Iteration 61, loss = 1299.59448708\n",
      "Iteration 415, loss = 853.06965998\n",
      "Iteration 64, loss = 1179.20863379\n",
      "Iteration 29, loss = 1877.48978578\n",
      "Iteration 281, loss = 935.07002859\n",
      "Iteration 277, loss = 924.21833033\n",
      "Iteration 19, loss = 2594.36380883\n",
      "Iteration 47, loss = 1479.32075095\n",
      "Iteration 416, loss = 854.10506906\n",
      "Iteration 282, loss = 934.47975825\n",
      "Iteration 62, loss = 1319.42438722\n",
      "Iteration 65, loss = 1221.72975695\n",
      "Iteration 278, loss = 914.57075974\n",
      "Iteration 30, loss = 1869.01114470\n",
      "Iteration 417, loss = 852.61757136\n",
      "Iteration 283, loss = 934.28433140\n",
      "Iteration 20, loss = 2420.93124565\n",
      "Iteration 48, loss = 1468.44217351\n",
      "Iteration 279, loss = 918.57204032\n",
      "Iteration 418, loss = 848.23439229\n",
      "Iteration 284, loss = 931.91033216\n",
      "Iteration 63, loss = 1368.03453674\n",
      "Iteration 66, loss = 1252.92449578\n",
      "Iteration 31, loss = 1800.21728441\n",
      "Iteration 280, loss = 922.21041536\n",
      "Iteration 419, loss = 853.63963194\n",
      "Iteration 21, loss = 2325.44319372\n",
      "Iteration 285, loss = 926.48625134\n",
      "Iteration 49, loss = 1413.87584515\n",
      "Iteration 281, loss = 911.34531799\n",
      "Iteration 64, loss = 1362.70471607\n",
      "Iteration 67, loss = 1324.93858062\n",
      "Iteration 420, loss = 852.08738862\n",
      "Iteration 32, loss = 1794.24320657\n",
      "Iteration 286, loss = 930.71400340\n",
      "Iteration 282, loss = 908.41417772\n",
      "Iteration 22, loss = 2242.31788417\n",
      "Iteration 421, loss = 853.15561239\n",
      "Iteration 50, loss = 1415.89710870\n",
      "Iteration 287, loss = 928.36523341\n",
      "Iteration 65, loss = 1249.69453478\n",
      "Iteration 68, loss = 1183.49572124\n",
      "Iteration 283, loss = 913.25355674\n",
      "Iteration 33, loss = 1733.05335769\n",
      "Iteration 422, loss = 847.90732453\n",
      "Iteration 288, loss = 924.57169676\n",
      "Iteration 23, loss = 2163.24509611\n",
      "Iteration 284, loss = 909.00828401\n",
      "Iteration 51, loss = 1370.50573007\n",
      "Iteration 423, loss = 852.29648338\n",
      "Iteration 66, loss = 1223.31998482\n",
      "Iteration 69, loss = 1206.41861205\n",
      "Iteration 289, loss = 926.44276846\n",
      "Iteration 34, loss = 1716.76235973\n",
      "Iteration 285, loss = 909.73803549\n",
      "Iteration 424, loss = 853.82805157\n",
      "Iteration 24, loss = 2079.11685477\n",
      "Iteration 52, loss = 1358.45636657\n",
      "Iteration 290, loss = 925.13647914\n",
      "Iteration 286, loss = 906.20572694\n",
      "Iteration 70, loss = 1213.42659601\n",
      "Iteration 67, loss = 1305.96092612\n",
      "Iteration 425, loss = 846.54355760\n",
      "Iteration 35, loss = 1687.08968604\n",
      "Iteration 291, loss = 926.27114445\n",
      "Iteration 287, loss = 904.61655305\n",
      "Iteration 25, loss = 2036.90314908\n",
      "Iteration 426, loss = 846.62245828\n",
      "Iteration 53, loss = 1353.25596612\n",
      "Iteration 292, loss = 920.55551623\n",
      "Iteration 288, loss = 904.27909587\n",
      "Iteration 68, loss = 1323.12344033\n",
      "Iteration 71, loss = 1185.08605159\n",
      "Iteration 36, loss = 1699.79810857\n",
      "Iteration 427, loss = 848.08588355\n",
      "Iteration 293, loss = 924.04241109\n",
      "Iteration 26, loss = 1981.09700879\n",
      "Iteration 289, loss = 900.96790291\n",
      "Iteration 54, loss = 1344.29544708\n",
      "Iteration 428, loss = 850.02148629\n",
      "Iteration 69, loss = 1261.33445886\n",
      "Iteration 294, loss = 917.12839822\n",
      "Iteration 72, loss = 1152.48093650\n",
      "Iteration 37, loss = 1636.31014299\n",
      "Iteration 290, loss = 906.98586248\n",
      "Iteration 429, loss = 842.27141778\n",
      "Iteration 27, loss = 1909.95477254\n",
      "Iteration 295, loss = 919.76635079\n",
      "Iteration 55, loss = 1339.87743293\n",
      "Iteration 291, loss = 902.75293873\n",
      "Iteration 430, loss = 849.32098600\n",
      "Iteration 73, loss = 1151.16712263\n",
      "Iteration 38, loss = 1644.48341392\n",
      "Iteration 70, loss = 1265.43885289\n",
      "Iteration 296, loss = 920.18558856\n",
      "Iteration 292, loss = 897.99223287\n",
      "Iteration 28, loss = 1910.34984447\n",
      "Iteration 431, loss = 848.41920384\n",
      "Iteration 56, loss = 1396.40523801\n",
      "Iteration 297, loss = 911.08170009\n",
      "Iteration 39, loss = 1626.07490810\n",
      "Iteration 293, loss = 901.83208611\n",
      "Iteration 74, loss = 1188.17146968\n",
      "Iteration 71, loss = 1291.79238340\n",
      "Iteration 432, loss = 845.26660663\n",
      "Iteration 298, loss = 916.79036011\n",
      "Iteration 29, loss = 1875.05323503\n",
      "Iteration 294, loss = 895.72022963\n",
      "Iteration 57, loss = 1454.75435634\n",
      "Iteration 433, loss = 835.27007459\n",
      "Iteration 299, loss = 912.53806227\n",
      "Iteration 40, loss = 1593.70069069\n",
      "Iteration 75, loss = 1182.44980212\n",
      "Iteration 72, loss = 1186.44800042\n",
      "Iteration 295, loss = 891.23561110\n",
      "Iteration 30, loss = 1804.51513863\n",
      "Iteration 434, loss = 842.21745708\n",
      "Iteration 300, loss = 912.47466059\n",
      "Iteration 58, loss = 1438.11739567\n",
      "Iteration 296, loss = 897.95540397\n",
      "Iteration 41, loss = 1632.11442492\n",
      "Iteration 435, loss = 850.86581971\n",
      "Iteration 76, loss = 1208.16194496\n",
      "Iteration 301, loss = 911.48234131\n",
      "Iteration 73, loss = 1196.50380963\n",
      "Iteration 297, loss = 891.94024745\n",
      "Iteration 31, loss = 1785.40049361\n",
      "Iteration 436, loss = 839.71935574\n",
      "Iteration 302, loss = 912.29778111\n",
      "Iteration 59, loss = 1327.96313940\n",
      "Iteration 42, loss = 1551.14986949\n",
      "Iteration 298, loss = 891.84569024\n",
      "Iteration 77, loss = 1252.75222658\n",
      "Iteration 74, loss = 1260.25247099\n",
      "Iteration 437, loss = 841.98521409\n",
      "Iteration 303, loss = 909.96733841\n",
      "Iteration 32, loss = 1771.37936134\n",
      "Iteration 299, loss = 885.04979948\n",
      "Iteration 60, loss = 1319.78042427\n",
      "Iteration 438, loss = 842.24577601\n",
      "Iteration 304, loss = 907.81018439\n",
      "Iteration 43, loss = 1562.98625047\n",
      "Iteration 75, loss = 1258.30732097\n",
      "Iteration 78, loss = 1190.83612811\n",
      "Iteration 300, loss = 891.12917805\n",
      "Iteration 439, loss = 843.26108618\n",
      "Iteration 305, loss = 911.15738537\n",
      "Iteration 33, loss = 1735.61275806\n",
      "Iteration 61, loss = 1329.62163007\n",
      "Iteration 301, loss = 887.89607841\n",
      "Iteration 306, loss = 909.49428639\n",
      "Iteration 440, loss = 840.91346824\n",
      "Iteration 44, loss = 1500.86350737\n",
      "Iteration 76, loss = 1222.93163604\n",
      "Iteration 79, loss = 1190.87220715\n",
      "Iteration 34, loss = 1757.59261959\n",
      "Iteration 302, loss = 888.27176154\n",
      "Iteration 441, loss = 837.31602936\n",
      "Iteration 307, loss = 904.24708221\n",
      "Iteration 62, loss = 1319.96035690\n",
      "Iteration 303, loss = 884.76431491\n",
      "Iteration 77, loss = 1169.59852043\n",
      "Iteration 45, loss = 1552.82877785\n",
      "Iteration 308, loss = 902.76337742\n",
      "Iteration 442, loss = 843.27379301\n",
      "Iteration 80, loss = 1202.25190972\n",
      "Iteration 35, loss = 1658.50113195\n",
      "Iteration 304, loss = 879.11465499\n",
      "Iteration 309, loss = 904.46496050\n",
      "Iteration 63, loss = 1332.35492414\n",
      "Iteration 443, loss = 837.90274843\n",
      "Iteration 46, loss = 1509.01870778\n",
      "Iteration 78, loss = 1238.35701255\n",
      "Iteration 305, loss = 883.94324493\n",
      "Iteration 81, loss = 1201.86205027\n",
      "Iteration 310, loss = 903.56458984\n",
      "Iteration 36, loss = 1686.85457201\n",
      "Iteration 444, loss = 838.02405226\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 64, loss = 1299.77038718\n",
      "Iteration 306, loss = 882.72035802\n",
      "Iteration 47, loss = 1426.39167760\n",
      "Iteration 311, loss = 899.52402574\n",
      "Iteration 79, loss = 1215.62559653\n",
      "Iteration 82, loss = 1212.23692852\n",
      "Iteration 307, loss = 875.81071368\n",
      "Iteration 37, loss = 1568.50676682\n",
      "Iteration 312, loss = 899.39194862\n",
      "Iteration 65, loss = 1294.97560935\n",
      "Iteration 1, loss = 10584.58715442\n",
      "Iteration 308, loss = 877.06309376\n",
      "Iteration 48, loss = 1434.04204850\n",
      "Iteration 313, loss = 899.01703932\n",
      "Iteration 80, loss = 1236.10772864\n",
      "Iteration 83, loss = 1201.45722177\n",
      "Iteration 38, loss = 1614.67590549\n",
      "Iteration 309, loss = 877.72014772\n",
      "Iteration 314, loss = 897.54322098\n",
      "Iteration 49, loss = 1442.86973321\n",
      "Iteration 2, loss = 8676.23932278\n",
      "Iteration 66, loss = 1319.95239401\n",
      "Iteration 310, loss = 880.92092685\n",
      "Iteration 81, loss = 1328.54843711\n",
      "Iteration 315, loss = 897.40244722\n",
      "Iteration 84, loss = 1123.65363849\n",
      "Iteration 39, loss = 1631.15903191\n",
      "Iteration 311, loss = 875.22132242\n",
      "Iteration 50, loss = 1421.90644063\n",
      "Iteration 316, loss = 897.24334839\n",
      "Iteration 3, loss = 7550.24867827\n",
      "Iteration 67, loss = 1219.50900757\n",
      "Iteration 312, loss = 877.50185148\n",
      "Iteration 82, loss = 1441.67479817\n",
      "Iteration 85, loss = 1201.15525758\n",
      "Iteration 317, loss = 893.11902886\n",
      "Iteration 40, loss = 1560.21768153\n",
      "Iteration 51, loss = 1430.67002969\n",
      "Iteration 313, loss = 873.07773682\n",
      "Iteration 318, loss = 896.98043648\n",
      "Iteration 4, loss = 6742.76970437\n",
      "Iteration 68, loss = 1340.83440313\n",
      "Iteration 83, loss = 1292.74186039\n",
      "Iteration 314, loss = 873.69553764\n",
      "Iteration 86, loss = 1195.78170668\n",
      "Iteration 41, loss = 1509.08620843\n",
      "Iteration 319, loss = 888.64321361\n",
      "Iteration 52, loss = 1379.50473496\n",
      "Iteration 315, loss = 871.91053200\n",
      "Iteration 5, loss = 6102.84737909\n",
      "Iteration 69, loss = 1232.70121048\n",
      "Iteration 84, loss = 1235.20043009\n",
      "Iteration 320, loss = 896.42736385\n",
      "Iteration 87, loss = 1427.38580544\n",
      "Iteration 42, loss = 1567.06556383\n",
      "Iteration 316, loss = 871.34968469\n",
      "Iteration 321, loss = 889.06864732\n",
      "Iteration 53, loss = 1409.24964206\n",
      "Iteration 6, loss = 5554.71044698\n",
      "Iteration 70, loss = 1310.70594010\n",
      "Iteration 317, loss = 868.86186862\n",
      "Iteration 85, loss = 1193.46187673\n",
      "Iteration 322, loss = 890.44907859\n",
      "Iteration 88, loss = 1187.52037193\n",
      "Iteration 43, loss = 1459.17103465\n",
      "Iteration 318, loss = 866.93643920\n",
      "Iteration 54, loss = 1396.36193037\n",
      "Iteration 323, loss = 889.39993570\n",
      "Iteration 71, loss = 1389.85089482\n",
      "Iteration 7, loss = 5130.02805115\n",
      "Iteration 86, loss = 1160.30133948\n",
      "Iteration 319, loss = 864.46541583\n",
      "Iteration 44, loss = 1479.19872868\n",
      "Iteration 89, loss = 1248.96592452\n",
      "Iteration 324, loss = 886.86808546\n",
      "Iteration 55, loss = 1366.09429455\n",
      "Iteration 320, loss = 866.18132263\n",
      "Iteration 325, loss = 890.88825658\n",
      "Iteration 72, loss = 1354.07730877\n",
      "Iteration 8, loss = 4759.18938713\n",
      "Iteration 87, loss = 1273.45535930\n",
      "Iteration 45, loss = 1470.14648743\n",
      "Iteration 90, loss = 1109.63810617\n",
      "Iteration 321, loss = 864.90278546\n",
      "Iteration 326, loss = 884.71003664\n",
      "Iteration 56, loss = 1426.12282585\n",
      "Iteration 322, loss = 862.71124655\n",
      "Iteration 327, loss = 884.55743887\n",
      "Iteration 9, loss = 4410.74459226\n",
      "Iteration 73, loss = 1317.94224159\n",
      "Iteration 91, loss = 1126.99875076\n",
      "Iteration 46, loss = 1465.15840038\n",
      "Iteration 88, loss = 1313.28211813\n",
      "Iteration 323, loss = 861.48428525\n",
      "Iteration 328, loss = 883.74682538\n",
      "Iteration 57, loss = 1423.96564957\n",
      "Iteration 10, loss = 4128.81547380\n",
      "Iteration 324, loss = 860.37526342\n",
      "Iteration 74, loss = 1404.27450326\n",
      "Iteration 329, loss = 885.78751193\n",
      "Iteration 92, loss = 1183.35570513\n",
      "Iteration 47, loss = 1416.06947672\n",
      "Iteration 89, loss = 1260.83431711\n",
      "Iteration 58, loss = 1477.95969070\n",
      "Iteration 330, loss = 879.69063899\n",
      "Iteration 325, loss = 864.06228627\n",
      "Iteration 11, loss = 3847.30476608\n",
      "Iteration 75, loss = 1237.61154227\n",
      "Iteration 93, loss = 1155.21762529\n",
      "Iteration 90, loss = 1204.45215400\n",
      "Iteration 48, loss = 1395.80610813\n",
      "Iteration 331, loss = 880.33336539\n",
      "Iteration 326, loss = 862.43927543\n",
      "Iteration 59, loss = 1368.41652675\n",
      "Iteration 332, loss = 880.90089796\n",
      "Iteration 327, loss = 860.99779912\n",
      "Iteration 12, loss = 3623.09623994\n",
      "Iteration 76, loss = 1348.61471810\n",
      "Iteration 94, loss = 1140.02812789\n",
      "Iteration 91, loss = 1156.16166702\n",
      "Iteration 49, loss = 1419.56168799\n",
      "Iteration 333, loss = 880.49592040\n",
      "Iteration 328, loss = 857.80073956\n",
      "Iteration 60, loss = 1378.23972798\n",
      "Iteration 13, loss = 3389.44133667\n",
      "Iteration 334, loss = 882.99687187\n",
      "Iteration 329, loss = 856.28758354\n",
      "Iteration 77, loss = 1357.19567298\n",
      "Iteration 95, loss = 1166.05926443\n",
      "Iteration 92, loss = 1203.42044530\n",
      "Iteration 50, loss = 1449.09553108\n",
      "Iteration 335, loss = 872.75567212\n",
      "Iteration 330, loss = 854.20835016\n",
      "Iteration 61, loss = 1368.90968158\n",
      "Iteration 14, loss = 3226.21921160\n",
      "Iteration 78, loss = 1371.92443951\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 96, loss = 1173.94636618\n",
      "Iteration 336, loss = 879.65926644\n",
      "Iteration 331, loss = 850.10657739\n",
      "Iteration 93, loss = 1234.37384493\n",
      "Iteration 51, loss = 1431.12786747\n",
      "Iteration 62, loss = 1376.04433118\n",
      "Iteration 337, loss = 877.97867971\n",
      "Iteration 332, loss = 859.21661171\n",
      "Iteration 15, loss = 3062.45798953\n",
      "Iteration 97, loss = 1118.58714703\n",
      "Iteration 94, loss = 1316.02347379\n",
      "Iteration 338, loss = 873.44458067\n",
      "Iteration 1, loss = 11616.63728788\n",
      "Iteration 52, loss = 1424.66187538\n",
      "Iteration 333, loss = 866.51086148\n",
      "Iteration 63, loss = 1459.13566403\n",
      "Iteration 339, loss = 875.09866858\n",
      "Iteration 334, loss = 855.48216198\n",
      "Iteration 16, loss = 2922.14904867\n",
      "Iteration 98, loss = 1135.76968629\n",
      "Iteration 95, loss = 1224.99672669\n",
      "Iteration 53, loss = 1425.84476692\n",
      "Iteration 2, loss = 11229.88777145\n",
      "Iteration 340, loss = 872.37503637\n",
      "Iteration 335, loss = 852.40248678\n",
      "Iteration 64, loss = 1413.09900675\n",
      "Iteration 341, loss = 869.03250980\n",
      "Iteration 17, loss = 2764.72258454\n",
      "Iteration 99, loss = 1113.38505375\n",
      "Iteration 96, loss = 1134.44630220\n",
      "Iteration 336, loss = 848.63743624\n",
      "Iteration 54, loss = 1394.82993826\n",
      "Iteration 3, loss = 10922.99930056\n",
      "Iteration 342, loss = 871.17480841\n",
      "Iteration 65, loss = 1362.00644037\n",
      "Iteration 337, loss = 850.49480722\n",
      "Iteration 18, loss = 2630.91225111\n",
      "Iteration 100, loss = 1129.42064794\n",
      "Iteration 343, loss = 873.57492257\n",
      "Iteration 97, loss = 1169.45757063\n",
      "Iteration 55, loss = 1389.89238456\n",
      "Iteration 338, loss = 848.62631334\n",
      "Iteration 4, loss = 10669.73463367\n",
      "Iteration 66, loss = 1323.55199399\n",
      "Iteration 344, loss = 872.09309013\n",
      "Iteration 101, loss = 1137.48135280\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 339, loss = 849.11720703\n",
      "Iteration 19, loss = 2594.82024873\n",
      "Iteration 98, loss = 1207.49843885\n",
      "Iteration 56, loss = 1323.85595548\n",
      "Iteration 345, loss = 864.72357849\n",
      "Iteration 5, loss = 10431.65374918\n",
      "Iteration 340, loss = 850.33018036\n",
      "Iteration 67, loss = 1299.15657619\n",
      "Iteration 346, loss = 867.44461691\n",
      "Iteration 20, loss = 2414.84947212\n",
      "Iteration 341, loss = 845.27789477\n",
      "Iteration 99, loss = 1248.41798306\n",
      "Iteration 1, loss = 12019.64819403\n",
      "Iteration 57, loss = 1333.67785239\n",
      "Iteration 347, loss = 867.48774421\n",
      "Iteration 6, loss = 10107.84594074\n",
      "Iteration 68, loss = 1378.62410379\n",
      "Iteration 342, loss = 846.65458909\n",
      "Iteration 348, loss = 866.59692196\n",
      "Iteration 21, loss = 2317.02749312\n",
      "Iteration 100, loss = 1157.10239845\n",
      "Iteration 343, loss = 849.96435206\n",
      "Iteration 2, loss = 11627.03343831\n",
      "Iteration 58, loss = 1328.25041777\n",
      "Iteration 349, loss = 868.21738625\n",
      "Iteration 7, loss = 9850.10502050\n",
      "Iteration 69, loss = 1258.43022620\n",
      "Iteration 344, loss = 849.36160915\n",
      "Iteration 350, loss = 863.24100647\n",
      "Iteration 22, loss = 2236.33016692\n",
      "Iteration 101, loss = 1329.33949984\n",
      "Iteration 59, loss = 1306.12627897\n",
      "Iteration 3, loss = 11315.06150514\n",
      "Iteration 8, loss = 9618.49650216\n",
      "Iteration 70, loss = 1288.35764663\n",
      "Iteration 345, loss = 839.89309554\n",
      "Iteration 351, loss = 858.38087625\n",
      "Iteration 23, loss = 2185.03311338\n",
      "Iteration 60, loss = 1325.85019153\n",
      "Iteration 352, loss = 864.22666375\n",
      "Iteration 346, loss = 845.14927849\n",
      "Iteration 4, loss = 11057.10997975\n",
      "Iteration 102, loss = 1210.92748830\n",
      "Iteration 71, loss = 1306.16314462\n",
      "Iteration 9, loss = 9403.81186307\n",
      "Iteration 347, loss = 843.62215866\n",
      "Iteration 353, loss = 869.65927404\n",
      "Iteration 61, loss = 1330.66449879\n",
      "Iteration 24, loss = 2120.85320163\n",
      "Iteration 5, loss = 10834.57251527\n",
      "Iteration 103, loss = 1181.17646467\n",
      "Iteration 72, loss = 1281.60437384\n",
      "Iteration 348, loss = 838.06283344\n",
      "Iteration 354, loss = 863.22211426\n",
      "Iteration 10, loss = 9202.80811690\n",
      "Iteration 62, loss = 1312.26067203\n",
      "Iteration 349, loss = 845.76065187\n",
      "Iteration 355, loss = 863.17200950\n",
      "Iteration 25, loss = 2063.91981179\n",
      "Iteration 73, loss = 1258.05369145\n",
      "Iteration 104, loss = 1104.47418847\n",
      "Iteration 6, loss = 10495.93007347\n",
      "Iteration 11, loss = 9013.33935833\n",
      "Iteration 350, loss = 838.85213585\n",
      "Iteration 356, loss = 857.52695153\n",
      "Iteration 63, loss = 1316.67137910\n",
      "Iteration 26, loss = 2060.13837759\n",
      "Iteration 74, loss = 1334.97858359\n",
      "Iteration 351, loss = 841.16494490\n",
      "Iteration 357, loss = 862.52135332\n",
      "Iteration 7, loss = 10229.68628234\n",
      "Iteration 105, loss = 1183.75597500\n",
      "Iteration 12, loss = 8832.84025708\n",
      "Iteration 352, loss = 838.21893201\n",
      "Iteration 358, loss = 854.55524578\n",
      "Iteration 64, loss = 1356.72858851\n",
      "Iteration 27, loss = 1997.06420372\n",
      "Iteration 75, loss = 1327.41116841\n",
      "Iteration 353, loss = 841.96668520\n",
      "Iteration 8, loss = 9992.40274900\n",
      "Iteration 106, loss = 1181.08379110\n",
      "Iteration 359, loss = 862.45621226\n",
      "Iteration 13, loss = 8660.77760057\n",
      "Iteration 354, loss = 834.81637218\n",
      "Iteration 65, loss = 1299.10303383\n",
      "Iteration 360, loss = 859.53943367\n",
      "Iteration 76, loss = 1269.91052062\n",
      "Iteration 28, loss = 1898.06771733\n",
      "Iteration 9, loss = 9772.66922698\n",
      "Iteration 107, loss = 1198.37943612\n",
      "Iteration 14, loss = 8496.50206293\n",
      "Iteration 355, loss = 836.91530946\n",
      "Iteration 361, loss = 853.96558335\n",
      "Iteration 66, loss = 1337.29452921\n",
      "Iteration 356, loss = 833.18177302\n",
      "Iteration 77, loss = 1327.74866196\n",
      "Iteration 29, loss = 1856.25534145\n",
      "Iteration 362, loss = 857.91733566\n",
      "Iteration 10, loss = 9567.21652699\n",
      "Iteration 108, loss = 1170.91549075\n",
      "Iteration 15, loss = 8339.09536817\n",
      "Iteration 357, loss = 833.21149205\n",
      "Iteration 363, loss = 858.97052893\n",
      "Iteration 67, loss = 1408.72268822\n",
      "Iteration 78, loss = 1264.29770355\n",
      "Iteration 30, loss = 1828.43716492\n",
      "Iteration 358, loss = 832.71099782\n",
      "Iteration 11, loss = 9373.35763591\n",
      "Iteration 16, loss = 8188.35397433\n",
      "Iteration 364, loss = 857.86362217\n",
      "Iteration 109, loss = 1191.12315219\n",
      "Iteration 359, loss = 836.02566378\n",
      "Iteration 68, loss = 1406.71670025\n",
      "Iteration 365, loss = 850.78858343\n",
      "Iteration 79, loss = 1315.48886160\n",
      "Iteration 31, loss = 1861.53027157\n",
      "Iteration 360, loss = 830.41540190\n",
      "Iteration 12, loss = 9188.83697168\n",
      "Iteration 17, loss = 8044.54040535\n",
      "Iteration 110, loss = 1115.43215901\n",
      "Iteration 366, loss = 851.42968215\n",
      "Iteration 69, loss = 1318.61537467\n",
      "Iteration 361, loss = 832.92460054\n",
      "Iteration 80, loss = 1198.49970150\n",
      "Iteration 367, loss = 851.53809085\n",
      "Iteration 32, loss = 1786.79603276\n",
      "Iteration 18, loss = 7904.86721948\n",
      "Iteration 111, loss = 1117.72529343\n",
      "Iteration 13, loss = 9012.66020133\n",
      "Iteration 362, loss = 829.32915346\n",
      "Iteration 368, loss = 852.17575715\n",
      "Iteration 70, loss = 1237.83469185\n",
      "Iteration 363, loss = 827.75609586\n",
      "Iteration 81, loss = 1359.45705629\n",
      "Iteration 369, loss = 850.40749281\n",
      "Iteration 33, loss = 1750.67713101\n",
      "Iteration 112, loss = 1121.78350763\n",
      "Iteration 19, loss = 7770.79145099\n",
      "Iteration 14, loss = 8844.15335803\n",
      "Iteration 364, loss = 829.46693309\n",
      "Iteration 370, loss = 859.20505413\n",
      "Iteration 71, loss = 1295.86272900\n",
      "Iteration 82, loss = 1312.40241735\n",
      "Iteration 365, loss = 830.26747207\n",
      "Iteration 113, loss = 1135.56797903\n",
      "Iteration 34, loss = 1736.06199385\n",
      "Iteration 371, loss = 854.68711052\n",
      "Iteration 20, loss = 7641.91171288\n",
      "Iteration 15, loss = 8683.27545017\n",
      "Iteration 366, loss = 829.73673931\n",
      "Iteration 72, loss = 1331.55167150\n",
      "Iteration 372, loss = 854.19238444\n",
      "Iteration 83, loss = 1232.28898746\n",
      "Iteration 114, loss = 1220.41348916\n",
      "Iteration 35, loss = 1683.42383783\n",
      "Iteration 367, loss = 825.25060922\n",
      "Iteration 21, loss = 7517.28509657\n",
      "Iteration 16, loss = 8529.04654144\n",
      "Iteration 373, loss = 851.12623115\n",
      "Iteration 73, loss = 1342.59353071\n",
      "Iteration 368, loss = 827.49342557\n",
      "Iteration 84, loss = 1257.26494511\n",
      "Iteration 115, loss = 1233.51837307Iteration 374, loss = 848.57022335\n",
      "\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 1680.30008685\n",
      "Iteration 22, loss = 7395.52197446\n",
      "Iteration 369, loss = 827.48210234\n",
      "Iteration 17, loss = 8380.92722229\n",
      "Iteration 375, loss = 850.09954281\n",
      "Iteration 74, loss = 1276.22543620\n",
      "Iteration 85, loss = 1306.36577532\n",
      "Iteration 370, loss = 832.01613040\n",
      "Iteration 37, loss = 1657.94056629\n",
      "Iteration 376, loss = 845.93604332\n",
      "Iteration 23, loss = 7277.53805376\n",
      "Iteration 1, loss = 11727.77243996\n",
      "Iteration 18, loss = 8236.96305127\n",
      "Iteration 371, loss = 828.90134702\n",
      "Iteration 75, loss = 1249.22222377\n",
      "Iteration 377, loss = 845.51305066\n",
      "Iteration 86, loss = 1297.32851919\n",
      "Iteration 372, loss = 825.17989817\n",
      "Iteration 38, loss = 1645.21110239\n",
      "Iteration 24, loss = 7163.98500026\n",
      "Iteration 378, loss = 847.19948534\n",
      "Iteration 2, loss = 11331.22610586\n",
      "Iteration 19, loss = 8098.74331547\n",
      "Iteration 76, loss = 1297.44850050\n",
      "Iteration 373, loss = 820.16542143\n",
      "Iteration 379, loss = 849.97970332\n",
      "Iteration 87, loss = 1387.99518764\n",
      "Iteration 39, loss = 1679.34035027\n",
      "Iteration 25, loss = 7054.37405757\n",
      "Iteration 374, loss = 820.18004119\n",
      "Iteration 380, loss = 850.14571361\n",
      "Iteration 20, loss = 7966.03908379\n",
      "Iteration 3, loss = 11019.71456606\n",
      "Iteration 77, loss = 1330.56497322\n",
      "Iteration 88, loss = 1292.20071016\n",
      "Iteration 375, loss = 823.02754042\n",
      "Iteration 381, loss = 851.26019319\n",
      "Iteration 40, loss = 1613.74238517\n",
      "Iteration 26, loss = 6946.84742405\n",
      "Iteration 21, loss = 7837.60955907\n",
      "Iteration 376, loss = 820.24568903\n",
      "Iteration 4, loss = 10761.32637667\n",
      "Iteration 382, loss = 842.65418719\n",
      "Iteration 78, loss = 1253.93481616\n",
      "Iteration 89, loss = 1349.46093669\n",
      "Iteration 377, loss = 821.46091510\n",
      "Iteration 41, loss = 1608.49392417\n",
      "Iteration 383, loss = 842.38905383\n",
      "Iteration 27, loss = 6843.26861637\n",
      "Iteration 22, loss = 7712.88061535\n",
      "Iteration 5, loss = 10537.30282616\n",
      "Iteration 90, loss = 1246.53503934\n",
      "Iteration 384, loss = 836.58460597\n",
      "Iteration 378, loss = 818.13837695\n",
      "Iteration 79, loss = 1258.39108691\n",
      "Iteration 42, loss = 1540.70043904\n",
      "Iteration 28, loss = 6743.21065609\n",
      "Iteration 385, loss = 838.01765137\n",
      "Iteration 379, loss = 827.93301014\n",
      "Iteration 23, loss = 7591.58872470\n",
      "Iteration 6, loss = 10199.08734166\n",
      "Iteration 91, loss = 1313.78802609\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 80, loss = 1232.31901901\n",
      "Iteration 386, loss = 838.92638766\n",
      "Iteration 380, loss = 826.43719755\n",
      "Iteration 29, loss = 6645.02383667\n",
      "Iteration 43, loss = 1549.97265008\n",
      "Iteration 24, loss = 7474.99912220\n",
      "Iteration 387, loss = 838.08776030\n",
      "Iteration 7, loss = 9934.54596214\n",
      "Iteration 381, loss = 821.25281044\n",
      "Iteration 1, loss = 12023.20805827\n",
      "Iteration 81, loss = 1229.42889631\n",
      "Iteration 388, loss = 843.77157182\n",
      "Iteration 30, loss = 6549.68776695\n",
      "Iteration 44, loss = 1620.74523192\n",
      "Iteration 382, loss = 817.05717747\n",
      "Iteration 25, loss = 7362.47585194\n",
      "Iteration 8, loss = 9697.84646001\n",
      "Iteration 389, loss = 837.38427453\n",
      "Iteration 383, loss = 819.68859293\n",
      "Iteration 82, loss = 1236.72719639\n",
      "Iteration 2, loss = 11626.91500419\n",
      "Iteration 45, loss = 1575.21153412\n",
      "Iteration 390, loss = 838.53155293\n",
      "Iteration 31, loss = 6456.58546570\n",
      "Iteration 384, loss = 815.77379838\n",
      "Iteration 26, loss = 7251.94814816\n",
      "Iteration 9, loss = 9479.67237109\n",
      "Iteration 391, loss = 836.05688546\n",
      "Iteration 83, loss = 1209.39806916\n",
      "Iteration 385, loss = 812.57429382\n",
      "Iteration 3, loss = 11314.87721807\n",
      "Iteration 46, loss = 1498.43035224\n",
      "Iteration 32, loss = 6366.68651297\n",
      "Iteration 392, loss = 842.17906089\n",
      "Iteration 27, loss = 7144.88865957\n",
      "Iteration 10, loss = 9276.06938658\n",
      "Iteration 386, loss = 816.40051504\n",
      "Iteration 84, loss = 1236.24967540\n",
      "Iteration 393, loss = 834.73714511\n",
      "Iteration 4, loss = 11055.62774902\n",
      "Iteration 47, loss = 1530.80323360\n",
      "Iteration 387, loss = 810.65505802\n",
      "Iteration 33, loss = 6280.47333651\n",
      "Iteration 28, loss = 7041.93482241\n",
      "Iteration 11, loss = 9083.17582492\n",
      "Iteration 394, loss = 837.55027468\n",
      "Iteration 388, loss = 812.51007770\n",
      "Iteration 85, loss = 1206.45943128\n",
      "Iteration 5, loss = 10841.42626635\n",
      "Iteration 48, loss = 1483.10602885\n",
      "Iteration 395, loss = 837.59019853\n",
      "Iteration 389, loss = 815.03263639\n",
      "Iteration 34, loss = 6196.50133568\n",
      "Iteration 12, loss = 8899.46874750\n",
      "Iteration 29, loss = 6940.60919290\n",
      "Iteration 396, loss = 835.48033989\n",
      "Iteration 86, loss = 1207.90439752\n",
      "Iteration 390, loss = 811.98321804\n",
      "Iteration 6, loss = 10546.26174826\n",
      "Iteration 49, loss = 1400.36745479\n",
      "Iteration 397, loss = 833.95477031\n",
      "Iteration 35, loss = 6112.63590692\n",
      "Iteration 391, loss = 811.28524282\n",
      "Iteration 13, loss = 8725.32982884\n",
      "Iteration 30, loss = 6842.15354524\n",
      "Iteration 87, loss = 1268.69024292\n",
      "Iteration 398, loss = 836.94819876\n",
      "Iteration 7, loss = 10241.35983129\n",
      "Iteration 392, loss = 814.97613916\n",
      "Iteration 50, loss = 1490.37030266\n",
      "Iteration 14, loss = 8558.37635919\n",
      "Iteration 36, loss = 6031.61511412\n",
      "Iteration 399, loss = 838.90935685\n",
      "Iteration 31, loss = 6747.43876669\n",
      "Iteration 393, loss = 809.45405555\n",
      "Iteration 88, loss = 1216.29484603\n",
      "Iteration 400, loss = 833.26539967\n",
      "Iteration 8, loss = 9999.18435238\n",
      "Iteration 51, loss = 1445.66294939\n",
      "Iteration 394, loss = 810.21708318\n",
      "Iteration 15, loss = 8399.37273539\n",
      "Iteration 37, loss = 5952.98028393\n",
      "Iteration 401, loss = 830.39383292\n",
      "Iteration 32, loss = 6652.68115553\n",
      "Iteration 89, loss = 1214.65032217\n",
      "Iteration 395, loss = 808.51474143\n",
      "Iteration 9, loss = 9777.70383279\n",
      "Iteration 402, loss = 836.59696948\n",
      "Iteration 52, loss = 1372.23816552\n",
      "Iteration 16, loss = 8245.34810178\n",
      "Iteration 396, loss = 813.95803520\n",
      "Iteration 38, loss = 5877.83890997\n",
      "Iteration 90, loss = 1195.02525909\n",
      "Iteration 33, loss = 6563.17629209\n",
      "Iteration 403, loss = 830.43214901\n",
      "Iteration 397, loss = 810.15990701\n",
      "Iteration 10, loss = 9572.10822845\n",
      "Iteration 404, loss = 830.42894074\n",
      "Iteration 53, loss = 1450.15751444\n",
      "Iteration 17, loss = 8097.84749514\n",
      "Iteration 398, loss = 807.57166301\n",
      "Iteration 34, loss = 6476.16718955\n",
      "Iteration 39, loss = 5802.94424214\n",
      "Iteration 91, loss = 1202.20255126\n",
      "Iteration 405, loss = 837.72201046\n",
      "Iteration 11, loss = 9377.37876410\n",
      "Iteration 399, loss = 813.62640175\n",
      "Iteration 54, loss = 1394.79263669\n",
      "Iteration 406, loss = 834.51201070\n",
      "Iteration 18, loss = 7955.46774350\n",
      "Iteration 35, loss = 6389.42203737\n",
      "Iteration 40, loss = 5729.45822808\n",
      "Iteration 92, loss = 1266.85735525\n",
      "Iteration 400, loss = 806.92551717\n",
      "Iteration 12, loss = 9191.80946868\n",
      "Iteration 407, loss = 836.40073535\n",
      "Iteration 401, loss = 806.41203864\n",
      "Iteration 55, loss = 1352.89050965\n",
      "Iteration 19, loss = 7817.79327164\n",
      "Iteration 36, loss = 6307.02211864\n",
      "Iteration 93, loss = 1235.57285934\n",
      "Iteration 408, loss = 833.68443538\n",
      "Iteration 41, loss = 5658.37040091\n",
      "Iteration 402, loss = 810.29738321\n",
      "Iteration 13, loss = 9016.62996089\n",
      "Iteration 409, loss = 829.01484257\n",
      "Iteration 56, loss = 1305.79328549\n",
      "Iteration 20, loss = 7685.05359742\n",
      "Iteration 403, loss = 804.76928376\n",
      "Iteration 37, loss = 6226.26223403\n",
      "Iteration 94, loss = 1230.31710296\n",
      "Iteration 42, loss = 5590.34469182\n",
      "Iteration 410, loss = 829.67302472\n",
      "Iteration 14, loss = 8848.01073366\n",
      "Iteration 404, loss = 803.44261052\n",
      "Iteration 57, loss = 1328.63972836\n",
      "Iteration 411, loss = 827.75609136\n",
      "Iteration 21, loss = 7557.28925374\n",
      "Iteration 38, loss = 6147.06730675\n",
      "Iteration 95, loss = 1168.92240345\n",
      "Iteration 405, loss = 807.93701197\n",
      "Iteration 43, loss = 5521.86257783\n",
      "Iteration 412, loss = 825.35165627\n",
      "Iteration 15, loss = 8687.58915737\n",
      "Iteration 406, loss = 808.21021373\n",
      "Iteration 39, loss = 6070.44634789\n",
      "Iteration 58, loss = 1320.66754639\n",
      "Iteration 22, loss = 7434.79548581\n",
      "Iteration 413, loss = 824.72865647\n",
      "Iteration 96, loss = 1223.63295262\n",
      "Iteration 44, loss = 5457.41126925\n",
      "Iteration 407, loss = 806.04212710\n",
      "Iteration 414, loss = 827.93302466\n",
      "Iteration 16, loss = 8532.70582618\n",
      "Iteration 59, loss = 1273.37116592\n",
      "Iteration 408, loss = 805.61507568\n",
      "Iteration 40, loss = 5996.30481992\n",
      "Iteration 97, loss = 1171.28459511\n",
      "Iteration 23, loss = 7315.43402005\n",
      "Iteration 415, loss = 823.90866469\n",
      "Iteration 45, loss = 5390.67227032\n",
      "Iteration 409, loss = 806.37361838\n",
      "Iteration 17, loss = 8383.95096422\n",
      "Iteration 416, loss = 830.12746327\n",
      "Iteration 60, loss = 1348.80432787\n",
      "Iteration 41, loss = 5922.87712676\n",
      "Iteration 98, loss = 1206.29032690\n",
      "Iteration 410, loss = 803.09532583\n",
      "Iteration 24, loss = 7199.15016111\n",
      "Iteration 46, loss = 5329.27290380\n",
      "Iteration 417, loss = 827.38399483\n",
      "Iteration 411, loss = 803.94658928\n",
      "Iteration 18, loss = 8241.59631188\n",
      "Iteration 61, loss = 1330.78925013\n",
      "Iteration 42, loss = 5852.00771145\n",
      "Iteration 418, loss = 822.78999378\n",
      "Iteration 99, loss = 1210.92048406\n",
      "Iteration 25, loss = 7086.39275194\n",
      "Iteration 412, loss = 803.59885025\n",
      "Iteration 47, loss = 5267.56133088\n",
      "Iteration 419, loss = 824.78686095\n",
      "Iteration 43, loss = 5782.92710155\n",
      "Iteration 413, loss = 801.05050016\n",
      "Iteration 62, loss = 1411.29713824\n",
      "Iteration 19, loss = 8103.55924181\n",
      "Iteration 420, loss = 822.01042598\n",
      "Iteration 100, loss = 1368.49458214\n",
      "Iteration 26, loss = 6975.94565978\n",
      "Iteration 48, loss = 5207.49877707\n",
      "Iteration 414, loss = 799.70131108\n",
      "Iteration 421, loss = 828.66419770\n",
      "Iteration 44, loss = 5716.41749152\n",
      "Iteration 63, loss = 1290.21111166\n",
      "Iteration 415, loss = 799.56210536\n",
      "Iteration 20, loss = 7970.32234375\n",
      "Iteration 422, loss = 822.30475686\n",
      "Iteration 101, loss = 1309.44349182\n",
      "Iteration 27, loss = 6869.78418510\n",
      "Iteration 49, loss = 5148.70629059\n",
      "Iteration 416, loss = 798.40918028\n",
      "Iteration 423, loss = 828.21700834\n",
      "Iteration 45, loss = 5647.31341406\n",
      "Iteration 64, loss = 1346.58965974\n",
      "Iteration 21, loss = 7842.04227642\n",
      "Iteration 102, loss = 1225.91484391\n",
      "Iteration 417, loss = 798.71289480\n",
      "Iteration 28, loss = 6766.06924744\n",
      "Iteration 424, loss = 825.41524000\n",
      "Iteration 50, loss = 5090.71330374\n",
      "Iteration 418, loss = 797.19011741\n",
      "Iteration 46, loss = 5580.74635494\n",
      "Iteration 65, loss = 1299.06415845\n",
      "Iteration 425, loss = 824.29506788\n",
      "Iteration 22, loss = 7718.56672286\n",
      "Iteration 103, loss = 1192.48897244\n",
      "Iteration 51, loss = 5035.24732941\n",
      "Iteration 29, loss = 6665.70107249\n",
      "Iteration 419, loss = 795.18466699\n",
      "Iteration 426, loss = 821.91486243\n",
      "Iteration 47, loss = 5518.84050580\n",
      "Iteration 66, loss = 1371.28495126\n",
      "Iteration 420, loss = 797.88703584\n",
      "Iteration 23, loss = 7598.46840123\n",
      "Iteration 427, loss = 819.19573142\n",
      "Iteration 104, loss = 1209.07008261\n",
      "Iteration 30, loss = 6567.53703904\n",
      "Iteration 52, loss = 4979.09815487\n",
      "Iteration 421, loss = 796.92466238\n",
      "Iteration 428, loss = 826.64723379\n",
      "Iteration 48, loss = 5454.08461543\n",
      "Iteration 24, loss = 7480.54839624\n",
      "Iteration 67, loss = 1382.66634944\n",
      "Iteration 422, loss = 796.38720713\n",
      "Iteration 105, loss = 1138.99071161\n",
      "Iteration 429, loss = 819.92439506\n",
      "Iteration 31, loss = 6473.71989164\n",
      "Iteration 53, loss = 4925.95673464\n",
      "Iteration 423, loss = 797.04043705\n",
      "Iteration 430, loss = 820.16213445\n",
      "Iteration 25, loss = 7367.26805566\n",
      "Iteration 49, loss = 5393.66015595\n",
      "Iteration 68, loss = 1312.39111095\n",
      "Iteration 106, loss = 1136.63839283\n",
      "Iteration 424, loss = 794.59172763\n",
      "Iteration 54, loss = 4873.49656783\n",
      "Iteration 32, loss = 6380.65659011\n",
      "Iteration 431, loss = 822.73600933\n",
      "Iteration 425, loss = 794.28974506\n",
      "Iteration 50, loss = 5333.02468143\n",
      "Iteration 69, loss = 1250.93535396\n",
      "Iteration 26, loss = 7255.94911454\n",
      "Iteration 107, loss = 1218.55007984\n",
      "Iteration 432, loss = 822.62094762\n",
      "Iteration 33, loss = 6290.91520244\n",
      "Iteration 55, loss = 4820.44136389\n",
      "Iteration 426, loss = 796.46605427\n",
      "Iteration 433, loss = 816.63530497\n",
      "Iteration 51, loss = 5276.68720917\n",
      "Iteration 70, loss = 1289.44916314\n",
      "Iteration 27, loss = 7148.29575406\n",
      "Iteration 427, loss = 791.97775379\n",
      "Iteration 108, loss = 1200.66392249\n",
      "Iteration 434, loss = 815.76945106\n",
      "Iteration 34, loss = 6204.33852946\n",
      "Iteration 56, loss = 4770.25238200\n",
      "Iteration 428, loss = 791.37988433\n",
      "Iteration 28, loss = 7044.06076825\n",
      "Iteration 435, loss = 819.20737380\n",
      "Iteration 52, loss = 5216.81419278\n",
      "Iteration 71, loss = 1340.15292252\n",
      "Iteration 109, loss = 1201.01703960\n",
      "Iteration 429, loss = 785.87536728\n",
      "Iteration 57, loss = 4720.73238667\n",
      "Iteration 35, loss = 6119.81267624\n",
      "Iteration 436, loss = 814.69732101\n",
      "Iteration 430, loss = 794.63583142\n",
      "Iteration 29, loss = 6943.41501655\n",
      "Iteration 53, loss = 5160.94079799\n",
      "Iteration 72, loss = 1250.67404037\n",
      "Iteration 110, loss = 1240.51594400\n",
      "Iteration 437, loss = 820.19142036\n",
      "Iteration 431, loss = 789.74507872\n",
      "Iteration 58, loss = 4670.76377128\n",
      "Iteration 36, loss = 6035.67017713\n",
      "Iteration 438, loss = 815.36257873\n",
      "Iteration 30, loss = 6843.98935658\n",
      "Iteration 432, loss = 793.56613966\n",
      "Iteration 54, loss = 5104.35530717\n",
      "Iteration 73, loss = 1276.12865317\n",
      "Iteration 111, loss = 1193.80746195\n",
      "Iteration 59, loss = 4622.69631811\n",
      "Iteration 439, loss = 815.48278081\n",
      "Iteration 433, loss = 787.02458097\n",
      "Iteration 37, loss = 5954.19056307\n",
      "Iteration 31, loss = 6749.72278948\n",
      "Iteration 440, loss = 815.51230643\n",
      "Iteration 434, loss = 788.73072434\n",
      "Iteration 55, loss = 5052.21457014\n",
      "Iteration 112, loss = 1190.38928184\n",
      "Iteration 74, loss = 1197.57339031\n",
      "Iteration 60, loss = 4576.85614613\n",
      "Iteration 38, loss = 5873.48009935\n",
      "Iteration 441, loss = 816.52357738\n",
      "Iteration 435, loss = 785.34559473\n",
      "Iteration 32, loss = 6657.40610730\n",
      "Iteration 113, loss = 1171.41070493\n",
      "Iteration 56, loss = 4997.27362062\n",
      "Iteration 442, loss = 819.19428363\n",
      "Iteration 75, loss = 1267.78717101\n",
      "Iteration 436, loss = 789.44411455\n",
      "Iteration 61, loss = 4530.65758074\n",
      "Iteration 39, loss = 5796.26675012\n",
      "Iteration 443, loss = 814.84446117\n",
      "Iteration 33, loss = 6567.06509301\n",
      "Iteration 437, loss = 786.23173248\n",
      "Iteration 114, loss = 1187.54926813\n",
      "Iteration 57, loss = 4946.87309267\n",
      "Iteration 76, loss = 1338.74110285\n",
      "Iteration 444, loss = 812.20214292\n",
      "Iteration 62, loss = 4487.63558988\n",
      "Iteration 438, loss = 786.99527349\n",
      "Iteration 40, loss = 5724.12349997\n",
      "Iteration 445, loss = 814.65575565\n",
      "Iteration 34, loss = 6480.88890598\n",
      "Iteration 58, loss = 4896.08738033\n",
      "Iteration 115, loss = 1218.20818009\n",
      "Iteration 439, loss = 788.62727679\n",
      "Iteration 63, loss = 4442.88887396\n",
      "Iteration 77, loss = 1214.80108543\n",
      "Iteration 41, loss = 5650.70075372\n",
      "Iteration 446, loss = 818.63531300\n",
      "Iteration 440, loss = 786.48129679\n",
      "Iteration 35, loss = 6395.25757192\n",
      "Iteration 59, loss = 4845.01369650\n",
      "Iteration 116, loss = 1222.95887667\n",
      "Iteration 447, loss = 814.10156484\n",
      "Iteration 441, loss = 784.30204529\n",
      "Iteration 78, loss = 1166.02404978\n",
      "Iteration 64, loss = 4400.81630495\n",
      "Iteration 42, loss = 5579.29224124\n",
      "Iteration 448, loss = 810.20894681\n",
      "Iteration 442, loss = 787.82049803\n",
      "Iteration 36, loss = 6310.55106870\n",
      "Iteration 60, loss = 4798.35754264\n",
      "Iteration 117, loss = 1245.70303876\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 79, loss = 1249.24982893\n",
      "Iteration 449, loss = 813.51681363\n",
      "Iteration 65, loss = 4357.30579927\n",
      "Iteration 443, loss = 783.16167709\n",
      "Iteration 43, loss = 5508.49096219\n",
      "Iteration 450, loss = 810.21072493\n",
      "Iteration 37, loss = 6227.92968668\n",
      "Iteration 61, loss = 4748.51726863\n",
      "Iteration 444, loss = 783.31217960\n",
      "Iteration 1, loss = 11867.33596200\n",
      "Iteration 80, loss = 1255.63830582\n",
      "Iteration 451, loss = 812.64250580\n",
      "Iteration 66, loss = 4318.33339669\n",
      "Iteration 445, loss = 782.37157343\n",
      "Iteration 44, loss = 5439.35794916\n",
      "Iteration 38, loss = 6148.03156570\n",
      "Iteration 62, loss = 4701.51241071\n",
      "Iteration 452, loss = 810.04477388\n",
      "Iteration 446, loss = 785.38959954\n",
      "Iteration 2, loss = 11472.14162347\n",
      "Iteration 81, loss = 1195.89619050\n",
      "Iteration 67, loss = 4275.91616032\n",
      "Iteration 453, loss = 813.83820789\n",
      "Iteration 447, loss = 787.10187492\n",
      "Iteration 45, loss = 5373.35983063\n",
      "Iteration 39, loss = 6070.24536092\n",
      "Iteration 63, loss = 4656.12414834\n",
      "Iteration 3, loss = 11159.42427150\n",
      "Iteration 454, loss = 810.05852443\n",
      "Iteration 82, loss = 1266.41432756\n",
      "Iteration 448, loss = 782.81556991\n",
      "Iteration 68, loss = 4239.79396314\n",
      "Iteration 455, loss = 809.35154494\n",
      "Iteration 46, loss = 5309.20875491\n",
      "Iteration 40, loss = 5995.66100234\n",
      "Iteration 449, loss = 782.63924577\n",
      "Iteration 64, loss = 4612.34181451\n",
      "Iteration 4, loss = 10899.52966839\n",
      "Iteration 456, loss = 808.78128751\n",
      "Iteration 83, loss = 1187.09213760\n",
      "Iteration 450, loss = 782.85095780\n",
      "Iteration 69, loss = 4202.47889776\n",
      "Iteration 47, loss = 5243.96861666\n",
      "Iteration 457, loss = 807.36282506\n",
      "Iteration 41, loss = 5922.67826514\n",
      "Iteration 65, loss = 4566.38830891\n",
      "Iteration 451, loss = 780.86862086\n",
      "Iteration 5, loss = 10685.58590901\n",
      "Iteration 84, loss = 1297.48200989\n",
      "Iteration 70, loss = 4160.78580245\n",
      "Iteration 458, loss = 812.81927978\n",
      "Iteration 452, loss = 780.14260143\n",
      "Iteration 48, loss = 5182.36941387\n",
      "Iteration 42, loss = 5849.98069564\n",
      "Iteration 66, loss = 4524.18746537\n",
      "Iteration 459, loss = 809.79254060\n",
      "Iteration 6, loss = 10391.13686025\n",
      "Iteration 453, loss = 778.90005964\n",
      "Iteration 71, loss = 4121.59101414\n",
      "Iteration 85, loss = 1223.65225949\n",
      "Iteration 460, loss = 810.42159848\n",
      "Iteration 49, loss = 5120.47324307\n",
      "Iteration 454, loss = 778.86208657\n",
      "Iteration 43, loss = 5780.41245400\n",
      "Iteration 67, loss = 4481.87664273\n",
      "Iteration 7, loss = 10093.60869282\n",
      "Iteration 461, loss = 799.73488984\n",
      "Iteration 72, loss = 4085.40102602\n",
      "Iteration 455, loss = 777.40578218\n",
      "Iteration 86, loss = 1148.06620765\n",
      "Iteration 462, loss = 810.96490653\n",
      "Iteration 50, loss = 5062.05430209\n",
      "Iteration 44, loss = 5711.09098633\n",
      "Iteration 456, loss = 781.52455762\n",
      "Iteration 68, loss = 4443.21114888\n",
      "Iteration 8, loss = 9847.32736342\n",
      "Iteration 463, loss = 803.92449351\n",
      "Iteration 87, loss = 1179.85575190\n",
      "Iteration 73, loss = 4050.41324414\n",
      "Iteration 457, loss = 777.93126504\n",
      "Iteration 51, loss = 5004.25947602\n",
      "Iteration 464, loss = 804.60009575\n",
      "Iteration 45, loss = 5644.07799516\n",
      "Iteration 69, loss = 4401.21190877\n",
      "Iteration 458, loss = 778.02443083\n",
      "Iteration 9, loss = 9624.37767313\n",
      "Iteration 74, loss = 4016.56334793\n",
      "Iteration 465, loss = 806.06201720\n",
      "Iteration 88, loss = 1202.01353263\n",
      "Iteration 459, loss = 780.00708568\n",
      "Iteration 52, loss = 4947.66620861\n",
      "Iteration 46, loss = 5578.48605909\n",
      "Iteration 70, loss = 4360.76564599\n",
      "Iteration 466, loss = 803.19697445\n",
      "Iteration 10, loss = 9418.93111604\n",
      "Iteration 460, loss = 774.23783134\n",
      "Iteration 75, loss = 3979.42361280\n",
      "Iteration 89, loss = 1177.54408292\n",
      "Iteration 467, loss = 804.29280280\n",
      "Iteration 53, loss = 4891.87748377\n",
      "Iteration 71, loss = 4317.60663776\n",
      "Iteration 461, loss = 773.91899753\n",
      "Iteration 47, loss = 5512.84346005\n",
      "Iteration 11, loss = 9224.12989483\n",
      "Iteration 468, loss = 808.58688326\n",
      "Iteration 76, loss = 3947.87284748\n",
      "Iteration 462, loss = 781.24830008\n",
      "Iteration 90, loss = 1207.38977204\n",
      "Iteration 72, loss = 4278.97772073\n",
      "Iteration 469, loss = 807.37545985\n",
      "Iteration 54, loss = 4836.85733818\n",
      "Iteration 48, loss = 5450.17801980\n",
      "Iteration 463, loss = 770.99983826\n",
      "Iteration 12, loss = 9038.99987211\n",
      "Iteration 77, loss = 3906.67681116\n",
      "Iteration 470, loss = 804.87686304\n",
      "Iteration 91, loss = 1181.09320748\n",
      "Iteration 464, loss = 771.89490971\n",
      "Iteration 73, loss = 4243.65601923\n",
      "Iteration 55, loss = 4784.32910690\n",
      "Iteration 49, loss = 5388.18592641\n",
      "Iteration 471, loss = 808.19392098\n",
      "Iteration 13, loss = 8863.16933753\n",
      "Iteration 465, loss = 773.47557554\n",
      "Iteration 78, loss = 3871.74681630\n",
      "Iteration 92, loss = 1158.43005589\n",
      "Iteration 472, loss = 800.78347379\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 74, loss = 4203.76293864\n",
      "Iteration 56, loss = 4732.72437697\n",
      "Iteration 466, loss = 773.38770900\n",
      "Iteration 50, loss = 5328.80582089\n",
      "Iteration 14, loss = 8695.16631309\n",
      "Iteration 467, loss = 775.19398926\n",
      "Iteration 79, loss = 3841.48950271\n",
      "Iteration 93, loss = 1110.62551020\n",
      "Iteration 57, loss = 4681.70872167\n",
      "Iteration 75, loss = 4166.31041577\n",
      "Iteration 1, loss = 11779.47849671\n",
      "Iteration 51, loss = 5271.86177935\n",
      "Iteration 468, loss = 776.31163838\n",
      "Iteration 15, loss = 8534.51244201\n",
      "Iteration 80, loss = 3809.57953721\n",
      "Iteration 469, loss = 770.56837705\n",
      "Iteration 94, loss = 1225.21545847\n",
      "Iteration 58, loss = 4632.74883909\n",
      "Iteration 76, loss = 4133.10014012\n",
      "Iteration 52, loss = 5213.97763866\n",
      "Iteration 2, loss = 11386.17391371\n",
      "Iteration 470, loss = 772.27284090\n",
      "Iteration 16, loss = 8379.85340830\n",
      "Iteration 81, loss = 3776.85786431\n",
      "Iteration 95, loss = 1158.92889967\n",
      "Iteration 59, loss = 4584.10174219\n",
      "Iteration 471, loss = 774.49956421\n",
      "Iteration 77, loss = 4093.24769841\n",
      "Iteration 3, loss = 11074.21287096\n",
      "Iteration 53, loss = 5156.35445860\n",
      "Iteration 472, loss = 769.11708827\n",
      "Iteration 17, loss = 8231.27428150\n",
      "Iteration 96, loss = 1233.10657270\n",
      "Iteration 82, loss = 3741.62024601\n",
      "Iteration 78, loss = 4055.46467611Iteration 473, loss = 772.81760110\n",
      "\n",
      "Iteration 60, loss = 4532.84023833\n",
      "Iteration 4, loss = 10815.74618846\n",
      "Iteration 54, loss = 5101.02012667\n",
      "Iteration 474, loss = 773.83573692\n",
      "Iteration 18, loss = 8088.02296483\n",
      "Iteration 97, loss = 1135.95416304\n",
      "Iteration 83, loss = 3716.15183584\n",
      "Iteration 61, loss = 4487.01807721\n",
      "Iteration 79, loss = 4021.47744937\n",
      "Iteration 5, loss = 10602.86468838\n",
      "Iteration 475, loss = 769.16701320\n",
      "Iteration 55, loss = 5048.12937610\n",
      "Iteration 19, loss = 7950.32814331\n",
      "Iteration 476, loss = 770.11777999\n",
      "Iteration 98, loss = 1132.56301103\n",
      "Iteration 84, loss = 3684.23805875\n",
      "Iteration 62, loss = 4441.76155448\n",
      "Iteration 80, loss = 3988.97865964\n",
      "Iteration 6, loss = 10307.55729513\n",
      "Iteration 56, loss = 4995.10102039\n",
      "Iteration 477, loss = 769.27046224\n",
      "Iteration 20, loss = 7816.83021327\n",
      "Iteration 85, loss = 3647.31445512\n",
      "Iteration 99, loss = 1098.81142316\n",
      "Iteration 478, loss = 770.83506166\n",
      "Iteration 81, loss = 3950.47202075\n",
      "Iteration 63, loss = 4394.07501807\n",
      "Iteration 7, loss = 10012.17109043\n",
      "Iteration 57, loss = 4944.82143078\n",
      "Iteration 479, loss = 762.97882724\n",
      "Iteration 21, loss = 7688.24490052\n",
      "Iteration 86, loss = 3619.72488752\n",
      "Iteration 100, loss = 1127.20830828\n",
      "Iteration 64, loss = 4350.94082756\n",
      "Iteration 82, loss = 3919.33600053\n",
      "Iteration 480, loss = 771.04732607\n",
      "Iteration 8, loss = 9767.80088203\n",
      "Iteration 58, loss = 4897.86789421\n",
      "Iteration 481, loss = 765.71371789\n",
      "Iteration 22, loss = 7564.53861869\n",
      "Iteration 101, loss = 1127.23018922\n",
      "Iteration 87, loss = 3591.90327739\n",
      "Iteration 65, loss = 4308.38998076\n",
      "Iteration 9, loss = 9546.36046537\n",
      "Iteration 83, loss = 3885.17248558\n",
      "Iteration 59, loss = 4846.08489233\n",
      "Iteration 482, loss = 766.05863919\n",
      "Iteration 483, loss = 767.70075979\n",
      "Iteration 23, loss = 7444.33812841\n",
      "Iteration 88, loss = 3560.37248130\n",
      "Iteration 102, loss = 1157.40867919\n",
      "Iteration 10, loss = 9342.14993680\n",
      "Iteration 66, loss = 4261.15458404\n",
      "Iteration 84, loss = 3853.29826476\n",
      "Iteration 60, loss = 4795.68042226\n",
      "Iteration 484, loss = 767.53582962\n",
      "Iteration 24, loss = 7327.29834600\n",
      "Iteration 89, loss = 3536.24715373\n",
      "Iteration 103, loss = 1175.88415424\n",
      "Iteration 485, loss = 764.08353678\n",
      "Iteration 11, loss = 9148.50394505\n",
      "Iteration 67, loss = 4220.99318889\n",
      "Iteration 85, loss = 3821.42580702\n",
      "Iteration 61, loss = 4746.33243356\n",
      "Iteration 486, loss = 773.43939846\n",
      "Iteration 25, loss = 7212.76138491\n",
      "Iteration 90, loss = 3505.53114188\n",
      "Iteration 104, loss = 1176.34993056\n",
      "Iteration 487, loss = 760.53323797\n",
      "Iteration 12, loss = 8965.41444934\n",
      "Iteration 68, loss = 4179.50250071\n",
      "Iteration 86, loss = 3785.65151637\n",
      "Iteration 62, loss = 4700.90836073\n",
      "Iteration 488, loss = 765.07632587\n",
      "Iteration 26, loss = 7102.31610839\n",
      "Iteration 91, loss = 3480.03958608\n",
      "Iteration 105, loss = 1192.00473956\n",
      "Iteration 13, loss = 8791.54001540\n",
      "Iteration 69, loss = 4136.13177982\n",
      "Iteration 489, loss = 766.20662415\n",
      "Iteration 63, loss = 4654.88303877\n",
      "Iteration 87, loss = 3756.86475348\n",
      "Iteration 27, loss = 6994.69465023\n",
      "Iteration 92, loss = 3453.98638414\n",
      "Iteration 490, loss = 763.35387663\n",
      "Iteration 106, loss = 1166.16132239\n",
      "Iteration 14, loss = 8624.04316291\n",
      "Iteration 70, loss = 4097.98903646\n",
      "Iteration 64, loss = 4609.11851964\n",
      "Iteration 88, loss = 3722.75315814\n",
      "Iteration 491, loss = 761.46238403\n",
      "Iteration 28, loss = 6890.08622068\n",
      "Iteration 93, loss = 3423.81507831\n",
      "Iteration 107, loss = 1115.15454192\n",
      "Iteration 492, loss = 763.49285886\n",
      "Iteration 15, loss = 8464.48497248\n",
      "Iteration 71, loss = 4057.32158075\n",
      "Iteration 65, loss = 4564.51426555\n",
      "Iteration 89, loss = 3697.68080058\n",
      "Iteration 29, loss = 6788.73142670\n",
      "Iteration 493, loss = 764.00213869\n",
      "Iteration 94, loss = 3401.45739936\n",
      "Iteration 108, loss = 1117.75227096\n",
      "Iteration 16, loss = 8311.36118235\n",
      "Iteration 494, loss = 761.11928151\n",
      "Iteration 66, loss = 4517.88031612\n",
      "Iteration 72, loss = 4020.76223798\n",
      "Iteration 90, loss = 3665.79765525\n",
      "Iteration 30, loss = 6689.94393838\n",
      "Iteration 95, loss = 3373.20841521\n",
      "Iteration 495, loss = 760.05272877\n",
      "Iteration 109, loss = 1085.82784940\n",
      "Iteration 17, loss = 8163.66975611\n",
      "Iteration 67, loss = 4478.41948040\n",
      "Iteration 73, loss = 3983.32423696\n",
      "Iteration 496, loss = 762.72045413\n",
      "Iteration 91, loss = 3635.47738599\n",
      "Iteration 31, loss = 6594.48326677\n",
      "Iteration 96, loss = 3349.50089797\n",
      "Iteration 18, loss = 8022.07426314\n",
      "Iteration 497, loss = 754.94547839\n",
      "Iteration 110, loss = 1153.91142045\n",
      "Iteration 68, loss = 4435.43581509\n",
      "Iteration 74, loss = 3943.81694281\n",
      "Iteration 498, loss = 757.58959227\n",
      "Iteration 92, loss = 3605.78539191\n",
      "Iteration 32, loss = 6501.78649684\n",
      "Iteration 97, loss = 3322.51059655\n",
      "Iteration 19, loss = 7885.67859073\n",
      "Iteration 111, loss = 1125.79530254\n",
      "Iteration 69, loss = 4393.38346234\n",
      "Iteration 499, loss = 761.00795259\n",
      "Iteration 75, loss = 3907.33711030\n",
      "Iteration 93, loss = 3579.56937165\n",
      "Iteration 33, loss = 6412.23438367\n",
      "Iteration 98, loss = 3296.98180518\n",
      "Iteration 20, loss = 7753.32806402\n",
      "Iteration 500, loss = 759.09300018\n",
      "Iteration 112, loss = 1160.36873668\n",
      "Iteration 70, loss = 4352.62598334\n",
      "Iteration 76, loss = 3872.44644834\n",
      "Iteration 501, loss = 761.90098577\n",
      "Iteration 94, loss = 3549.39701208\n",
      "Iteration 34, loss = 6326.06819755\n",
      "Iteration 99, loss = 3272.31743497\n",
      "Iteration 21, loss = 7625.93568152\n",
      "Iteration 502, loss = 757.13041333\n",
      "Iteration 113, loss = 1193.97904829\n",
      "Iteration 71, loss = 4311.05279738\n",
      "Iteration 77, loss = 3836.35151378\n",
      "Iteration 503, loss = 753.85542477\n",
      "Iteration 95, loss = 3523.43090521\n",
      "Iteration 35, loss = 6238.66452511\n",
      "Iteration 22, loss = 7503.26074573\n",
      "Iteration 100, loss = 3249.89893305\n",
      "Iteration 504, loss = 758.00581071\n",
      "Iteration 114, loss = 1131.86438760\n",
      "Iteration 72, loss = 4272.85801506\n",
      "Iteration 78, loss = 3805.37835592\n",
      "Iteration 96, loss = 3499.95547593\n",
      "Iteration 505, loss = 759.21326078\n",
      "Iteration 36, loss = 6153.81611487\n",
      "Iteration 23, loss = 7382.98715953\n",
      "Iteration 101, loss = 3227.92789571\n",
      "Iteration 115, loss = 1159.89958541\n",
      "Iteration 73, loss = 4233.13116225\n",
      "Iteration 79, loss = 3767.30307402\n",
      "Iteration 506, loss = 755.22839571\n",
      "Iteration 24, loss = 7268.24100040\n",
      "Iteration 37, loss = 6071.87560399\n",
      "Iteration 97, loss = 3472.05696359\n",
      "Iteration 507, loss = 759.66698156\n",
      "Iteration 102, loss = 3199.59534199\n",
      "Iteration 80, loss = 3735.68382176\n",
      "Iteration 74, loss = 4193.65084985\n",
      "Iteration 116, loss = 1135.58173940\n",
      "Iteration 508, loss = 759.75912670\n",
      "Iteration 25, loss = 7154.87078735\n",
      "Iteration 38, loss = 5991.02953520\n",
      "Iteration 98, loss = 3444.26639556\n",
      "Iteration 103, loss = 3185.58585068\n",
      "Iteration 509, loss = 756.75470362\n",
      "Iteration 81, loss = 3702.58913426\n",
      "Iteration 117, loss = 1185.13536359\n",
      "Iteration 75, loss = 4157.78418580\n",
      "Iteration 510, loss = 756.28776376\n",
      "Iteration 26, loss = 7045.50175211\n",
      "Iteration 39, loss = 5915.24049794\n",
      "Iteration 99, loss = 3415.47914401\n",
      "Iteration 104, loss = 3154.80227600\n",
      "Iteration 118, loss = 1147.02514050\n",
      "Iteration 82, loss = 3669.25548348\n",
      "Iteration 511, loss = 761.20100253\n",
      "Iteration 76, loss = 4121.83671204\n",
      "Iteration 27, loss = 6938.92705169\n",
      "Iteration 40, loss = 5839.95025511\n",
      "Iteration 512, loss = 753.99205642\n",
      "Iteration 100, loss = 3395.59246173\n",
      "Iteration 105, loss = 3131.78728306\n",
      "Iteration 119, loss = 1214.97405796\n",
      "Iteration 77, loss = 4084.84975481\n",
      "Iteration 83, loss = 3636.82380018\n",
      "Iteration 513, loss = 756.46528260\n",
      "Iteration 28, loss = 6834.89753371\n",
      "Iteration 41, loss = 5766.33421396\n",
      "Iteration 106, loss = 3109.97197672\n",
      "Iteration 101, loss = 3370.83615399\n",
      "Iteration 514, loss = 756.15754721\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 120, loss = 1109.84990974\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 78, loss = 4052.84649560\n",
      "Iteration 84, loss = 3606.34444362\n",
      "Iteration 29, loss = 6735.58104062\n",
      "Iteration 42, loss = 5694.81434129\n",
      "Iteration 107, loss = 3091.13405612\n",
      "Iteration 102, loss = 3338.77478406\n",
      "Iteration 85, loss = 3576.62251196\n",
      "Iteration 1, loss = 11865.76811455\n",
      "Iteration 79, loss = 4014.46507976\n",
      "Iteration 1, loss = 11834.89499304\n",
      "Iteration 30, loss = 6638.32678770\n",
      "Iteration 43, loss = 5626.65326422\n",
      "Iteration 108, loss = 3069.13778021\n",
      "Iteration 103, loss = 3315.60583458\n",
      "Iteration 80, loss = 3981.27418706\n",
      "Iteration 86, loss = 3549.69154370\n",
      "Iteration 2, loss = 11469.43210003\n",
      "Iteration 2, loss = 11438.62869689\n",
      "Iteration 31, loss = 6545.44570576\n",
      "Iteration 44, loss = 5555.58797000\n",
      "Iteration 109, loss = 3043.83329944\n",
      "Iteration 104, loss = 3289.00028392\n",
      "Iteration 81, loss = 3944.77010352\n",
      "Iteration 87, loss = 3516.11249949\n",
      "Iteration 3, loss = 11156.61534383\n",
      "Iteration 3, loss = 11126.84049573\n",
      "Iteration 32, loss = 6454.40976266\n",
      "Iteration 45, loss = 5489.57269484\n",
      "Iteration 110, loss = 3024.39846822\n",
      "Iteration 105, loss = 3267.02871936\n",
      "Iteration 82, loss = 3911.87914609\n",
      "Iteration 88, loss = 3486.93477022\n",
      "Iteration 4, loss = 10897.51242623\n",
      "Iteration 33, loss = 6367.40227946\n",
      "Iteration 4, loss = 10868.40419831\n",
      "Iteration 46, loss = 5423.39226367\n",
      "Iteration 106, loss = 3245.73979693\n",
      "Iteration 111, loss = 3004.41851930\n",
      "Iteration 83, loss = 3878.60923381\n",
      "Iteration 89, loss = 3458.92479712\n",
      "Iteration 5, loss = 10684.05804965\n",
      "Iteration 5, loss = 10655.26974300\n",
      "Iteration 34, loss = 6278.60866281\n",
      "Iteration 107, loss = 3220.78537062\n",
      "Iteration 47, loss = 5358.31846917\n",
      "Iteration 112, loss = 2983.38191256\n",
      "Iteration 84, loss = 3846.46365931\n",
      "Iteration 90, loss = 3430.92444251\n",
      "Iteration 6, loss = 10398.37490772\n",
      "Iteration 35, loss = 6192.72746199\n",
      "Iteration 6, loss = 10393.23806923\n",
      "Iteration 108, loss = 3200.12557564\n",
      "Iteration 48, loss = 5296.96422734\n",
      "Iteration 113, loss = 2964.01074488\n",
      "Iteration 85, loss = 3815.13071912Iteration 91, loss = 3400.84616434\n",
      "\n",
      "Iteration 7, loss = 10094.63293727\n",
      "Iteration 36, loss = 6110.09799304\n",
      "Iteration 7, loss = 10075.20306903\n",
      "Iteration 109, loss = 3178.78449761\n",
      "Iteration 49, loss = 5233.87633493\n",
      "Iteration 114, loss = 2942.11647764\n",
      "Iteration 86, loss = 3789.16625291\n",
      "Iteration 92, loss = 3369.66790343\n",
      "Iteration 8, loss = 9845.86866743\n",
      "Iteration 8, loss = 9825.36637186\n",
      "Iteration 37, loss = 6029.30912656\n",
      "Iteration 110, loss = 3150.16709860\n",
      "Iteration 50, loss = 5176.25591069\n",
      "Iteration 115, loss = 2924.28547492\n",
      "Iteration 87, loss = 3755.69292206\n",
      "Iteration 93, loss = 3343.60237315\n",
      "Iteration 9, loss = 9622.35066308\n",
      "Iteration 9, loss = 9601.67321013\n",
      "Iteration 38, loss = 5950.84013957\n",
      "Iteration 111, loss = 3127.81529744\n",
      "Iteration 51, loss = 5117.15755405\n",
      "Iteration 116, loss = 2903.91581554\n",
      "Iteration 88, loss = 3726.07427027\n",
      "Iteration 94, loss = 3317.59155804\n",
      "Iteration 10, loss = 9415.98404496\n",
      "Iteration 39, loss = 5875.34515330\n",
      "Iteration 10, loss = 9395.67328674\n",
      "Iteration 112, loss = 3105.28112595\n",
      "Iteration 52, loss = 5059.69349583\n",
      "Iteration 117, loss = 2884.59800770\n",
      "Iteration 95, loss = 3287.94048763\n",
      "Iteration 89, loss = 3694.02393355\n",
      "Iteration 11, loss = 9220.96862684\n",
      "Iteration 40, loss = 5801.83017353\n",
      "Iteration 11, loss = 9201.01194249\n",
      "Iteration 53, loss = 5001.15395975\n",
      "Iteration 113, loss = 3085.55588915\n",
      "Iteration 118, loss = 2869.74432131\n",
      "Iteration 96, loss = 3266.44264700\n",
      "Iteration 90, loss = 3667.55356376\n",
      "Iteration 12, loss = 9036.12108121\n",
      "Iteration 41, loss = 5728.57334888\n",
      "Iteration 12, loss = 9016.96995649\n",
      "Iteration 114, loss = 3062.55107507\n",
      "Iteration 54, loss = 4947.68535446\n",
      "Iteration 119, loss = 2845.80564349\n",
      "Iteration 97, loss = 3232.23892883\n",
      "Iteration 91, loss = 3636.68123751\n",
      "Iteration 13, loss = 8860.56874294\n",
      "Iteration 42, loss = 5657.47477827\n",
      "Iteration 13, loss = 8841.77465798\n",
      "Iteration 115, loss = 3042.29700513\n",
      "Iteration 55, loss = 4894.24609339\n",
      "Iteration 120, loss = 2828.39312163\n",
      "Iteration 92, loss = 3607.57022141\n",
      "Iteration 98, loss = 3212.32665100\n",
      "Iteration 43, loss = 5588.31771184\n",
      "Iteration 14, loss = 8691.87081128\n",
      "Iteration 14, loss = 8674.87970700\n",
      "Iteration 116, loss = 3028.22294524\n",
      "Iteration 56, loss = 4843.51924450\n",
      "Iteration 121, loss = 2811.96202814\n",
      "Iteration 99, loss = 3187.73924585\n",
      "Iteration 93, loss = 3580.07079775\n",
      "Iteration 15, loss = 8530.40706158\n",
      "Iteration 44, loss = 5521.12995629\n",
      "Iteration 15, loss = 8514.72862224\n",
      "Iteration 117, loss = 3012.32041922\n",
      "Iteration 57, loss = 4793.77406032\n",
      "Iteration 122, loss = 2794.73063857\n",
      "Iteration 94, loss = 3552.84222564\n",
      "Iteration 100, loss = 3157.09634820\n",
      "Iteration 45, loss = 5454.17675593\n",
      "Iteration 16, loss = 8375.85007447\n",
      "Iteration 16, loss = 8362.42189898\n",
      "Iteration 118, loss = 2981.70409035\n",
      "Iteration 58, loss = 4743.45715848\n",
      "Iteration 123, loss = 2779.20730665\n",
      "Iteration 95, loss = 3522.72560775\n",
      "Iteration 101, loss = 3133.92866661\n",
      "Iteration 46, loss = 5390.14284465\n",
      "Iteration 17, loss = 8226.49262938\n",
      "Iteration 17, loss = 8214.03193378\n",
      "Iteration 119, loss = 2957.44981473\n",
      "Iteration 59, loss = 4693.36244798\n",
      "Iteration 124, loss = 2758.43358210\n",
      "Iteration 102, loss = 3107.73318441\n",
      "Iteration 47, loss = 5325.95335113\n",
      "Iteration 96, loss = 3498.05216487\n",
      "Iteration 18, loss = 8083.40136480\n",
      "Iteration 18, loss = 8072.35365322\n",
      "Iteration 120, loss = 2941.51288787\n",
      "Iteration 60, loss = 4645.56484538\n",
      "Iteration 125, loss = 2740.17584245\n",
      "Iteration 48, loss = 5264.25210858\n",
      "Iteration 97, loss = 3468.32859406\n",
      "Iteration 103, loss = 3081.97476773\n",
      "Iteration 19, loss = 7944.75271101\n",
      "Iteration 19, loss = 7935.98058428\n",
      "Iteration 121, loss = 2921.45658790\n",
      "Iteration 61, loss = 4598.67228788\n",
      "Iteration 126, loss = 2726.35180947\n",
      "Iteration 49, loss = 5203.80280912\n",
      "Iteration 104, loss = 3056.74797085\n",
      "Iteration 98, loss = 3445.35557405\n",
      "Iteration 20, loss = 7811.28223998\n",
      "Iteration 20, loss = 7803.39883201\n",
      "Iteration 122, loss = 2904.82595147\n",
      "Iteration 62, loss = 4551.31881485\n",
      "Iteration 127, loss = 2707.21246035\n",
      "Iteration 50, loss = 5147.33129837\n",
      "Iteration 99, loss = 3418.76229290\n",
      "Iteration 105, loss = 3041.51902175\n",
      "Iteration 21, loss = 7681.83015390\n",
      "Iteration 21, loss = 7675.62947226\n",
      "Iteration 123, loss = 2889.02126434\n",
      "Iteration 63, loss = 4507.19942129\n",
      "Iteration 128, loss = 2691.47417338\n",
      "Iteration 51, loss = 5088.13500225\n",
      "Iteration 100, loss = 3391.43548126\n",
      "Iteration 106, loss = 3010.82738700\n",
      "Iteration 22, loss = 7556.46090027\n",
      "Iteration 22, loss = 7552.14281489\n",
      "Iteration 124, loss = 2867.16995032\n",
      "Iteration 64, loss = 4462.53816284\n",
      "Iteration 129, loss = 2676.29063767\n",
      "Iteration 52, loss = 5031.49296935\n",
      "Iteration 101, loss = 3367.01197903\n",
      "Iteration 107, loss = 2989.32500452\n",
      "Iteration 23, loss = 7434.86296851\n",
      "Iteration 23, loss = 7431.41672874\n",
      "Iteration 125, loss = 2843.68445680\n",
      "Iteration 65, loss = 4415.55374056\n",
      "Iteration 130, loss = 2660.65136809\n",
      "Iteration 53, loss = 4976.11305573\n",
      "Iteration 102, loss = 3342.30518662\n",
      "Iteration 108, loss = 2970.40926436\n",
      "Iteration 24, loss = 7317.64166968\n",
      "Iteration 24, loss = 7315.21084533\n",
      "Iteration 126, loss = 2829.07346938\n",
      "Iteration 66, loss = 4370.71537567\n",
      "Iteration 54, loss = 4921.83145415\n",
      "Iteration 131, loss = 2645.35502171\n",
      "Iteration 109, loss = 2944.92685337\n",
      "Iteration 103, loss = 3315.19676908\n",
      "Iteration 25, loss = 7204.45705698\n",
      "Iteration 25, loss = 7203.39544110\n",
      "Iteration 127, loss = 2811.30863434\n",
      "Iteration 55, loss = 4871.30005818\n",
      "Iteration 132, loss = 2626.17411787\n",
      "Iteration 67, loss = 4327.63390627\n",
      "Iteration 110, loss = 2923.58446441\n",
      "Iteration 104, loss = 3286.71629425\n",
      "Iteration 26, loss = 7093.08976203\n",
      "Iteration 26, loss = 7094.09949149\n",
      "Iteration 128, loss = 2794.29676263\n",
      "Iteration 56, loss = 4819.98740243\n",
      "Iteration 68, loss = 4285.93476115\n",
      "Iteration 133, loss = 2609.41674265\n",
      "Iteration 111, loss = 2900.23976936\n",
      "Iteration 105, loss = 3269.45878774\n",
      "Iteration 27, loss = 6984.59855510\n",
      "Iteration 27, loss = 6988.08412365\n",
      "Iteration 129, loss = 2773.73732356\n",
      "Iteration 57, loss = 4770.16748274\n",
      "Iteration 69, loss = 4243.67451978\n",
      "Iteration 134, loss = 2599.70332780\n",
      "Iteration 112, loss = 2885.57409985\n",
      "Iteration 106, loss = 3243.14934439\n",
      "Iteration 28, loss = 6879.07462542\n",
      "Iteration 28, loss = 6884.18017672\n",
      "Iteration 130, loss = 2758.03682685\n",
      "Iteration 58, loss = 4721.53298868\n",
      "Iteration 70, loss = 4205.33015497\n",
      "Iteration 135, loss = 2582.22240829\n",
      "Iteration 113, loss = 2860.59710208\n",
      "Iteration 107, loss = 3224.16780532\n",
      "Iteration 29, loss = 6778.89998323\n",
      "Iteration 131, loss = 2742.10688431\n",
      "Iteration 29, loss = 6784.20717114\n",
      "Iteration 59, loss = 4671.83198065\n",
      "Iteration 71, loss = 4164.91886887\n",
      "Iteration 114, loss = 2837.84898260\n",
      "Iteration 136, loss = 2569.92612744\n",
      "Iteration 108, loss = 3197.18147509\n",
      "Iteration 30, loss = 6680.09564757\n",
      "Iteration 132, loss = 2723.61892892\n",
      "Iteration 72, loss = 4126.63613567\n",
      "Iteration 30, loss = 6686.99445018\n",
      "Iteration 60, loss = 4625.01634311\n",
      "Iteration 115, loss = 2823.56372583\n",
      "Iteration 137, loss = 2548.36092663\n",
      "Iteration 109, loss = 3171.60816121\n",
      "Iteration 31, loss = 6585.23661434\n",
      "Iteration 73, loss = 4085.82246281\n",
      "Iteration 133, loss = 2702.94821895\n",
      "Iteration 31, loss = 6592.74589523\n",
      "Iteration 61, loss = 4579.33649108\n",
      "Iteration 138, loss = 2538.63306695\n",
      "Iteration 116, loss = 2798.73967868\n",
      "Iteration 110, loss = 3146.60007061\n",
      "Iteration 134, loss = 2696.25389091\n",
      "Iteration 32, loss = 6493.44155280\n",
      "Iteration 74, loss = 4047.96131708\n",
      "Iteration 32, loss = 6501.49293600\n",
      "Iteration 62, loss = 4534.28727584\n",
      "Iteration 117, loss = 2778.35851140\n",
      "Iteration 139, loss = 2520.56980299\n",
      "Iteration 111, loss = 3125.33848416\n",
      "Iteration 135, loss = 2672.47747975\n",
      "Iteration 63, loss = 4489.32187345\n",
      "Iteration 33, loss = 6402.77814344\n",
      "Iteration 75, loss = 4011.85478366\n",
      "Iteration 33, loss = 6412.29016412\n",
      "Iteration 118, loss = 2757.92539675\n",
      "Iteration 140, loss = 2513.08616589\n",
      "Iteration 112, loss = 3107.35933513\n",
      "Iteration 136, loss = 2659.60223326\n",
      "Iteration 76, loss = 3974.29797881\n",
      "Iteration 64, loss = 4444.79893475\n",
      "Iteration 34, loss = 6314.21395711\n",
      "Iteration 34, loss = 6325.20924029\n",
      "Iteration 119, loss = 2745.32852409\n",
      "Iteration 141, loss = 2493.94552766\n",
      "Iteration 113, loss = 3081.19905891\n",
      "Iteration 77, loss = 3940.37873227\n",
      "Iteration 137, loss = 2641.83483565\n",
      "Iteration 35, loss = 6228.63583030\n",
      "Iteration 35, loss = 6240.18927754\n",
      "Iteration 65, loss = 4402.85734824\n",
      "Iteration 120, loss = 2718.47997157\n",
      "Iteration 142, loss = 2476.04645149\n",
      "Iteration 114, loss = 3060.21046615\n",
      "Iteration 78, loss = 3904.73606887\n",
      "Iteration 138, loss = 2625.85368414\n",
      "Iteration 66, loss = 4358.97472934\n",
      "Iteration 36, loss = 6144.57530103\n",
      "Iteration 36, loss = 6159.58475250\n",
      "Iteration 121, loss = 2699.20285910\n",
      "Iteration 143, loss = 2465.74066616\n",
      "Iteration 115, loss = 3053.29013103\n",
      "Iteration 79, loss = 3866.93728792\n",
      "Iteration 139, loss = 2603.91584145\n",
      "Iteration 67, loss = 4317.36909521\n",
      "Iteration 37, loss = 6077.97447132\n",
      "Iteration 37, loss = 6062.28681682\n",
      "Iteration 122, loss = 2682.87356389\n",
      "Iteration 116, loss = 3025.55601913\n",
      "Iteration 144, loss = 2452.71755424\n",
      "Iteration 80, loss = 3835.82732712\n",
      "Iteration 68, loss = 4274.52219480\n",
      "Iteration 38, loss = 5983.59049387\n",
      "Iteration 140, loss = 2600.22523910\n",
      "Iteration 38, loss = 5999.62897199\n",
      "Iteration 123, loss = 2663.14899081\n",
      "Iteration 117, loss = 2999.68146265\n",
      "Iteration 145, loss = 2440.68081623\n",
      "Iteration 81, loss = 3801.58560917\n",
      "Iteration 69, loss = 4233.13955502\n",
      "Iteration 39, loss = 5903.77279091\n",
      "Iteration 39, loss = 5924.00791206\n",
      "Iteration 141, loss = 2589.08473992\n",
      "Iteration 124, loss = 2652.70952082\n",
      "Iteration 118, loss = 2980.86705348\n",
      "Iteration 146, loss = 2428.75286143\n",
      "Iteration 82, loss = 3768.40126062\n",
      "Iteration 70, loss = 4196.04079392\n",
      "Iteration 40, loss = 5848.59205877\n",
      "Iteration 40, loss = 5830.59432588\n",
      "Iteration 142, loss = 2561.92607782\n",
      "Iteration 125, loss = 2627.73903409\n",
      "Iteration 119, loss = 2957.44814953\n",
      "Iteration 147, loss = 2409.01632456\n",
      "Iteration 71, loss = 4155.49654123\n",
      "Iteration 41, loss = 5776.42833369\n",
      "Iteration 143, loss = 2549.26886561\n",
      "Iteration 41, loss = 5755.57175909\n",
      "Iteration 83, loss = 3729.55932153\n",
      "Iteration 126, loss = 2610.30790679\n",
      "Iteration 120, loss = 2937.58310908\n",
      "Iteration 148, loss = 2404.38926644\n",
      "Iteration 72, loss = 4119.52506062\n",
      "Iteration 42, loss = 5705.52345228\n",
      "Iteration 144, loss = 2534.10520685\n",
      "Iteration 42, loss = 5684.76903933\n",
      "Iteration 84, loss = 3708.26451112\n",
      "Iteration 127, loss = 2600.29021732\n",
      "Iteration 121, loss = 2918.79471145\n",
      "Iteration 73, loss = 4084.64670837\n",
      "Iteration 149, loss = 2384.78907236\n",
      "Iteration 43, loss = 5636.03852537\n",
      "Iteration 85, loss = 3675.49816509\n",
      "Iteration 145, loss = 2523.11493529\n",
      "Iteration 43, loss = 5613.02256368\n",
      "Iteration 128, loss = 2572.89071121\n",
      "Iteration 122, loss = 2898.38665807\n",
      "Iteration 74, loss = 4041.27103546\n",
      "Iteration 86, loss = 3641.22021586\n",
      "Iteration 150, loss = 2368.96955846\n",
      "Iteration 44, loss = 5568.76978287\n",
      "Iteration 44, loss = 5544.74204962\n",
      "Iteration 146, loss = 2503.67238993\n",
      "Iteration 129, loss = 2559.63476265\n",
      "Iteration 123, loss = 2882.33745348\n",
      "Iteration 45, loss = 5504.29817733\n",
      "Iteration 75, loss = 4005.25748743\n",
      "Iteration 87, loss = 3609.45871129\n",
      "Iteration 151, loss = 2357.32098679\n",
      "Iteration 147, loss = 2491.53510154\n",
      "Iteration 45, loss = 5478.38547321\n",
      "Iteration 130, loss = 2544.52856143\n",
      "Iteration 124, loss = 2862.70243757\n",
      "Iteration 46, loss = 5440.52940781\n",
      "Iteration 76, loss = 3970.00324732\n",
      "Iteration 88, loss = 3577.57975514\n",
      "Iteration 152, loss = 2348.47988538\n",
      "Iteration 148, loss = 2476.48344025\n",
      "Iteration 46, loss = 5410.83237802\n",
      "Iteration 131, loss = 2526.84815409\n",
      "Iteration 125, loss = 2845.10276877\n",
      "Iteration 47, loss = 5375.96675807\n",
      "Iteration 77, loss = 3935.16198845\n",
      "Iteration 89, loss = 3548.70907448\n",
      "Iteration 153, loss = 2342.20620697\n",
      "Iteration 149, loss = 2460.99107310\n",
      "Iteration 132, loss = 2509.18067130\n",
      "Iteration 47, loss = 5346.30309297\n",
      "Iteration 126, loss = 2828.04015290\n",
      "Iteration 78, loss = 3900.44658393\n",
      "Iteration 48, loss = 5316.05168551\n",
      "Iteration 90, loss = 3522.62474338\n",
      "Iteration 154, loss = 2320.79405245\n",
      "Iteration 150, loss = 2445.67562975\n",
      "Iteration 133, loss = 2492.62691404\n",
      "Iteration 48, loss = 5283.96083444\n",
      "Iteration 79, loss = 3867.59496697\n",
      "Iteration 127, loss = 2802.50274209\n",
      "Iteration 91, loss = 3491.29199786\n",
      "Iteration 49, loss = 5254.88618619\n",
      "Iteration 155, loss = 2308.81088501\n",
      "Iteration 151, loss = 2432.45370077\n",
      "Iteration 49, loss = 5222.84902443\n",
      "Iteration 134, loss = 2478.51103998\n",
      "Iteration 80, loss = 3835.54747704\n",
      "Iteration 128, loss = 2789.63805024\n",
      "Iteration 50, loss = 5197.48181346\n",
      "Iteration 92, loss = 3461.02921618\n",
      "Iteration 156, loss = 2295.86852300\n",
      "Iteration 152, loss = 2430.02941123\n",
      "Iteration 135, loss = 2471.49467898\n",
      "Iteration 50, loss = 5164.91982387\n",
      "Iteration 81, loss = 3805.34465911\n",
      "Iteration 129, loss = 2772.92764905\n",
      "Iteration 51, loss = 5138.67721019\n",
      "Iteration 93, loss = 3436.04058518\n",
      "Iteration 157, loss = 2286.63905684\n",
      "Iteration 153, loss = 2407.42939363\n",
      "Iteration 136, loss = 2444.33723769\n",
      "Iteration 51, loss = 5102.91795381\n",
      "Iteration 82, loss = 3770.48900932\n",
      "Iteration 130, loss = 2761.30452302\n",
      "Iteration 52, loss = 5082.04360651\n",
      "Iteration 94, loss = 3410.83054344\n",
      "Iteration 158, loss = 2273.95334101\n",
      "Iteration 154, loss = 2398.50364423\n",
      "Iteration 137, loss = 2431.93360258\n",
      "Iteration 52, loss = 5045.62972198\n",
      "Iteration 83, loss = 3733.21831369\n",
      "Iteration 131, loss = 2741.63144019\n",
      "Iteration 53, loss = 5025.04077830\n",
      "Iteration 159, loss = 2262.70453160\n",
      "Iteration 95, loss = 3379.54215140\n",
      "Iteration 138, loss = 2415.76721391\n",
      "Iteration 155, loss = 2386.69683138\n",
      "Iteration 53, loss = 4989.65237814\n",
      "Iteration 84, loss = 3702.01625548\n",
      "Iteration 132, loss = 2720.09709165\n",
      "Iteration 160, loss = 2263.24307911\n",
      "Iteration 54, loss = 4973.91090934\n",
      "Iteration 139, loss = 2400.28933409\n",
      "Iteration 96, loss = 3354.46844059\n",
      "Iteration 156, loss = 2369.73405892\n",
      "Iteration 54, loss = 4933.88680082\n",
      "Iteration 85, loss = 3676.97639637\n",
      "Iteration 133, loss = 2698.47764091\n",
      "Iteration 161, loss = 2242.43080034\n",
      "Iteration 55, loss = 4920.65756781\n",
      "Iteration 140, loss = 2384.58217093\n",
      "Iteration 97, loss = 3327.89968900\n",
      "Iteration 157, loss = 2357.69757925\n",
      "Iteration 55, loss = 4879.90359838\n",
      "Iteration 86, loss = 3646.87904941\n",
      "Iteration 134, loss = 2683.84546460\n",
      "Iteration 162, loss = 2229.86461731\n",
      "Iteration 141, loss = 2372.73772485\n",
      "Iteration 56, loss = 4870.38981372\n",
      "Iteration 98, loss = 3304.85829844\n",
      "Iteration 158, loss = 2346.19113755\n",
      "Iteration 56, loss = 4827.76624630\n",
      "Iteration 87, loss = 3613.72065330\n",
      "Iteration 135, loss = 2667.88574191\n",
      "Iteration 163, loss = 2220.40222603\n",
      "Iteration 142, loss = 2355.57643700\n",
      "Iteration 57, loss = 4819.80544920\n",
      "Iteration 57, loss = 4778.38996267\n",
      "Iteration 159, loss = 2331.32369160\n",
      "Iteration 99, loss = 3275.09986926\n",
      "Iteration 88, loss = 3585.30652826\n",
      "Iteration 136, loss = 2651.04728437\n",
      "Iteration 164, loss = 2210.58870544\n",
      "Iteration 143, loss = 2341.32434124\n",
      "Iteration 58, loss = 4770.44124083\n",
      "Iteration 58, loss = 4728.96487580\n",
      "Iteration 160, loss = 2323.16785661\n",
      "Iteration 100, loss = 3250.98528161\n",
      "Iteration 89, loss = 3555.90719279\n",
      "Iteration 137, loss = 2640.69878505\n",
      "Iteration 165, loss = 2193.02193432\n",
      "Iteration 59, loss = 4721.39018396\n",
      "Iteration 59, loss = 4679.38165349\n",
      "Iteration 144, loss = 2323.20871614\n",
      "Iteration 101, loss = 3226.91504393\n",
      "Iteration 161, loss = 2304.61026644\n",
      "Iteration 90, loss = 3530.39406002\n",
      "Iteration 166, loss = 2188.79323505\n",
      "Iteration 138, loss = 2629.03266699\n",
      "Iteration 60, loss = 4628.97659330\n",
      "Iteration 145, loss = 2310.00116991\n",
      "Iteration 60, loss = 4674.46919222\n",
      "Iteration 91, loss = 3500.69975099\n",
      "Iteration 102, loss = 3200.27950340\n",
      "Iteration 162, loss = 2289.56145594\n",
      "Iteration 139, loss = 2616.94040994\n",
      "Iteration 167, loss = 2172.52113714\n",
      "Iteration 61, loss = 4581.02247385\n",
      "Iteration 146, loss = 2305.79916450\n",
      "Iteration 92, loss = 3470.16462336\n",
      "Iteration 103, loss = 3177.21902110\n",
      "Iteration 61, loss = 4629.10749667\n",
      "Iteration 163, loss = 2281.26900265\n",
      "Iteration 140, loss = 2589.18168768\n",
      "Iteration 168, loss = 2161.07604947\n",
      "Iteration 147, loss = 2287.47304330\n",
      "Iteration 62, loss = 4534.93272537\n",
      "Iteration 93, loss = 3443.89582899\n",
      "Iteration 104, loss = 3152.23754078\n",
      "Iteration 62, loss = 4582.70357492\n",
      "Iteration 164, loss = 2271.43467136\n",
      "Iteration 141, loss = 2570.32184200\n",
      "Iteration 169, loss = 2163.13799461\n",
      "Iteration 148, loss = 2268.49205731\n",
      "Iteration 94, loss = 3417.35733906\n",
      "Iteration 105, loss = 3131.42992315\n",
      "Iteration 63, loss = 4487.56067677\n",
      "Iteration 165, loss = 2254.89080428\n",
      "Iteration 63, loss = 4537.66421388\n",
      "Iteration 170, loss = 2142.64453349\n",
      "Iteration 142, loss = 2556.08092595\n",
      "Iteration 64, loss = 4444.46497847\n",
      "Iteration 149, loss = 2257.70251008\n",
      "Iteration 95, loss = 3394.90980876\n",
      "Iteration 106, loss = 3105.24392958\n",
      "Iteration 166, loss = 2252.25722355\n",
      "Iteration 64, loss = 4494.03620955\n",
      "Iteration 143, loss = 2534.93032684\n",
      "Iteration 171, loss = 2135.93194986\n",
      "Iteration 65, loss = 4401.00085098\n",
      "Iteration 150, loss = 2244.10562944\n",
      "Iteration 96, loss = 3365.57215173\n",
      "Iteration 107, loss = 3080.92746662\n",
      "Iteration 167, loss = 2237.57713353\n",
      "Iteration 65, loss = 4451.12398613\n",
      "Iteration 144, loss = 2524.09981822\n",
      "Iteration 172, loss = 2128.42845406\n",
      "Iteration 66, loss = 4355.04879470\n",
      "Iteration 97, loss = 3338.40783733\n",
      "Iteration 151, loss = 2228.38066699\n",
      "Iteration 108, loss = 3064.36307820\n",
      "Iteration 168, loss = 2219.02292455\n",
      "Iteration 66, loss = 4409.10345018\n",
      "Iteration 145, loss = 2509.49618980\n",
      "Iteration 173, loss = 2112.64255568\n",
      "Iteration 67, loss = 4312.49764432\n",
      "Iteration 98, loss = 3319.57277696\n",
      "Iteration 152, loss = 2216.15391380\n",
      "Iteration 109, loss = 3037.80010655\n",
      "Iteration 169, loss = 2222.99547628\n",
      "Iteration 67, loss = 4367.79283978\n",
      "Iteration 146, loss = 2493.79978848\n",
      "Iteration 174, loss = 2101.89656782\n",
      "Iteration 99, loss = 3289.27439403\n",
      "Iteration 68, loss = 4270.12858314\n",
      "Iteration 153, loss = 2210.03260987\n",
      "Iteration 110, loss = 3014.47448546\n",
      "Iteration 170, loss = 2199.38867576\n",
      "Iteration 68, loss = 4326.58003329\n",
      "Iteration 147, loss = 2484.47789599\n",
      "Iteration 175, loss = 2095.91629110\n",
      "Iteration 100, loss = 3264.86282241\n",
      "Iteration 154, loss = 2194.25435819\n",
      "Iteration 69, loss = 4227.12841260\n",
      "Iteration 111, loss = 2992.75336240\n",
      "Iteration 171, loss = 2191.13513745\n",
      "Iteration 148, loss = 2458.67354900\n",
      "Iteration 69, loss = 4284.70111110\n",
      "Iteration 176, loss = 2088.57164973\n",
      "Iteration 101, loss = 3240.36141995\n",
      "Iteration 155, loss = 2184.75616706\n",
      "Iteration 70, loss = 4188.31148565\n",
      "Iteration 112, loss = 2980.61223900\n",
      "Iteration 172, loss = 2181.00038940\n",
      "Iteration 70, loss = 4246.39866051\n",
      "Iteration 149, loss = 2447.76815955\n",
      "Iteration 102, loss = 3213.31304041\n",
      "Iteration 177, loss = 2076.38604415\n",
      "Iteration 156, loss = 2165.58645622\n",
      "Iteration 71, loss = 4150.33778357\n",
      "Iteration 113, loss = 2952.72753034\n",
      "Iteration 173, loss = 2168.29505281\n",
      "Iteration 71, loss = 4207.72413896\n",
      "Iteration 150, loss = 2443.73961882\n",
      "Iteration 103, loss = 3191.94808469\n",
      "Iteration 178, loss = 2064.89241613\n",
      "Iteration 157, loss = 2154.46059321\n",
      "Iteration 72, loss = 4109.51317958\n",
      "Iteration 114, loss = 2930.81813326\n",
      "Iteration 104, loss = 3166.25169322\n",
      "Iteration 174, loss = 2162.22601871\n",
      "Iteration 151, loss = 2426.99932506\n",
      "Iteration 72, loss = 4173.01704120\n",
      "Iteration 179, loss = 2060.06116112\n",
      "Iteration 158, loss = 2141.46389415\n",
      "Iteration 73, loss = 4077.48069841\n",
      "Iteration 115, loss = 2915.62642994\n",
      "Iteration 105, loss = 3146.65374291\n",
      "Iteration 175, loss = 2147.07691906\n",
      "Iteration 180, loss = 2048.55645588\n",
      "Iteration 73, loss = 4133.24754846\n",
      "Iteration 152, loss = 2407.95552996\n",
      "Iteration 159, loss = 2143.38025005\n",
      "Iteration 74, loss = 4032.36075744\n",
      "Iteration 116, loss = 2891.25842386\n",
      "Iteration 106, loss = 3127.15771395\n",
      "Iteration 176, loss = 2133.69586721\n",
      "Iteration 74, loss = 4093.82325564\n",
      "Iteration 153, loss = 2396.90125579\n",
      "Iteration 181, loss = 2047.51135589\n",
      "Iteration 160, loss = 2117.54696107\n",
      "Iteration 75, loss = 3996.22427917\n",
      "Iteration 117, loss = 2875.36996102\n",
      "Iteration 107, loss = 3101.35890278\n",
      "Iteration 177, loss = 2138.37742295\n",
      "Iteration 154, loss = 2380.56819320\n",
      "Iteration 75, loss = 4059.48433475\n",
      "Iteration 182, loss = 2033.68693641\n",
      "Iteration 161, loss = 2106.15643753\n",
      "Iteration 118, loss = 2848.36912742\n",
      "Iteration 76, loss = 3960.41448789\n",
      "Iteration 108, loss = 3077.20539695\n",
      "Iteration 178, loss = 2112.01273607\n",
      "Iteration 155, loss = 2367.92115158\n",
      "Iteration 183, loss = 2028.62390639\n",
      "Iteration 162, loss = 2091.81230207\n",
      "Iteration 76, loss = 4024.30401827\n",
      "Iteration 119, loss = 2832.52743835\n",
      "Iteration 77, loss = 3922.98008274\n",
      "Iteration 109, loss = 3058.82416635\n",
      "Iteration 179, loss = 2110.70287296\n",
      "Iteration 156, loss = 2360.22086924\n",
      "Iteration 184, loss = 2015.45063773\n",
      "Iteration 163, loss = 2082.80915438\n",
      "Iteration 77, loss = 3989.43929129\n",
      "Iteration 120, loss = 2813.60619963\n",
      "Iteration 78, loss = 3889.24114214\n",
      "Iteration 110, loss = 3037.41153235\n",
      "Iteration 180, loss = 2094.95143300\n",
      "Iteration 157, loss = 2352.15136895\n",
      "Iteration 185, loss = 2005.78861508\n",
      "Iteration 164, loss = 2065.35518172\n",
      "Iteration 78, loss = 3953.86295622\n",
      "Iteration 79, loss = 3853.77380268\n",
      "Iteration 121, loss = 2792.79553594\n",
      "Iteration 111, loss = 3013.87910184\n",
      "Iteration 181, loss = 2098.68096525\n",
      "Iteration 158, loss = 2332.19939718\n",
      "Iteration 186, loss = 2001.14800644\n",
      "Iteration 165, loss = 2063.34316787\n",
      "Iteration 79, loss = 3918.69817089\n",
      "Iteration 122, loss = 2776.19472074\n",
      "Iteration 80, loss = 3820.74104991\n",
      "Iteration 112, loss = 3001.16012937\n",
      "Iteration 159, loss = 2315.78554785\n",
      "Iteration 182, loss = 2080.10988419\n",
      "Iteration 187, loss = 2008.21230455\n",
      "Iteration 166, loss = 2048.85323387\n",
      "Iteration 80, loss = 3884.91500877\n",
      "Iteration 123, loss = 2755.58860930\n",
      "Iteration 81, loss = 3783.96333827\n",
      "Iteration 113, loss = 2974.32458980\n",
      "Iteration 160, loss = 2304.84327562\n",
      "Iteration 183, loss = 2061.71228240\n",
      "Iteration 188, loss = 1976.34549704\n",
      "Iteration 167, loss = 2031.62012076\n",
      "Iteration 81, loss = 3849.99598132\n",
      "Iteration 82, loss = 3753.79080077\n",
      "Iteration 124, loss = 2742.10256737\n",
      "Iteration 114, loss = 2955.99295415\n",
      "Iteration 184, loss = 2055.51677432\n",
      "Iteration 161, loss = 2287.01943068\n",
      "Iteration 168, loss = 2027.23438215\n",
      "Iteration 189, loss = 1967.57579215\n",
      "Iteration 82, loss = 3821.05668906\n",
      "Iteration 83, loss = 3715.86698719\n",
      "Iteration 125, loss = 2719.51659181\n",
      "Iteration 115, loss = 2940.31683753\n",
      "Iteration 185, loss = 2044.38609816\n",
      "Iteration 162, loss = 2276.99765360\n",
      "Iteration 190, loss = 1966.40427565\n",
      "Iteration 169, loss = 2014.22945543\n",
      "Iteration 83, loss = 3787.79844402\n",
      "Iteration 84, loss = 3685.53057898\n",
      "Iteration 126, loss = 2710.65097741\n",
      "Iteration 116, loss = 2918.84740350\n",
      "Iteration 186, loss = 2046.93805095\n",
      "Iteration 163, loss = 2270.99821176\n",
      "Iteration 191, loss = 1954.24253699\n",
      "Iteration 84, loss = 3755.51963807\n",
      "Iteration 170, loss = 2004.86902046\n",
      "Iteration 85, loss = 3655.53725417\n",
      "Iteration 117, loss = 2899.03600829\n",
      "Iteration 127, loss = 2683.48712853\n",
      "Iteration 187, loss = 2027.28412061\n",
      "Iteration 164, loss = 2248.60959941\n",
      "Iteration 171, loss = 1997.16533649\n",
      "Iteration 192, loss = 1942.47904140\n",
      "Iteration 85, loss = 3726.53298964\n",
      "Iteration 86, loss = 3631.83616985\n",
      "Iteration 118, loss = 2875.81299600\n",
      "Iteration 128, loss = 2666.18364675\n",
      "Iteration 165, loss = 2241.62075075\n",
      "Iteration 188, loss = 2007.96292392\n",
      "Iteration 193, loss = 1938.41223661\n",
      "Iteration 172, loss = 1985.67654349\n",
      "Iteration 86, loss = 3695.67049152\n",
      "Iteration 87, loss = 3598.12730306\n",
      "Iteration 119, loss = 2856.28400987\n",
      "Iteration 129, loss = 2649.70461770\n",
      "Iteration 166, loss = 2228.03480044\n",
      "Iteration 189, loss = 2001.37138244\n",
      "Iteration 194, loss = 1923.95724755\n",
      "Iteration 173, loss = 1975.79612438\n",
      "Iteration 87, loss = 3664.05678931\n",
      "Iteration 88, loss = 3563.62297733\n",
      "Iteration 120, loss = 2837.04887201\n",
      "Iteration 130, loss = 2635.70151310\n",
      "Iteration 167, loss = 2219.41823411\n",
      "Iteration 190, loss = 2003.40282386\n",
      "Iteration 195, loss = 1925.20783354\n",
      "Iteration 174, loss = 1963.65238203\n",
      "Iteration 88, loss = 3633.47847621\n",
      "Iteration 89, loss = 3532.39520762\n",
      "Iteration 121, loss = 2821.67653896\n",
      "Iteration 131, loss = 2617.07008974\n",
      "Iteration 168, loss = 2212.51078675\n",
      "Iteration 191, loss = 1994.88946912\n",
      "Iteration 196, loss = 1919.50555468\n",
      "Iteration 89, loss = 3607.28539794\n",
      "Iteration 175, loss = 1954.63816212\n",
      "Iteration 122, loss = 2806.73356207\n",
      "Iteration 90, loss = 3510.59557098\n",
      "Iteration 132, loss = 2596.77796874\n",
      "Iteration 169, loss = 2195.70836441\n",
      "Iteration 197, loss = 1904.12869679\n",
      "Iteration 90, loss = 3577.15019607\n",
      "Iteration 192, loss = 1977.27031390\n",
      "Iteration 176, loss = 1944.22392667\n",
      "Iteration 123, loss = 2781.97033583\n",
      "Iteration 91, loss = 3473.54976035\n",
      "Iteration 133, loss = 2584.18550680\n",
      "Iteration 170, loss = 2185.54406692\n",
      "Iteration 198, loss = 1904.27032487\n",
      "Iteration 91, loss = 3547.92453456\n",
      "Iteration 193, loss = 1976.64694892\n",
      "Iteration 177, loss = 1936.50430373\n",
      "Iteration 124, loss = 2767.11657571\n",
      "Iteration 134, loss = 2567.03644519\n",
      "Iteration 92, loss = 3444.99325828\n",
      "Iteration 171, loss = 2176.93812817\n",
      "Iteration 199, loss = 1889.63554802\n",
      "Iteration 194, loss = 1953.99885605\n",
      "Iteration 92, loss = 3516.52134617\n",
      "Iteration 178, loss = 1924.01741466\n",
      "Iteration 125, loss = 2744.71542795\n",
      "Iteration 135, loss = 2550.78499161\n",
      "Iteration 93, loss = 3415.21848304\n",
      "Iteration 172, loss = 2170.79736382\n",
      "Iteration 200, loss = 1886.06708995\n",
      "Iteration 195, loss = 1958.52668905\n",
      "Iteration 93, loss = 3490.13531559\n",
      "Iteration 179, loss = 1914.92279216\n",
      "Iteration 126, loss = 2728.99586088\n",
      "Iteration 136, loss = 2559.58563829\n",
      "Iteration 173, loss = 2149.42092621\n",
      "Iteration 94, loss = 3394.25104868\n",
      "Iteration 196, loss = 1938.19108371\n",
      "Iteration 201, loss = 1881.91619478\n",
      "Iteration 94, loss = 3463.34454324\n",
      "Iteration 180, loss = 1902.30435679\n",
      "Iteration 127, loss = 2709.60703001\n",
      "Iteration 137, loss = 2523.79636247\n",
      "Iteration 174, loss = 2146.03226141\n",
      "Iteration 95, loss = 3364.57188553\n",
      "Iteration 197, loss = 1934.44681965\n",
      "Iteration 202, loss = 1866.57924359\n",
      "Iteration 95, loss = 3434.97463142\n",
      "Iteration 128, loss = 2695.59866300\n",
      "Iteration 181, loss = 1895.56127357\n",
      "Iteration 138, loss = 2508.27675652\n",
      "Iteration 175, loss = 2131.18708105\n",
      "Iteration 96, loss = 3334.48050779\n",
      "Iteration 198, loss = 1924.47210621\n",
      "Iteration 203, loss = 1856.47350912\n",
      "Iteration 129, loss = 2682.62352066\n",
      "Iteration 182, loss = 1888.66618971\n",
      "Iteration 96, loss = 3408.10309580\n",
      "Iteration 139, loss = 2489.80153920\n",
      "Iteration 176, loss = 2118.80065597\n",
      "Iteration 97, loss = 3307.29544770\n",
      "Iteration 199, loss = 1937.06509076\n",
      "Iteration 204, loss = 1852.16325150\n",
      "Iteration 130, loss = 2657.98829832\n",
      "Iteration 97, loss = 3381.52776262\n",
      "Iteration 183, loss = 1883.64240521\n",
      "Iteration 140, loss = 2472.63454828\n",
      "Iteration 177, loss = 2113.60808246\n",
      "Iteration 98, loss = 3287.31681917\n",
      "Iteration 200, loss = 1910.28451740\n",
      "Iteration 131, loss = 2641.82190512\n",
      "Iteration 205, loss = 1848.87298134\n",
      "Iteration 184, loss = 1871.07901308\n",
      "Iteration 98, loss = 3360.92579141\n",
      "Iteration 141, loss = 2460.30824427\n",
      "Iteration 178, loss = 2115.69827193\n",
      "Iteration 99, loss = 3256.89217442\n",
      "Iteration 201, loss = 1914.00107131\n",
      "Iteration 206, loss = 1849.87816421\n",
      "Iteration 132, loss = 2632.17128995\n",
      "Iteration 99, loss = 3330.28979985\n",
      "Iteration 185, loss = 1855.17594724\n",
      "Iteration 142, loss = 2447.73485892\n",
      "Iteration 179, loss = 2093.22241466\n",
      "Iteration 100, loss = 3232.59535626\n",
      "Iteration 207, loss = 1835.14887526\n",
      "Iteration 202, loss = 1896.00824597\n",
      "Iteration 133, loss = 2614.33764399\n",
      "Iteration 100, loss = 3306.26368537\n",
      "Iteration 186, loss = 1854.87119431\n",
      "Iteration 143, loss = 2428.33284945\n",
      "Iteration 180, loss = 2077.19663398\n",
      "Iteration 101, loss = 3208.91608688\n",
      "Iteration 208, loss = 1831.98490911\n",
      "Iteration 203, loss = 1881.37879349\n",
      "Iteration 134, loss = 2595.42690239\n",
      "Iteration 101, loss = 3286.95331747\n",
      "Iteration 187, loss = 1843.36382983\n",
      "Iteration 144, loss = 2416.08441241\n",
      "Iteration 181, loss = 2079.47942416\n",
      "Iteration 102, loss = 3182.62692860\n",
      "Iteration 135, loss = 2586.62988686\n",
      "Iteration 204, loss = 1873.81957504\n",
      "Iteration 209, loss = 1815.40181921\n",
      "Iteration 188, loss = 1837.30822269\n",
      "Iteration 102, loss = 3256.98547012\n",
      "Iteration 145, loss = 2397.85565825\n",
      "Iteration 182, loss = 2061.87819722\n",
      "Iteration 136, loss = 2563.14843682\n",
      "Iteration 103, loss = 3156.65833907\n",
      "Iteration 205, loss = 1867.29326140\n",
      "Iteration 210, loss = 1809.97880947\n",
      "Iteration 103, loss = 3241.81649302\n",
      "Iteration 189, loss = 1827.52892177\n",
      "Iteration 146, loss = 2382.28690045\n",
      "Iteration 183, loss = 2054.16571126\n",
      "Iteration 137, loss = 2557.78723035\n",
      "Iteration 206, loss = 1857.08416775\n",
      "Iteration 211, loss = 1805.27536865\n",
      "Iteration 104, loss = 3132.53553381\n",
      "Iteration 147, loss = 2375.12454141\n",
      "Iteration 104, loss = 3209.89653149\n",
      "Iteration 190, loss = 1821.55227792\n",
      "Iteration 138, loss = 2530.77995330\n",
      "Iteration 184, loss = 2048.02640772\n",
      "Iteration 207, loss = 1849.94974618\n",
      "Iteration 212, loss = 1795.25665335\n",
      "Iteration 105, loss = 3107.94343647\n",
      "Iteration 148, loss = 2354.28994126\n",
      "Iteration 191, loss = 1811.59052595\n",
      "Iteration 105, loss = 3185.16614903\n",
      "Iteration 139, loss = 2523.50470148\n",
      "Iteration 185, loss = 2026.43551358\n",
      "Iteration 208, loss = 1844.22518000\n",
      "Iteration 106, loss = 3085.53373802\n",
      "Iteration 192, loss = 1805.96971146\n",
      "Iteration 213, loss = 1789.09410049\n",
      "Iteration 149, loss = 2339.60460381\n",
      "Iteration 106, loss = 3163.17215832\n",
      "Iteration 140, loss = 2503.74721574\n",
      "Iteration 186, loss = 2022.22936959\n",
      "Iteration 209, loss = 1840.95017465\n",
      "Iteration 107, loss = 3062.59756428\n",
      "Iteration 150, loss = 2334.36123299\n",
      "Iteration 214, loss = 1795.65057156\n",
      "Iteration 193, loss = 1799.86489788\n",
      "Iteration 107, loss = 3141.52800471\n",
      "Iteration 141, loss = 2495.13338694\n",
      "Iteration 187, loss = 2015.06231200\n",
      "Iteration 210, loss = 1840.00019125\n",
      "Iteration 108, loss = 3040.87293979\n",
      "Iteration 194, loss = 1786.95618321\n",
      "Iteration 215, loss = 1785.73832340\n",
      "Iteration 151, loss = 2316.28283344\n",
      "Iteration 108, loss = 3130.97937530\n",
      "Iteration 142, loss = 2475.21467148\n",
      "Iteration 188, loss = 2012.27207295\n",
      "Iteration 211, loss = 1829.50370977\n",
      "Iteration 109, loss = 3019.03296750\n",
      "Iteration 216, loss = 1767.90332674\n",
      "Iteration 195, loss = 1777.58669519\n",
      "Iteration 143, loss = 2462.87238902\n",
      "Iteration 109, loss = 3096.73798956\n",
      "Iteration 152, loss = 2301.02673140\n",
      "Iteration 189, loss = 2000.99966134\n",
      "Iteration 212, loss = 1814.34179164\n",
      "Iteration 110, loss = 2997.56975054\n",
      "Iteration 196, loss = 1771.30492133\n",
      "Iteration 217, loss = 1765.84403193\n",
      "Iteration 110, loss = 3075.09797394\n",
      "Iteration 144, loss = 2447.85399779\n",
      "Iteration 153, loss = 2284.69062157\n",
      "Iteration 190, loss = 1986.11019590\n",
      "Iteration 213, loss = 1803.10677783\n",
      "Iteration 111, loss = 2983.64218637\n",
      "Iteration 218, loss = 1759.81876426\n",
      "Iteration 197, loss = 1761.50586454\n",
      "Iteration 145, loss = 2438.50228196\n",
      "Iteration 154, loss = 2278.08847976\n",
      "Iteration 111, loss = 3057.57940414\n",
      "Iteration 191, loss = 1984.23181606\n",
      "Iteration 214, loss = 1806.50244745\n",
      "Iteration 112, loss = 2954.80913605\n",
      "Iteration 198, loss = 1764.31313241\n",
      "Iteration 219, loss = 1746.50872487\n",
      "Iteration 146, loss = 2415.90603014\n",
      "Iteration 155, loss = 2260.19242061\n",
      "Iteration 112, loss = 3035.62768623\n",
      "Iteration 192, loss = 1968.10754417\n",
      "Iteration 215, loss = 1800.33919153\n",
      "Iteration 113, loss = 2931.71583690\n",
      "Iteration 220, loss = 1748.31124826\n",
      "Iteration 199, loss = 1746.63077583\n",
      "Iteration 147, loss = 2406.01110167\n",
      "Iteration 156, loss = 2248.42696121\n",
      "Iteration 113, loss = 3013.91889747\n",
      "Iteration 193, loss = 1968.78643004\n",
      "Iteration 216, loss = 1781.27854866\n",
      "Iteration 114, loss = 2910.50389600\n",
      "Iteration 221, loss = 1742.92515999\n",
      "Iteration 200, loss = 1744.86666122\n",
      "Iteration 148, loss = 2393.46477341\n",
      "Iteration 114, loss = 2992.69042353\n",
      "Iteration 157, loss = 2238.97801092\n",
      "Iteration 217, loss = 1799.21348502\n",
      "Iteration 194, loss = 1947.01578066\n",
      "Iteration 115, loss = 2890.29289631\n",
      "Iteration 201, loss = 1730.26351436\n",
      "Iteration 222, loss = 1727.27310860\n",
      "Iteration 149, loss = 2373.31870888\n",
      "Iteration 115, loss = 2975.22640577\n",
      "Iteration 158, loss = 2228.23597589\n",
      "Iteration 195, loss = 1935.21218386\n",
      "Iteration 218, loss = 1776.25954565\n",
      "Iteration 116, loss = 2873.03780111\n",
      "Iteration 202, loss = 1723.49883461\n",
      "Iteration 223, loss = 1720.21779634\n",
      "Iteration 150, loss = 2363.39554326\n",
      "Iteration 159, loss = 2214.58787661\n",
      "Iteration 116, loss = 2956.19321280\n",
      "Iteration 219, loss = 1763.19043606\n",
      "Iteration 196, loss = 1947.88305811\n",
      "Iteration 117, loss = 2849.29240433\n",
      "Iteration 203, loss = 1717.75580424\n",
      "Iteration 224, loss = 1707.59596558\n",
      "Iteration 151, loss = 2356.89195075\n",
      "Iteration 160, loss = 2197.66818015\n",
      "Iteration 117, loss = 2933.04006819\n",
      "Iteration 220, loss = 1759.31841282\n",
      "Iteration 197, loss = 1936.21944278\n",
      "Iteration 118, loss = 2830.59903307\n",
      "Iteration 204, loss = 1725.64943378\n",
      "Iteration 225, loss = 1711.17765178\n",
      "Iteration 152, loss = 2341.90158071\n",
      "Iteration 161, loss = 2183.04133996\n",
      "Iteration 118, loss = 2913.30526861\n",
      "Iteration 221, loss = 1763.23862454\n",
      "Iteration 198, loss = 1933.08733275\n",
      "Iteration 119, loss = 2810.42388523\n",
      "Iteration 205, loss = 1708.81656413\n",
      "Iteration 226, loss = 1703.44575230\n",
      "Iteration 153, loss = 2320.64815874\n",
      "Iteration 162, loss = 2171.50182128\n",
      "Iteration 119, loss = 2895.26810288\n",
      "Iteration 199, loss = 1908.54823605\n",
      "Iteration 222, loss = 1752.22845806\n",
      "Iteration 120, loss = 2799.37885494\n",
      "Iteration 206, loss = 1699.30049313\n",
      "Iteration 227, loss = 1695.89635622\n",
      "Iteration 154, loss = 2326.68138279\n",
      "Iteration 163, loss = 2170.77293164\n",
      "Iteration 120, loss = 2872.13596899\n",
      "Iteration 200, loss = 1913.09857196\n",
      "Iteration 223, loss = 1752.05388101\n",
      "Iteration 207, loss = 1689.11539291\n",
      "Iteration 121, loss = 2771.91487333\n",
      "Iteration 155, loss = 2294.14968850\n",
      "Iteration 228, loss = 1692.55979509\n",
      "Iteration 164, loss = 2145.87479031\n",
      "Iteration 201, loss = 1886.40718130\n",
      "Iteration 121, loss = 2859.23802058\n",
      "Iteration 224, loss = 1723.89059584\n",
      "Iteration 208, loss = 1681.58470398\n",
      "Iteration 122, loss = 2752.25304032\n",
      "Iteration 229, loss = 1682.97420250\n",
      "Iteration 156, loss = 2286.25321534\n",
      "Iteration 165, loss = 2138.99538128\n",
      "Iteration 202, loss = 1879.00404342\n",
      "Iteration 122, loss = 2836.16292153\n",
      "Iteration 225, loss = 1742.10883028\n",
      "Iteration 209, loss = 1676.06047330\n",
      "Iteration 123, loss = 2735.24547030\n",
      "Iteration 230, loss = 1679.81604097\n",
      "Iteration 157, loss = 2284.00252569\n",
      "Iteration 166, loss = 2126.87731700\n",
      "Iteration 203, loss = 1868.22699683\n",
      "Iteration 226, loss = 1736.00139599\n",
      "Iteration 123, loss = 2820.54020113\n",
      "Iteration 124, loss = 2718.28922854\n",
      "Iteration 210, loss = 1669.38698617\n",
      "Iteration 158, loss = 2267.27564749\n",
      "Iteration 231, loss = 1675.07163455\n",
      "Iteration 167, loss = 2113.51976561\n",
      "Iteration 204, loss = 1864.59803200\n",
      "Iteration 227, loss = 1724.60900803\n",
      "Iteration 124, loss = 2803.76668097\n",
      "Iteration 159, loss = 2254.58900388\n",
      "Iteration 125, loss = 2699.37340309\n",
      "Iteration 211, loss = 1670.86503041\n",
      "Iteration 232, loss = 1665.37935069\n",
      "Iteration 168, loss = 2105.30266045\n",
      "Iteration 205, loss = 1856.28722571\n",
      "Iteration 228, loss = 1713.25286830\n",
      "Iteration 125, loss = 2783.21332072\n",
      "Iteration 160, loss = 2242.72010496\n",
      "Iteration 126, loss = 2684.07033829\n",
      "Iteration 212, loss = 1660.83151340\n",
      "Iteration 233, loss = 1663.18727021\n",
      "Iteration 169, loss = 2092.51305092\n",
      "Iteration 206, loss = 1848.59211686\n",
      "Iteration 229, loss = 1704.29145230\n",
      "Iteration 126, loss = 2768.54951085\n",
      "Iteration 161, loss = 2226.19047482\n",
      "Iteration 127, loss = 2663.84639480\n",
      "Iteration 234, loss = 1655.44586798\n",
      "Iteration 213, loss = 1653.38267034\n",
      "Iteration 170, loss = 2080.61947223\n",
      "Iteration 207, loss = 1838.54390150\n",
      "Iteration 230, loss = 1702.45562521\n",
      "Iteration 162, loss = 2217.97016964\n",
      "Iteration 127, loss = 2744.22921006\n",
      "Iteration 128, loss = 2654.60960275\n",
      "Iteration 214, loss = 1643.30094915\n",
      "Iteration 235, loss = 1645.48451955\n",
      "Iteration 171, loss = 2079.10889860\n",
      "Iteration 231, loss = 1700.51649828\n",
      "Iteration 208, loss = 1832.70518983\n",
      "Iteration 163, loss = 2201.73800352\n",
      "Iteration 128, loss = 2726.41226549\n",
      "Iteration 129, loss = 2632.06043952\n",
      "Iteration 215, loss = 1636.84899713\n",
      "Iteration 236, loss = 1650.29678799\n",
      "Iteration 232, loss = 1683.15835659\n",
      "Iteration 172, loss = 2057.06101587\n",
      "Iteration 164, loss = 2187.35026393\n",
      "Iteration 209, loss = 1825.32947280\n",
      "Iteration 129, loss = 2712.49408906\n",
      "Iteration 130, loss = 2617.77294952\n",
      "Iteration 216, loss = 1643.29675845\n",
      "Iteration 237, loss = 1632.67474601\n",
      "Iteration 233, loss = 1684.27167381\n",
      "Iteration 165, loss = 2176.34784155\n",
      "Iteration 173, loss = 2050.03318690\n",
      "Iteration 210, loss = 1819.95332802\n",
      "Iteration 130, loss = 2696.84566144\n",
      "Iteration 131, loss = 2597.94386648\n",
      "Iteration 217, loss = 1630.21623086\n",
      "Iteration 238, loss = 1638.03238452\n",
      "Iteration 166, loss = 2177.61149264\n",
      "Iteration 174, loss = 2036.49325489\n",
      "Iteration 234, loss = 1673.54366819\n",
      "Iteration 211, loss = 1829.30211789\n",
      "Iteration 131, loss = 2678.57566388\n",
      "Iteration 132, loss = 2586.34668813\n",
      "Iteration 218, loss = 1622.76849295\n",
      "Iteration 239, loss = 1630.24135083\n",
      "Iteration 167, loss = 2154.70724262\n",
      "Iteration 175, loss = 2035.22179413\n",
      "Iteration 235, loss = 1664.36514962\n",
      "Iteration 212, loss = 1814.64575643\n",
      "Iteration 132, loss = 2665.58007313\n",
      "Iteration 133, loss = 2569.70628075\n",
      "Iteration 219, loss = 1615.71010589\n",
      "Iteration 240, loss = 1629.96537141\n",
      "Iteration 168, loss = 2146.13046000\n",
      "Iteration 176, loss = 2022.99222764\n",
      "Iteration 213, loss = 1792.96371221\n",
      "Iteration 236, loss = 1662.86742325\n",
      "Iteration 133, loss = 2654.64584796\n",
      "Iteration 134, loss = 2552.16858479\n",
      "Iteration 220, loss = 1610.58261762\n",
      "Iteration 241, loss = 1616.34855923\n",
      "Iteration 169, loss = 2133.96655761\n",
      "Iteration 214, loss = 1786.79844612\n",
      "Iteration 177, loss = 2013.00070002\n",
      "Iteration 237, loss = 1658.27221600\n",
      "Iteration 134, loss = 2634.57815146\n",
      "Iteration 221, loss = 1604.14370930\n",
      "Iteration 242, loss = 1622.44171212\n",
      "Iteration 135, loss = 2534.46242199\n",
      "Iteration 170, loss = 2128.45815959\n",
      "Iteration 178, loss = 2018.39721499\n",
      "Iteration 215, loss = 1787.47402954\n",
      "Iteration 238, loss = 1652.66665193\n",
      "Iteration 135, loss = 2611.11149554\n",
      "Iteration 222, loss = 1608.19294913\n",
      "Iteration 243, loss = 1608.70023324\n",
      "Iteration 136, loss = 2522.44794065\n",
      "Iteration 171, loss = 2120.07578106\n",
      "Iteration 179, loss = 1987.39430159\n",
      "Iteration 216, loss = 1785.86570784\n",
      "Iteration 239, loss = 1638.86463910\n",
      "Iteration 223, loss = 1593.26686724\n",
      "Iteration 136, loss = 2598.69579039\n",
      "Iteration 244, loss = 1604.53896918\n",
      "Iteration 137, loss = 2508.38704044\n",
      "Iteration 172, loss = 2114.43960839\n",
      "Iteration 180, loss = 1980.39303746\n",
      "Iteration 217, loss = 1776.36540963\n",
      "Iteration 240, loss = 1638.36649156\n",
      "Iteration 224, loss = 1599.18367153\n",
      "Iteration 137, loss = 2585.48123773\n",
      "Iteration 245, loss = 1592.20869274\n",
      "Iteration 138, loss = 2493.30344309\n",
      "Iteration 173, loss = 2096.67293302\n",
      "Iteration 181, loss = 1973.15354352\n",
      "Iteration 218, loss = 1775.38172793\n",
      "Iteration 241, loss = 1639.12282928\n",
      "Iteration 225, loss = 1580.00720157\n",
      "Iteration 138, loss = 2572.90053327\n",
      "Iteration 246, loss = 1589.30325616\n",
      "Iteration 139, loss = 2473.95957948\n",
      "Iteration 174, loss = 2078.30026780\n",
      "Iteration 219, loss = 1769.36886961\n",
      "Iteration 182, loss = 1960.38750164\n",
      "Iteration 242, loss = 1624.91540826\n",
      "Iteration 226, loss = 1579.07668420\n",
      "Iteration 139, loss = 2552.56554205\n",
      "Iteration 247, loss = 1594.77851108\n",
      "Iteration 140, loss = 2458.17177387\n",
      "Iteration 175, loss = 2077.72008767\n",
      "Iteration 220, loss = 1754.44415355\n",
      "Iteration 183, loss = 1949.69487283\n",
      "Iteration 243, loss = 1618.28529276\n",
      "Iteration 140, loss = 2540.84256997\n",
      "Iteration 227, loss = 1573.28890143\n",
      "Iteration 248, loss = 1594.01850983\n",
      "Iteration 141, loss = 2446.51541230\n",
      "Iteration 176, loss = 2060.21023628\n",
      "Iteration 221, loss = 1741.08809466\n",
      "Iteration 244, loss = 1612.93486326\n",
      "Iteration 184, loss = 1943.14870158\n",
      "Iteration 141, loss = 2525.69806090\n",
      "Iteration 228, loss = 1569.02314055\n",
      "Iteration 177, loss = 2051.06922275\n",
      "Iteration 249, loss = 1579.11930923\n",
      "Iteration 142, loss = 2433.95676394\n",
      "Iteration 222, loss = 1737.74638952\n",
      "Iteration 245, loss = 1606.89334001\n",
      "Iteration 185, loss = 1932.51852081\n",
      "Iteration 142, loss = 2515.18858375\n",
      "Iteration 178, loss = 2056.53265452\n",
      "Iteration 229, loss = 1561.30111213\n",
      "Iteration 250, loss = 1579.89327804\n",
      "Iteration 143, loss = 2419.35964673\n",
      "Iteration 223, loss = 1733.41154872\n",
      "Iteration 186, loss = 1924.48369705\n",
      "Iteration 246, loss = 1604.90501685\n",
      "Iteration 143, loss = 2491.56841332\n",
      "Iteration 179, loss = 2048.61479981\n",
      "Iteration 251, loss = 1563.07984147\n",
      "Iteration 230, loss = 1555.24528899\n",
      "Iteration 144, loss = 2398.72383686\n",
      "Iteration 224, loss = 1729.16178672\n",
      "Iteration 247, loss = 1611.12589646\n",
      "Iteration 187, loss = 1914.03636646\n",
      "Iteration 144, loss = 2483.71339214\n",
      "Iteration 180, loss = 2040.76577819\n",
      "Iteration 252, loss = 1554.61542545\n",
      "Iteration 231, loss = 1550.03271091\n",
      "Iteration 145, loss = 2383.79119609\n",
      "Iteration 225, loss = 1724.48558304\n",
      "Iteration 248, loss = 1607.52248150\n",
      "Iteration 188, loss = 1905.88571967\n",
      "Iteration 181, loss = 2014.62025433\n",
      "Iteration 145, loss = 2465.42466345\n",
      "Iteration 232, loss = 1554.64218885\n",
      "Iteration 253, loss = 1552.92425460\n",
      "Iteration 146, loss = 2368.91775676\n",
      "Iteration 226, loss = 1719.56365730\n",
      "Iteration 189, loss = 1899.32739367\n",
      "Iteration 249, loss = 1591.43350620\n",
      "Iteration 146, loss = 2450.75366312\n",
      "Iteration 182, loss = 2009.49038884\n",
      "Iteration 254, loss = 1570.35988378\n",
      "Iteration 147, loss = 2356.15972874\n",
      "Iteration 233, loss = 1534.83865974\n",
      "Iteration 227, loss = 1710.54383334\n",
      "Iteration 190, loss = 1893.68783508\n",
      "Iteration 250, loss = 1583.32527382\n",
      "Iteration 147, loss = 2438.62462539\n",
      "Iteration 183, loss = 2000.27568698\n",
      "Iteration 255, loss = 1547.93088575\n",
      "Iteration 234, loss = 1528.07717284\n",
      "Iteration 148, loss = 2345.51273647\n",
      "Iteration 228, loss = 1699.50912034\n",
      "Iteration 191, loss = 1893.78526179\n",
      "Iteration 251, loss = 1586.95130423\n",
      "Iteration 184, loss = 1994.15252865\n",
      "Iteration 148, loss = 2426.58891816\n",
      "Iteration 256, loss = 1546.49692633\n",
      "Iteration 149, loss = 2340.26328120\n",
      "Iteration 235, loss = 1516.37808376\n",
      "Iteration 229, loss = 1695.79036188\n",
      "Iteration 192, loss = 1870.66057466\n",
      "Iteration 185, loss = 1980.13981949\n",
      "Iteration 252, loss = 1574.19988669\n",
      "Iteration 149, loss = 2414.11706468\n",
      "Iteration 150, loss = 2318.51328157\n",
      "Iteration 257, loss = 1536.42236566\n",
      "Iteration 236, loss = 1512.96614744\n",
      "Iteration 230, loss = 1689.97890351\n",
      "Iteration 193, loss = 1863.20001810\n",
      "Iteration 186, loss = 1976.84261570\n",
      "Iteration 253, loss = 1558.32019852\n",
      "Iteration 150, loss = 2399.86934050\n",
      "Iteration 151, loss = 2308.31940727\n",
      "Iteration 258, loss = 1536.95617259\n",
      "Iteration 237, loss = 1508.78894178\n",
      "Iteration 231, loss = 1679.82155937\n",
      "Iteration 187, loss = 1958.14036929\n",
      "Iteration 254, loss = 1573.43081849\n",
      "Iteration 194, loss = 1851.64221526\n",
      "Iteration 151, loss = 2386.99153355\n",
      "Iteration 259, loss = 1535.52343836\n",
      "Iteration 152, loss = 2289.14586478\n",
      "Iteration 238, loss = 1507.38232749\n",
      "Iteration 232, loss = 1679.24330905\n",
      "Iteration 255, loss = 1560.08794116\n",
      "Iteration 188, loss = 1962.70477666\n",
      "Iteration 152, loss = 2374.45659027\n",
      "Iteration 195, loss = 1845.91520515\n",
      "Iteration 260, loss = 1522.35950270\n",
      "Iteration 153, loss = 2276.27226478\n",
      "Iteration 233, loss = 1665.44363530\n",
      "Iteration 239, loss = 1511.77322715\n",
      "Iteration 153, loss = 2362.33953871\n",
      "Iteration 256, loss = 1553.51858737\n",
      "Iteration 189, loss = 1945.87582360\n",
      "Iteration 261, loss = 1519.62687094\n",
      "Iteration 196, loss = 1836.10740645\n",
      "Iteration 154, loss = 2264.32186353\n",
      "Iteration 234, loss = 1660.02664148\n",
      "Iteration 240, loss = 1504.41456796\n",
      "Iteration 154, loss = 2347.06818149\n",
      "Iteration 257, loss = 1542.06387245\n",
      "Iteration 190, loss = 1939.57074070\n",
      "Iteration 262, loss = 1512.83890808\n",
      "Iteration 197, loss = 1825.89811765\n",
      "Iteration 235, loss = 1650.97422738\n",
      "Iteration 155, loss = 2253.25646169\n",
      "Iteration 241, loss = 1491.90911374\n",
      "Iteration 155, loss = 2335.78384811\n",
      "Iteration 258, loss = 1546.05239768\n",
      "Iteration 191, loss = 1925.39809344\n",
      "Iteration 263, loss = 1515.69793808\n",
      "Iteration 198, loss = 1818.56619495\n",
      "Iteration 156, loss = 2240.36101350\n",
      "Iteration 236, loss = 1648.15588246\n",
      "Iteration 242, loss = 1479.59770250\n",
      "Iteration 192, loss = 1921.60021784\n",
      "Iteration 259, loss = 1546.26768627\n",
      "Iteration 156, loss = 2325.46592587\n",
      "Iteration 264, loss = 1512.06492472\n",
      "Iteration 199, loss = 1813.14693880\n",
      "Iteration 243, loss = 1475.24516378\n",
      "Iteration 157, loss = 2229.22822737\n",
      "Iteration 237, loss = 1656.69419428\n",
      "Iteration 260, loss = 1529.61672895\n",
      "Iteration 193, loss = 1912.13664569\n",
      "Iteration 157, loss = 2311.82878111\n",
      "Iteration 265, loss = 1506.34987039\n",
      "Iteration 200, loss = 1811.14206944\n",
      "Iteration 244, loss = 1470.04370817\n",
      "Iteration 158, loss = 2222.82981454\n",
      "Iteration 238, loss = 1635.61014294\n",
      "Iteration 261, loss = 1529.87649515\n",
      "Iteration 194, loss = 1907.47735086\n",
      "Iteration 266, loss = 1504.30300806\n",
      "Iteration 201, loss = 1790.46702086\n",
      "Iteration 158, loss = 2300.36223710\n",
      "Iteration 245, loss = 1465.67140431\n",
      "Iteration 239, loss = 1633.58934466\n",
      "Iteration 159, loss = 2204.70247193\n",
      "Iteration 195, loss = 1897.18037350\n",
      "Iteration 262, loss = 1529.11111246\n",
      "Iteration 267, loss = 1490.33471889\n",
      "Iteration 159, loss = 2288.77168348\n",
      "Iteration 202, loss = 1791.37242252\n",
      "Iteration 246, loss = 1459.63571312\n",
      "Iteration 160, loss = 2193.17046072\n",
      "Iteration 240, loss = 1627.84647768\n",
      "Iteration 196, loss = 1881.99885958\n",
      "Iteration 263, loss = 1513.23727337\n",
      "Iteration 268, loss = 1486.58455382\n",
      "Iteration 203, loss = 1777.19452665\n",
      "Iteration 160, loss = 2277.05858299\n",
      "Iteration 247, loss = 1453.12196990\n",
      "Iteration 241, loss = 1622.92084817\n",
      "Iteration 161, loss = 2178.34807430\n",
      "Iteration 197, loss = 1868.16059534\n",
      "Iteration 264, loss = 1511.12162023\n",
      "Iteration 269, loss = 1491.84743018\n",
      "Iteration 204, loss = 1763.21218422\n",
      "Iteration 161, loss = 2263.22715928\n",
      "Iteration 248, loss = 1453.14594761\n",
      "Iteration 242, loss = 1631.09328198\n",
      "Iteration 198, loss = 1869.71430521\n",
      "Iteration 265, loss = 1514.91497904\n",
      "Iteration 162, loss = 2167.91176297\n",
      "Iteration 270, loss = 1486.74623175\n",
      "Iteration 162, loss = 2254.49741770\n",
      "Iteration 205, loss = 1764.25773761\n",
      "Iteration 249, loss = 1462.64079632\n",
      "Iteration 243, loss = 1617.51522666\n",
      "Iteration 199, loss = 1874.15793063\n",
      "Iteration 266, loss = 1499.62357393\n",
      "Iteration 163, loss = 2156.35228589\n",
      "Iteration 271, loss = 1475.81515850\n",
      "Iteration 163, loss = 2243.15844010\n",
      "Iteration 206, loss = 1761.85040329\n",
      "Iteration 200, loss = 1855.20866622\n",
      "Iteration 250, loss = 1444.43381376\n",
      "Iteration 267, loss = 1494.76170296\n",
      "Iteration 244, loss = 1608.62473720\n",
      "Iteration 164, loss = 2141.50349982\n",
      "Iteration 272, loss = 1470.40796793\n",
      "Iteration 164, loss = 2228.81092657\n",
      "Iteration 207, loss = 1743.46942397\n",
      "Iteration 251, loss = 1445.38123934\n",
      "Iteration 201, loss = 1841.80160641\n",
      "Iteration 268, loss = 1494.73483761\n",
      "Iteration 245, loss = 1601.52332120\n",
      "Iteration 165, loss = 2137.30969076\n",
      "Iteration 273, loss = 1488.56428998\n",
      "Iteration 165, loss = 2217.59124929\n",
      "Iteration 208, loss = 1739.61802803\n",
      "Iteration 252, loss = 1429.59520945\n",
      "Iteration 202, loss = 1853.67086985\n",
      "Iteration 269, loss = 1492.95022289\n",
      "Iteration 246, loss = 1591.55186037\n",
      "Iteration 166, loss = 2121.57045463\n",
      "Iteration 274, loss = 1484.33805216\n",
      "Iteration 209, loss = 1734.71582415\n",
      "Iteration 166, loss = 2210.36804237\n",
      "Iteration 253, loss = 1428.05512325\n",
      "Iteration 203, loss = 1832.32566275\n",
      "Iteration 270, loss = 1493.35774974\n",
      "Iteration 247, loss = 1583.42901327\n",
      "Iteration 167, loss = 2111.04891291\n",
      "Iteration 275, loss = 1478.15921681\n",
      "Iteration 210, loss = 1722.03467996\n",
      "Iteration 167, loss = 2201.35789036\n",
      "Iteration 254, loss = 1417.90711230\n",
      "Iteration 204, loss = 1825.91145722\n",
      "Iteration 248, loss = 1583.69001459\n",
      "Iteration 271, loss = 1479.86028366\n",
      "Iteration 168, loss = 2100.96538016\n",
      "Iteration 276, loss = 1469.72159027\n",
      "Iteration 211, loss = 1717.85175104\n",
      "Iteration 255, loss = 1414.81216780\n",
      "Iteration 168, loss = 2186.32613268\n",
      "Iteration 205, loss = 1814.54069737\n",
      "Iteration 249, loss = 1592.04991408\n",
      "Iteration 272, loss = 1472.71920223\n",
      "Iteration 169, loss = 2093.42264912\n",
      "Iteration 277, loss = 1455.43427039\n",
      "Iteration 212, loss = 1712.02186160\n",
      "Iteration 169, loss = 2178.17734970\n",
      "Iteration 256, loss = 1413.60011554\n",
      "Iteration 206, loss = 1810.65813976\n",
      "Iteration 273, loss = 1466.06729480\n",
      "Iteration 250, loss = 1578.77844460\n",
      "Iteration 170, loss = 2086.75336122\n",
      "Iteration 278, loss = 1459.33230737\n",
      "Iteration 213, loss = 1707.31672852\n",
      "Iteration 170, loss = 2165.50148911\n",
      "Iteration 257, loss = 1405.71807985\n",
      "Iteration 207, loss = 1805.48236619\n",
      "Iteration 171, loss = 2075.27785587\n",
      "Iteration 274, loss = 1465.22580973\n",
      "Iteration 251, loss = 1570.84078177\n",
      "Iteration 214, loss = 1696.76179150\n",
      "Iteration 279, loss = 1447.26385102\n",
      "Iteration 171, loss = 2161.70405142\n",
      "Iteration 208, loss = 1792.01618837\n",
      "Iteration 258, loss = 1407.63116591\n",
      "Iteration 172, loss = 2056.00543941\n",
      "Iteration 275, loss = 1461.77254426\n",
      "Iteration 252, loss = 1566.76972485\n",
      "Iteration 280, loss = 1447.55396551\n",
      "Iteration 215, loss = 1693.67602425\n",
      "Iteration 172, loss = 2143.00511262\n",
      "Iteration 209, loss = 1792.19484628\n",
      "Iteration 259, loss = 1394.53814170\n",
      "Iteration 173, loss = 2049.13876305\n",
      "Iteration 276, loss = 1461.76866253\n",
      "Iteration 253, loss = 1559.76877707\n",
      "Iteration 281, loss = 1440.43007956\n",
      "Iteration 216, loss = 1685.19438707\n",
      "Iteration 173, loss = 2131.34536374\n",
      "Iteration 210, loss = 1777.75118165\n",
      "Iteration 174, loss = 2032.41444473\n",
      "Iteration 260, loss = 1400.25361624\n",
      "Iteration 277, loss = 1453.40142586\n",
      "Iteration 254, loss = 1548.66230258\n",
      "Iteration 282, loss = 1436.47050849\n",
      "Iteration 217, loss = 1687.85974867\n",
      "Iteration 174, loss = 2122.32853610\n",
      "Iteration 211, loss = 1772.34594078\n",
      "Iteration 175, loss = 2032.40146864\n",
      "Iteration 261, loss = 1390.12527152\n",
      "Iteration 255, loss = 1546.92689144\n",
      "Iteration 278, loss = 1441.87187302\n",
      "Iteration 218, loss = 1672.01929659\n",
      "Iteration 283, loss = 1429.70886288\n",
      "Iteration 175, loss = 2116.80596833\n",
      "Iteration 212, loss = 1763.63807057\n",
      "Iteration 262, loss = 1389.74757420\n",
      "Iteration 176, loss = 2029.07550409\n",
      "Iteration 256, loss = 1557.93795673\n",
      "Iteration 279, loss = 1440.85797975\n",
      "Iteration 219, loss = 1670.71019133\n",
      "Iteration 284, loss = 1420.38728942\n",
      "Iteration 213, loss = 1769.33553385\n",
      "Iteration 176, loss = 2109.05464615\n",
      "Iteration 263, loss = 1388.79226533\n",
      "Iteration 177, loss = 2012.65236462\n",
      "Iteration 257, loss = 1532.02022417\n",
      "Iteration 280, loss = 1437.88040812\n",
      "Iteration 220, loss = 1650.71650710\n",
      "Iteration 177, loss = 2095.22741865\n",
      "Iteration 285, loss = 1417.91136582\n",
      "Iteration 214, loss = 1754.89913839\n",
      "Iteration 264, loss = 1375.43347377\n",
      "Iteration 178, loss = 2005.73262910\n",
      "Iteration 258, loss = 1533.09419248\n",
      "Iteration 281, loss = 1435.47372056\n",
      "Iteration 221, loss = 1654.63224147\n",
      "Iteration 286, loss = 1414.52723400\n",
      "Iteration 215, loss = 1747.23979634\n",
      "Iteration 178, loss = 2085.84977239\n",
      "Iteration 265, loss = 1370.81537536\n",
      "Iteration 179, loss = 1995.82391829\n",
      "Iteration 259, loss = 1531.92397439\n",
      "Iteration 222, loss = 1640.72295291\n",
      "Iteration 282, loss = 1427.14180827\n",
      "Iteration 287, loss = 1405.09957040\n",
      "Iteration 216, loss = 1739.25581600\n",
      "Iteration 179, loss = 2081.68881667\n",
      "Iteration 266, loss = 1366.98234642\n",
      "Iteration 180, loss = 1984.63058544\n",
      "Iteration 260, loss = 1527.31841490\n",
      "Iteration 223, loss = 1634.83928240\n",
      "Iteration 283, loss = 1452.01764238\n",
      "Iteration 217, loss = 1728.32103201\n",
      "Iteration 288, loss = 1418.57262728\n",
      "Iteration 180, loss = 2068.70082525\n",
      "Iteration 267, loss = 1356.95489658\n",
      "Iteration 261, loss = 1520.18155270\n",
      "Iteration 181, loss = 1974.27905809\n",
      "Iteration 224, loss = 1660.96772930\n",
      "Iteration 284, loss = 1441.05748932\n",
      "Iteration 289, loss = 1393.66933521\n",
      "Iteration 218, loss = 1731.42976180\n",
      "Iteration 181, loss = 2057.44286255\n",
      "Iteration 268, loss = 1355.83468423\n",
      "Iteration 262, loss = 1517.67954182\n",
      "Iteration 182, loss = 1967.49120496\n",
      "Iteration 225, loss = 1631.05069912\n",
      "Iteration 285, loss = 1420.13609576\n",
      "Iteration 290, loss = 1391.71724977\n",
      "Iteration 219, loss = 1722.65851734\n",
      "Iteration 269, loss = 1361.17452416\n",
      "Iteration 182, loss = 2052.25641746\n",
      "Iteration 263, loss = 1506.98837710\n",
      "Iteration 183, loss = 1954.66846300\n",
      "Iteration 286, loss = 1419.57474290\n",
      "Iteration 226, loss = 1619.85775043\n",
      "Iteration 220, loss = 1715.33770681\n",
      "Iteration 291, loss = 1396.25247947\n",
      "Iteration 270, loss = 1346.17084504\n",
      "Iteration 183, loss = 2050.55488397\n",
      "Iteration 264, loss = 1497.08107932\n",
      "Iteration 184, loss = 1947.53294697\n",
      "Iteration 227, loss = 1614.34123346\n",
      "Iteration 287, loss = 1410.91299564\n",
      "Iteration 271, loss = 1349.67780966\n",
      "Iteration 221, loss = 1708.61005903\n",
      "Iteration 292, loss = 1384.83959425\n",
      "Iteration 184, loss = 2031.91413075\n",
      "Iteration 265, loss = 1508.61234794\n",
      "Iteration 185, loss = 1932.74195661\n",
      "Iteration 288, loss = 1419.86639027\n",
      "Iteration 228, loss = 1613.42541678\n",
      "Iteration 222, loss = 1706.81588342\n",
      "Iteration 272, loss = 1338.90270389\n",
      "Iteration 293, loss = 1381.90176253\n",
      "Iteration 185, loss = 2025.94573393\n",
      "Iteration 266, loss = 1491.73776048\n",
      "Iteration 186, loss = 1929.79240976\n",
      "Iteration 289, loss = 1395.97955562\n",
      "Iteration 229, loss = 1598.93198278\n",
      "Iteration 223, loss = 1690.60256352\n",
      "Iteration 273, loss = 1335.87653523\n",
      "Iteration 294, loss = 1383.58552079\n",
      "Iteration 267, loss = 1493.80888065\n",
      "Iteration 186, loss = 2016.96242848\n",
      "Iteration 187, loss = 1918.69047616\n",
      "Iteration 290, loss = 1391.34846964\n",
      "Iteration 230, loss = 1597.36323103\n",
      "Iteration 224, loss = 1699.53448928\n",
      "Iteration 274, loss = 1346.77569144\n",
      "Iteration 295, loss = 1369.44824468\n",
      "Iteration 268, loss = 1500.76562740\n",
      "Iteration 187, loss = 2002.67148402\n",
      "Iteration 188, loss = 1909.35015482\n",
      "Iteration 231, loss = 1587.33105031\n",
      "Iteration 291, loss = 1395.22806989\n",
      "Iteration 225, loss = 1682.28763452\n",
      "Iteration 275, loss = 1320.99359880\n",
      "Iteration 296, loss = 1363.92289474\n",
      "Iteration 269, loss = 1480.45757817\n",
      "Iteration 188, loss = 1996.06738339\n",
      "Iteration 189, loss = 1899.49573519\n",
      "Iteration 292, loss = 1390.36190836\n",
      "Iteration 226, loss = 1680.74102029\n",
      "Iteration 232, loss = 1585.65741285\n",
      "Iteration 276, loss = 1331.88507206\n",
      "Iteration 297, loss = 1359.67814647\n",
      "Iteration 270, loss = 1466.49392078\n",
      "Iteration 190, loss = 1898.20740394\n",
      "Iteration 189, loss = 1987.45293485\n",
      "Iteration 293, loss = 1387.40981831\n",
      "Iteration 227, loss = 1673.10613334\n",
      "Iteration 233, loss = 1573.89130660\n",
      "Iteration 277, loss = 1317.42524096\n",
      "Iteration 298, loss = 1362.69451920\n",
      "Iteration 191, loss = 1884.62681253\n",
      "Iteration 271, loss = 1465.75683059\n",
      "Iteration 190, loss = 1979.54813328\n",
      "Iteration 294, loss = 1381.92665760\n",
      "Iteration 228, loss = 1666.41706628\n",
      "Iteration 234, loss = 1574.74302428\n",
      "Iteration 278, loss = 1308.11339287\n",
      "Iteration 299, loss = 1361.91933450\n",
      "Iteration 192, loss = 1871.30849727\n",
      "Iteration 272, loss = 1466.36686453\n",
      "Iteration 191, loss = 1966.82364101\n",
      "Iteration 229, loss = 1660.56748651\n",
      "Iteration 295, loss = 1386.05894028\n",
      "Iteration 279, loss = 1311.48343653\n",
      "Iteration 235, loss = 1560.35239114\n",
      "Iteration 300, loss = 1349.91217003\n",
      "Iteration 193, loss = 1861.85642423\n",
      "Iteration 273, loss = 1456.24224063\n",
      "Iteration 230, loss = 1650.02544100\n",
      "Iteration 296, loss = 1373.75011624\n",
      "Iteration 192, loss = 1967.42219875\n",
      "Iteration 280, loss = 1323.76226852\n",
      "Iteration 301, loss = 1350.78938876\n",
      "Iteration 236, loss = 1565.78001689\n",
      "Iteration 194, loss = 1854.75856508\n",
      "Iteration 274, loss = 1458.73123957\n",
      "Iteration 231, loss = 1652.47959117\n",
      "Iteration 297, loss = 1371.76019099\n",
      "Iteration 193, loss = 1949.74346046\n",
      "Iteration 281, loss = 1328.80850767\n",
      "Iteration 302, loss = 1343.36714552\n",
      "Iteration 237, loss = 1554.44597108\n",
      "Iteration 195, loss = 1850.29783352\n",
      "Iteration 275, loss = 1450.88280609\n",
      "Iteration 232, loss = 1642.61754138\n",
      "Iteration 298, loss = 1365.39551717\n",
      "Iteration 194, loss = 1951.44735898\n",
      "Iteration 282, loss = 1300.90672307\n",
      "Iteration 238, loss = 1553.31722969\n",
      "Iteration 303, loss = 1335.34228079\n",
      "Iteration 196, loss = 1842.92336946\n",
      "Iteration 276, loss = 1441.20145547\n",
      "Iteration 233, loss = 1634.21630899\n",
      "Iteration 283, loss = 1295.75637020\n",
      "Iteration 299, loss = 1356.72800279\n",
      "Iteration 195, loss = 1939.21065850\n",
      "Iteration 304, loss = 1339.30091448\n",
      "Iteration 239, loss = 1543.07113906\n",
      "Iteration 197, loss = 1831.59533792\n",
      "Iteration 277, loss = 1446.48808043\n",
      "Iteration 234, loss = 1631.12914578\n",
      "Iteration 284, loss = 1284.23889773\n",
      "Iteration 300, loss = 1352.15319921\n",
      "Iteration 196, loss = 1938.14321631\n",
      "Iteration 305, loss = 1332.68838624\n",
      "Iteration 240, loss = 1538.14235433\n",
      "Iteration 198, loss = 1825.05445511\n",
      "Iteration 278, loss = 1429.40012035\n",
      "Iteration 235, loss = 1616.04221201\n",
      "Iteration 285, loss = 1286.43732438\n",
      "Iteration 301, loss = 1355.84160294\n",
      "Iteration 306, loss = 1345.56797706\n",
      "Iteration 197, loss = 1926.81487737\n",
      "Iteration 241, loss = 1539.14296759\n",
      "Iteration 199, loss = 1811.21173268\n",
      "Iteration 279, loss = 1448.02284643\n",
      "Iteration 236, loss = 1621.86782750\n",
      "Iteration 286, loss = 1283.39020211\n",
      "Iteration 302, loss = 1356.87997493\n",
      "Iteration 307, loss = 1322.06798202\n",
      "Iteration 198, loss = 1915.07513893\n",
      "Iteration 242, loss = 1525.71774727\n",
      "Iteration 200, loss = 1806.49188981\n",
      "Iteration 237, loss = 1615.76661386\n",
      "Iteration 280, loss = 1420.71702355\n",
      "Iteration 287, loss = 1277.95463786\n",
      "Iteration 303, loss = 1355.49738382\n",
      "Iteration 199, loss = 1900.94244703\n",
      "Iteration 308, loss = 1333.99083050\n",
      "Iteration 243, loss = 1527.20816035\n",
      "Iteration 201, loss = 1797.30724773\n",
      "Iteration 238, loss = 1608.81892443\n",
      "Iteration 281, loss = 1419.23721004\n",
      "Iteration 288, loss = 1273.16906000\n",
      "Iteration 304, loss = 1349.55297352\n",
      "Iteration 200, loss = 1898.33679099\n",
      "Iteration 309, loss = 1317.55197177\n",
      "Iteration 244, loss = 1517.54690759\n",
      "Iteration 239, loss = 1603.08170769\n",
      "Iteration 202, loss = 1798.11179816\n",
      "Iteration 282, loss = 1415.69381986\n",
      "Iteration 289, loss = 1269.27118112\n",
      "Iteration 305, loss = 1348.83006888\n",
      "Iteration 310, loss = 1309.53977774\n",
      "Iteration 245, loss = 1517.37992105\n",
      "Iteration 201, loss = 1887.76141689\n",
      "Iteration 240, loss = 1590.27169572\n",
      "Iteration 283, loss = 1416.96197845\n",
      "Iteration 203, loss = 1785.90364688\n",
      "Iteration 290, loss = 1283.69901684\n",
      "Iteration 311, loss = 1320.82584490\n",
      "Iteration 306, loss = 1360.12513170\n",
      "Iteration 202, loss = 1882.06561359\n",
      "Iteration 241, loss = 1610.17993079\n",
      "Iteration 246, loss = 1500.76905327\n",
      "Iteration 284, loss = 1409.07510591\n",
      "Iteration 204, loss = 1775.95797099\n",
      "Iteration 291, loss = 1263.19660960\n",
      "Iteration 307, loss = 1338.78733063\n",
      "Iteration 312, loss = 1323.68264418\n",
      "Iteration 242, loss = 1583.87731910\n",
      "Iteration 285, loss = 1409.58943219\n",
      "Iteration 203, loss = 1881.24718663\n",
      "Iteration 205, loss = 1765.10086701\n",
      "Iteration 247, loss = 1513.21848701\n",
      "Iteration 292, loss = 1259.64765102\n",
      "Iteration 308, loss = 1325.77702104\n",
      "Iteration 313, loss = 1307.44288079\n",
      "Iteration 243, loss = 1584.72594526\n",
      "Iteration 286, loss = 1399.59424382\n",
      "Iteration 248, loss = 1494.39196033\n",
      "Iteration 206, loss = 1758.00172584\n",
      "Iteration 204, loss = 1869.13553879\n",
      "Iteration 293, loss = 1262.13072054\n",
      "Iteration 309, loss = 1313.75304119\n",
      "Iteration 314, loss = 1292.24287667\n",
      "Iteration 244, loss = 1584.86304150\n",
      "Iteration 249, loss = 1494.10325951\n",
      "Iteration 287, loss = 1402.48373577\n",
      "Iteration 205, loss = 1862.49210043\n",
      "Iteration 207, loss = 1749.67708850\n",
      "Iteration 294, loss = 1253.47226498\n",
      "Iteration 310, loss = 1319.08210861\n",
      "Iteration 245, loss = 1577.11576307\n",
      "Iteration 315, loss = 1298.89573156\n",
      "Iteration 206, loss = 1860.49913445\n",
      "Iteration 250, loss = 1487.02091993\n",
      "Iteration 288, loss = 1402.87444032\n",
      "Iteration 208, loss = 1740.57477775\n",
      "Iteration 295, loss = 1245.17828729\n",
      "Iteration 311, loss = 1318.00578111\n",
      "Iteration 316, loss = 1303.31102549\n",
      "Iteration 246, loss = 1562.68311268\n",
      "Iteration 207, loss = 1843.81379956\n",
      "Iteration 251, loss = 1488.04804964\n",
      "Iteration 289, loss = 1389.74112189\n",
      "Iteration 209, loss = 1746.45045253\n",
      "Iteration 296, loss = 1244.47591872\n",
      "Iteration 312, loss = 1316.09029539\n",
      "Iteration 247, loss = 1571.63427846\n",
      "Iteration 317, loss = 1287.68628301\n",
      "Iteration 208, loss = 1835.36860226\n",
      "Iteration 290, loss = 1389.95250917\n",
      "Iteration 252, loss = 1481.24552348\n",
      "Iteration 210, loss = 1723.84886856\n",
      "Iteration 297, loss = 1239.96131067\n",
      "Iteration 318, loss = 1294.64783675\n",
      "Iteration 248, loss = 1556.02702172\n",
      "Iteration 313, loss = 1317.84463487\n",
      "Iteration 209, loss = 1837.72368212\n",
      "Iteration 291, loss = 1383.21350367\n",
      "Iteration 253, loss = 1472.26924785\n",
      "Iteration 211, loss = 1756.66060181\n",
      "Iteration 298, loss = 1245.80980356\n",
      "Iteration 249, loss = 1554.37626063\n",
      "Iteration 319, loss = 1286.96915108\n",
      "Iteration 314, loss = 1295.17540008\n",
      "Iteration 292, loss = 1384.07989445\n",
      "Iteration 210, loss = 1822.90480769\n",
      "Iteration 254, loss = 1469.29564835\n",
      "Iteration 299, loss = 1231.20509058\n",
      "Iteration 212, loss = 1730.81923561\n",
      "Iteration 250, loss = 1551.93619744\n",
      "Iteration 320, loss = 1280.01543129\n",
      "Iteration 315, loss = 1302.99391870\n",
      "Iteration 211, loss = 1825.24923984\n",
      "Iteration 255, loss = 1455.65638982\n",
      "Iteration 293, loss = 1371.47527944\n",
      "Iteration 300, loss = 1235.90546953\n",
      "Iteration 213, loss = 1708.46093467\n",
      "Iteration 251, loss = 1540.21874074\n",
      "Iteration 321, loss = 1280.68750338\n",
      "Iteration 316, loss = 1298.50335130\n",
      "Iteration 212, loss = 1811.45108536\n",
      "Iteration 294, loss = 1365.47947825\n",
      "Iteration 256, loss = 1463.84189359\n",
      "Iteration 214, loss = 1698.87178837\n",
      "Iteration 301, loss = 1223.99672270\n",
      "Iteration 252, loss = 1545.15198790\n",
      "Iteration 322, loss = 1282.44258461\n",
      "Iteration 213, loss = 1808.81541439\n",
      "Iteration 257, loss = 1451.05502045\n",
      "Iteration 317, loss = 1300.41139464\n",
      "Iteration 295, loss = 1369.00829142\n",
      "Iteration 215, loss = 1698.43519412\n",
      "Iteration 302, loss = 1222.83177614\n",
      "Iteration 253, loss = 1544.20175505\n",
      "Iteration 323, loss = 1281.62194404\n",
      "Iteration 258, loss = 1452.65490597\n",
      "Iteration 318, loss = 1304.42687704\n",
      "Iteration 296, loss = 1353.55971065\n",
      "Iteration 216, loss = 1691.67691705\n",
      "Iteration 214, loss = 1800.96296661\n",
      "Iteration 303, loss = 1221.19027118\n",
      "Iteration 254, loss = 1523.95814613\n",
      "Iteration 324, loss = 1263.31546419\n",
      "Iteration 259, loss = 1441.79738897\n",
      "Iteration 319, loss = 1287.02251658\n",
      "Iteration 217, loss = 1684.73990029\n",
      "Iteration 297, loss = 1370.37905545\n",
      "Iteration 215, loss = 1793.52899443\n",
      "Iteration 304, loss = 1215.12598609\n",
      "Iteration 255, loss = 1518.10597343\n",
      "Iteration 325, loss = 1287.04009918\n",
      "Iteration 320, loss = 1290.40347198\n",
      "Iteration 298, loss = 1356.36151897\n",
      "Iteration 218, loss = 1680.10475528\n",
      "Iteration 260, loss = 1438.25638125\n",
      "Iteration 216, loss = 1787.96281052\n",
      "Iteration 256, loss = 1516.97303043\n",
      "Iteration 305, loss = 1213.05207452\n",
      "Iteration 326, loss = 1274.89386361\n",
      "Iteration 321, loss = 1273.19193431\n",
      "Iteration 299, loss = 1354.78485861\n",
      "Iteration 261, loss = 1426.07068921\n",
      "Iteration 219, loss = 1675.12350420\n",
      "Iteration 217, loss = 1777.66466812\n",
      "Iteration 257, loss = 1517.64766400\n",
      "Iteration 306, loss = 1217.84874283\n",
      "Iteration 327, loss = 1255.30239454\n",
      "Iteration 300, loss = 1344.72884079\n",
      "Iteration 322, loss = 1292.27134765\n",
      "Iteration 262, loss = 1420.99621489\n",
      "Iteration 220, loss = 1665.60748721\n",
      "Iteration 258, loss = 1497.57738553\n",
      "Iteration 218, loss = 1771.32420553\n",
      "Iteration 307, loss = 1211.57021743\n",
      "Iteration 328, loss = 1251.98163885\n",
      "Iteration 301, loss = 1339.66076162\n",
      "Iteration 221, loss = 1661.67085408\n",
      "Iteration 263, loss = 1420.82473695\n",
      "Iteration 323, loss = 1283.11671653\n",
      "Iteration 259, loss = 1499.42459827\n",
      "Iteration 219, loss = 1765.68694109\n",
      "Iteration 308, loss = 1203.47975000\n",
      "Iteration 302, loss = 1335.64392055\n",
      "Iteration 329, loss = 1245.64730580\n",
      "Iteration 324, loss = 1278.55363492\n",
      "Iteration 222, loss = 1658.65499180\n",
      "Iteration 264, loss = 1409.04565814\n",
      "Iteration 260, loss = 1496.14299279\n",
      "Iteration 309, loss = 1206.16084440\n",
      "Iteration 220, loss = 1760.99157430\n",
      "Iteration 330, loss = 1244.87055074\n",
      "Iteration 303, loss = 1335.00643233\n",
      "Iteration 325, loss = 1276.48418067\n",
      "Iteration 265, loss = 1433.32517798\n",
      "Iteration 223, loss = 1648.28511995\n",
      "Iteration 261, loss = 1490.45679325\n",
      "Iteration 310, loss = 1192.69661105\n",
      "Iteration 221, loss = 1756.72494781\n",
      "Iteration 304, loss = 1332.09340291\n",
      "Iteration 326, loss = 1274.50998664\n",
      "Iteration 331, loss = 1281.78953208\n",
      "Iteration 266, loss = 1414.19918705\n",
      "Iteration 262, loss = 1480.37936763\n",
      "Iteration 224, loss = 1637.55257521\n",
      "Iteration 311, loss = 1194.00649569\n",
      "Iteration 222, loss = 1745.18544996\n",
      "Iteration 267, loss = 1397.46779768\n",
      "Iteration 305, loss = 1343.38469307\n",
      "Iteration 327, loss = 1260.46725129\n",
      "Iteration 332, loss = 1238.48908956\n",
      "Iteration 263, loss = 1487.10608321\n",
      "Iteration 312, loss = 1187.96843520\n",
      "Iteration 225, loss = 1631.93057351\n",
      "Iteration 223, loss = 1739.14827213\n",
      "Iteration 306, loss = 1333.34610382\n",
      "Iteration 268, loss = 1395.15797419\n",
      "Iteration 328, loss = 1254.32525532\n",
      "Iteration 333, loss = 1223.02125927\n",
      "Iteration 264, loss = 1467.89548521\n",
      "Iteration 226, loss = 1633.57479543\n",
      "Iteration 313, loss = 1190.21926850\n",
      "Iteration 224, loss = 1732.56750605\n",
      "Iteration 307, loss = 1317.99610509\n",
      "Iteration 329, loss = 1263.08466593\n",
      "Iteration 269, loss = 1393.68915954\n",
      "Iteration 334, loss = 1234.26418270\n",
      "Iteration 265, loss = 1480.61269306\n",
      "Iteration 227, loss = 1616.97716405\n",
      "Iteration 314, loss = 1184.61424464\n",
      "Iteration 225, loss = 1728.45056439\n",
      "Iteration 308, loss = 1315.55473795\n",
      "Iteration 330, loss = 1251.80710320\n",
      "Iteration 270, loss = 1383.87704111\n",
      "Iteration 335, loss = 1233.65894251\n",
      "Iteration 266, loss = 1466.01190330\n",
      "Iteration 228, loss = 1616.96908349\n",
      "Iteration 315, loss = 1195.49519278\n",
      "Iteration 226, loss = 1717.60639302\n",
      "Iteration 331, loss = 1269.91565670\n",
      "Iteration 309, loss = 1309.29093225\n",
      "Iteration 271, loss = 1387.94302491\n",
      "Iteration 267, loss = 1451.35318934\n",
      "Iteration 336, loss = 1229.73131413\n",
      "Iteration 229, loss = 1607.42443707\n",
      "Iteration 316, loss = 1179.07642396\n",
      "Iteration 227, loss = 1716.39925028\n",
      "Iteration 332, loss = 1264.09378883\n",
      "Iteration 310, loss = 1305.29986832\n",
      "Iteration 272, loss = 1384.28999606\n",
      "Iteration 268, loss = 1453.36884382\n",
      "Iteration 230, loss = 1597.31459757\n",
      "Iteration 337, loss = 1225.47648139\n",
      "Iteration 317, loss = 1179.34858773\n",
      "Iteration 228, loss = 1704.97477552\n",
      "Iteration 311, loss = 1308.60159320\n",
      "Iteration 333, loss = 1256.80868034\n",
      "Iteration 273, loss = 1383.13547110\n",
      "Iteration 269, loss = 1446.54332736\n",
      "Iteration 231, loss = 1599.82716108\n",
      "Iteration 338, loss = 1220.06453014\n",
      "Iteration 318, loss = 1165.90040819\n",
      "Iteration 229, loss = 1701.10149676\n",
      "Iteration 334, loss = 1258.04933437\n",
      "Iteration 312, loss = 1295.13683362\n",
      "Iteration 270, loss = 1439.94718348\n",
      "Iteration 274, loss = 1371.78496594\n",
      "Iteration 232, loss = 1589.51525683\n",
      "Iteration 339, loss = 1224.48234717\n",
      "Iteration 319, loss = 1164.99243423\n",
      "Iteration 230, loss = 1687.43804268\n",
      "Iteration 313, loss = 1310.81305269\n",
      "Iteration 335, loss = 1247.43675367\n",
      "Iteration 271, loss = 1441.02618873\n",
      "Iteration 275, loss = 1359.88378648\n",
      "Iteration 233, loss = 1591.82333439\n",
      "Iteration 340, loss = 1227.23698173\n",
      "Iteration 320, loss = 1166.64489093\n",
      "Iteration 231, loss = 1687.06180687\n",
      "Iteration 272, loss = 1442.90188163\n",
      "Iteration 314, loss = 1293.89822580\n",
      "Iteration 336, loss = 1235.98853103\n",
      "Iteration 276, loss = 1362.30515085\n",
      "Iteration 234, loss = 1571.03851195\n",
      "Iteration 341, loss = 1210.17829076\n",
      "Iteration 321, loss = 1174.87986657\n",
      "Iteration 273, loss = 1431.27733754\n",
      "Iteration 232, loss = 1675.35458955\n",
      "Iteration 315, loss = 1292.70017050\n",
      "Iteration 337, loss = 1239.63368755\n",
      "Iteration 277, loss = 1358.34346973\n",
      "Iteration 235, loss = 1572.89232119\n",
      "Iteration 342, loss = 1210.27555789\n",
      "Iteration 322, loss = 1191.50892313\n",
      "Iteration 274, loss = 1431.43319696\n",
      "Iteration 233, loss = 1669.81471634\n",
      "Iteration 316, loss = 1273.87938732\n",
      "Iteration 338, loss = 1260.10250659\n",
      "Iteration 278, loss = 1372.00850093\n",
      "Iteration 236, loss = 1583.45747823\n",
      "Iteration 343, loss = 1201.57080102\n",
      "Iteration 323, loss = 1168.13997115\n",
      "Iteration 275, loss = 1420.53120198\n",
      "Iteration 234, loss = 1702.99550935\n",
      "Iteration 317, loss = 1284.86563868\n",
      "Iteration 339, loss = 1244.00332545\n",
      "Iteration 279, loss = 1361.43403811\n",
      "Iteration 237, loss = 1557.63347716\n",
      "Iteration 344, loss = 1210.73345047\n",
      "Iteration 324, loss = 1152.48122415\n",
      "Iteration 235, loss = 1655.88718012\n",
      "Iteration 276, loss = 1417.13092931\n",
      "Iteration 318, loss = 1282.43554881\n",
      "Iteration 280, loss = 1354.23575657\n",
      "Iteration 340, loss = 1226.54398095\n",
      "Iteration 238, loss = 1554.70371854\n",
      "Iteration 345, loss = 1198.58600495\n",
      "Iteration 325, loss = 1153.78296744\n",
      "Iteration 277, loss = 1412.49839440\n",
      "Iteration 319, loss = 1269.65375496\n",
      "Iteration 236, loss = 1675.60262476\n",
      "Iteration 281, loss = 1347.31796615\n",
      "Iteration 341, loss = 1233.54679805\n",
      "Iteration 239, loss = 1540.20876189\n",
      "Iteration 346, loss = 1199.31099482\n",
      "Iteration 326, loss = 1154.54018909\n",
      "Iteration 278, loss = 1413.36272986\n",
      "Iteration 237, loss = 1653.21835132\n",
      "Iteration 282, loss = 1333.38861781\n",
      "Iteration 320, loss = 1277.09834935\n",
      "Iteration 342, loss = 1227.50927896\n",
      "Iteration 240, loss = 1548.71780750\n",
      "Iteration 347, loss = 1194.82111061\n",
      "Iteration 327, loss = 1145.68282756\n",
      "Iteration 238, loss = 1643.70842775\n",
      "Iteration 279, loss = 1425.08510025\n",
      "Iteration 283, loss = 1329.30882727\n",
      "Iteration 321, loss = 1263.03190288\n",
      "Iteration 343, loss = 1229.02753821\n",
      "Iteration 241, loss = 1544.59941638\n",
      "Iteration 328, loss = 1145.48618530\n",
      "Iteration 348, loss = 1186.30028808\n",
      "Iteration 280, loss = 1404.33199705\n",
      "Iteration 322, loss = 1273.08426256\n",
      "Iteration 239, loss = 1634.98886858\n",
      "Iteration 284, loss = 1330.00364255\n",
      "Iteration 344, loss = 1238.22425272\n",
      "Iteration 242, loss = 1533.79596324\n",
      "Iteration 329, loss = 1149.05785021\n",
      "Iteration 349, loss = 1189.99257962\n",
      "Iteration 281, loss = 1394.95743236\n",
      "Iteration 323, loss = 1274.77792141\n",
      "Iteration 240, loss = 1633.41544447\n",
      "Iteration 345, loss = 1221.72556687\n",
      "Iteration 285, loss = 1327.50184051\n",
      "Iteration 243, loss = 1526.01827089\n",
      "Iteration 330, loss = 1133.75278784\n",
      "Iteration 350, loss = 1212.86429100\n",
      "Iteration 282, loss = 1390.51045569\n",
      "Iteration 241, loss = 1641.47598441\n",
      "Iteration 324, loss = 1259.63373561\n",
      "Iteration 346, loss = 1203.97316966\n",
      "Iteration 286, loss = 1323.09967915\n",
      "Iteration 244, loss = 1538.18218155\n",
      "Iteration 331, loss = 1151.74481948\n",
      "Iteration 351, loss = 1175.01722516\n",
      "Iteration 283, loss = 1379.79455934\n",
      "Iteration 325, loss = 1268.16771032\n",
      "Iteration 347, loss = 1223.42466927\n",
      "Iteration 242, loss = 1625.78872066\n",
      "Iteration 287, loss = 1320.13161960\n",
      "Iteration 245, loss = 1520.66132171\n",
      "Iteration 332, loss = 1137.77819521\n",
      "Iteration 352, loss = 1176.21518856\n",
      "Iteration 284, loss = 1387.41161357\n",
      "Iteration 326, loss = 1259.98306434\n",
      "Iteration 348, loss = 1212.16419486\n",
      "Iteration 243, loss = 1614.46337584\n",
      "Iteration 288, loss = 1310.05060076\n",
      "Iteration 246, loss = 1512.72994645\n",
      "Iteration 333, loss = 1131.85104016\n",
      "Iteration 353, loss = 1183.67214163\n",
      "Iteration 327, loss = 1246.57042316\n",
      "Iteration 285, loss = 1391.33980896\n",
      "Iteration 244, loss = 1608.75108515\n",
      "Iteration 349, loss = 1221.16725533\n",
      "Iteration 289, loss = 1312.25392135\n",
      "Iteration 247, loss = 1500.90599006\n",
      "Iteration 334, loss = 1134.76535120\n",
      "Iteration 354, loss = 1186.09507124\n",
      "Iteration 286, loss = 1372.77990593\n",
      "Iteration 328, loss = 1235.16179945\n",
      "Iteration 245, loss = 1598.64517677\n",
      "Iteration 350, loss = 1199.52464921\n",
      "Iteration 290, loss = 1311.45748072\n",
      "Iteration 248, loss = 1494.13879625\n",
      "Iteration 335, loss = 1123.95061589\n",
      "Iteration 287, loss = 1375.23876045\n",
      "Iteration 355, loss = 1175.82941701\n",
      "Iteration 329, loss = 1248.15585429\n",
      "Iteration 351, loss = 1219.70306788\n",
      "Iteration 246, loss = 1606.14149274\n",
      "Iteration 291, loss = 1302.24120280\n",
      "Iteration 336, loss = 1122.21319457\n",
      "Iteration 249, loss = 1497.69723605\n",
      "Iteration 356, loss = 1177.41187935\n",
      "Iteration 288, loss = 1358.03021887\n",
      "Iteration 330, loss = 1239.97056930\n",
      "Iteration 352, loss = 1200.39639217\n",
      "Iteration 247, loss = 1593.48907976\n",
      "Iteration 292, loss = 1298.52796003\n",
      "Iteration 337, loss = 1126.28181987\n",
      "Iteration 250, loss = 1491.08754133\n",
      "Iteration 357, loss = 1183.46615814\n",
      "Iteration 289, loss = 1357.21056276\n",
      "Iteration 331, loss = 1225.64683291\n",
      "Iteration 353, loss = 1191.76631374\n",
      "Iteration 248, loss = 1591.73047568\n",
      "Iteration 293, loss = 1300.62794042\n",
      "Iteration 338, loss = 1133.61320125\n",
      "Iteration 358, loss = 1162.87113173\n",
      "Iteration 251, loss = 1483.70285578\n",
      "Iteration 290, loss = 1370.21000101\n",
      "Iteration 332, loss = 1226.39310898\n",
      "Iteration 249, loss = 1578.14969605\n",
      "Iteration 354, loss = 1190.32210913\n",
      "Iteration 294, loss = 1285.91013507\n",
      "Iteration 339, loss = 1118.37468552\n",
      "Iteration 252, loss = 1485.54689555\n",
      "Iteration 359, loss = 1173.76448281\n",
      "Iteration 333, loss = 1220.91176461\n",
      "Iteration 291, loss = 1356.48690440\n",
      "Iteration 250, loss = 1569.67398492\n",
      "Iteration 355, loss = 1195.40456293\n",
      "Iteration 295, loss = 1344.83476370\n",
      "Iteration 340, loss = 1112.39033383\n",
      "Iteration 253, loss = 1468.27850812\n",
      "Iteration 334, loss = 1235.10066667\n",
      "Iteration 360, loss = 1152.37992179\n",
      "Iteration 292, loss = 1348.85044647\n",
      "Iteration 251, loss = 1569.82730433\n",
      "Iteration 356, loss = 1196.29162032\n",
      "Iteration 296, loss = 1300.64973806\n",
      "Iteration 254, loss = 1464.79542997\n",
      "Iteration 341, loss = 1115.69534291\n",
      "Iteration 335, loss = 1229.89327520\n",
      "Iteration 361, loss = 1160.65088891\n",
      "Iteration 357, loss = 1187.19589585\n",
      "Iteration 293, loss = 1346.29994609\n",
      "Iteration 252, loss = 1568.32988889\n",
      "Iteration 297, loss = 1288.31179556\n",
      "Iteration 255, loss = 1460.83954004\n",
      "Iteration 336, loss = 1218.98241420\n",
      "Iteration 342, loss = 1113.94345474\n",
      "Iteration 362, loss = 1152.50978252\n",
      "Iteration 358, loss = 1182.95415593\n",
      "Iteration 294, loss = 1339.43121803\n",
      "Iteration 253, loss = 1552.06781532\n",
      "Iteration 298, loss = 1287.65922190\n",
      "Iteration 256, loss = 1460.85614201\n",
      "Iteration 337, loss = 1224.98857399\n",
      "Iteration 343, loss = 1103.85068715\n",
      "Iteration 363, loss = 1155.78065075\n",
      "Iteration 359, loss = 1189.21474719\n",
      "Iteration 295, loss = 1355.92961553\n",
      "Iteration 254, loss = 1557.02947678\n",
      "Iteration 299, loss = 1269.91739195\n",
      "Iteration 338, loss = 1234.93872265\n",
      "Iteration 344, loss = 1101.40129873\n",
      "Iteration 257, loss = 1450.82932631\n",
      "Iteration 296, loss = 1355.22755757\n",
      "Iteration 364, loss = 1147.85878306\n",
      "Iteration 360, loss = 1171.72530173\n",
      "Iteration 255, loss = 1544.68439029\n",
      "Iteration 300, loss = 1277.44103779\n",
      "Iteration 339, loss = 1227.73960360\n",
      "Iteration 345, loss = 1096.08538845\n",
      "Iteration 258, loss = 1450.23436945\n",
      "Iteration 297, loss = 1328.93234635\n",
      "Iteration 365, loss = 1149.89945855\n",
      "Iteration 361, loss = 1171.67375496\n",
      "Iteration 256, loss = 1540.70822885\n",
      "Iteration 301, loss = 1278.93688083\n",
      "Iteration 340, loss = 1207.33647515\n",
      "Iteration 259, loss = 1441.49600847\n",
      "Iteration 346, loss = 1107.86991872\n",
      "Iteration 298, loss = 1325.03247950\n",
      "Iteration 366, loss = 1147.83579861\n",
      "Iteration 362, loss = 1161.35437198\n",
      "Iteration 257, loss = 1532.90842701\n",
      "Iteration 302, loss = 1269.33110408\n",
      "Iteration 341, loss = 1203.19848101\n",
      "Iteration 347, loss = 1099.65610745\n",
      "Iteration 260, loss = 1446.21727347\n",
      "Iteration 299, loss = 1327.87831510\n",
      "Iteration 367, loss = 1132.32650525\n",
      "Iteration 363, loss = 1179.59991982\n",
      "Iteration 258, loss = 1525.44015086\n",
      "Iteration 303, loss = 1277.73488593\n",
      "Iteration 342, loss = 1208.59862138\n",
      "Iteration 348, loss = 1094.61096774\n",
      "Iteration 261, loss = 1437.87430707\n",
      "Iteration 300, loss = 1317.88669016\n",
      "Iteration 368, loss = 1142.68790560\n",
      "Iteration 364, loss = 1165.55427990\n",
      "Iteration 259, loss = 1526.70353836\n",
      "Iteration 304, loss = 1248.28887949\n",
      "Iteration 343, loss = 1209.94851581\n",
      "Iteration 349, loss = 1103.23575851\n",
      "Iteration 301, loss = 1311.74083326\n",
      "Iteration 262, loss = 1426.09365194\n",
      "Iteration 365, loss = 1175.09173229\n",
      "Iteration 369, loss = 1145.88961740\n",
      "Iteration 260, loss = 1523.45232190\n",
      "Iteration 305, loss = 1264.24543563\n",
      "Iteration 344, loss = 1190.20812043\n",
      "Iteration 350, loss = 1091.40596243\n",
      "Iteration 302, loss = 1318.19825716\n",
      "Iteration 263, loss = 1430.17089338\n",
      "Iteration 366, loss = 1184.73665782\n",
      "Iteration 370, loss = 1124.90353064\n",
      "Iteration 306, loss = 1255.39658143\n",
      "Iteration 261, loss = 1517.77575164\n",
      "Iteration 345, loss = 1186.19634439\n",
      "Iteration 351, loss = 1084.92687873\n",
      "Iteration 303, loss = 1327.07971537\n",
      "Iteration 371, loss = 1123.85712837\n",
      "Iteration 367, loss = 1196.80509132\n",
      "Iteration 264, loss = 1415.32333888\n",
      "Iteration 262, loss = 1505.59649089\n",
      "Iteration 307, loss = 1235.28235634\n",
      "Iteration 346, loss = 1203.49646715\n",
      "Iteration 304, loss = 1305.95606957\n",
      "Iteration 352, loss = 1089.10076465\n",
      "Iteration 372, loss = 1135.74474687\n",
      "Iteration 265, loss = 1436.18734657\n",
      "Iteration 368, loss = 1155.84938435\n",
      "Iteration 308, loss = 1238.14679300\n",
      "Iteration 263, loss = 1512.79598996\n",
      "Iteration 347, loss = 1186.31763835\n",
      "Iteration 305, loss = 1300.38990058\n",
      "Iteration 353, loss = 1089.08808317\n",
      "Iteration 266, loss = 1415.97445073\n",
      "Iteration 373, loss = 1128.09657564\n",
      "Iteration 309, loss = 1255.04689520\n",
      "Iteration 369, loss = 1166.94467322\n",
      "Iteration 264, loss = 1498.92363077\n",
      "Iteration 348, loss = 1183.70113689\n",
      "Iteration 306, loss = 1302.31971518\n",
      "Iteration 354, loss = 1077.68018411\n",
      "Iteration 374, loss = 1134.24093607\n",
      "Iteration 267, loss = 1403.68777798\n",
      "Iteration 310, loss = 1257.89228634\n",
      "Iteration 265, loss = 1501.86431037\n",
      "Iteration 370, loss = 1166.71868132\n",
      "Iteration 349, loss = 1178.29688440\n",
      "Iteration 307, loss = 1305.88860545\n",
      "Iteration 355, loss = 1071.71376698\n",
      "Iteration 375, loss = 1120.45324436\n",
      "Iteration 268, loss = 1390.21570154\n",
      "Iteration 311, loss = 1235.72299943\n",
      "Iteration 371, loss = 1155.20609122\n",
      "Iteration 350, loss = 1180.21691599\n",
      "Iteration 266, loss = 1499.05560747\n",
      "Iteration 308, loss = 1283.21003664\n",
      "Iteration 356, loss = 1080.70238866\n",
      "Iteration 376, loss = 1118.49508226\n",
      "Iteration 269, loss = 1403.21977874\n",
      "Iteration 312, loss = 1220.86973355\n",
      "Iteration 372, loss = 1145.12561940\n",
      "Iteration 309, loss = 1293.78487549\n",
      "Iteration 267, loss = 1484.41209596\n",
      "Iteration 357, loss = 1066.44158227\n",
      "Iteration 351, loss = 1191.76605246\n",
      "Iteration 377, loss = 1108.66688797\n",
      "Iteration 270, loss = 1385.61298680\n",
      "Iteration 313, loss = 1218.86221437\n",
      "Iteration 310, loss = 1283.61715991\n",
      "Iteration 373, loss = 1150.11847662\n",
      "Iteration 268, loss = 1472.42043727\n",
      "Iteration 352, loss = 1179.09515082\n",
      "Iteration 358, loss = 1074.06880909\n",
      "Iteration 378, loss = 1110.39941962\n",
      "Iteration 271, loss = 1395.75658118\n",
      "Iteration 314, loss = 1226.80675225\n",
      "Iteration 311, loss = 1276.50068906\n",
      "Iteration 374, loss = 1140.17547912\n",
      "Iteration 353, loss = 1168.00208111\n",
      "Iteration 269, loss = 1484.68639712\n",
      "Iteration 359, loss = 1063.66097492\n",
      "Iteration 379, loss = 1106.99020386\n",
      "Iteration 272, loss = 1378.57370319\n",
      "Iteration 315, loss = 1216.87811341\n",
      "Iteration 375, loss = 1141.65703915\n",
      "Iteration 312, loss = 1282.70979891\n",
      "Iteration 354, loss = 1177.96926624\n",
      "Iteration 270, loss = 1466.02755316\n",
      "Iteration 380, loss = 1114.21828996\n",
      "Iteration 360, loss = 1059.78518953\n",
      "Iteration 273, loss = 1411.59426442\n",
      "Iteration 316, loss = 1207.50929326\n",
      "Iteration 376, loss = 1135.23280125\n",
      "Iteration 313, loss = 1283.68769639\n",
      "Iteration 355, loss = 1161.79557067\n",
      "Iteration 271, loss = 1470.21833006\n",
      "Iteration 361, loss = 1056.18688591\n",
      "Iteration 381, loss = 1114.01397125\n",
      "Iteration 317, loss = 1218.23156298\n",
      "Iteration 274, loss = 1383.69218643\n",
      "Iteration 377, loss = 1137.09156001\n",
      "Iteration 356, loss = 1156.59649685\n",
      "Iteration 314, loss = 1274.32392299\n",
      "Iteration 272, loss = 1466.32057224\n",
      "Iteration 362, loss = 1072.36617263\n",
      "Iteration 382, loss = 1108.32498793\n",
      "Iteration 318, loss = 1207.77464369\n",
      "Iteration 275, loss = 1367.71462822\n",
      "Iteration 378, loss = 1134.90419760\n",
      "Iteration 315, loss = 1284.27080953\n",
      "Iteration 357, loss = 1157.92150803\n",
      "Iteration 273, loss = 1455.21928360\n",
      "Iteration 383, loss = 1111.23244946\n",
      "Iteration 363, loss = 1054.18657923\n",
      "Iteration 319, loss = 1202.71927824\n",
      "Iteration 276, loss = 1356.86406127\n",
      "Iteration 379, loss = 1129.03915428\n",
      "Iteration 316, loss = 1265.48052979\n",
      "Iteration 358, loss = 1167.63316494\n",
      "Iteration 274, loss = 1451.77068546\n",
      "Iteration 384, loss = 1100.42758007\n",
      "Iteration 364, loss = 1053.88866001\n",
      "Iteration 277, loss = 1355.72069414\n",
      "Iteration 320, loss = 1195.75077410\n",
      "Iteration 317, loss = 1271.37550225\n",
      "Iteration 359, loss = 1158.55275599\n",
      "Iteration 380, loss = 1152.60608679\n",
      "Iteration 275, loss = 1455.70502153\n",
      "Iteration 385, loss = 1125.02803898\n",
      "Iteration 365, loss = 1077.65380143\n",
      "Iteration 321, loss = 1191.84797328\n",
      "Iteration 318, loss = 1275.64434615\n",
      "Iteration 278, loss = 1360.87837400\n",
      "Iteration 360, loss = 1152.04463375\n",
      "Iteration 381, loss = 1130.55097096\n",
      "Iteration 276, loss = 1439.09657190\n",
      "Iteration 386, loss = 1099.70289498\n",
      "Iteration 366, loss = 1066.71328313\n",
      "Iteration 322, loss = 1217.74115461\n",
      "Iteration 279, loss = 1356.90379453\n",
      "Iteration 361, loss = 1132.85939604\n",
      "Iteration 382, loss = 1130.88292886\n",
      "Iteration 319, loss = 1266.45278228\n",
      "Iteration 277, loss = 1437.91197828\n",
      "Iteration 387, loss = 1093.36590662\n",
      "Iteration 367, loss = 1064.81660714\n",
      "Iteration 323, loss = 1219.22384292\n",
      "Iteration 280, loss = 1356.27037215\n",
      "Iteration 320, loss = 1257.19769437\n",
      "Iteration 383, loss = 1123.64557631\n",
      "Iteration 362, loss = 1161.30256222\n",
      "Iteration 278, loss = 1436.34995641\n",
      "Iteration 388, loss = 1104.28624840\n",
      "Iteration 368, loss = 1073.98123301\n",
      "Iteration 324, loss = 1190.43476162\n",
      "Iteration 281, loss = 1342.51506944\n",
      "Iteration 384, loss = 1121.46742395\n",
      "Iteration 363, loss = 1149.74406559\n",
      "Iteration 321, loss = 1275.77243783\n",
      "Iteration 279, loss = 1443.93223517\n",
      "Iteration 389, loss = 1068.22457615\n",
      "Iteration 369, loss = 1068.84061071\n",
      "Iteration 325, loss = 1186.07875473\n",
      "Iteration 282, loss = 1343.90362441\n",
      "Iteration 364, loss = 1161.71854821\n",
      "Iteration 385, loss = 1116.54314712\n",
      "Iteration 322, loss = 1256.69936058\n",
      "Iteration 280, loss = 1440.86689024\n",
      "Iteration 390, loss = 1111.82400248\n",
      "Iteration 370, loss = 1048.36204615\n",
      "Iteration 326, loss = 1178.10609614\n",
      "Iteration 283, loss = 1331.86426430\n",
      "Iteration 365, loss = 1123.03267337\n",
      "Iteration 323, loss = 1249.37577255\n",
      "Iteration 386, loss = 1123.58553520\n",
      "Iteration 281, loss = 1418.05283223\n",
      "Iteration 391, loss = 1076.97386217\n",
      "Iteration 371, loss = 1045.87822761\n",
      "Iteration 327, loss = 1173.91391795\n",
      "Iteration 284, loss = 1355.81828521\n",
      "Iteration 387, loss = 1112.80519043\n",
      "Iteration 324, loss = 1248.90773297\n",
      "Iteration 366, loss = 1136.05739281\n",
      "Iteration 282, loss = 1438.88683481\n",
      "Iteration 392, loss = 1089.36836861\n",
      "Iteration 372, loss = 1035.30867088\n",
      "Iteration 328, loss = 1167.48282363\n",
      "Iteration 388, loss = 1114.46744293\n",
      "Iteration 285, loss = 1334.45144230\n",
      "Iteration 325, loss = 1241.28964202\n",
      "Iteration 367, loss = 1137.36035307\n",
      "Iteration 283, loss = 1409.41703471\n",
      "Iteration 393, loss = 1082.19284951\n",
      "Iteration 373, loss = 1042.15550927\n",
      "Iteration 329, loss = 1168.42239821\n",
      "Iteration 389, loss = 1115.49662275\n",
      "Iteration 326, loss = 1247.64196284\n",
      "Iteration 368, loss = 1119.73486785\n",
      "Iteration 286, loss = 1328.14962420\n",
      "Iteration 284, loss = 1401.30257546\n",
      "Iteration 394, loss = 1063.18773750\n",
      "Iteration 374, loss = 1046.71575873\n",
      "Iteration 390, loss = 1120.16820554\n",
      "Iteration 330, loss = 1197.01188982\n",
      "Iteration 369, loss = 1142.01750788\n",
      "Iteration 327, loss = 1237.92375448\n",
      "Iteration 287, loss = 1311.32136457\n",
      "Iteration 285, loss = 1400.91851991\n",
      "Iteration 375, loss = 1025.87315490\n",
      "Iteration 395, loss = 1081.39279833\n",
      "Iteration 391, loss = 1135.51549937\n",
      "Iteration 331, loss = 1179.99778671\n",
      "Iteration 370, loss = 1125.07949524\n",
      "Iteration 328, loss = 1233.28899340\n",
      "Iteration 288, loss = 1332.98537549\n",
      "Iteration 286, loss = 1394.47703216\n",
      "Iteration 376, loss = 1027.53475369\n",
      "Iteration 396, loss = 1093.39916348\n",
      "Iteration 332, loss = 1158.38515449\n",
      "Iteration 392, loss = 1128.34346596\n",
      "Iteration 329, loss = 1230.59510791\n",
      "Iteration 371, loss = 1146.27806382\n",
      "Iteration 289, loss = 1312.37028310\n",
      "Iteration 287, loss = 1401.30158206\n",
      "Iteration 377, loss = 1020.15777958\n",
      "Iteration 397, loss = 1067.95898931\n",
      "Iteration 333, loss = 1166.85711016\n",
      "Iteration 393, loss = 1099.50920548\n",
      "Iteration 372, loss = 1125.41260887\n",
      "Iteration 330, loss = 1226.65491313\n",
      "Iteration 288, loss = 1382.91780914\n",
      "Iteration 290, loss = 1327.38418751\n",
      "Iteration 378, loss = 1027.72836606\n",
      "Iteration 398, loss = 1073.19046326\n",
      "Iteration 334, loss = 1156.33688850\n",
      "Iteration 394, loss = 1100.19420085\n",
      "Iteration 331, loss = 1210.83813109\n",
      "Iteration 373, loss = 1125.11652175\n",
      "Iteration 291, loss = 1317.29134257\n",
      "Iteration 289, loss = 1380.90462930\n",
      "Iteration 379, loss = 1019.02902448\n",
      "Iteration 399, loss = 1069.75868340\n",
      "Iteration 395, loss = 1097.65240832\n",
      "Iteration 374, loss = 1129.55037001\n",
      "Iteration 332, loss = 1255.91621619\n",
      "Iteration 292, loss = 1305.46023521\n",
      "Iteration 335, loss = 1170.16416990\n",
      "Iteration 290, loss = 1391.27835288\n",
      "Iteration 380, loss = 1020.07468261\n",
      "Iteration 400, loss = 1059.79150214\n",
      "Iteration 396, loss = 1095.18410745\n",
      "Iteration 333, loss = 1225.98406987\n",
      "Iteration 375, loss = 1111.79932379\n",
      "Iteration 336, loss = 1147.90808333\n",
      "Iteration 293, loss = 1312.29700697\n",
      "Iteration 291, loss = 1388.98643389\n",
      "Iteration 381, loss = 1008.34601539\n",
      "Iteration 401, loss = 1055.91568339\n",
      "Iteration 397, loss = 1106.37967318\n",
      "Iteration 334, loss = 1212.02552914\n",
      "Iteration 376, loss = 1119.09534134\n",
      "Iteration 294, loss = 1294.33413216\n",
      "Iteration 337, loss = 1146.88562962\n",
      "Iteration 292, loss = 1377.44399251\n",
      "Iteration 382, loss = 1027.97364292\n",
      "Iteration 402, loss = 1062.66530583\n",
      "Iteration 335, loss = 1226.76803255\n",
      "Iteration 398, loss = 1098.40305732\n",
      "Iteration 377, loss = 1114.86554584\n",
      "Iteration 295, loss = 1285.35392400\n",
      "Iteration 338, loss = 1150.14955223\n",
      "Iteration 293, loss = 1405.55963490\n",
      "Iteration 383, loss = 1015.03947335\n",
      "Iteration 403, loss = 1062.47206270\n",
      "Iteration 336, loss = 1213.69244904\n",
      "Iteration 399, loss = 1095.93569494\n",
      "Iteration 378, loss = 1122.21463975\n",
      "Iteration 339, loss = 1158.69409293\n",
      "Iteration 296, loss = 1292.28198303\n",
      "Iteration 294, loss = 1375.45003339\n",
      "Iteration 337, loss = 1210.05098150\n",
      "Iteration 384, loss = 1002.91876472\n",
      "Iteration 404, loss = 1067.42919781\n",
      "Iteration 400, loss = 1104.28695743\n",
      "Iteration 379, loss = 1122.92224870\n",
      "Iteration 340, loss = 1137.95631706\n",
      "Iteration 295, loss = 1363.86709393\n",
      "Iteration 338, loss = 1201.33904481\n",
      "Iteration 297, loss = 1304.47788455\n",
      "Iteration 405, loss = 1056.01968152\n",
      "Iteration 385, loss = 1021.87967420\n",
      "Iteration 401, loss = 1088.31148168\n",
      "Iteration 380, loss = 1110.61087971\n",
      "Iteration 341, loss = 1150.07374781\n",
      "Iteration 339, loss = 1210.78268291\n",
      "Iteration 296, loss = 1370.74600641\n",
      "Iteration 298, loss = 1273.96708909\n",
      "Iteration 406, loss = 1042.76028000\n",
      "Iteration 386, loss = 1015.05756278\n",
      "Iteration 402, loss = 1084.69841659\n",
      "Iteration 381, loss = 1093.97602397\n",
      "Iteration 340, loss = 1196.88434065\n",
      "Iteration 342, loss = 1138.74845736\n",
      "Iteration 297, loss = 1369.70655369\n",
      "Iteration 299, loss = 1296.95240126\n",
      "Iteration 407, loss = 1069.58404675\n",
      "Iteration 387, loss = 1019.03414815\n",
      "Iteration 403, loss = 1089.81139959\n",
      "Iteration 382, loss = 1091.68997628\n",
      "Iteration 341, loss = 1194.21723630\n",
      "Iteration 343, loss = 1129.93833644\n",
      "Iteration 300, loss = 1290.59197679\n",
      "Iteration 298, loss = 1346.45865162\n",
      "Iteration 408, loss = 1051.86314398\n",
      "Iteration 404, loss = 1084.66890158\n",
      "Iteration 388, loss = 1022.50736930\n",
      "Iteration 342, loss = 1202.92121649\n",
      "Iteration 383, loss = 1100.90014761\n",
      "Iteration 344, loss = 1119.04429724\n",
      "Iteration 299, loss = 1346.06578468\n",
      "Iteration 301, loss = 1271.18729329\n",
      "Iteration 409, loss = 1039.65249105\n",
      "Iteration 343, loss = 1197.22825107\n",
      "Iteration 405, loss = 1101.12580164\n",
      "Iteration 389, loss = 1010.28138922\n",
      "Iteration 384, loss = 1086.17820339\n",
      "Iteration 345, loss = 1117.06418807\n",
      "Iteration 300, loss = 1355.96646944\n",
      "Iteration 302, loss = 1280.33837908\n",
      "Iteration 410, loss = 1075.16513797\n",
      "Iteration 344, loss = 1188.26229719\n",
      "Iteration 406, loss = 1071.21409373\n",
      "Iteration 390, loss = 999.04521327\n",
      "Iteration 385, loss = 1092.85689199\n",
      "Iteration 346, loss = 1117.98636344\n",
      "Iteration 301, loss = 1338.03791154\n",
      "Iteration 345, loss = 1176.31472527\n",
      "Iteration 411, loss = 1051.33651914\n",
      "Iteration 303, loss = 1284.14050941\n",
      "Iteration 407, loss = 1105.55314755\n",
      "Iteration 386, loss = 1096.86355017\n",
      "Iteration 391, loss = 998.90560490\n",
      "Iteration 347, loss = 1121.26644628\n",
      "Iteration 346, loss = 1195.11356343\n",
      "Iteration 302, loss = 1335.31167032\n",
      "Iteration 412, loss = 1038.19110181\n",
      "Iteration 304, loss = 1252.99555669\n",
      "Iteration 408, loss = 1074.95955296\n",
      "Iteration 387, loss = 1086.86653388\n",
      "Iteration 392, loss = 1003.33341196\n",
      "Iteration 347, loss = 1172.67072892\n",
      "Iteration 348, loss = 1138.64660437\n",
      "Iteration 413, loss = 1039.40268658\n",
      "Iteration 303, loss = 1323.58779164\n",
      "Iteration 305, loss = 1255.43208369\n",
      "Iteration 409, loss = 1069.82556893\n",
      "Iteration 388, loss = 1081.17304446\n",
      "Iteration 348, loss = 1189.88126060\n",
      "Iteration 393, loss = 997.06288425\n",
      "Iteration 349, loss = 1121.60211291\n",
      "Iteration 414, loss = 1029.84835354\n",
      "Iteration 304, loss = 1329.79347312\n",
      "Iteration 306, loss = 1261.16866679\n",
      "Iteration 410, loss = 1087.11212383\n",
      "Iteration 349, loss = 1176.88798634\n",
      "Iteration 389, loss = 1080.73595290\n",
      "Iteration 394, loss = 999.62350844\n",
      "Iteration 350, loss = 1118.13012231\n",
      "Iteration 305, loss = 1332.00990245\n",
      "Iteration 415, loss = 1066.45731792\n",
      "Iteration 411, loss = 1063.62883622\n",
      "Iteration 307, loss = 1248.42295172\n",
      "Iteration 350, loss = 1180.49428026\n",
      "Iteration 390, loss = 1081.14119344\n",
      "Iteration 395, loss = 989.20353516\n",
      "Iteration 306, loss = 1315.23386913\n",
      "Iteration 351, loss = 1106.57510554\n",
      "Iteration 416, loss = 1041.88739427\n",
      "Iteration 412, loss = 1073.97310060\n",
      "Iteration 351, loss = 1170.15779920\n",
      "Iteration 308, loss = 1248.42357769\n",
      "Iteration 391, loss = 1077.39908242\n",
      "Iteration 396, loss = 1009.21920876\n",
      "Iteration 352, loss = 1136.66874577\n",
      "Iteration 307, loss = 1327.00475002\n",
      "Iteration 417, loss = 1028.77815646\n",
      "Iteration 352, loss = 1171.36430815\n",
      "Iteration 413, loss = 1070.87157383\n",
      "Iteration 309, loss = 1236.46117739\n",
      "Iteration 392, loss = 1107.04230623\n",
      "Iteration 353, loss = 1164.48174620\n",
      "Iteration 353, loss = 1097.27363526\n",
      "Iteration 397, loss = 1025.72266786\n",
      "Iteration 418, loss = 1026.91154237\n",
      "Iteration 414, loss = 1062.97441956\n",
      "Iteration 308, loss = 1330.53600871\n",
      "Iteration 310, loss = 1244.55369516\n",
      "Iteration 393, loss = 1089.85590809\n",
      "Iteration 354, loss = 1168.58994262\n",
      "Iteration 419, loss = 1051.85857035\n",
      "Iteration 398, loss = 1003.12911737\n",
      "Iteration 354, loss = 1102.05270867\n",
      "Iteration 415, loss = 1067.03913859\n",
      "Iteration 309, loss = 1315.54248376\n",
      "Iteration 311, loss = 1236.07807774\n",
      "Iteration 394, loss = 1079.18457249\n",
      "Iteration 355, loss = 1159.39752648\n",
      "Iteration 420, loss = 1018.64230872\n",
      "Iteration 355, loss = 1101.96848716\n",
      "Iteration 399, loss = 984.88881019\n",
      "Iteration 310, loss = 1301.84489373\n",
      "Iteration 416, loss = 1067.92812834\n",
      "Iteration 312, loss = 1231.86586699\n",
      "Iteration 395, loss = 1068.23625964\n",
      "Iteration 356, loss = 1154.73864240\n",
      "Iteration 421, loss = 1033.16303972\n",
      "Iteration 356, loss = 1110.80323726\n",
      "Iteration 311, loss = 1299.81058778\n",
      "Iteration 400, loss = 979.76584892\n",
      "Iteration 417, loss = 1052.79842618\n",
      "Iteration 313, loss = 1252.88324590\n",
      "Iteration 396, loss = 1061.71035314\n",
      "Iteration 357, loss = 1159.58604055\n",
      "Iteration 422, loss = 1028.80598971\n",
      "Iteration 357, loss = 1093.22269885\n",
      "Iteration 312, loss = 1301.04438158\n",
      "Iteration 418, loss = 1061.66935957\n",
      "Iteration 401, loss = 990.69516253\n",
      "Iteration 314, loss = 1229.01253635\n",
      "Iteration 358, loss = 1177.27696285\n",
      "Iteration 397, loss = 1079.01851430\n",
      "Iteration 423, loss = 1031.46080355\n",
      "Iteration 358, loss = 1090.88179822\n",
      "Iteration 419, loss = 1055.66810480\n",
      "Iteration 313, loss = 1302.61973277\n",
      "Iteration 315, loss = 1237.77860696\n",
      "Iteration 402, loss = 991.48109659\n",
      "Iteration 359, loss = 1157.70902147\n",
      "Iteration 398, loss = 1064.19900706\n",
      "Iteration 424, loss = 1035.11227548\n",
      "Iteration 359, loss = 1104.25452745\n",
      "Iteration 420, loss = 1061.95365150\n",
      "Iteration 403, loss = 983.05842353\n",
      "Iteration 314, loss = 1293.92694352\n",
      "Iteration 316, loss = 1227.70814592\n",
      "Iteration 360, loss = 1155.73552464\n",
      "Iteration 399, loss = 1057.80501707\n",
      "Iteration 425, loss = 1018.86577493\n",
      "Iteration 360, loss = 1091.21907848\n",
      "Iteration 361, loss = 1159.77835759\n",
      "Iteration 421, loss = 1050.83359650\n",
      "Iteration 404, loss = 984.40109595\n",
      "Iteration 317, loss = 1227.29533150\n",
      "Iteration 315, loss = 1290.19947056\n",
      "Iteration 400, loss = 1060.98893809\n",
      "Iteration 426, loss = 1010.82626060\n",
      "Iteration 362, loss = 1153.83539021\n",
      "Iteration 361, loss = 1084.73145422\n",
      "Iteration 422, loss = 1035.77687464\n",
      "Iteration 318, loss = 1228.93155647\n",
      "Iteration 316, loss = 1270.85293801\n",
      "Iteration 405, loss = 976.32033839\n",
      "Iteration 401, loss = 1076.33620415\n",
      "Iteration 427, loss = 1012.92513047\n",
      "Iteration 363, loss = 1157.75928853\n",
      "Iteration 423, loss = 1070.93926072\n",
      "Iteration 362, loss = 1090.59779536\n",
      "Iteration 319, loss = 1213.23140260\n",
      "Iteration 406, loss = 976.88882422\n",
      "Iteration 317, loss = 1278.73959542\n",
      "Iteration 402, loss = 1065.64672649\n",
      "Iteration 364, loss = 1140.52105677\n",
      "Iteration 428, loss = 1006.57221085\n",
      "Iteration 424, loss = 1055.52686362\n",
      "Iteration 363, loss = 1110.32845857\n",
      "Iteration 320, loss = 1205.00968412\n",
      "Iteration 318, loss = 1275.20240016\n",
      "Iteration 407, loss = 971.54382110\n",
      "Iteration 365, loss = 1140.29081093\n",
      "Iteration 403, loss = 1050.95741749\n",
      "Iteration 429, loss = 1009.04140688\n",
      "Iteration 425, loss = 1052.58263715\n",
      "Iteration 364, loss = 1083.65359810\n",
      "Iteration 366, loss = 1155.79511750\n",
      "Iteration 321, loss = 1207.03026905\n",
      "Iteration 404, loss = 1041.72043691\n",
      "Iteration 319, loss = 1284.16020269\n",
      "Iteration 408, loss = 979.42915338\n",
      "Iteration 430, loss = 1015.52738047\n",
      "Iteration 426, loss = 1041.99026957\n",
      "Iteration 365, loss = 1074.47665345\n",
      "Iteration 367, loss = 1144.85366735\n",
      "Iteration 405, loss = 1063.53635774\n",
      "Iteration 322, loss = 1221.29822663\n",
      "Iteration 320, loss = 1278.79017329\n",
      "Iteration 409, loss = 980.67936422\n",
      "Iteration 431, loss = 1016.31063695\n",
      "Iteration 427, loss = 1062.82357736\n",
      "Iteration 368, loss = 1142.94454461\n",
      "Iteration 366, loss = 1081.05527687\n",
      "Iteration 406, loss = 1048.84047358\n",
      "Iteration 321, loss = 1263.38792338\n",
      "Iteration 323, loss = 1212.07100143\n",
      "Iteration 432, loss = 1013.40606806\n",
      "Iteration 410, loss = 985.19923912\n",
      "Iteration 428, loss = 1052.93852723\n",
      "Iteration 369, loss = 1122.20143595\n",
      "Iteration 367, loss = 1075.84429636\n",
      "Iteration 407, loss = 1043.47064025\n",
      "Iteration 322, loss = 1261.37053459\n",
      "Iteration 324, loss = 1210.39699346\n",
      "Iteration 433, loss = 1004.75267749\n",
      "Iteration 411, loss = 963.32742450\n",
      "Iteration 370, loss = 1128.52252424\n",
      "Iteration 429, loss = 1039.02291782\n",
      "Iteration 368, loss = 1072.03057623\n",
      "Iteration 408, loss = 1053.04502789\n",
      "Iteration 323, loss = 1277.35771893\n",
      "Iteration 325, loss = 1197.49137104\n",
      "Iteration 371, loss = 1135.04790599\n",
      "Iteration 434, loss = 1011.92349984\n",
      "Iteration 412, loss = 974.47986199\n",
      "Iteration 430, loss = 1033.86883810\n",
      "Iteration 369, loss = 1070.34293580\n",
      "Iteration 409, loss = 1065.42357442\n",
      "Iteration 372, loss = 1120.09009404\n",
      "Iteration 324, loss = 1276.19776475\n",
      "Iteration 326, loss = 1191.14578387\n",
      "Iteration 435, loss = 993.30438800\n",
      "Iteration 431, loss = 1034.10733799\n",
      "Iteration 413, loss = 971.01133063\n",
      "Iteration 370, loss = 1073.79791119\n",
      "Iteration 410, loss = 1042.23370513\n",
      "Iteration 373, loss = 1133.44913390\n",
      "Iteration 325, loss = 1256.86198441\n",
      "Iteration 436, loss = 993.13977849\n",
      "Iteration 327, loss = 1183.41207557\n",
      "Iteration 432, loss = 1041.02706257\n",
      "Iteration 414, loss = 966.11469536\n",
      "Iteration 371, loss = 1067.04885865\n",
      "Iteration 374, loss = 1122.04463884\n",
      "Iteration 411, loss = 1033.22779538\n",
      "Iteration 437, loss = 989.20072562\n",
      "Iteration 326, loss = 1245.49348624\n",
      "Iteration 433, loss = 1028.88136860\n",
      "Iteration 328, loss = 1197.81570782\n",
      "Iteration 415, loss = 964.63292835\n",
      "Iteration 375, loss = 1121.13375690\n",
      "Iteration 372, loss = 1057.57309483\n",
      "Iteration 412, loss = 1045.24634084\n",
      "Iteration 438, loss = 989.17419866\n",
      "Iteration 327, loss = 1244.78208202\n",
      "Iteration 434, loss = 1021.54432175\n",
      "Iteration 329, loss = 1250.28903477\n",
      "Iteration 416, loss = 956.95186538\n",
      "Iteration 376, loss = 1115.88790630\n",
      "Iteration 373, loss = 1061.11158031\n",
      "Iteration 413, loss = 1046.24762345\n",
      "Iteration 439, loss = 1008.14926187\n",
      "Iteration 328, loss = 1262.77391549\n",
      "Iteration 435, loss = 1050.25150485\n",
      "Iteration 330, loss = 1227.41430285\n",
      "Iteration 377, loss = 1111.92165726\n",
      "Iteration 417, loss = 955.10534960\n",
      "Iteration 414, loss = 1043.99548749\n",
      "Iteration 374, loss = 1050.57755408\n",
      "Iteration 440, loss = 980.34138602\n",
      "Iteration 436, loss = 1022.06415656\n",
      "Iteration 329, loss = 1235.58500094\n",
      "Iteration 378, loss = 1136.17553788\n",
      "Iteration 331, loss = 1181.77170036\n",
      "Iteration 418, loss = 946.31157335\n",
      "Iteration 441, loss = 994.52963602\n",
      "Iteration 415, loss = 1041.27674431\n",
      "Iteration 375, loss = 1059.35117101\n",
      "Iteration 330, loss = 1248.11797296\n",
      "Iteration 437, loss = 1027.99474235\n",
      "Iteration 379, loss = 1111.05015173\n",
      "Iteration 332, loss = 1183.26585210\n",
      "Iteration 419, loss = 982.17376654\n",
      "Iteration 442, loss = 982.96380135\n",
      "Iteration 416, loss = 1033.80976155\n",
      "Iteration 376, loss = 1046.64819831\n",
      "Iteration 380, loss = 1112.07199142\n",
      "Iteration 331, loss = 1233.07552062\n",
      "Iteration 438, loss = 1020.76366015\n",
      "Iteration 333, loss = 1180.15534361\n",
      "Iteration 420, loss = 960.83696961\n",
      "Iteration 443, loss = 997.11415946\n",
      "Iteration 417, loss = 1028.50902002\n",
      "Iteration 377, loss = 1050.49004179\n",
      "Iteration 381, loss = 1102.60006521\n",
      "Iteration 439, loss = 1031.65785247\n",
      "Iteration 332, loss = 1258.62083660\n",
      "Iteration 334, loss = 1175.90183804\n",
      "Iteration 444, loss = 995.09045191\n",
      "Iteration 382, loss = 1116.39691556\n",
      "Iteration 418, loss = 1031.70857473\n",
      "Iteration 421, loss = 954.72448368\n",
      "Iteration 378, loss = 1067.01638023\n",
      "Iteration 440, loss = 1041.50463660\n",
      "Iteration 333, loss = 1219.20218932\n",
      "Iteration 335, loss = 1187.14066352\n",
      "Iteration 445, loss = 995.01069522\n",
      "Iteration 383, loss = 1107.60235488\n",
      "Iteration 422, loss = 953.90880059\n",
      "Iteration 419, loss = 1030.32888064\n",
      "Iteration 379, loss = 1059.79170549\n",
      "Iteration 441, loss = 1021.48500130\n",
      "Iteration 334, loss = 1229.94155768\n",
      "Iteration 336, loss = 1170.31362610\n",
      "Iteration 384, loss = 1119.73643638\n",
      "Iteration 446, loss = 986.26916873\n",
      "Iteration 420, loss = 1046.85684278\n",
      "Iteration 423, loss = 957.43741510\n",
      "Iteration 380, loss = 1051.16477700\n",
      "Iteration 442, loss = 1010.09695460\n",
      "Iteration 335, loss = 1220.43444703\n",
      "Iteration 337, loss = 1171.87529117\n",
      "Iteration 385, loss = 1110.73010921\n",
      "Iteration 447, loss = 986.57042926\n",
      "Iteration 421, loss = 1026.18715829\n",
      "Iteration 424, loss = 946.14271400\n",
      "Iteration 381, loss = 1036.20702964\n",
      "Iteration 443, loss = 1002.81492690\n",
      "Iteration 336, loss = 1241.16938567\n",
      "Iteration 386, loss = 1098.54507012\n",
      "Iteration 338, loss = 1163.18006186\n",
      "Iteration 448, loss = 1001.30375051\n",
      "Iteration 422, loss = 1033.49996222\n",
      "Iteration 425, loss = 953.45503687\n",
      "Iteration 444, loss = 1018.75731716\n",
      "Iteration 382, loss = 1042.84984153\n",
      "Iteration 337, loss = 1216.21449323\n",
      "Iteration 387, loss = 1095.77415488\n",
      "Iteration 339, loss = 1166.25413817\n",
      "Iteration 449, loss = 975.76448807\n",
      "Iteration 423, loss = 1032.78407008\n",
      "Iteration 426, loss = 941.28265751\n",
      "Iteration 445, loss = 1028.72260616\n",
      "Iteration 338, loss = 1213.63983622\n",
      "Iteration 383, loss = 1030.12203461\n",
      "Iteration 388, loss = 1095.05522130\n",
      "Iteration 450, loss = 977.87707816\n",
      "Iteration 340, loss = 1160.85662168\n",
      "Iteration 424, loss = 1029.71081451\n",
      "Iteration 446, loss = 1015.26693062\n",
      "Iteration 427, loss = 947.20446867\n",
      "Iteration 389, loss = 1090.09937511\n",
      "Iteration 339, loss = 1219.09929118\n",
      "Iteration 384, loss = 1041.04238962\n",
      "Iteration 451, loss = 983.87575248\n",
      "Iteration 341, loss = 1156.27683999\n",
      "Iteration 425, loss = 1024.19862625\n",
      "Iteration 390, loss = 1100.69154754\n",
      "Iteration 447, loss = 1029.27338123\n",
      "Iteration 428, loss = 945.90379660\n",
      "Iteration 340, loss = 1208.84832738\n",
      "Iteration 385, loss = 1052.80681715\n",
      "Iteration 452, loss = 960.08513263\n",
      "Iteration 342, loss = 1161.84950298\n",
      "Iteration 426, loss = 1023.62590443\n",
      "Iteration 391, loss = 1089.72480783\n",
      "Iteration 448, loss = 1007.92443500\n",
      "Iteration 341, loss = 1208.39168530\n",
      "Iteration 429, loss = 941.46598293\n",
      "Iteration 386, loss = 1037.16348615\n",
      "Iteration 453, loss = 992.43612091\n",
      "Iteration 343, loss = 1181.55323866\n",
      "Iteration 392, loss = 1100.81418959\n",
      "Iteration 427, loss = 1017.06212036\n",
      "Iteration 449, loss = 1023.89311536\n",
      "Iteration 342, loss = 1204.68116068\n",
      "Iteration 430, loss = 941.36838903\n",
      "Iteration 454, loss = 970.60416289\n",
      "Iteration 387, loss = 1027.70874013\n",
      "Iteration 393, loss = 1101.42737996\n",
      "Iteration 344, loss = 1156.89198896\n",
      "Iteration 428, loss = 1003.45087601\n",
      "Iteration 450, loss = 1004.47353064\n",
      "Iteration 343, loss = 1204.83036232\n",
      "Iteration 431, loss = 951.32877894\n",
      "Iteration 455, loss = 951.88412462\n",
      "Iteration 394, loss = 1090.15624775\n",
      "Iteration 388, loss = 1039.38684967\n",
      "Iteration 345, loss = 1132.43818101\n",
      "Iteration 429, loss = 1023.82723732\n",
      "Iteration 451, loss = 1000.42312740\n",
      "Iteration 344, loss = 1198.76013787\n",
      "Iteration 456, loss = 971.99131054\n",
      "Iteration 432, loss = 955.11121988\n",
      "Iteration 395, loss = 1077.24237903\n",
      "Iteration 389, loss = 1031.89862664\n",
      "Iteration 430, loss = 1008.11973972\n",
      "Iteration 346, loss = 1156.42705508\n",
      "Iteration 452, loss = 988.46385667\n",
      "Iteration 345, loss = 1179.33075106\n",
      "Iteration 457, loss = 962.22611093\n",
      "Iteration 433, loss = 928.16046755\n",
      "Iteration 396, loss = 1081.35839859\n",
      "Iteration 390, loss = 1015.91335186\n",
      "Iteration 431, loss = 1035.94636885\n",
      "Iteration 347, loss = 1142.31834464\n",
      "Iteration 453, loss = 990.86945369\n",
      "Iteration 346, loss = 1214.85469725\n",
      "Iteration 397, loss = 1081.50271833\n",
      "Iteration 458, loss = 961.65382925\n",
      "Iteration 434, loss = 936.22979924\n",
      "Iteration 391, loss = 1024.15449544\n",
      "Iteration 432, loss = 1011.64453943\n",
      "Iteration 348, loss = 1187.11430328\n",
      "Iteration 454, loss = 1019.61868388\n",
      "Iteration 398, loss = 1078.60906698\n",
      "Iteration 347, loss = 1191.59105300\n",
      "Iteration 435, loss = 929.83308059\n",
      "Iteration 459, loss = 975.77897391\n",
      "Iteration 392, loss = 1086.47958639\n",
      "Iteration 433, loss = 999.12111192\n",
      "Iteration 349, loss = 1140.37826344\n",
      "Iteration 399, loss = 1093.29196412\n",
      "Iteration 455, loss = 999.53742942\n",
      "Iteration 348, loss = 1220.11470026\n",
      "Iteration 436, loss = 945.92989062\n",
      "Iteration 460, loss = 1004.76804640\n",
      "Iteration 393, loss = 1044.68567515\n",
      "Iteration 350, loss = 1141.55047526\n",
      "Iteration 434, loss = 999.74687188\n",
      "Iteration 400, loss = 1075.10625408\n",
      "Iteration 456, loss = 1007.65621817\n",
      "Iteration 349, loss = 1192.86668494\n",
      "Iteration 437, loss = 934.68307782\n",
      "Iteration 461, loss = 967.23342119\n",
      "Iteration 394, loss = 1011.55979640\n",
      "Iteration 351, loss = 1135.21418694\n",
      "Iteration 435, loss = 1012.67615354\n",
      "Iteration 401, loss = 1076.67735441\n",
      "Iteration 457, loss = 1008.31363251\n",
      "Iteration 350, loss = 1203.11406004\n",
      "Iteration 438, loss = 935.75323951\n",
      "Iteration 462, loss = 970.85792003\n",
      "Iteration 402, loss = 1074.11302129\n",
      "Iteration 395, loss = 1011.55209877\n",
      "Iteration 436, loss = 999.88312124\n",
      "Iteration 352, loss = 1138.84918252\n",
      "Iteration 458, loss = 994.16816810\n",
      "Iteration 351, loss = 1180.38418947\n",
      "Iteration 463, loss = 957.45475803\n",
      "Iteration 439, loss = 924.37338208\n",
      "Iteration 403, loss = 1078.11244702\n",
      "Iteration 396, loss = 1014.92633414\n",
      "Iteration 437, loss = 1029.45223977\n",
      "Iteration 353, loss = 1116.41805481\n",
      "Iteration 459, loss = 987.00578355\n",
      "Iteration 352, loss = 1187.98948415\n",
      "Iteration 464, loss = 948.52188456\n",
      "Iteration 404, loss = 1095.79441783\n",
      "Iteration 440, loss = 931.50863477\n",
      "Iteration 438, loss = 1021.27289024\n",
      "Iteration 397, loss = 1023.18173392\n",
      "Iteration 460, loss = 985.68220730\n",
      "Iteration 354, loss = 1145.39758688\n",
      "Iteration 405, loss = 1060.96749882\n",
      "Iteration 353, loss = 1170.89480440\n",
      "Iteration 465, loss = 954.94163207\n",
      "Iteration 441, loss = 929.00448750\n",
      "Iteration 439, loss = 1005.27939119\n",
      "Iteration 398, loss = 1008.95614462\n",
      "Iteration 355, loss = 1132.92774862\n",
      "Iteration 461, loss = 995.84510216\n",
      "Iteration 406, loss = 1069.72920985\n",
      "Iteration 354, loss = 1170.56224327\n",
      "Iteration 466, loss = 977.26411550\n",
      "Iteration 440, loss = 1007.25764989\n",
      "Iteration 399, loss = 1009.62476456\n",
      "Iteration 442, loss = 917.59217812\n",
      "Iteration 356, loss = 1132.17034212\n",
      "Iteration 462, loss = 991.54437220\n",
      "Iteration 407, loss = 1053.97992871\n",
      "Iteration 467, loss = 956.53077064\n",
      "Iteration 355, loss = 1164.28309161\n",
      "Iteration 441, loss = 996.91014993\n",
      "Iteration 400, loss = 999.74818641\n",
      "Iteration 443, loss = 921.73619168\n",
      "Iteration 357, loss = 1162.47154474\n",
      "Iteration 408, loss = 1066.59027613\n",
      "Iteration 463, loss = 1001.66787982\n",
      "Iteration 468, loss = 944.55033973\n",
      "Iteration 356, loss = 1191.21728964\n",
      "Iteration 442, loss = 987.54678672\n",
      "Iteration 401, loss = 1002.08460081\n",
      "Iteration 409, loss = 1062.73602872\n",
      "Iteration 444, loss = 928.33028147\n",
      "Iteration 358, loss = 1122.81980164\n",
      "Iteration 464, loss = 986.33481720\n",
      "Iteration 469, loss = 949.93201290\n",
      "Iteration 357, loss = 1203.81038893\n",
      "Iteration 443, loss = 985.02631023\n",
      "Iteration 402, loss = 1004.43637160\n",
      "Iteration 410, loss = 1052.96953279\n",
      "Iteration 445, loss = 918.99371222\n",
      "Iteration 359, loss = 1126.38411413\n",
      "Iteration 465, loss = 983.29962338\n",
      "Iteration 470, loss = 953.23351095\n",
      "Iteration 358, loss = 1172.68530346\n",
      "Iteration 411, loss = 1051.28694190\n",
      "Iteration 444, loss = 988.56650593\n",
      "Iteration 403, loss = 999.69958177\n",
      "Iteration 466, loss = 981.50465003\n",
      "Iteration 446, loss = 934.13162541\n",
      "Iteration 360, loss = 1123.08461974\n",
      "Iteration 471, loss = 953.93883654\n",
      "Iteration 359, loss = 1159.75863141\n",
      "Iteration 412, loss = 1051.02999468\n",
      "Iteration 404, loss = 994.83156345\n",
      "Iteration 445, loss = 1005.41520329\n",
      "Iteration 467, loss = 981.34163442\n",
      "Iteration 361, loss = 1099.18245043\n",
      "Iteration 447, loss = 950.57252694\n",
      "Iteration 472, loss = 953.24168395\n",
      "Iteration 413, loss = 1057.46879684\n",
      "Iteration 360, loss = 1172.56030913\n",
      "Iteration 446, loss = 998.11329090\n",
      "Iteration 405, loss = 997.36064977\n",
      "Iteration 468, loss = 977.03879121\n",
      "Iteration 362, loss = 1122.21882271\n",
      "Iteration 473, loss = 951.15155393\n",
      "Iteration 448, loss = 915.34571937\n",
      "Iteration 361, loss = 1172.46667772\n",
      "Iteration 414, loss = 1044.10553424\n",
      "Iteration 447, loss = 982.01919815\n",
      "Iteration 406, loss = 989.05434103\n",
      "Iteration 469, loss = 994.00746222\n",
      "Iteration 474, loss = 955.54896353\n",
      "Iteration 363, loss = 1146.39620268\n",
      "Iteration 449, loss = 894.18392110\n",
      "Iteration 415, loss = 1050.45404116\n",
      "Iteration 362, loss = 1169.07221171\n",
      "Iteration 448, loss = 991.62039093\n",
      "Iteration 407, loss = 993.08170587\n",
      "Iteration 470, loss = 979.67778516\n",
      "Iteration 364, loss = 1123.19040832\n",
      "Iteration 475, loss = 936.28615006\n",
      "Iteration 450, loss = 905.97777096\n",
      "Iteration 416, loss = 1063.83031114\n",
      "Iteration 363, loss = 1169.51817956\n",
      "Iteration 449, loss = 996.03799992\n",
      "Iteration 471, loss = 974.07856418\n",
      "Iteration 408, loss = 985.74263270\n",
      "Iteration 365, loss = 1163.09989039\n",
      "Iteration 476, loss = 930.92947441\n",
      "Iteration 417, loss = 1064.11064416\n",
      "Iteration 451, loss = 914.62253687\n",
      "Iteration 364, loss = 1155.42449718\n",
      "Iteration 450, loss = 984.51399156\n",
      "Iteration 472, loss = 991.96165506\n",
      "Iteration 409, loss = 981.76628521\n",
      "Iteration 418, loss = 1054.10631151\n",
      "Iteration 366, loss = 1124.32759908\n",
      "Iteration 477, loss = 927.98520905\n",
      "Iteration 452, loss = 911.39634157\n",
      "Iteration 365, loss = 1151.08211585\n",
      "Iteration 451, loss = 974.56198480\n",
      "Iteration 473, loss = 998.59155125\n",
      "Iteration 419, loss = 1047.39773523\n",
      "Iteration 410, loss = 978.40807380\n",
      "Iteration 367, loss = 1106.49556746\n",
      "Iteration 478, loss = 941.95865193\n",
      "Iteration 453, loss = 899.77732335\n",
      "Iteration 366, loss = 1140.76785380\n",
      "Iteration 452, loss = 981.19171237\n",
      "Iteration 420, loss = 1062.72234046\n",
      "Iteration 474, loss = 985.52384453\n",
      "Iteration 479, loss = 961.93325506\n",
      "Iteration 411, loss = 984.65237783\n",
      "Iteration 368, loss = 1111.49765485\n",
      "Iteration 454, loss = 913.35002096\n",
      "Iteration 367, loss = 1143.94938910\n",
      "Iteration 453, loss = 987.77918291\n",
      "Iteration 421, loss = 1041.94303565\n",
      "Iteration 475, loss = 987.54364034\n",
      "Iteration 480, loss = 941.61149336\n",
      "Iteration 369, loss = 1095.23875638\n",
      "Iteration 412, loss = 981.71738693\n",
      "Iteration 368, loss = 1168.92273857\n",
      "Iteration 455, loss = 925.74909245\n",
      "Iteration 422, loss = 1030.63499105\n",
      "Iteration 454, loss = 979.64572497\n",
      "Iteration 476, loss = 963.29653206\n",
      "Iteration 481, loss = 932.92949819\n",
      "Iteration 370, loss = 1080.15998355\n",
      "Iteration 413, loss = 1001.15466697\n",
      "Iteration 423, loss = 1026.84055002\n",
      "Iteration 369, loss = 1153.63851059\n",
      "Iteration 456, loss = 907.24596701\n",
      "Iteration 455, loss = 966.27926206\n",
      "Iteration 477, loss = 974.39762361\n",
      "Iteration 482, loss = 929.30102876\n",
      "Iteration 371, loss = 1119.38966631\n",
      "Iteration 414, loss = 983.36443303\n",
      "Iteration 424, loss = 1056.68533920\n",
      "Iteration 370, loss = 1132.03716021\n",
      "Iteration 456, loss = 973.65687967\n",
      "Iteration 457, loss = 903.77503663\n",
      "Iteration 478, loss = 964.74733116\n",
      "Iteration 483, loss = 933.42750653\n",
      "Iteration 425, loss = 1041.32055664\n",
      "Iteration 372, loss = 1085.62230478\n",
      "Iteration 415, loss = 977.38380783\n",
      "Iteration 371, loss = 1183.73067531\n",
      "Iteration 479, loss = 965.96152089\n",
      "Iteration 457, loss = 992.99130441\n",
      "Iteration 458, loss = 906.82450224\n",
      "Iteration 484, loss = 922.81309318\n",
      "Iteration 426, loss = 1044.04567708\n",
      "Iteration 373, loss = 1083.32512138\n",
      "Iteration 416, loss = 969.63516477\n",
      "Iteration 372, loss = 1146.16063220\n",
      "Iteration 480, loss = 967.32500284\n",
      "Iteration 458, loss = 975.29761441\n",
      "Iteration 485, loss = 919.39329597\n",
      "Iteration 427, loss = 1034.32468661\n",
      "Iteration 459, loss = 902.78177445\n",
      "Iteration 374, loss = 1096.92330923\n",
      "Iteration 373, loss = 1162.94448592\n",
      "Iteration 417, loss = 973.28131925\n",
      "Iteration 481, loss = 972.24703290\n",
      "Iteration 459, loss = 978.46095144\n",
      "Iteration 428, loss = 1017.36255151\n",
      "Iteration 486, loss = 945.99333791\n",
      "Iteration 460, loss = 905.38041896\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 375, loss = 1100.48928131\n",
      "Iteration 374, loss = 1152.17776710\n",
      "Iteration 418, loss = 980.12332877\n",
      "Iteration 429, loss = 1017.36490053\n",
      "Iteration 482, loss = 964.65064690\n",
      "Iteration 460, loss = 997.17316872\n",
      "Iteration 487, loss = 922.84708191\n",
      "Iteration 1, loss = 11915.43698673\n",
      "Iteration 376, loss = 1094.25568070\n",
      "Iteration 375, loss = 1137.61102324\n",
      "Iteration 430, loss = 1023.12488575\n",
      "Iteration 419, loss = 968.54802883\n",
      "Iteration 483, loss = 970.63977810\n",
      "Iteration 461, loss = 963.07660682\n",
      "Iteration 488, loss = 906.48459572\n",
      "Iteration 2, loss = 11517.68511288\n",
      "Iteration 431, loss = 1036.43729494\n",
      "Iteration 377, loss = 1107.66089040\n",
      "Iteration 376, loss = 1128.33172789\n",
      "Iteration 420, loss = 976.49426211\n",
      "Iteration 484, loss = 981.33539845\n",
      "Iteration 462, loss = 957.25328699\n",
      "Iteration 489, loss = 936.30732710\n",
      "Iteration 432, loss = 1031.71196122\n",
      "Iteration 3, loss = 11205.45156912\n",
      "Iteration 378, loss = 1081.34577012\n",
      "Iteration 377, loss = 1117.49394770\n",
      "Iteration 421, loss = 978.41872596\n",
      "Iteration 485, loss = 964.06238132\n",
      "Iteration 463, loss = 970.89795841\n",
      "Iteration 490, loss = 926.07895832\n",
      "Iteration 433, loss = 1016.14654015\n",
      "Iteration 4, loss = 10946.97430313\n",
      "Iteration 378, loss = 1126.19086881\n",
      "Iteration 486, loss = 967.98441561\n",
      "Iteration 422, loss = 985.84206365\n",
      "Iteration 379, loss = 1081.93559990\n",
      "Iteration 464, loss = 994.71172499\n",
      "Iteration 491, loss = 932.04401434\n",
      "Iteration 434, loss = 1022.93296243\n",
      "Iteration 5, loss = 10733.65153617\n",
      "Iteration 487, loss = 958.01399280\n",
      "Iteration 379, loss = 1116.00127608\n",
      "Iteration 465, loss = 958.90813069\n",
      "Iteration 380, loss = 1084.41088023\n",
      "Iteration 423, loss = 966.75274044\n",
      "Iteration 492, loss = 929.83959179\n",
      "Iteration 435, loss = 1015.54826160\n",
      "Iteration 6, loss = 10437.95009771\n",
      "Iteration 488, loss = 972.86885407\n",
      "Iteration 380, loss = 1117.87967811\n",
      "Iteration 466, loss = 967.14975898\n",
      "Iteration 424, loss = 959.73014110\n",
      "Iteration 381, loss = 1077.22892920\n",
      "Iteration 493, loss = 916.02316120\n",
      "Iteration 436, loss = 1011.77043101\n",
      "Iteration 7, loss = 10144.01130770\n",
      "Iteration 489, loss = 950.97304055\n",
      "Iteration 467, loss = 975.96014694\n",
      "Iteration 381, loss = 1111.11756652\n",
      "Iteration 382, loss = 1091.62490085\n",
      "Iteration 494, loss = 909.91185572\n",
      "Iteration 425, loss = 947.69185045\n",
      "Iteration 437, loss = 1022.29510465\n",
      "Iteration 8, loss = 9897.66443763\n",
      "Iteration 490, loss = 975.72639868\n",
      "Iteration 468, loss = 983.50882581\n",
      "Iteration 382, loss = 1110.13965571\n",
      "Iteration 438, loss = 1021.40970126\n",
      "Iteration 495, loss = 931.19605721\n",
      "Iteration 383, loss = 1077.28140237\n",
      "Iteration 426, loss = 975.40068263\n",
      "Iteration 9, loss = 9675.63614632\n",
      "Iteration 491, loss = 968.30078383\n",
      "Iteration 439, loss = 1016.01699735\n",
      "Iteration 496, loss = 923.73569732\n",
      "Iteration 383, loss = 1108.01710465\n",
      "Iteration 469, loss = 967.36058310\n",
      "Iteration 384, loss = 1078.85445396\n",
      "Iteration 427, loss = 965.89766832\n",
      "Iteration 492, loss = 988.43493285\n",
      "Iteration 10, loss = 9470.50162623\n",
      "Iteration 440, loss = 1014.42079284\n",
      "Iteration 497, loss = 914.68520571\n",
      "Iteration 384, loss = 1129.20946683\n",
      "Iteration 470, loss = 944.82549762\n",
      "Iteration 428, loss = 953.72110556\n",
      "Iteration 385, loss = 1099.48592600\n",
      "Iteration 493, loss = 960.35942311\n",
      "Iteration 441, loss = 1011.59786507\n",
      "Iteration 11, loss = 9276.05181470\n",
      "Iteration 385, loss = 1126.63913596\n",
      "Iteration 498, loss = 903.23001585\n",
      "Iteration 471, loss = 973.33347856\n",
      "Iteration 429, loss = 951.32107609\n",
      "Iteration 386, loss = 1089.87835547\n",
      "Iteration 494, loss = 949.29321466\n",
      "Iteration 442, loss = 1015.91272051\n",
      "Iteration 12, loss = 9092.27767772\n",
      "Iteration 386, loss = 1115.06559663\n",
      "Iteration 499, loss = 962.06459128\n",
      "Iteration 472, loss = 948.97831104\n",
      "Iteration 430, loss = 964.91122403\n",
      "Iteration 387, loss = 1062.13556358\n",
      "Iteration 443, loss = 1005.88811003\n",
      "Iteration 495, loss = 946.39552498\n",
      "Iteration 13, loss = 8917.42757913\n",
      "Iteration 387, loss = 1129.82066245\n",
      "Iteration 500, loss = 964.20433628\n",
      "Iteration 473, loss = 954.96362982\n",
      "Iteration 431, loss = 955.78151679\n",
      "Iteration 444, loss = 1000.25959139\n",
      "Iteration 388, loss = 1048.96236668\n",
      "Iteration 496, loss = 941.65434120\n",
      "Iteration 14, loss = 8749.92732563\n",
      "Iteration 388, loss = 1092.02727860\n",
      "Iteration 501, loss = 909.21283535\n",
      "Iteration 474, loss = 937.63787673\n",
      "Iteration 445, loss = 1001.29972434\n",
      "Iteration 432, loss = 946.51567504\n",
      "Iteration 389, loss = 1067.00011638\n",
      "Iteration 497, loss = 961.71283209\n",
      "Iteration 15, loss = 8590.00427684\n",
      "Iteration 475, loss = 943.81208402\n",
      "Iteration 389, loss = 1088.74672855\n",
      "Iteration 502, loss = 902.66835470\n",
      "Iteration 446, loss = 1016.30492317\n",
      "Iteration 433, loss = 943.29218335\n",
      "Iteration 498, loss = 1015.32869543\n",
      "Iteration 390, loss = 1070.38202820\n",
      "Iteration 16, loss = 8436.30239736\n",
      "Iteration 447, loss = 1019.57279474\n",
      "Iteration 390, loss = 1099.41024353\n",
      "Iteration 503, loss = 919.29005106\n",
      "Iteration 476, loss = 940.62736173\n",
      "Iteration 434, loss = 946.20333540\n",
      "Iteration 499, loss = 963.97071733\n",
      "Iteration 391, loss = 1088.18938996\n",
      "Iteration 448, loss = 1000.87219729\n",
      "Iteration 17, loss = 8287.48336346\n",
      "Iteration 504, loss = 914.40303554\n",
      "Iteration 391, loss = 1098.52790810\n",
      "Iteration 477, loss = 962.00424439\n",
      "Iteration 435, loss = 940.96116161\n",
      "Iteration 500, loss = 965.76365385\n",
      "Iteration 392, loss = 1066.23604188\n",
      "Iteration 449, loss = 1011.02066456\n",
      "Iteration 18, loss = 8145.05454914\n",
      "Iteration 392, loss = 1091.65916650\n",
      "Iteration 505, loss = 904.69819212\n",
      "Iteration 478, loss = 961.08927856\n",
      "Iteration 436, loss = 939.17977016\n",
      "Iteration 501, loss = 956.74742838\n",
      "Iteration 450, loss = 991.00542619\n",
      "Iteration 393, loss = 1056.57856564\n",
      "Iteration 19, loss = 8007.27828593\n",
      "Iteration 393, loss = 1104.81950158\n",
      "Iteration 506, loss = 909.85283386\n",
      "Iteration 479, loss = 933.36867302\n",
      "Iteration 437, loss = 940.60481107\n",
      "Iteration 502, loss = 947.88282885\n",
      "Iteration 451, loss = 1009.01439163\n",
      "Iteration 394, loss = 1057.71964932\n",
      "Iteration 20, loss = 7873.80996004\n",
      "Iteration 507, loss = 903.71591048\n",
      "Iteration 394, loss = 1087.83822200\n",
      "Iteration 480, loss = 936.58202657\n",
      "Iteration 438, loss = 981.16085767\n",
      "Iteration 452, loss = 982.72270426\n",
      "Iteration 503, loss = 947.07934255\n",
      "Iteration 395, loss = 1055.87336929\n",
      "Iteration 21, loss = 7745.34732881\n",
      "Iteration 508, loss = 904.31190663\n",
      "Iteration 395, loss = 1075.13609687\n",
      "Iteration 481, loss = 939.43544484\n",
      "Iteration 453, loss = 1002.02285446\n",
      "Iteration 439, loss = 943.13257083\n",
      "Iteration 504, loss = 963.04740824\n",
      "Iteration 22, loss = 7620.43078796\n",
      "Iteration 396, loss = 1066.79325904\n",
      "Iteration 509, loss = 895.80856780\n",
      "Iteration 396, loss = 1087.46229034\n",
      "Iteration 454, loss = 985.26558747\n",
      "Iteration 482, loss = 948.64817763\n",
      "Iteration 440, loss = 926.79164401\n",
      "Iteration 505, loss = 965.67186416\n",
      "Iteration 510, loss = 915.00801906\n",
      "Iteration 397, loss = 1055.08770651\n",
      "Iteration 23, loss = 7498.88873393\n",
      "Iteration 455, loss = 994.54963920\n",
      "Iteration 397, loss = 1116.16973572\n",
      "Iteration 483, loss = 967.57220603\n",
      "Iteration 441, loss = 929.20421653\n",
      "Iteration 506, loss = 948.97401546\n",
      "Iteration 511, loss = 908.68857756\n",
      "Iteration 24, loss = 7381.98569570\n",
      "Iteration 456, loss = 985.83176563\n",
      "Iteration 398, loss = 1057.16790448\n",
      "Iteration 398, loss = 1077.41272174\n",
      "Iteration 484, loss = 943.38817355\n",
      "Iteration 442, loss = 942.16773711\n",
      "Iteration 507, loss = 947.73559193\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 512, loss = 897.93851978\n",
      "Iteration 457, loss = 1008.13397591\n",
      "Iteration 25, loss = 7268.96068971\n",
      "Iteration 399, loss = 1051.50127774\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 399, loss = 1076.52458494\n",
      "Iteration 485, loss = 937.58000854\n",
      "Iteration 443, loss = 918.76421696\n",
      "Iteration 1, loss = 5407.62308867\n",
      "Iteration 513, loss = 888.74702588\n",
      "Iteration 458, loss = 999.77063840\n",
      "Iteration 26, loss = 7159.44188844\n",
      "Iteration 1, loss = 11828.88149668\n",
      "Iteration 2, loss = 1996.59154152\n",
      "Iteration 400, loss = 1086.42423702\n",
      "Iteration 3, loss = 1329.60654291\n",
      "Iteration 486, loss = 931.68911268\n",
      "Iteration 444, loss = 925.41011083\n",
      "Iteration 4, loss = 1179.84685806\n",
      "Iteration 514, loss = 908.11010487\n",
      "Iteration 459, loss = 976.44361508\n",
      "Iteration 2, loss = 11431.93671903\n",
      "Iteration 27, loss = 7052.59959372\n",
      "Iteration 5, loss = 1108.55226330\n",
      "Iteration 401, loss = 1092.32242075\n",
      "Iteration 487, loss = 922.13910406\n",
      "Iteration 6, loss = 1079.04904796\n",
      "Iteration 460, loss = 985.39477741\n",
      "Iteration 515, loss = 895.74230209\n",
      "Iteration 445, loss = 921.40595239\n",
      "Iteration 7, loss = 1041.90196271\n",
      "Iteration 28, loss = 6948.69032296\n",
      "Iteration 3, loss = 11120.41961367\n",
      "Iteration 8, loss = 1026.38692034\n",
      "Iteration 402, loss = 1073.81285614\n",
      "Iteration 488, loss = 939.16394650\n",
      "Iteration 516, loss = 907.12080465\n",
      "Iteration 461, loss = 981.81717619\n",
      "Iteration 446, loss = 928.61446758\n",
      "Iteration 9, loss = 1010.99783941\n",
      "Iteration 29, loss = 6847.04390564\n",
      "Iteration 4, loss = 10862.42034064\n",
      "Iteration 10, loss = 989.89101383\n",
      "Iteration 489, loss = 936.00994309\n",
      "Iteration 403, loss = 1091.31489589\n",
      "Iteration 11, loss = 966.35733255\n",
      "Iteration 462, loss = 968.44616032\n",
      "Iteration 517, loss = 893.78992823\n",
      "Iteration 447, loss = 938.55069983\n",
      "Iteration 12, loss = 969.09802808\n",
      "Iteration 30, loss = 6749.62395191\n",
      "Iteration 5, loss = 10649.79857285\n",
      "Iteration 13, loss = 950.80396201\n",
      "Iteration 490, loss = 942.74496351\n",
      "Iteration 463, loss = 995.06121505\n",
      "Iteration 404, loss = 1090.52925220\n",
      "Iteration 14, loss = 942.57768924\n",
      "Iteration 518, loss = 911.18701189\n",
      "Iteration 448, loss = 919.36828770\n",
      "Iteration 31, loss = 6654.37406882\n",
      "Iteration 15, loss = 917.23348683\n",
      "Iteration 6, loss = 10350.34121862\n",
      "Iteration 464, loss = 981.78616140\n",
      "Iteration 16, loss = 918.68205267\n",
      "Iteration 491, loss = 946.49467469\n",
      "Iteration 405, loss = 1060.54760024\n",
      "Iteration 519, loss = 890.03121109\n",
      "Iteration 449, loss = 966.59712925\n",
      "Iteration 17, loss = 904.16631834\n",
      "Iteration 32, loss = 6560.91540655\n",
      "Iteration 18, loss = 897.00602568\n",
      "Iteration 465, loss = 972.41191886\n",
      "Iteration 7, loss = 10058.36790126\n",
      "Iteration 492, loss = 942.97241799\n",
      "Iteration 406, loss = 1056.57238397\n",
      "Iteration 19, loss = 900.48981693\n",
      "Iteration 520, loss = 890.03403854\n",
      "Iteration 450, loss = 920.93811590\n",
      "Iteration 20, loss = 895.27739336\n",
      "Iteration 33, loss = 6471.54200545\n",
      "Iteration 466, loss = 985.21265544\n",
      "Iteration 8, loss = 9813.29495745\n",
      "Iteration 21, loss = 883.78282790\n",
      "Iteration 493, loss = 936.37808535\n",
      "Iteration 407, loss = 1058.81544010\n",
      "Iteration 521, loss = 879.51319187\n",
      "Iteration 22, loss = 883.88246182\n",
      "Iteration 451, loss = 926.65506663\n",
      "Iteration 34, loss = 6382.53734432\n",
      "Iteration 23, loss = 882.67859319\n",
      "Iteration 467, loss = 972.56924231\n",
      "Iteration 24, loss = 880.25368584\n",
      "Iteration 9, loss = 9591.37568999\n",
      "Iteration 494, loss = 921.27788556\n",
      "Iteration 408, loss = 1070.48192410\n",
      "Iteration 522, loss = 908.38384992\n",
      "Iteration 25, loss = 879.35921277\n",
      "Iteration 452, loss = 914.52671340\n",
      "Iteration 468, loss = 968.49692680\n",
      "Iteration 35, loss = 6297.14091237\n",
      "Iteration 26, loss = 870.13717259\n",
      "Iteration 10, loss = 9386.37476537\n",
      "Iteration 495, loss = 915.69914968\n",
      "Iteration 27, loss = 872.10318155\n",
      "Iteration 409, loss = 1043.39512386\n",
      "Iteration 523, loss = 883.03299807\n",
      "Iteration 28, loss = 869.23790562\n",
      "Iteration 469, loss = 994.35984395\n",
      "Iteration 453, loss = 917.49522011\n",
      "Iteration 36, loss = 6214.49118685\n",
      "Iteration 29, loss = 877.61125471\n",
      "Iteration 496, loss = 932.53167765\n",
      "Iteration 11, loss = 9192.20526599\n",
      "Iteration 30, loss = 855.56360286\n",
      "Iteration 524, loss = 880.86093356\n",
      "Iteration 410, loss = 1064.26738223\n",
      "Iteration 470, loss = 969.51550169\n",
      "Iteration 454, loss = 920.44246631\n",
      "Iteration 31, loss = 862.99179899\n",
      "Iteration 37, loss = 6132.32743900\n",
      "Iteration 12, loss = 9009.40025236\n",
      "Iteration 497, loss = 929.74186158\n",
      "Iteration 32, loss = 870.32373422\n",
      "Iteration 471, loss = 967.47738651\n",
      "Iteration 411, loss = 1061.83311276\n",
      "Iteration 525, loss = 899.27723066\n",
      "Iteration 33, loss = 853.16071167\n",
      "Iteration 455, loss = 919.16702622\n",
      "Iteration 38, loss = 6053.61453705\n",
      "Iteration 34, loss = 855.60518889\n",
      "Iteration 13, loss = 8835.20823720\n",
      "Iteration 498, loss = 940.63650310\n",
      "Iteration 35, loss = 861.33852943\n",
      "Iteration 472, loss = 972.15650537\n",
      "Iteration 526, loss = 894.99590859\n",
      "Iteration 412, loss = 1054.02779022\n",
      "Iteration 456, loss = 920.75745359\n",
      "Iteration 36, loss = 852.89563111\n",
      "Iteration 39, loss = 5975.58378799\n",
      "Iteration 37, loss = 846.59699683\n",
      "Iteration 14, loss = 8668.14060140\n",
      "Iteration 499, loss = 939.69092953\n",
      "Iteration 473, loss = 968.62206622\n",
      "Iteration 38, loss = 854.00562500\n",
      "Iteration 527, loss = 903.22800695\n",
      "Iteration 413, loss = 1054.31812849\n",
      "Iteration 457, loss = 911.53883417\n",
      "Iteration 39, loss = 850.17574934\n",
      "Iteration 40, loss = 5900.34042620\n",
      "Iteration 40, loss = 865.89317670\n",
      "Iteration 500, loss = 932.23902364\n",
      "Iteration 474, loss = 957.23188059\n",
      "Iteration 15, loss = 8508.43836436\n",
      "Iteration 528, loss = 879.40140537\n",
      "Iteration 414, loss = 1072.78633919\n",
      "Iteration 41, loss = 859.70807755\n",
      "Iteration 458, loss = 911.43342797\n",
      "Iteration 41, loss = 5828.42164256\n",
      "Iteration 42, loss = 852.79751547\n",
      "Iteration 475, loss = 979.11167249\n",
      "Iteration 501, loss = 915.85851796\n",
      "Iteration 43, loss = 852.98864289\n",
      "Iteration 16, loss = 8356.64136023\n",
      "Iteration 529, loss = 873.82895061\n",
      "Iteration 415, loss = 1064.41193561\n",
      "Iteration 459, loss = 915.88779202\n",
      "Iteration 44, loss = 852.25773898\n",
      "Iteration 42, loss = 5755.10285404\n",
      "Iteration 476, loss = 975.73637505\n",
      "Iteration 45, loss = 838.91958880\n",
      "Iteration 502, loss = 929.98419219\n",
      "Iteration 17, loss = 8207.83000853\n",
      "Iteration 46, loss = 862.28145015\n",
      "Iteration 530, loss = 888.02772223\n",
      "Iteration 416, loss = 1067.46884712\n",
      "Iteration 460, loss = 947.46378399\n",
      "Iteration 477, loss = 974.69613562\n",
      "Iteration 47, loss = 853.34436319\n",
      "Iteration 43, loss = 5685.36675511\n",
      "Iteration 503, loss = 910.24802593\n",
      "Iteration 48, loss = 847.56582304\n",
      "Iteration 531, loss = 894.67210098\n",
      "Iteration 18, loss = 8065.44104714\n",
      "Iteration 49, loss = 838.18186832\n",
      "Iteration 417, loss = 1041.61247071\n",
      "Iteration 478, loss = 953.26214327\n",
      "Iteration 461, loss = 907.06636254\n",
      "Iteration 44, loss = 5615.43622136\n",
      "Iteration 50, loss = 848.76470520\n",
      "Iteration 504, loss = 934.33065035\n",
      "Iteration 532, loss = 874.07838912\n",
      "Iteration 51, loss = 848.21861290\n",
      "Iteration 19, loss = 7928.51928775\n",
      "Iteration 479, loss = 971.44218520\n",
      "Iteration 418, loss = 1053.98579495\n",
      "Iteration 52, loss = 845.58206979\n",
      "Iteration 462, loss = 893.41561000\n",
      "Iteration 45, loss = 5549.79026846\n",
      "Iteration 505, loss = 901.77220708\n",
      "Iteration 53, loss = 847.64570150\n",
      "Iteration 533, loss = 896.40362505\n",
      "Iteration 480, loss = 953.97724490\n",
      "Iteration 54, loss = 830.33345154\n",
      "Iteration 20, loss = 7795.13187715\n",
      "Iteration 419, loss = 1045.16022925\n",
      "Iteration 46, loss = 5485.62101422\n",
      "Iteration 463, loss = 902.62462600\n",
      "Iteration 55, loss = 844.09517391\n",
      "Iteration 506, loss = 936.02031857\n",
      "Iteration 481, loss = 956.54595761\n",
      "Iteration 534, loss = 893.73400232\n",
      "Iteration 56, loss = 846.56564322\n",
      "Iteration 420, loss = 1050.56927947\n",
      "Iteration 21, loss = 7667.52692584\n",
      "Iteration 57, loss = 848.16943943\n",
      "Iteration 47, loss = 5419.57605349\n",
      "Iteration 464, loss = 905.61566980\n",
      "Iteration 507, loss = 907.05265494\n",
      "Iteration 482, loss = 942.22462029\n",
      "Iteration 58, loss = 844.78224432\n",
      "Iteration 535, loss = 874.88055151\n",
      "Iteration 59, loss = 839.21922432\n",
      "Iteration 421, loss = 1046.55324238\n",
      "Iteration 22, loss = 7542.75819340\n",
      "Iteration 48, loss = 5357.18580587\n",
      "Iteration 483, loss = 944.10352672\n",
      "Iteration 465, loss = 914.72377427\n",
      "Iteration 60, loss = 847.19520678\n",
      "Iteration 508, loss = 925.76707658\n",
      "Iteration 536, loss = 893.99629081\n",
      "Iteration 61, loss = 832.95590949\n",
      "Iteration 23, loss = 7421.96770838\n",
      "Iteration 484, loss = 981.13610743\n",
      "Iteration 422, loss = 1048.28371854\n",
      "Iteration 62, loss = 843.18539534\n",
      "Iteration 49, loss = 5296.33536885\n",
      "Iteration 466, loss = 896.97221125\n",
      "Iteration 509, loss = 914.53813708\n",
      "Iteration 63, loss = 856.47860523\n",
      "Iteration 537, loss = 890.22435504\n",
      "Iteration 64, loss = 838.64173985\n",
      "Iteration 24, loss = 7306.13167740\n",
      "Iteration 485, loss = 969.26165398\n",
      "Iteration 423, loss = 1044.30393660\n",
      "Iteration 50, loss = 5237.27782209\n",
      "Iteration 65, loss = 834.68727177\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 467, loss = 909.10283385\n",
      "Iteration 510, loss = 905.92779892\n",
      "Iteration 538, loss = 889.80323451\n",
      "Iteration 1, loss = 5615.33439918\n",
      "Iteration 486, loss = 947.39525306\n",
      "Iteration 25, loss = 7195.54219060\n",
      "Iteration 51, loss = 5178.30143044\n",
      "Iteration 424, loss = 1043.46308363\n",
      "Iteration 2, loss = 2051.97172355\n",
      "Iteration 468, loss = 894.49442347\n",
      "Iteration 511, loss = 909.28321397\n",
      "Iteration 539, loss = 864.22745256\n",
      "Iteration 3, loss = 1362.00436234\n",
      "Iteration 487, loss = 945.49818693\n",
      "Iteration 26, loss = 7086.66427132\n",
      "Iteration 4, loss = 1208.80232712\n",
      "Iteration 425, loss = 1040.89152104\n",
      "Iteration 52, loss = 5120.70334571\n",
      "Iteration 512, loss = 910.37390911\n",
      "Iteration 5, loss = 1141.03997921\n",
      "Iteration 469, loss = 899.62692650\n",
      "Iteration 540, loss = 876.20724254\n",
      "Iteration 6, loss = 1102.76653878\n",
      "Iteration 488, loss = 941.64410014\n",
      "Iteration 27, loss = 6980.77802613\n",
      "Iteration 7, loss = 1051.82811670\n",
      "Iteration 53, loss = 5064.26278779\n",
      "Iteration 426, loss = 1034.66908430\n",
      "Iteration 513, loss = 908.46339113\n",
      "Iteration 470, loss = 898.13774497\n",
      "Iteration 8, loss = 1025.21145787\n",
      "Iteration 541, loss = 877.87297549\n",
      "Iteration 489, loss = 937.25398343\n",
      "Iteration 9, loss = 983.29712715\n",
      "Iteration 28, loss = 6877.33990852\n",
      "Iteration 10, loss = 970.24257127\n",
      "Iteration 54, loss = 5011.23868470\n",
      "Iteration 427, loss = 1026.14881262\n",
      "Iteration 514, loss = 923.12002182\n",
      "Iteration 11, loss = 935.79445625\n",
      "Iteration 471, loss = 894.21987931\n",
      "Iteration 490, loss = 941.04769520\n",
      "Iteration 542, loss = 871.08326176\n",
      "Iteration 12, loss = 933.28159984\n",
      "Iteration 29, loss = 6776.33979103\n",
      "Iteration 55, loss = 4960.97228427\n",
      "Iteration 13, loss = 911.32255309\n",
      "Iteration 428, loss = 1029.65623801\n",
      "Iteration 515, loss = 913.86192902\n",
      "Iteration 543, loss = 882.52600934\n",
      "Iteration 472, loss = 902.78827005\n",
      "Iteration 14, loss = 904.86318591\n",
      "Iteration 491, loss = 942.86837690\n",
      "Iteration 15, loss = 888.40716615\n",
      "Iteration 30, loss = 6679.56973155\n",
      "Iteration 56, loss = 4905.81875333\n",
      "Iteration 429, loss = 1022.59136414\n",
      "Iteration 16, loss = 885.72856419\n",
      "Iteration 492, loss = 949.57537887\n",
      "Iteration 516, loss = 905.12660602\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 544, loss = 903.60654763\n",
      "Iteration 17, loss = 877.49802727\n",
      "Iteration 473, loss = 886.27025631\n",
      "Iteration 31, loss = 6585.16757700\n",
      "Iteration 18, loss = 866.01424902\n",
      "Iteration 1, loss = 5344.31346898\n",
      "Iteration 57, loss = 4855.68742469\n",
      "Iteration 430, loss = 1034.36951991\n",
      "Iteration 493, loss = 942.57128437\n",
      "Iteration 19, loss = 866.83970878\n",
      "Iteration 2, loss = 1932.45613869\n",
      "Iteration 545, loss = 889.69634589\n",
      "Iteration 474, loss = 891.84124719\n",
      "Iteration 3, loss = 1292.37044064\n",
      "Iteration 20, loss = 871.43344871\n",
      "Iteration 4, loss = 1151.26223314\n",
      "Iteration 32, loss = 6494.71502028\n",
      "Iteration 21, loss = 857.79188638\n",
      "Iteration 494, loss = 941.84599581\n",
      "Iteration 58, loss = 4807.58095179\n",
      "Iteration 5, loss = 1094.23690330\n",
      "Iteration 431, loss = 1059.94849765\n",
      "Iteration 22, loss = 849.24566649\n",
      "Iteration 546, loss = 855.42934497\n",
      "Iteration 6, loss = 1034.33559920\n",
      "Iteration 475, loss = 883.49249057\n",
      "Iteration 23, loss = 858.13692449\n",
      "Iteration 7, loss = 1009.69556640\n",
      "Iteration 495, loss = 929.82160673\n",
      "Iteration 33, loss = 6405.18069765\n",
      "Iteration 59, loss = 4756.45483558\n",
      "Iteration 24, loss = 857.30695489\n",
      "Iteration 8, loss = 981.88122529\n",
      "Iteration 547, loss = 867.13427150\n",
      "Iteration 432, loss = 1038.78794056\n",
      "Iteration 25, loss = 853.71898380\n",
      "Iteration 9, loss = 967.82273227\n",
      "Iteration 476, loss = 884.55838150\n",
      "Iteration 496, loss = 940.05930105\n",
      "Iteration 26, loss = 842.86664037\n",
      "Iteration 10, loss = 933.60013003\n",
      "Iteration 34, loss = 6316.24970173\n",
      "Iteration 60, loss = 4709.59914674\n",
      "Iteration 11, loss = 901.20897130\n",
      "Iteration 27, loss = 853.06200800\n",
      "Iteration 548, loss = 873.60166962\n",
      "Iteration 12, loss = 901.58219660\n",
      "Iteration 433, loss = 1024.33945189\n",
      "Iteration 28, loss = 838.35804495\n",
      "Iteration 497, loss = 962.43795323\n",
      "Iteration 477, loss = 891.90316220\n",
      "Iteration 13, loss = 886.74507315\n",
      "Iteration 29, loss = 842.40343184\n",
      "Iteration 14, loss = 873.68804598\n",
      "Iteration 61, loss = 4663.64366903\n",
      "Iteration 35, loss = 6231.38380901\n",
      "Iteration 30, loss = 825.32042454\n",
      "Iteration 549, loss = 873.09820158\n",
      "Iteration 15, loss = 862.14788426\n",
      "Iteration 434, loss = 1029.66004156\n",
      "Iteration 498, loss = 953.80818503\n",
      "Iteration 31, loss = 842.79762411\n",
      "Iteration 478, loss = 909.87223368\n",
      "Iteration 16, loss = 849.14081096\n",
      "Iteration 17, loss = 846.25897959\n",
      "Iteration 32, loss = 839.62472596\n",
      "Iteration 36, loss = 6148.87263430\n",
      "Iteration 62, loss = 4616.15647014\n",
      "Iteration 550, loss = 873.58921415\n",
      "Iteration 18, loss = 845.58873923\n",
      "Iteration 33, loss = 833.70683043\n",
      "Iteration 499, loss = 954.16669902\n",
      "Iteration 435, loss = 1020.68682665\n",
      "Iteration 19, loss = 834.07689781\n",
      "Iteration 479, loss = 880.13278617\n",
      "Iteration 34, loss = 830.01527100\n",
      "Iteration 20, loss = 833.83433941\n",
      "Iteration 63, loss = 4572.45686780\n",
      "Iteration 35, loss = 828.14036581\n",
      "Iteration 37, loss = 6068.64669139\n",
      "Iteration 551, loss = 876.48441363\n",
      "Iteration 500, loss = 930.02605847\n",
      "Iteration 21, loss = 830.59618629\n",
      "Iteration 36, loss = 833.01302666\n",
      "Iteration 436, loss = 1034.12849289\n",
      "Iteration 22, loss = 833.80345977\n",
      "Iteration 480, loss = 899.78078714\n",
      "Iteration 37, loss = 822.49644913\n",
      "Iteration 23, loss = 843.02772281\n",
      "Iteration 501, loss = 928.48363193\n",
      "Iteration 552, loss = 861.75455165\n",
      "Iteration 64, loss = 4528.72816933\n",
      "Iteration 38, loss = 834.93346423\n",
      "Iteration 24, loss = 825.72201513\n",
      "Iteration 38, loss = 5989.54713507\n",
      "Iteration 25, loss = 806.91207807\n",
      "Iteration 39, loss = 824.29884905\n",
      "Iteration 437, loss = 1031.28245841\n",
      "Iteration 26, loss = 819.59196677\n",
      "Iteration 481, loss = 887.41256265\n",
      "Iteration 40, loss = 836.09348296\n",
      "Iteration 502, loss = 931.95436405\n",
      "Iteration 65, loss = 4483.25062780\n",
      "Iteration 553, loss = 861.82438930\n",
      "Iteration 27, loss = 819.15595432\n",
      "Iteration 41, loss = 835.00856007\n",
      "Iteration 39, loss = 5912.22835928\n",
      "Iteration 28, loss = 807.69062682\n",
      "Iteration 438, loss = 1069.88753510\n",
      "Iteration 42, loss = 820.12276968\n",
      "Iteration 29, loss = 814.44587994\n",
      "Iteration 482, loss = 872.22700118\n",
      "Iteration 43, loss = 819.81316444\n",
      "Iteration 503, loss = 962.92666806\n",
      "Iteration 554, loss = 903.82124736\n",
      "Iteration 30, loss = 810.64392946\n",
      "Iteration 66, loss = 4440.89942234\n",
      "Iteration 44, loss = 823.52336989\n",
      "Iteration 40, loss = 5836.91262208\n",
      "Iteration 31, loss = 808.83587341\n",
      "Iteration 45, loss = 813.93335061\n",
      "Iteration 439, loss = 1014.75669646\n",
      "Iteration 32, loss = 826.15575672\n",
      "Iteration 504, loss = 926.70811846\n",
      "Iteration 483, loss = 870.47297338\n",
      "Iteration 33, loss = 813.67218131\n",
      "Iteration 46, loss = 825.43260981\n",
      "Iteration 555, loss = 866.34925070\n",
      "Iteration 67, loss = 4394.87151614\n",
      "Iteration 34, loss = 815.04262646\n",
      "Iteration 47, loss = 823.23037621\n",
      "Iteration 41, loss = 5764.58341415\n",
      "Iteration 35, loss = 799.94853648\n",
      "Iteration 505, loss = 914.01791241\n",
      "Iteration 440, loss = 1011.83910255\n",
      "Iteration 48, loss = 821.09680526\n",
      "Iteration 36, loss = 801.41689133\n",
      "Iteration 484, loss = 892.09721220\n",
      "Iteration 556, loss = 858.50458827\n",
      "Iteration 68, loss = 4357.39198837\n",
      "Iteration 49, loss = 809.53074744\n",
      "Iteration 37, loss = 810.40600601\n",
      "Iteration 42, loss = 5692.25524971\n",
      "Iteration 50, loss = 817.87291543\n",
      "Iteration 38, loss = 801.49096478\n",
      "Iteration 506, loss = 931.30821124\n",
      "Iteration 441, loss = 1021.52619691\n",
      "Iteration 51, loss = 811.41096803\n",
      "Iteration 39, loss = 792.92837050\n",
      "Iteration 485, loss = 894.46420806\n",
      "Iteration 557, loss = 895.18014929\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 69, loss = 4314.27048747\n",
      "Iteration 40, loss = 808.47347254\n",
      "Iteration 52, loss = 813.76620713\n",
      "Iteration 43, loss = 5622.21114651\n",
      "Iteration 507, loss = 920.77233673\n",
      "Iteration 41, loss = 803.72173278\n",
      "Iteration 53, loss = 812.87445626\n",
      "Iteration 1, loss = 5486.41699478\n",
      "Iteration 442, loss = 1001.66703294\n",
      "Iteration 42, loss = 810.00131250\n",
      "Iteration 54, loss = 801.36337782\n",
      "Iteration 486, loss = 883.05048490\n",
      "Iteration 70, loss = 4272.32225068\n",
      "Iteration 2, loss = 2005.80835212\n",
      "Iteration 43, loss = 805.83957351\n",
      "Iteration 55, loss = 809.09196673\n",
      "Iteration 508, loss = 925.59594051\n",
      "Iteration 44, loss = 5555.09074738\n",
      "Iteration 44, loss = 796.62150559\n",
      "Iteration 3, loss = 1333.51161615\n",
      "Iteration 56, loss = 821.99942792\n",
      "Iteration 45, loss = 790.08447764\n",
      "Iteration 443, loss = 1016.26001063\n",
      "Iteration 4, loss = 1191.31037341\n",
      "Iteration 57, loss = 820.81412714\n",
      "Iteration 71, loss = 4231.62538746\n",
      "Iteration 46, loss = 801.10282669\n",
      "Iteration 487, loss = 861.00122546\n",
      "Iteration 5, loss = 1144.32787835\n",
      "Iteration 509, loss = 973.10474995\n",
      "Iteration 47, loss = 794.36302348\n",
      "Iteration 45, loss = 5488.55313992\n",
      "Iteration 58, loss = 817.71991862\n",
      "Iteration 6, loss = 1090.34140925\n",
      "Iteration 48, loss = 801.88303827\n",
      "Iteration 444, loss = 1017.82498443\n",
      "Iteration 59, loss = 810.45931881\n",
      "Iteration 7, loss = 1054.21190122\n",
      "Iteration 488, loss = 869.09475041\n",
      "Iteration 49, loss = 795.90720684\n",
      "Iteration 72, loss = 4194.04659597\n",
      "Iteration 60, loss = 816.39329778\n",
      "Iteration 510, loss = 945.66239241\n",
      "Iteration 8, loss = 1028.49022759\n",
      "Iteration 50, loss = 792.38313458\n",
      "Iteration 46, loss = 5425.35545479\n",
      "Iteration 61, loss = 800.53792046\n",
      "Iteration 9, loss = 1005.93785422\n",
      "Iteration 51, loss = 795.47506242\n",
      "Iteration 445, loss = 1012.60261181\n",
      "Iteration 62, loss = 810.50909826\n",
      "Iteration 10, loss = 967.03123697\n",
      "Iteration 52, loss = 791.44251806\n",
      "Iteration 511, loss = 934.77796621\n",
      "Iteration 73, loss = 4154.92523435\n",
      "Iteration 489, loss = 876.65906028\n",
      "Iteration 63, loss = 819.82441171\n",
      "Iteration 53, loss = 803.33623843\n",
      "Iteration 11, loss = 956.54182991\n",
      "Iteration 47, loss = 5362.13749844\n",
      "Iteration 64, loss = 804.17525384\n",
      "Iteration 54, loss = 788.52428510\n",
      "Iteration 12, loss = 948.04070104\n",
      "Iteration 446, loss = 1004.58780570\n",
      "Iteration 65, loss = 805.72222711\n",
      "Iteration 512, loss = 922.56185781\n",
      "Iteration 55, loss = 814.77066420\n",
      "Iteration 490, loss = 865.50793398\n",
      "Iteration 13, loss = 919.08285702\n",
      "Iteration 74, loss = 4120.59528233\n",
      "Iteration 66, loss = 799.21013180\n",
      "Iteration 56, loss = 787.17142594\n",
      "Iteration 14, loss = 914.16208672\n",
      "Iteration 48, loss = 5300.85511358\n",
      "Iteration 67, loss = 816.44972351\n",
      "Iteration 57, loss = 780.27622563\n",
      "Iteration 513, loss = 922.37422467\n",
      "Iteration 447, loss = 1007.12420036\n",
      "Iteration 15, loss = 906.74863139\n",
      "Iteration 68, loss = 798.68869126\n",
      "Iteration 58, loss = 787.71997354\n",
      "Iteration 491, loss = 858.03606326\n",
      "Iteration 75, loss = 4081.13767756\n",
      "Iteration 16, loss = 895.14573756\n",
      "Iteration 69, loss = 803.00538791\n",
      "Iteration 59, loss = 803.78234184\n",
      "Iteration 49, loss = 5238.98109281\n",
      "Iteration 17, loss = 894.59405592\n",
      "Iteration 60, loss = 798.97133408\n",
      "Iteration 70, loss = 799.59253982\n",
      "Iteration 514, loss = 917.27476693\n",
      "Iteration 448, loss = 1006.50856343\n",
      "Iteration 71, loss = 807.36039337\n",
      "Iteration 18, loss = 886.11518926\n",
      "Iteration 61, loss = 782.75467936\n",
      "Iteration 492, loss = 887.43680305\n",
      "Iteration 76, loss = 4041.20449672\n",
      "Iteration 62, loss = 780.54351882\n",
      "Iteration 19, loss = 881.53583602\n",
      "Iteration 72, loss = 796.58843892\n",
      "Iteration 515, loss = 922.79427028\n",
      "Iteration 50, loss = 5183.28628632\n",
      "Iteration 63, loss = 782.35252831\n",
      "Iteration 20, loss = 881.61048521\n",
      "Iteration 73, loss = 798.51707652\n",
      "Iteration 449, loss = 999.46138428\n",
      "Iteration 64, loss = 786.38927982\n",
      "Iteration 74, loss = 801.01033739\n",
      "Iteration 21, loss = 871.33515822\n",
      "Iteration 493, loss = 865.36745198\n",
      "Iteration 77, loss = 4004.08736960\n",
      "Iteration 65, loss = 782.24798675\n",
      "Iteration 75, loss = 787.90909829\n",
      "Iteration 22, loss = 868.66045640\n",
      "Iteration 516, loss = 927.55156507\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 51, loss = 5122.96336394\n",
      "Iteration 66, loss = 786.24268171\n",
      "Iteration 76, loss = 807.23312127\n",
      "Iteration 23, loss = 876.61020159\n",
      "Iteration 450, loss = 999.56406777\n",
      "Iteration 67, loss = 775.74291845\n",
      "Iteration 77, loss = 800.69222580\n",
      "Iteration 1, loss = 5405.83123521\n",
      "Iteration 494, loss = 870.51382888\n",
      "Iteration 24, loss = 867.83541681\n",
      "Iteration 78, loss = 3969.94701369\n",
      "Iteration 68, loss = 777.14547760\n",
      "Iteration 78, loss = 798.55798951\n",
      "Iteration 2, loss = 1949.73743879\n",
      "Iteration 25, loss = 856.43562048\n",
      "Iteration 52, loss = 5067.32427841\n",
      "Iteration 69, loss = 780.56981233\n",
      "Iteration 79, loss = 803.21051359\n",
      "Iteration 26, loss = 863.82085722\n",
      "Iteration 3, loss = 1257.72256392\n",
      "Iteration 451, loss = 1015.27553563\n",
      "Iteration 70, loss = 792.27508651\n",
      "Iteration 80, loss = 800.46581871\n",
      "Iteration 79, loss = 3932.91847961\n",
      "Iteration 27, loss = 850.29450322\n",
      "Iteration 71, loss = 777.47803311\n",
      "Iteration 4, loss = 1138.03618603\n",
      "Iteration 495, loss = 861.40728052\n",
      "Iteration 81, loss = 805.07391917\n",
      "Iteration 53, loss = 5012.75480358\n",
      "Iteration 72, loss = 781.73614433\n",
      "Iteration 28, loss = 849.21272529\n",
      "Iteration 5, loss = 1086.75918309\n",
      "Iteration 82, loss = 793.38399581\n",
      "Iteration 73, loss = 777.21284931\n",
      "Iteration 6, loss = 1042.34725918\n",
      "Iteration 29, loss = 854.60170415\n",
      "Iteration 452, loss = 1008.88085252\n",
      "Iteration 83, loss = 799.30221717\n",
      "Iteration 74, loss = 779.01163873\n",
      "Iteration 7, loss = 1012.63845438\n",
      "Iteration 80, loss = 3907.62565573\n",
      "Iteration 496, loss = 890.57893386\n",
      "Iteration 30, loss = 844.20551416\n",
      "Iteration 75, loss = 777.61751040\n",
      "Iteration 84, loss = 795.53303621\n",
      "Iteration 54, loss = 4959.38920630\n",
      "Iteration 8, loss = 986.85444441\n",
      "Iteration 76, loss = 775.10667766\n",
      "Iteration 31, loss = 853.23907424\n",
      "Iteration 85, loss = 812.21865715\n",
      "Iteration 453, loss = 1015.41780546\n",
      "Iteration 9, loss = 983.43614772\n",
      "Iteration 77, loss = 781.45612262\n",
      "Iteration 86, loss = 792.06655030\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 859.63065611\n",
      "Iteration 81, loss = 3864.89307402\n",
      "Iteration 497, loss = 883.60705224\n",
      "Iteration 10, loss = 939.18728311\n",
      "Iteration 78, loss = 768.64744380\n",
      "Iteration 33, loss = 846.97999268\n",
      "Iteration 55, loss = 4909.04975327\n",
      "Iteration 11, loss = 930.86375949\n",
      "Iteration 79, loss = 772.79944804\n",
      "Iteration 1, loss = 5574.82738580\n",
      "Iteration 34, loss = 849.23518988\n",
      "Iteration 80, loss = 768.69198980\n",
      "Iteration 454, loss = 999.99696508\n",
      "Iteration 12, loss = 926.54590855\n",
      "Iteration 2, loss = 2068.05190195\n",
      "Iteration 35, loss = 839.79256397\n",
      "Iteration 82, loss = 3831.01182165\n",
      "Iteration 81, loss = 769.92333233\n",
      "Iteration 498, loss = 896.59946999\n",
      "Iteration 13, loss = 907.38470214\n",
      "Iteration 3, loss = 1372.16336373\n",
      "Iteration 56, loss = 4856.13733103\n",
      "Iteration 82, loss = 765.34141276\n",
      "Iteration 36, loss = 840.37229319\n",
      "Iteration 14, loss = 894.56185846\n",
      "Iteration 4, loss = 1259.74274927\n",
      "Iteration 83, loss = 770.88756240\n",
      "Iteration 37, loss = 845.24337272\n",
      "Iteration 455, loss = 992.12205896\n",
      "Iteration 15, loss = 883.18409782\n",
      "Iteration 5, loss = 1157.39479261\n",
      "Iteration 84, loss = 772.94069360\n",
      "Iteration 83, loss = 3797.94504709\n",
      "Iteration 38, loss = 837.85631593\n",
      "Iteration 499, loss = 882.43554253\n",
      "Iteration 16, loss = 877.27091272\n",
      "Iteration 6, loss = 1108.13395613\n",
      "Iteration 85, loss = 774.02407477\n",
      "Iteration 57, loss = 4806.97879896\n",
      "Iteration 39, loss = 836.64251814\n",
      "Iteration 17, loss = 887.89668875\n",
      "Iteration 7, loss = 1062.48510756\n",
      "Iteration 86, loss = 761.01720105\n",
      "Iteration 456, loss = 1008.70943791\n",
      "Iteration 40, loss = 838.61671673\n",
      "Iteration 18, loss = 870.67690744\n",
      "Iteration 84, loss = 3765.46716576\n",
      "Iteration 87, loss = 771.33876580\n",
      "Iteration 8, loss = 1033.20972814\n",
      "Iteration 500, loss = 851.93958657\n",
      "Iteration 41, loss = 843.05146946\n",
      "Iteration 19, loss = 860.37765442\n",
      "Iteration 88, loss = 785.84236644\n",
      "Iteration 9, loss = 1023.81279992\n",
      "Iteration 58, loss = 4757.65580363\n",
      "Iteration 42, loss = 848.06812445\n",
      "Iteration 20, loss = 853.43684654\n",
      "Iteration 89, loss = 771.37437523\n",
      "Iteration 10, loss = 972.09414804\n",
      "Iteration 457, loss = 985.27602069\n",
      "Iteration 43, loss = 844.35051557\n",
      "Iteration 85, loss = 3733.99835036\n",
      "Iteration 21, loss = 855.48093809\n",
      "Iteration 90, loss = 773.98391399\n",
      "Iteration 11, loss = 958.00747612\n",
      "Iteration 501, loss = 849.15137522\n",
      "Iteration 44, loss = 839.58659373\n",
      "Iteration 22, loss = 841.32960700\n",
      "Iteration 59, loss = 4711.21843092\n",
      "Iteration 91, loss = 772.44140066\n",
      "Iteration 12, loss = 949.38304774\n",
      "Iteration 45, loss = 827.47859777\n",
      "Iteration 23, loss = 850.54492181\n",
      "Iteration 92, loss = 760.96071602\n",
      "Iteration 13, loss = 930.09473603\n",
      "Iteration 458, loss = 994.08905236\n",
      "Iteration 86, loss = 3708.21183008\n",
      "Iteration 46, loss = 838.50994841\n",
      "Iteration 24, loss = 840.30004389\n",
      "Iteration 14, loss = 926.62786442\n",
      "Iteration 93, loss = 775.26559359\n",
      "Iteration 60, loss = 4661.06762688\n",
      "Iteration 502, loss = 866.04356969\n",
      "Iteration 25, loss = 840.26718766\n",
      "Iteration 47, loss = 834.25395389\n",
      "Iteration 94, loss = 778.86366653\n",
      "Iteration 15, loss = 901.80332760\n",
      "Iteration 26, loss = 836.02718178\n",
      "Iteration 95, loss = 757.34447642\n",
      "Iteration 48, loss = 836.89054290\n",
      "Iteration 16, loss = 897.63067644\n",
      "Iteration 87, loss = 3671.89825703\n",
      "Iteration 459, loss = 998.50496465\n",
      "Iteration 96, loss = 770.12606483\n",
      "Iteration 27, loss = 822.37980286\n",
      "Iteration 49, loss = 838.79213411\n",
      "Iteration 17, loss = 893.08199736\n",
      "Iteration 61, loss = 4615.78377161\n",
      "Iteration 97, loss = 766.66604765\n",
      "Iteration 503, loss = 859.74515282\n",
      "Iteration 28, loss = 824.77610924\n",
      "Iteration 50, loss = 838.15633533\n",
      "Iteration 98, loss = 764.51357658\n",
      "Iteration 18, loss = 885.17628537\n",
      "Iteration 29, loss = 831.78758547\n",
      "Iteration 51, loss = 836.26316143\n",
      "Iteration 88, loss = 3639.99428054\n",
      "Iteration 460, loss = 967.46487284\n",
      "Iteration 19, loss = 889.92792739\n",
      "Iteration 99, loss = 763.09761309\n",
      "Iteration 30, loss = 821.98359181\n",
      "Iteration 52, loss = 834.02785551\n",
      "Iteration 504, loss = 869.16102385\n",
      "Iteration 20, loss = 890.42101416\n",
      "Iteration 100, loss = 790.93064985\n",
      "Iteration 62, loss = 4570.07961121\n",
      "Iteration 31, loss = 824.14687632\n",
      "Iteration 53, loss = 852.84966021\n",
      "Iteration 101, loss = 767.54653913\n",
      "Iteration 21, loss = 873.94941668\n",
      "Iteration 32, loss = 827.86675920\n",
      "Iteration 102, loss = 762.19011879\n",
      "Iteration 54, loss = 830.02925422\n",
      "Iteration 461, loss = 992.94790577\n",
      "Iteration 89, loss = 3610.45827824\n",
      "Iteration 22, loss = 863.06446429\n",
      "Iteration 33, loss = 816.38668957\n",
      "Iteration 55, loss = 843.81364516\n",
      "Iteration 505, loss = 854.12560829\n",
      "Iteration 103, loss = 775.28698635\n",
      "Iteration 23, loss = 873.33367311\n",
      "Iteration 63, loss = 4523.21008733\n",
      "Iteration 34, loss = 821.89201621\n",
      "Iteration 104, loss = 769.81113657\n",
      "Iteration 56, loss = 829.56990603\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 875.42372467\n",
      "Iteration 35, loss = 819.57191069Iteration 105, loss = 770.01952745\n",
      "\n",
      "Iteration 90, loss = 3582.50363227\n",
      "Iteration 462, loss = 987.05421340\n",
      "Iteration 25, loss = 866.85530272\n",
      "Iteration 1, loss = 5445.57865853\n",
      "Iteration 106, loss = 764.93494558\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 813.49255179\n",
      "Iteration 506, loss = 852.24123925\n",
      "Iteration 64, loss = 4481.21692804\n",
      "Iteration 26, loss = 860.80034013\n",
      "Iteration 2, loss = 2022.12935886\n",
      "Iteration 37, loss = 819.83098521\n",
      "Iteration 1, loss = 5414.49357096\n",
      "Iteration 27, loss = 850.58208419\n",
      "Iteration 91, loss = 3552.56307901\n",
      "Iteration 38, loss = 809.78033370\n",
      "Iteration 463, loss = 977.56493147\n",
      "Iteration 3, loss = 1359.58793642\n",
      "Iteration 2, loss = 1964.59223393\n",
      "Iteration 28, loss = 850.04422430\n",
      "Iteration 4, loss = 1237.50549035\n",
      "Iteration 39, loss = 816.64637511\n",
      "Iteration 507, loss = 863.23258193\n",
      "Iteration 65, loss = 4436.55568759\n",
      "Iteration 3, loss = 1368.49324585\n",
      "Iteration 29, loss = 859.88034913\n",
      "Iteration 40, loss = 815.27704608\n",
      "Iteration 5, loss = 1138.80038907\n",
      "Iteration 4, loss = 1246.15508443\n",
      "Iteration 92, loss = 3524.48738065\n",
      "Iteration 464, loss = 979.40920638\n",
      "Iteration 30, loss = 852.10119193\n",
      "Iteration 41, loss = 819.11326231\n",
      "Iteration 6, loss = 1096.53188821\n",
      "Iteration 5, loss = 1167.98038698\n",
      "Iteration 31, loss = 846.35196592\n",
      "Iteration 42, loss = 811.67531237\n",
      "Iteration 508, loss = 895.17648426\n",
      "Iteration 66, loss = 4394.37660183\n",
      "Iteration 6, loss = 1116.27912959\n",
      "Iteration 7, loss = 1045.40835579\n",
      "Iteration 32, loss = 858.86660218\n",
      "Iteration 43, loss = 808.38162248\n",
      "Iteration 7, loss = 1058.19216671\n",
      "Iteration 93, loss = 3494.56083730\n",
      "Iteration 465, loss = 997.33163619\n",
      "Iteration 8, loss = 1018.25823249\n",
      "Iteration 33, loss = 844.89519554\n",
      "Iteration 8, loss = 1037.51260220\n",
      "Iteration 44, loss = 813.92487573\n",
      "Iteration 9, loss = 1002.77577749\n",
      "Iteration 34, loss = 844.91740747\n",
      "Iteration 509, loss = 850.49031717\n",
      "Iteration 9, loss = 1009.64379167\n",
      "Iteration 67, loss = 4351.30444876\n",
      "Iteration 45, loss = 796.33014377\n",
      "Iteration 10, loss = 960.92633023\n",
      "Iteration 35, loss = 847.85883129\n",
      "Iteration 94, loss = 3470.79421623\n",
      "Iteration 10, loss = 962.23480183\n",
      "Iteration 46, loss = 805.72777485\n",
      "Iteration 466, loss = 985.48223364\n",
      "Iteration 11, loss = 946.62170478\n",
      "Iteration 36, loss = 838.18562066\n",
      "Iteration 11, loss = 947.91829975\n",
      "Iteration 47, loss = 800.91693208\n",
      "Iteration 12, loss = 940.84184136\n",
      "Iteration 68, loss = 4314.02042466\n",
      "Iteration 37, loss = 855.43337652\n",
      "Iteration 12, loss = 943.43498363\n",
      "Iteration 510, loss = 865.83413976\n",
      "Iteration 48, loss = 800.69132046\n",
      "Iteration 13, loss = 924.60927326\n",
      "Iteration 38, loss = 839.30949496\n",
      "Iteration 95, loss = 3444.38216475\n",
      "Iteration 13, loss = 923.38949892\n",
      "Iteration 467, loss = 970.74521158\n",
      "Iteration 49, loss = 809.94856195\n",
      "Iteration 39, loss = 843.55799895\n",
      "Iteration 14, loss = 916.92394321\n",
      "Iteration 14, loss = 910.98229957\n",
      "Iteration 50, loss = 813.18132966\n",
      "Iteration 69, loss = 4265.88146596\n",
      "Iteration 40, loss = 839.69877590\n",
      "Iteration 15, loss = 897.64689891\n",
      "Iteration 511, loss = 853.73687115\n",
      "Iteration 15, loss = 900.88378837\n",
      "Iteration 51, loss = 797.85387232\n",
      "Iteration 96, loss = 3412.22045971\n",
      "Iteration 41, loss = 842.34997487\n",
      "Iteration 16, loss = 897.64520580\n",
      "Iteration 16, loss = 894.83865585\n",
      "Iteration 468, loss = 1001.24929029\n",
      "Iteration 52, loss = 801.10396974\n",
      "Iteration 17, loss = 897.26375537\n",
      "Iteration 42, loss = 842.69411673\n",
      "Iteration 17, loss = 898.14146199\n",
      "Iteration 70, loss = 4228.94522064\n",
      "Iteration 53, loss = 805.56112933\n",
      "Iteration 18, loss = 877.87821564\n",
      "Iteration 512, loss = 837.91987150\n",
      "Iteration 43, loss = 831.36907281\n",
      "Iteration 18, loss = 881.37424325\n",
      "Iteration 97, loss = 3384.53935674\n",
      "Iteration 54, loss = 799.07224901\n",
      "Iteration 19, loss = 880.90887848\n",
      "Iteration 44, loss = 837.53280779\n",
      "Iteration 469, loss = 1002.32519040\n",
      "Iteration 19, loss = 880.68283272\n",
      "Iteration 20, loss = 887.04186668\n",
      "Iteration 55, loss = 811.16267218\n",
      "Iteration 45, loss = 834.00283444\n",
      "Iteration 71, loss = 4185.81701828\n",
      "Iteration 513, loss = 870.93280171\n",
      "Iteration 20, loss = 883.98409770\n",
      "Iteration 21, loss = 870.79200917\n",
      "Iteration 56, loss = 803.32902651\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 46, loss = 851.00449340\n",
      "Iteration 98, loss = 3362.09885344\n",
      "Iteration 22, loss = 868.07662780\n",
      "Iteration 21, loss = 875.50343198\n",
      "Iteration 1, loss = 5497.45213065\n",
      "Iteration 47, loss = 833.52965893\n",
      "Iteration 470, loss = 964.36113688\n",
      "Iteration 23, loss = 874.15011963\n",
      "Iteration 22, loss = 869.29003708\n",
      "Iteration 2, loss = 1962.82171965\n",
      "Iteration 72, loss = 4151.66924654\n",
      "Iteration 48, loss = 826.90175091\n",
      "Iteration 514, loss = 842.03558576\n",
      "Iteration 24, loss = 869.93282423\n",
      "Iteration 3, loss = 1321.93620487\n",
      "Iteration 23, loss = 877.84783577\n",
      "Iteration 99, loss = 3333.32306849\n",
      "Iteration 49, loss = 829.13516996\n",
      "Iteration 25, loss = 868.04186866\n",
      "Iteration 4, loss = 1187.40048256\n",
      "Iteration 471, loss = 976.41845325\n",
      "Iteration 24, loss = 869.76053293\n",
      "Iteration 50, loss = 840.61162392\n",
      "Iteration 26, loss = 866.78939947\n",
      "Iteration 5, loss = 1114.55785883\n",
      "Iteration 515, loss = 844.69512816\n",
      "Iteration 73, loss = 4114.16386989\n",
      "Iteration 25, loss = 871.53399606\n",
      "Iteration 51, loss = 828.03681923\n",
      "Iteration 27, loss = 850.12893194\n",
      "Iteration 6, loss = 1077.94220907\n",
      "Iteration 100, loss = 3307.63893879\n",
      "Iteration 26, loss = 864.81027139\n",
      "Iteration 52, loss = 832.23177121\n",
      "Iteration 28, loss = 850.80584534\n",
      "Iteration 7, loss = 1041.90668250\n",
      "Iteration 472, loss = 969.92241345\n",
      "Iteration 27, loss = 855.29167097\n",
      "Iteration 53, loss = 833.78021369\n",
      "Iteration 8, loss = 1024.86855497\n",
      "Iteration 29, loss = 861.33702814\n",
      "Iteration 74, loss = 4074.65156096\n",
      "Iteration 516, loss = 839.06703201\n",
      "Iteration 28, loss = 854.35696020\n",
      "Iteration 54, loss = 833.91998937\n",
      "Iteration 9, loss = 1001.32599285\n",
      "Iteration 30, loss = 849.31607574\n",
      "Iteration 101, loss = 3283.11869054\n",
      "Iteration 55, loss = 852.19816319\n",
      "Iteration 10, loss = 962.16058663\n",
      "Iteration 31, loss = 851.64025579\n",
      "Iteration 29, loss = 860.84994159\n",
      "Iteration 473, loss = 976.17404027\n",
      "Iteration 11, loss = 954.97653376\n",
      "Iteration 56, loss = 826.21766405\n",
      "Iteration 32, loss = 848.54714028\n",
      "Iteration 30, loss = 851.37767905\n",
      "Iteration 75, loss = 4037.23904357\n",
      "Iteration 517, loss = 845.89455088\n",
      "Iteration 12, loss = 947.12791330\n",
      "Iteration 33, loss = 852.20172950\n",
      "Iteration 102, loss = 3257.09915953\n",
      "Iteration 57, loss = 825.37708249\n",
      "Iteration 31, loss = 848.24807987\n",
      "Iteration 13, loss = 933.10851853\n",
      "Iteration 34, loss = 836.13104539\n",
      "Iteration 474, loss = 958.25264089\n",
      "Iteration 58, loss = 834.21289819\n",
      "Iteration 32, loss = 850.10835334\n",
      "Iteration 76, loss = 4000.64093271\n",
      "Iteration 14, loss = 908.95786834\n",
      "Iteration 35, loss = 843.43252441\n",
      "Iteration 59, loss = 825.37610493\n",
      "Iteration 518, loss = 844.74361816\n",
      "Iteration 33, loss = 850.59736679\n",
      "Iteration 15, loss = 903.78786489\n",
      "Iteration 103, loss = 3232.37231936\n",
      "Iteration 36, loss = 836.12690166\n",
      "Iteration 60, loss = 828.01929204\n",
      "Iteration 34, loss = 838.24043159\n",
      "Iteration 16, loss = 893.97996346\n",
      "Iteration 475, loss = 996.81798003\n",
      "Iteration 37, loss = 843.19950932\n",
      "Iteration 61, loss = 819.01369721\n",
      "Iteration 35, loss = 847.01787992\n",
      "Iteration 17, loss = 902.42359436\n",
      "Iteration 77, loss = 3964.62073269\n",
      "Iteration 38, loss = 834.27541538\n",
      "Iteration 519, loss = 838.10512199\n",
      "Iteration 18, loss = 879.72310108\n",
      "Iteration 62, loss = 816.48757334\n",
      "Iteration 104, loss = 3213.85397035\n",
      "Iteration 36, loss = 842.13779449\n",
      "Iteration 39, loss = 842.69058978\n",
      "Iteration 19, loss = 873.33877484\n",
      "Iteration 63, loss = 823.35450852\n",
      "Iteration 476, loss = 954.11721683\n",
      "Iteration 40, loss = 829.99396135\n",
      "Iteration 37, loss = 843.07764153\n",
      "Iteration 20, loss = 899.20322965\n",
      "Iteration 78, loss = 3930.12880883\n",
      "Iteration 64, loss = 828.72610926\n",
      "Iteration 41, loss = 833.25619971\n",
      "Iteration 38, loss = 836.32455944\n",
      "Iteration 520, loss = 839.38723217\n",
      "Iteration 21, loss = 863.86212927\n",
      "Iteration 65, loss = 822.57199151\n",
      "Iteration 105, loss = 3184.00059678\n",
      "Iteration 42, loss = 846.26861055\n",
      "Iteration 39, loss = 845.85686009\n",
      "Iteration 22, loss = 860.58833531\n",
      "Iteration 66, loss = 828.00560943\n",
      "Iteration 43, loss = 831.80617664\n",
      "Iteration 477, loss = 953.15606940\n",
      "Iteration 40, loss = 836.40945821\n",
      "Iteration 23, loss = 862.54710176\n",
      "Iteration 79, loss = 3897.52472071\n",
      "Iteration 67, loss = 826.09790372\n",
      "Iteration 44, loss = 830.81235458\n",
      "Iteration 521, loss = 819.83271255\n",
      "Iteration 24, loss = 858.84329753\n",
      "Iteration 41, loss = 837.68683456\n",
      "Iteration 106, loss = 3163.00920818\n",
      "Iteration 68, loss = 815.58252426\n",
      "Iteration 45, loss = 827.41523734\n",
      "Iteration 25, loss = 854.00064513\n",
      "Iteration 69, loss = 826.01190947\n",
      "Iteration 478, loss = 962.59716297\n",
      "Iteration 42, loss = 846.39557324\n",
      "Iteration 46, loss = 828.83701174\n",
      "Iteration 26, loss = 859.04172651\n",
      "Iteration 70, loss = 819.87159846\n",
      "Iteration 80, loss = 3865.63469499\n",
      "Iteration 47, loss = 836.58017846\n",
      "Iteration 43, loss = 839.67789886\n",
      "Iteration 27, loss = 837.30036005\n",
      "Iteration 522, loss = 842.10678239\n",
      "Iteration 71, loss = 823.93071178\n",
      "Iteration 107, loss = 3137.98366744\n",
      "Iteration 48, loss = 825.74349271\n",
      "Iteration 28, loss = 839.01596017\n",
      "Iteration 44, loss = 839.59865055\n",
      "Iteration 72, loss = 818.05649981\n",
      "Iteration 49, loss = 822.88343364\n",
      "Iteration 479, loss = 986.17738937\n",
      "Iteration 29, loss = 846.68483312\n",
      "Iteration 45, loss = 832.77994818\n",
      "Iteration 73, loss = 814.44438731\n",
      "Iteration 81, loss = 3827.91419732\n",
      "Iteration 30, loss = 840.99161217\n",
      "Iteration 50, loss = 839.84310429\n",
      "Iteration 523, loss = 840.14844505\n",
      "Iteration 46, loss = 829.52146006\n",
      "Iteration 31, loss = 843.66229715\n",
      "Iteration 74, loss = 809.66330997\n",
      "Iteration 51, loss = 822.67070715\n",
      "Iteration 108, loss = 3120.21861297\n",
      "Iteration 480, loss = 966.01638210\n",
      "Iteration 32, loss = 836.00154795\n",
      "Iteration 47, loss = 836.20229040\n",
      "Iteration 52, loss = 829.26245921\n",
      "Iteration 75, loss = 822.72787882\n",
      "Iteration 82, loss = 3797.08810006\n",
      "Iteration 33, loss = 842.97220095\n",
      "Iteration 48, loss = 828.13319366\n",
      "Iteration 76, loss = 815.06805572\n",
      "Iteration 53, loss = 835.47161098\n",
      "Iteration 524, loss = 847.29813127\n",
      "Iteration 109, loss = 3091.62344241\n",
      "Iteration 34, loss = 829.64688734\n",
      "Iteration 49, loss = 829.12060925\n",
      "Iteration 77, loss = 816.71005517\n",
      "Iteration 54, loss = 830.83611264\n",
      "Iteration 481, loss = 980.74297655\n",
      "Iteration 35, loss = 836.13644005\n",
      "Iteration 55, loss = 851.54541330\n",
      "Iteration 50, loss = 842.71684892\n",
      "Iteration 78, loss = 831.19424091\n",
      "Iteration 83, loss = 3763.50578473\n",
      "Iteration 36, loss = 825.83637083\n",
      "Iteration 56, loss = 819.46019339\n",
      "Iteration 79, loss = 818.25359629\n",
      "Iteration 51, loss = 825.01041296\n",
      "Iteration 525, loss = 830.91050491\n",
      "Iteration 110, loss = 3068.53112356\n",
      "Iteration 37, loss = 829.66791930\n",
      "Iteration 57, loss = 817.12924422\n",
      "Iteration 80, loss = 809.78278978\n",
      "Iteration 482, loss = 953.20685422\n",
      "Iteration 52, loss = 827.97681852\n",
      "Iteration 38, loss = 832.35220640\n",
      "Iteration 58, loss = 832.41005043\n",
      "Iteration 81, loss = 809.47623795\n",
      "Iteration 39, loss = 837.42131900\n",
      "Iteration 53, loss = 836.34045313\n",
      "Iteration 59, loss = 827.18787955\n",
      "Iteration 84, loss = 3733.61802035\n",
      "Iteration 82, loss = 815.21444083\n",
      "Iteration 40, loss = 823.90453665\n",
      "Iteration 111, loss = 3049.98061305\n",
      "Iteration 526, loss = 845.68713261\n",
      "Iteration 54, loss = 830.18716501\n",
      "Iteration 60, loss = 828.92685556\n",
      "Iteration 483, loss = 985.84877531\n",
      "Iteration 83, loss = 817.09677042\n",
      "Iteration 41, loss = 825.74067406\n",
      "Iteration 55, loss = 853.25482876\n",
      "Iteration 61, loss = 815.74033590\n",
      "Iteration 84, loss = 814.42383177\n",
      "Iteration 42, loss = 837.54182596\n",
      "Iteration 85, loss = 3702.14413385\n",
      "Iteration 56, loss = 823.44072476\n",
      "Iteration 62, loss = 821.64908575\n",
      "Iteration 43, loss = 830.96889665\n",
      "Iteration 85, loss = 805.05638420\n",
      "Iteration 112, loss = 3027.67622721\n",
      "Iteration 527, loss = 824.01237881\n",
      "Iteration 57, loss = 821.51401460\n",
      "Iteration 63, loss = 817.53585436\n",
      "Iteration 44, loss = 828.43134968\n",
      "Iteration 86, loss = 801.24046631\n",
      "Iteration 484, loss = 958.79888825\n",
      "Iteration 45, loss = 822.72435692\n",
      "Iteration 64, loss = 820.73209492\n",
      "Iteration 58, loss = 831.78265412\n",
      "Iteration 87, loss = 815.51118140\n",
      "Iteration 86, loss = 3677.59968476\n",
      "Iteration 113, loss = 3008.11519462\n",
      "Iteration 65, loss = 818.73405640\n",
      "Iteration 46, loss = 820.62062481\n",
      "Iteration 528, loss = 850.27046324\n",
      "Iteration 59, loss = 822.24574428\n",
      "Iteration 88, loss = 822.01189483\n",
      "Iteration 47, loss = 826.26844728\n",
      "Iteration 66, loss = 818.44523441\n",
      "Iteration 485, loss = 965.69312064\n",
      "Iteration 60, loss = 829.35888569\n",
      "Iteration 89, loss = 816.32131559\n",
      "Iteration 48, loss = 817.77134813\n",
      "Iteration 67, loss = 825.58735168\n",
      "Iteration 61, loss = 823.09617244\n",
      "Iteration 87, loss = 3642.21910875\n",
      "Iteration 90, loss = 811.55971605\n",
      "Iteration 114, loss = 2984.46733363\n",
      "Iteration 49, loss = 818.72662081\n",
      "Iteration 68, loss = 819.83062335\n",
      "Iteration 529, loss = 853.80766731\n",
      "Iteration 62, loss = 821.59695396\n",
      "Iteration 91, loss = 810.51272966\n",
      "Iteration 50, loss = 830.99864755\n",
      "Iteration 69, loss = 820.06198669\n",
      "Iteration 486, loss = 960.56617289\n",
      "Iteration 63, loss = 821.27506330\n",
      "Iteration 92, loss = 808.09034035\n",
      "Iteration 51, loss = 830.05296142\n",
      "Iteration 70, loss = 821.97546444\n",
      "Iteration 88, loss = 3609.81632544\n",
      "Iteration 115, loss = 2964.64413392\n",
      "Iteration 52, loss = 830.51882141\n",
      "Iteration 93, loss = 808.68809199\n",
      "Iteration 64, loss = 825.94679368\n",
      "Iteration 71, loss = 827.06704022\n",
      "Iteration 530, loss = 838.71997052\n",
      "Iteration 53, loss = 824.56242086\n",
      "Iteration 94, loss = 810.94511080\n",
      "Iteration 72, loss = 815.38298012\n",
      "Iteration 65, loss = 815.99066613\n",
      "Iteration 487, loss = 959.71351891\n",
      "Iteration 54, loss = 823.43203179\n",
      "Iteration 95, loss = 798.61827973\n",
      "Iteration 73, loss = 815.67214849\n",
      "Iteration 66, loss = 826.12233049\n",
      "Iteration 89, loss = 3585.38245134\n",
      "Iteration 116, loss = 2942.05443526\n",
      "Iteration 55, loss = 840.30533898\n",
      "Iteration 96, loss = 813.26789903\n",
      "Iteration 531, loss = 823.90769469\n",
      "Iteration 74, loss = 809.32821052\n",
      "Iteration 67, loss = 822.91971827\n",
      "Iteration 56, loss = 808.15854067\n",
      "Iteration 97, loss = 811.11269797\n",
      "Iteration 488, loss = 950.78387760\n",
      "Iteration 75, loss = 821.15596965\n",
      "Iteration 68, loss = 820.36556371\n",
      "Iteration 57, loss = 809.85879658\n",
      "Iteration 98, loss = 805.50948145\n",
      "Iteration 76, loss = 824.09518036\n",
      "Iteration 90, loss = 3553.64173976\n",
      "Iteration 117, loss = 2920.85369700\n",
      "Iteration 58, loss = 818.30545682\n",
      "Iteration 69, loss = 826.63429190\n",
      "Iteration 99, loss = 811.18487348\n",
      "Iteration 532, loss = 849.78397674\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 77, loss = 815.33841331\n",
      "Iteration 59, loss = 816.94526196\n",
      "Iteration 70, loss = 822.81330865\n",
      "Iteration 100, loss = 810.35574318\n",
      "Iteration 78, loss = 820.03839543\n",
      "Iteration 489, loss = 949.67615312\n",
      "Iteration 1, loss = 5499.59720755\n",
      "Iteration 91, loss = 3521.32123200\n",
      "Iteration 71, loss = 823.66110753\n",
      "Iteration 60, loss = 818.35479218\n",
      "Iteration 101, loss = 803.49166686\n",
      "Iteration 2, loss = 1978.27660024\n",
      "Iteration 79, loss = 824.45507883\n",
      "Iteration 118, loss = 2902.59251814\n",
      "Iteration 61, loss = 814.96404476\n",
      "Iteration 72, loss = 820.39338563\n",
      "Iteration 102, loss = 802.99469427\n",
      "Iteration 3, loss = 1308.52054660\n",
      "Iteration 80, loss = 812.35057556\n",
      "Iteration 62, loss = 817.31857018\n",
      "Iteration 103, loss = 816.16341552\n",
      "Iteration 73, loss = 814.17252777\n",
      "Iteration 490, loss = 944.13576185\n",
      "Iteration 4, loss = 1190.45652078\n",
      "Iteration 81, loss = 815.36478312\n",
      "Iteration 92, loss = 3491.29978113\n",
      "Iteration 63, loss = 808.18367905\n",
      "Iteration 104, loss = 797.32605368\n",
      "Iteration 74, loss = 810.98722426\n",
      "Iteration 119, loss = 2879.87714153\n",
      "Iteration 5, loss = 1128.24194100\n",
      "Iteration 82, loss = 814.83394034\n",
      "Iteration 64, loss = 812.41781635\n",
      "Iteration 75, loss = 820.72626878Iteration 105, loss = 812.03667159\n",
      "\n",
      "Iteration 6, loss = 1072.22209523\n",
      "Iteration 83, loss = 817.75662478\n",
      "Iteration 65, loss = 813.19117727\n",
      "Iteration 106, loss = 801.55325171\n",
      "Iteration 76, loss = 820.52799564\n",
      "Iteration 491, loss = 944.15070834\n",
      "Iteration 84, loss = 818.63225874\n",
      "Iteration 7, loss = 1023.72545058\n",
      "Iteration 93, loss = 3463.80187457\n",
      "Iteration 66, loss = 813.49093197\n",
      "Iteration 107, loss = 806.99350852\n",
      "Iteration 77, loss = 816.38177526\n",
      "Iteration 85, loss = 804.12886805\n",
      "Iteration 8, loss = 989.65571559\n",
      "Iteration 67, loss = 814.76327921\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 120, loss = 2860.76555043\n",
      "Iteration 108, loss = 797.08339301\n",
      "Iteration 78, loss = 819.93845732\n",
      "Iteration 86, loss = 813.34737040\n",
      "Iteration 9, loss = 957.56680994\n",
      "Iteration 109, loss = 804.87177898\n",
      "Iteration 492, loss = 947.22906428\n",
      "Iteration 1, loss = 10447.68755427\n",
      "Iteration 94, loss = 3440.41907797\n",
      "Iteration 87, loss = 818.32537793\n",
      "Iteration 79, loss = 823.39062004\n",
      "Iteration 10, loss = 922.33548155\n",
      "Iteration 110, loss = 800.03340710\n",
      "Iteration 2, loss = 6733.83166812\n",
      "Iteration 121, loss = 2844.61203492\n",
      "Iteration 88, loss = 822.52996019\n",
      "Iteration 11, loss = 906.31560191\n",
      "Iteration 80, loss = 810.11985425\n",
      "Iteration 3, loss = 5745.28607573\n",
      "Iteration 111, loss = 801.51582057\n",
      "Iteration 89, loss = 810.77051942\n",
      "Iteration 12, loss = 894.55935282\n",
      "Iteration 81, loss = 808.24255163\n",
      "Iteration 4, loss = 5191.62378518\n",
      "Iteration 493, loss = 936.91372501\n",
      "Iteration 112, loss = 796.10998546\n",
      "Iteration 90, loss = 814.84243989\n",
      "Iteration 95, loss = 3409.88649179\n",
      "Iteration 13, loss = 889.85289396\n",
      "Iteration 5, loss = 4721.73337146\n",
      "Iteration 82, loss = 808.45837874\n",
      "Iteration 113, loss = 812.58046840\n",
      "Iteration 122, loss = 2822.76586933\n",
      "Iteration 91, loss = 816.94784374\n",
      "Iteration 14, loss = 865.84816904\n",
      "Iteration 6, loss = 4308.19745041\n",
      "Iteration 83, loss = 817.26153158\n",
      "Iteration 114, loss = 803.62725340\n",
      "Iteration 7, loss = 3933.14258582\n",
      "Iteration 92, loss = 810.68529830\n",
      "Iteration 15, loss = 857.05047003\n",
      "Iteration 494, loss = 935.00251061\n",
      "Iteration 84, loss = 815.42123861\n",
      "Iteration 8, loss = 3592.75357644\n",
      "Iteration 96, loss = 3385.23423088\n",
      "Iteration 115, loss = 807.21129810\n",
      "Iteration 93, loss = 813.99346132\n",
      "Iteration 16, loss = 843.48552991\n",
      "Iteration 9, loss = 3289.44086133\n",
      "Iteration 123, loss = 2806.69909836\n",
      "Iteration 94, loss = 817.12464341\n",
      "Iteration 85, loss = 800.14020340\n",
      "Iteration 116, loss = 800.98629359\n",
      "Iteration 17, loss = 855.85631650\n",
      "Iteration 10, loss = 3022.36736872\n",
      "Iteration 95, loss = 802.70069877\n",
      "Iteration 117, loss = 802.61943625\n",
      "Iteration 86, loss = 807.01520360\n",
      "Iteration 11, loss = 2770.68546501\n",
      "Iteration 18, loss = 843.36567611\n",
      "Iteration 495, loss = 928.35218149\n",
      "Iteration 96, loss = 813.93600101\n",
      "Iteration 12, loss = 2561.80754182\n",
      "Iteration 97, loss = 3356.66903525\n",
      "Iteration 87, loss = 817.65259265\n",
      "Iteration 118, loss = 800.76045179\n",
      "Iteration 19, loss = 829.85199522\n",
      "Iteration 13, loss = 2375.18896705\n",
      "Iteration 124, loss = 2794.56075822\n",
      "Iteration 97, loss = 813.54750413\n",
      "Iteration 119, loss = 801.13239997\n",
      "Iteration 88, loss = 819.08031984\n",
      "Iteration 20, loss = 837.05660127\n",
      "Iteration 14, loss = 2206.04841466\n",
      "Iteration 98, loss = 815.49319970\n",
      "Iteration 120, loss = 816.61160108\n",
      "Iteration 89, loss = 810.42824324\n",
      "Iteration 21, loss = 830.12883880\n",
      "Iteration 15, loss = 2056.28905621\n",
      "Iteration 496, loss = 929.31133685\n",
      "Iteration 98, loss = 3334.47265901\n",
      "Iteration 99, loss = 815.89198511\n",
      "Iteration 121, loss = 799.27979888\n",
      "Iteration 90, loss = 812.92597190\n",
      "Iteration 22, loss = 822.62661300\n",
      "Iteration 16, loss = 1919.01364054\n",
      "Iteration 100, loss = 816.04221297\n",
      "Iteration 125, loss = 2770.22125723\n",
      "Iteration 122, loss = 803.30598180\n",
      "Iteration 17, loss = 1794.57999989\n",
      "Iteration 23, loss = 817.20633647\n",
      "Iteration 91, loss = 814.86326569\n",
      "Iteration 101, loss = 812.44701097\n",
      "Iteration 18, loss = 1689.93827819\n",
      "Iteration 123, loss = 804.75579365\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 99, loss = 3308.06117938\n",
      "Iteration 24, loss = 820.35199613\n",
      "Iteration 497, loss = 949.62150101\n",
      "Iteration 102, loss = 808.59316089\n",
      "Iteration 19, loss = 1595.09618898\n",
      "Iteration 92, loss = 810.45018276\n",
      "Iteration 25, loss = 824.39259869\n",
      "Iteration 103, loss = 819.33755906\n",
      "Iteration 20, loss = 1515.19650366\n",
      "Iteration 1, loss = 10818.07583427\n",
      "Iteration 126, loss = 2751.73959942\n",
      "Iteration 93, loss = 807.56882903\n",
      "Iteration 26, loss = 825.34358653\n",
      "Iteration 104, loss = 805.59405905\n",
      "Iteration 21, loss = 1448.06806771\n",
      "Iteration 2, loss = 6960.29079055\n",
      "Iteration 94, loss = 813.68877026\n",
      "Iteration 27, loss = 803.99311058\n",
      "Iteration 105, loss = 818.07166049\n",
      "Iteration 100, loss = 3284.57963756\n",
      "Iteration 498, loss = 987.24181707\n",
      "Iteration 22, loss = 1391.42536120\n",
      "Iteration 3, loss = 5921.69360118\n",
      "Iteration 28, loss = 804.38994966Iteration 106, loss = 807.87767404\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "\n",
      "Iteration 95, loss = 801.74504171\n",
      "Iteration 23, loss = 1347.54338373\n",
      "Iteration 127, loss = 2729.23341938\n",
      "Iteration 4, loss = 5345.29729530\n",
      "Iteration 24, loss = 1308.58559079\n",
      "Iteration 29, loss = 817.03943968\n",
      "Iteration 96, loss = 809.09211035\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 5, loss = 4864.81633690\n",
      "Iteration 1, loss = 10525.03053754\n",
      "Iteration 101, loss = 3264.88627092\n",
      "Iteration 25, loss = 1277.29468779\n",
      "Iteration 499, loss = 936.46843877\n",
      "Iteration 30, loss = 802.66236646\n",
      "Iteration 6, loss = 4437.08622610\n",
      "Iteration 128, loss = 2718.10382566\n",
      "Iteration 26, loss = 1252.10892625\n",
      "Iteration 1, loss = 10814.83198719\n",
      "Iteration 2, loss = 6669.16701217\n",
      "Iteration 31, loss = 804.80247076\n",
      "Iteration 7, loss = 4055.21253108\n",
      "Iteration 27, loss = 1231.19585305\n",
      "Iteration 3, loss = 5673.94221745\n",
      "Iteration 2, loss = 6890.12653845\n",
      "Iteration 32, loss = 801.61007554\n",
      "Iteration 28, loss = 1213.04203041\n",
      "Iteration 4, loss = 5132.11733468\n",
      "Iteration 8, loss = 3719.00072764\n",
      "Iteration 3, loss = 5864.90047949\n",
      "Iteration 500, loss = 934.64565410\n",
      "Iteration 29, loss = 1197.76575997\n",
      "Iteration 102, loss = 3233.04476735\n",
      "Iteration 33, loss = 809.65003573\n",
      "Iteration 5, loss = 4654.99652219\n",
      "Iteration 129, loss = 2698.94663487\n",
      "Iteration 9, loss = 3416.42634324\n",
      "Iteration 4, loss = 5307.35844869\n",
      "Iteration 30, loss = 1183.98453745\n",
      "Iteration 34, loss = 791.56524058\n",
      "Iteration 6, loss = 4230.60935993\n",
      "Iteration 5, loss = 4818.29563328\n",
      "Iteration 10, loss = 3133.39069643\n",
      "Iteration 31, loss = 1172.77239691\n",
      "Iteration 35, loss = 798.65169934\n",
      "Iteration 7, loss = 3849.38989350\n",
      "Iteration 501, loss = 952.30338229\n",
      "Iteration 32, loss = 1161.76923372\n",
      "Iteration 6, loss = 4383.00991057\n",
      "Iteration 11, loss = 2875.25895140\n",
      "Iteration 36, loss = 793.62429792\n",
      "Iteration 103, loss = 3209.58854303\n",
      "Iteration 8, loss = 3512.59429283\n",
      "Iteration 33, loss = 1150.60545909\n",
      "Iteration 130, loss = 2688.03110395\n",
      "Iteration 7, loss = 3987.67311782\n",
      "Iteration 12, loss = 2644.80267064\n",
      "Iteration 34, loss = 1143.02614091\n",
      "Iteration 37, loss = 802.60087645\n",
      "Iteration 9, loss = 3215.70732480\n",
      "Iteration 8, loss = 3635.38365462\n",
      "Iteration 35, loss = 1132.72220997\n",
      "Iteration 13, loss = 2432.81015540\n",
      "Iteration 38, loss = 797.68630596\n",
      "Iteration 10, loss = 2950.20226828\n",
      "Iteration 502, loss = 951.97338316\n",
      "Iteration 14, loss = 2244.87405145\n",
      "Iteration 36, loss = 1128.63916675\n",
      "Iteration 9, loss = 3321.48606499\n",
      "Iteration 104, loss = 3186.18450403\n",
      "Iteration 39, loss = 801.70197715\n",
      "Iteration 11, loss = 2694.62491019\n",
      "Iteration 131, loss = 2663.13117111\n",
      "Iteration 37, loss = 1119.10660516\n",
      "Iteration 10, loss = 3033.13316651\n",
      "Iteration 15, loss = 2078.56831875\n",
      "Iteration 40, loss = 785.33492107\n",
      "Iteration 12, loss = 2481.45752098\n",
      "Iteration 38, loss = 1111.77786529\n",
      "Iteration 11, loss = 2762.49458981\n",
      "Iteration 16, loss = 1926.97714003\n",
      "Iteration 41, loss = 790.15758051\n",
      "Iteration 13, loss = 2286.21219190\n",
      "Iteration 39, loss = 1105.01792851\n",
      "Iteration 503, loss = 939.35326431\n",
      "Iteration 12, loss = 2536.61489571\n",
      "Iteration 105, loss = 3175.07451593\n",
      "Iteration 17, loss = 1796.61136187\n",
      "Iteration 132, loss = 2647.19279734\n",
      "Iteration 42, loss = 802.04726093\n",
      "Iteration 14, loss = 2111.19196148\n",
      "Iteration 40, loss = 1101.05119030\n",
      "Iteration 13, loss = 2332.32313713\n",
      "Iteration 43, loss = 792.82373135\n",
      "Iteration 18, loss = 1694.15751418\n",
      "Iteration 41, loss = 1094.63682043\n",
      "Iteration 15, loss = 1962.72647468\n",
      "Iteration 14, loss = 2163.35951665\n",
      "Iteration 42, loss = 1086.71692015\n",
      "Iteration 19, loss = 1602.41084719\n",
      "Iteration 44, loss = 798.23983183\n",
      "Iteration 16, loss = 1828.22781508\n",
      "Iteration 504, loss = 920.85278199\n",
      "Iteration 106, loss = 3140.07976249\n",
      "Iteration 43, loss = 1083.37464476\n",
      "Iteration 15, loss = 2020.14910334\n",
      "Iteration 20, loss = 1524.00360152\n",
      "Iteration 45, loss = 784.90355485\n",
      "Iteration 133, loss = 2631.73441778\n",
      "Iteration 17, loss = 1713.35573490\n",
      "Iteration 44, loss = 1077.93711814\n",
      "Iteration 16, loss = 1891.08758772\n",
      "Iteration 46, loss = 782.65339462\n",
      "Iteration 21, loss = 1458.93120675\n",
      "Iteration 45, loss = 1071.45937348\n",
      "Iteration 18, loss = 1615.77927063\n",
      "Iteration 17, loss = 1783.01036075\n",
      "Iteration 47, loss = 794.29158629\n",
      "Iteration 22, loss = 1403.74323144\n",
      "Iteration 46, loss = 1067.58333513\n",
      "Iteration 505, loss = 930.89634480\n",
      "Iteration 19, loss = 1526.21486616\n",
      "Iteration 107, loss = 3119.38038324\n",
      "Iteration 18, loss = 1683.90877647\n",
      "Iteration 47, loss = 1063.74992685\n",
      "Iteration 23, loss = 1359.74062738\n",
      "Iteration 48, loss = 787.78688797\n",
      "Iteration 134, loss = 2619.78032753\n",
      "Iteration 20, loss = 1450.62818123\n",
      "Iteration 48, loss = 1057.85717654\n",
      "Iteration 19, loss = 1601.95746115\n",
      "Iteration 49, loss = 780.32559991\n",
      "Iteration 24, loss = 1322.48883014\n",
      "Iteration 21, loss = 1389.41153274\n",
      "Iteration 49, loss = 1053.09949733\n",
      "Iteration 20, loss = 1526.38072141\n",
      "Iteration 108, loss = 3097.69258220\n",
      "Iteration 50, loss = 785.44167510\n",
      "Iteration 506, loss = 924.02268111\n",
      "Iteration 25, loss = 1291.21875751\n",
      "Iteration 50, loss = 1049.22378684\n",
      "Iteration 22, loss = 1337.01426607\n",
      "Iteration 21, loss = 1462.91355824\n",
      "Iteration 51, loss = 784.37834138\n",
      "Iteration 26, loss = 1263.21210273\n",
      "Iteration 51, loss = 1044.09536547\n",
      "Iteration 135, loss = 2596.06169741\n",
      "Iteration 22, loss = 1408.35969101\n",
      "Iteration 23, loss = 1293.93725044\n",
      "Iteration 52, loss = 798.49041346\n",
      "Iteration 52, loss = 1038.69293478\n",
      "Iteration 27, loss = 1242.68417877\n",
      "Iteration 24, loss = 1257.40667929\n",
      "Iteration 23, loss = 1363.56647849\n",
      "Iteration 53, loss = 1032.67195083\n",
      "Iteration 109, loss = 3074.28743622\n",
      "Iteration 53, loss = 794.02982896\n",
      "Iteration 28, loss = 1224.57768748\n",
      "Iteration 507, loss = 946.24045564\n",
      "Iteration 25, loss = 1225.56012201\n",
      "Iteration 24, loss = 1325.87640126\n",
      "Iteration 54, loss = 1028.61311341\n",
      "Iteration 29, loss = 1209.97166574\n",
      "Iteration 54, loss = 782.31086667\n",
      "Iteration 136, loss = 2596.78193796\n",
      "Iteration 26, loss = 1204.56114721\n",
      "Iteration 25, loss = 1293.83342256\n",
      "Iteration 55, loss = 1025.16338631\n",
      "Iteration 30, loss = 1197.46023741\n",
      "Iteration 55, loss = 802.34805241\n",
      "Iteration 26, loss = 1271.08421555\n",
      "Iteration 56, loss = 1020.23126801\n",
      "Iteration 27, loss = 1183.40612374\n",
      "Iteration 110, loss = 3051.80526182\n",
      "Iteration 31, loss = 1187.48965897\n",
      "Iteration 508, loss = 923.15463419\n",
      "Iteration 56, loss = 780.45773102\n",
      "Iteration 57, loss = 1015.69999079\n",
      "Iteration 27, loss = 1245.72746031\n",
      "Iteration 28, loss = 1169.42449540\n",
      "Iteration 137, loss = 2562.91048651\n",
      "Iteration 32, loss = 1176.18105958\n",
      "Iteration 57, loss = 779.82917541\n",
      "Iteration 58, loss = 1011.99644575\n",
      "Iteration 28, loss = 1230.69651887\n",
      "Iteration 29, loss = 1152.96430834\n",
      "Iteration 33, loss = 1166.42243157\n",
      "Iteration 59, loss = 1005.29188666\n",
      "Iteration 58, loss = 781.74239812\n",
      "Iteration 111, loss = 3030.78649581\n",
      "Iteration 29, loss = 1214.03295060\n",
      "Iteration 30, loss = 1137.52914163\n",
      "Iteration 509, loss = 930.94434453\n",
      "Iteration 34, loss = 1158.10255018\n",
      "Iteration 60, loss = 1003.72062023\n",
      "Iteration 30, loss = 1195.73712069\n",
      "Iteration 59, loss = 777.62361267\n",
      "Iteration 35, loss = 1148.57311619\n",
      "Iteration 31, loss = 1130.71289968\n",
      "Iteration 61, loss = 999.59080341\n",
      "Iteration 138, loss = 2549.86160867\n",
      "Iteration 60, loss = 779.59664435\n",
      "Iteration 31, loss = 1190.64367297\n",
      "Iteration 62, loss = 995.30584579\n",
      "Iteration 36, loss = 1144.00789352\n",
      "Iteration 32, loss = 1117.96106345\n",
      "Iteration 112, loss = 3013.20322776\n",
      "Iteration 61, loss = 777.36869022\n",
      "Iteration 32, loss = 1176.71066880\n",
      "Iteration 63, loss = 990.42232241\n",
      "Iteration 37, loss = 1133.06106941\n",
      "Iteration 33, loss = 1107.15677143\n",
      "Iteration 510, loss = 962.81865706\n",
      "Iteration 62, loss = 784.80701167\n",
      "Iteration 64, loss = 988.79292785\n",
      "Iteration 33, loss = 1164.57114532\n",
      "Iteration 139, loss = 2534.73180157\n",
      "Iteration 34, loss = 1099.15696781\n",
      "Iteration 38, loss = 1126.39478360\n",
      "Iteration 65, loss = 983.18239857\n",
      "Iteration 63, loss = 774.25264818\n",
      "Iteration 34, loss = 1156.17260569\n",
      "Iteration 39, loss = 1118.20539268\n",
      "Iteration 35, loss = 1091.05824547\n",
      "Iteration 113, loss = 2987.27884072\n",
      "Iteration 64, loss = 772.19432143\n",
      "Iteration 66, loss = 977.66066347\n",
      "Iteration 40, loss = 1112.66304609\n",
      "Iteration 511, loss = 923.60348864\n",
      "Iteration 35, loss = 1147.09449244\n",
      "Iteration 36, loss = 1082.76631848\n",
      "Iteration 67, loss = 976.10054981\n",
      "Iteration 65, loss = 770.97691330\n",
      "Iteration 140, loss = 2520.22275771\n",
      "Iteration 41, loss = 1107.16532536\n",
      "Iteration 36, loss = 1137.88923138\n",
      "Iteration 37, loss = 1073.29391311\n",
      "Iteration 68, loss = 971.93872196\n",
      "Iteration 66, loss = 779.20482699\n",
      "Iteration 42, loss = 1099.33467887\n",
      "Iteration 69, loss = 967.83727017\n",
      "Iteration 37, loss = 1127.20593785\n",
      "Iteration 38, loss = 1069.21232808\n",
      "Iteration 114, loss = 2973.64633428\n",
      "Iteration 67, loss = 780.87718362\n",
      "Iteration 70, loss = 963.98198863\n",
      "Iteration 512, loss = 932.18615748\n",
      "Iteration 43, loss = 1094.95107868\n",
      "Iteration 38, loss = 1122.68047740\n",
      "Iteration 39, loss = 1060.52791538\n",
      "Iteration 141, loss = 2506.21080234\n",
      "Iteration 71, loss = 962.98491437\n",
      "Iteration 68, loss = 772.22337037\n",
      "Iteration 44, loss = 1088.69498889\n",
      "Iteration 40, loss = 1056.72036820\n",
      "Iteration 39, loss = 1114.14217841\n",
      "Iteration 72, loss = 958.39637675\n",
      "Iteration 69, loss = 776.42385359\n",
      "Iteration 45, loss = 1083.63469310\n",
      "Iteration 115, loss = 2943.12915085\n",
      "Iteration 41, loss = 1051.28076416\n",
      "Iteration 40, loss = 1107.01715799\n",
      "Iteration 73, loss = 954.57169225\n",
      "Iteration 513, loss = 930.50937399\n",
      "Iteration 70, loss = 776.33682290\n",
      "Iteration 46, loss = 1078.73285279\n",
      "Iteration 42, loss = 1045.09550797\n",
      "Iteration 74, loss = 951.44660949\n",
      "Iteration 41, loss = 1101.50959196\n",
      "Iteration 142, loss = 2497.00122667\n",
      "Iteration 71, loss = 772.00449899\n",
      "Iteration 75, loss = 948.49526593\n",
      "Iteration 47, loss = 1072.69622429\n",
      "Iteration 43, loss = 1039.59708571\n",
      "Iteration 42, loss = 1094.96786921\n",
      "Iteration 72, loss = 768.05437672\n",
      "Iteration 76, loss = 945.08086220\n",
      "Iteration 116, loss = 2925.91857586\n",
      "Iteration 48, loss = 1068.61549485\n",
      "Iteration 44, loss = 1033.26998449\n",
      "Iteration 43, loss = 1089.50805118\n",
      "Iteration 77, loss = 944.49553441\n",
      "Iteration 73, loss = 775.47380436\n",
      "Iteration 514, loss = 930.38067493\n",
      "Iteration 49, loss = 1060.67433925\n",
      "Iteration 45, loss = 1029.35461067\n",
      "Iteration 44, loss = 1082.23487982\n",
      "Iteration 78, loss = 940.31812691\n",
      "Iteration 143, loss = 2473.53298324\n",
      "Iteration 74, loss = 771.61191832\n",
      "Iteration 50, loss = 1056.84509373\n",
      "Iteration 46, loss = 1023.39220039\n",
      "Iteration 45, loss = 1076.95590658\n",
      "Iteration 79, loss = 935.75381328\n",
      "Iteration 117, loss = 2904.49708607\n",
      "Iteration 75, loss = 777.24390757\n",
      "Iteration 51, loss = 1052.92738242\n",
      "Iteration 80, loss = 935.74295982\n",
      "Iteration 46, loss = 1071.42965635\n",
      "Iteration 47, loss = 1018.35891145\n",
      "Iteration 515, loss = 948.32023630\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 76, loss = 776.21351495\n",
      "Iteration 81, loss = 934.01909855\n",
      "Iteration 52, loss = 1047.38873729\n",
      "Iteration 47, loss = 1065.99863716\n",
      "Iteration 144, loss = 2466.75809720\n",
      "Iteration 48, loss = 1013.28102057\n",
      "Iteration 77, loss = 769.81002133\n",
      "Iteration 82, loss = 926.64705324\n",
      "Iteration 1, loss = 10692.00766792\n",
      "Iteration 53, loss = 1041.62599777\n",
      "Iteration 48, loss = 1059.87690121\n",
      "Iteration 118, loss = 2889.96914006\n",
      "Iteration 49, loss = 1007.53300613\n",
      "Iteration 83, loss = 927.03196212\n",
      "Iteration 78, loss = 775.37173315\n",
      "Iteration 49, loss = 1055.42656411\n",
      "Iteration 2, loss = 6810.88192418\n",
      "Iteration 54, loss = 1037.42744707\n",
      "Iteration 84, loss = 924.27383217\n",
      "Iteration 50, loss = 1002.85861003\n",
      "Iteration 79, loss = 783.62938271\n",
      "Iteration 50, loss = 1049.98270986\n",
      "Iteration 3, loss = 5792.42353423\n",
      "Iteration 55, loss = 1033.52539478\n",
      "Iteration 145, loss = 2449.09238117\n",
      "Iteration 85, loss = 924.42242759\n",
      "Iteration 51, loss = 997.63799004\n",
      "Iteration 80, loss = 771.56885326\n",
      "Iteration 4, loss = 5229.80345093\n",
      "Iteration 86, loss = 919.93169190\n",
      "Iteration 51, loss = 1042.82719962\n",
      "Iteration 56, loss = 1028.32389670\n",
      "Iteration 119, loss = 2868.22929135\n",
      "Iteration 52, loss = 993.75842361\n",
      "Iteration 81, loss = 771.33895296\n",
      "Iteration 87, loss = 918.04831816\n",
      "Iteration 5, loss = 4746.56969308\n",
      "Iteration 52, loss = 1039.19537835\n",
      "Iteration 57, loss = 1023.65801130\n",
      "Iteration 88, loss = 914.76689417\n",
      "Iteration 53, loss = 988.83541917\n",
      "Iteration 82, loss = 775.86722221\n",
      "Iteration 6, loss = 4320.10372036\n",
      "Iteration 146, loss = 2429.19611805\n",
      "Iteration 53, loss = 1034.35579020\n",
      "Iteration 58, loss = 1019.61303240\n",
      "Iteration 89, loss = 913.43878549\n",
      "Iteration 7, loss = 3939.11687320\n",
      "Iteration 54, loss = 984.62342257\n",
      "Iteration 83, loss = 786.41318834\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 120, loss = 2844.11681256\n",
      "Iteration 54, loss = 1029.60517443\n",
      "Iteration 59, loss = 1012.93657630\n",
      "Iteration 90, loss = 911.24689699\n",
      "Iteration 8, loss = 3606.21714999\n",
      "Iteration 55, loss = 982.19147500\n",
      "Iteration 55, loss = 1025.29035548\n",
      "Iteration 91, loss = 909.57612475\n",
      "Iteration 1, loss = 10666.82364086\n",
      "Iteration 60, loss = 1010.75484697\n",
      "Iteration 9, loss = 3311.93549771\n",
      "Iteration 56, loss = 975.23953057\n",
      "Iteration 56, loss = 1018.56849090\n",
      "Iteration 92, loss = 908.32317123\n",
      "Iteration 147, loss = 2416.94566786\n",
      "Iteration 2, loss = 6814.83132071\n",
      "Iteration 61, loss = 1006.88061297\n",
      "Iteration 10, loss = 3042.90355971\n",
      "Iteration 93, loss = 904.88737226\n",
      "Iteration 57, loss = 968.72590678\n",
      "Iteration 57, loss = 1012.47940592\n",
      "Iteration 121, loss = 2827.44659905\n",
      "Iteration 3, loss = 5793.29943884\n",
      "Iteration 11, loss = 2775.38107886\n",
      "Iteration 62, loss = 1002.09246217\n",
      "Iteration 94, loss = 902.78730024\n",
      "Iteration 58, loss = 967.11017451\n",
      "Iteration 58, loss = 1008.44705363\n",
      "Iteration 4, loss = 5245.60787841\n",
      "Iteration 95, loss = 901.54966329\n",
      "Iteration 63, loss = 997.29097095\n",
      "Iteration 12, loss = 2542.58596919\n",
      "Iteration 5, loss = 4766.98816850\n",
      "Iteration 59, loss = 1003.27650789\n",
      "Iteration 59, loss = 962.97711710\n",
      "Iteration 148, loss = 2409.50985856\n",
      "Iteration 96, loss = 898.59146543\n",
      "Iteration 64, loss = 994.28873652\n",
      "Iteration 13, loss = 2333.77498162\n",
      "Iteration 122, loss = 2807.78823516\n",
      "Iteration 6, loss = 4341.03092148\n",
      "Iteration 60, loss = 1000.29227273\n",
      "Iteration 97, loss = 897.84254394\n",
      "Iteration 60, loss = 958.04037677\n",
      "Iteration 65, loss = 988.36719929\n",
      "Iteration 14, loss = 2144.54380542\n",
      "Iteration 98, loss = 895.81217889\n",
      "Iteration 61, loss = 993.66485430\n",
      "Iteration 7, loss = 3957.98555386\n",
      "Iteration 61, loss = 952.44719458\n",
      "Iteration 15, loss = 1975.18745211\n",
      "Iteration 66, loss = 983.78754625\n",
      "Iteration 99, loss = 892.18314709\n",
      "Iteration 8, loss = 3625.15593063\n",
      "Iteration 149, loss = 2391.03056057\n",
      "Iteration 62, loss = 988.55523818\n",
      "Iteration 62, loss = 947.75509667\n",
      "Iteration 123, loss = 2795.15637857\n",
      "Iteration 16, loss = 1829.66965262\n",
      "Iteration 100, loss = 892.50756492\n",
      "Iteration 67, loss = 980.62497778\n",
      "Iteration 9, loss = 3332.02324359\n",
      "Iteration 63, loss = 944.92751672\n",
      "Iteration 63, loss = 984.67201540\n",
      "Iteration 101, loss = 890.37091184\n",
      "Iteration 17, loss = 1707.83973762\n",
      "Iteration 68, loss = 976.97337353\n",
      "Iteration 10, loss = 3061.70026354\n",
      "Iteration 64, loss = 980.63148272\n",
      "Iteration 102, loss = 888.77521359\n",
      "Iteration 64, loss = 940.69676142\n",
      "Iteration 18, loss = 1600.62369481\n",
      "Iteration 69, loss = 973.58550677\n",
      "Iteration 11, loss = 2801.59186305\n",
      "Iteration 103, loss = 886.84135231\n",
      "Iteration 65, loss = 977.38461443\n",
      "Iteration 19, loss = 1517.03756165\n",
      "Iteration 124, loss = 2778.02498283\n",
      "Iteration 65, loss = 938.21548095\n",
      "Iteration 150, loss = 2378.32672676\n",
      "Iteration 70, loss = 969.20534074\n",
      "Iteration 12, loss = 2582.79290145\n",
      "Iteration 104, loss = 886.49652141\n",
      "Iteration 66, loss = 973.90837053\n",
      "Iteration 71, loss = 967.08365815\n",
      "Iteration 66, loss = 935.46844563\n",
      "Iteration 20, loss = 1441.49896065\n",
      "Iteration 105, loss = 884.36911765\n",
      "Iteration 13, loss = 2375.65055792\n",
      "Iteration 67, loss = 968.45288824\n",
      "Iteration 21, loss = 1380.28779166\n",
      "Iteration 67, loss = 930.32353903\n",
      "Iteration 72, loss = 962.11862969\n",
      "Iteration 106, loss = 882.83224603\n",
      "Iteration 14, loss = 2185.22429721\n",
      "Iteration 125, loss = 2758.70528473\n",
      "Iteration 68, loss = 965.28089527\n",
      "Iteration 151, loss = 2369.60400414\n",
      "Iteration 22, loss = 1327.28674232\n",
      "Iteration 68, loss = 927.14680330\n",
      "Iteration 107, loss = 879.66702727\n",
      "Iteration 73, loss = 959.34715731\n",
      "Iteration 15, loss = 2022.44968884\n",
      "Iteration 69, loss = 959.83788273\n",
      "Iteration 23, loss = 1285.90703656\n",
      "Iteration 108, loss = 880.67695788\n",
      "Iteration 69, loss = 923.55325392\n",
      "Iteration 74, loss = 955.62196071\n",
      "Iteration 16, loss = 1886.77290947\n",
      "Iteration 24, loss = 1253.38372278\n",
      "Iteration 109, loss = 878.02545472\n",
      "Iteration 70, loss = 957.52728358\n",
      "Iteration 17, loss = 1770.32243267\n",
      "Iteration 70, loss = 921.83442535\n",
      "Iteration 75, loss = 952.73410591\n",
      "Iteration 110, loss = 877.33535292\n",
      "Iteration 25, loss = 1225.62048717\n",
      "Iteration 126, loss = 2738.54743557\n",
      "Iteration 71, loss = 952.40094505\n",
      "Iteration 152, loss = 2351.32701919\n",
      "Iteration 111, loss = 875.71894441\n",
      "Iteration 18, loss = 1666.45828085\n",
      "Iteration 76, loss = 949.20105825\n",
      "Iteration 71, loss = 916.25734903\n",
      "Iteration 26, loss = 1204.82226303\n",
      "Iteration 112, loss = 874.59757864\n",
      "Iteration 72, loss = 948.99702459\n",
      "Iteration 19, loss = 1585.06636301\n",
      "Iteration 72, loss = 913.75780443\n",
      "Iteration 77, loss = 946.93471601\n",
      "Iteration 27, loss = 1182.30128361\n",
      "Iteration 113, loss = 874.79156083\n",
      "Iteration 20, loss = 1511.58982081\n",
      "Iteration 73, loss = 945.03372580\n",
      "Iteration 78, loss = 942.32349190\n",
      "Iteration 73, loss = 909.84862656\n",
      "Iteration 28, loss = 1169.53963802\n",
      "Iteration 127, loss = 2720.98010857\n",
      "Iteration 153, loss = 2338.59742165\n",
      "Iteration 114, loss = 871.68346666\n",
      "Iteration 21, loss = 1449.43890848\n",
      "Iteration 79, loss = 938.42287284\n",
      "Iteration 29, loss = 1155.69976680\n",
      "Iteration 74, loss = 940.87862238\n",
      "Iteration 74, loss = 906.88802697\n",
      "Iteration 115, loss = 870.32717016\n",
      "Iteration 30, loss = 1141.77556930\n",
      "Iteration 22, loss = 1399.55693538\n",
      "Iteration 80, loss = 937.24398146\n",
      "Iteration 75, loss = 904.00922185\n",
      "Iteration 75, loss = 938.12489610\n",
      "Iteration 116, loss = 869.45943454\n",
      "Iteration 31, loss = 1134.33198620\n",
      "Iteration 76, loss = 899.30411148\n",
      "Iteration 128, loss = 2703.90245092\n",
      "Iteration 23, loss = 1359.48673069\n",
      "Iteration 81, loss = 935.40241572\n",
      "Iteration 117, loss = 869.60596230\n",
      "Iteration 76, loss = 934.37687086\n",
      "Iteration 32, loss = 1125.40520843\n",
      "Iteration 154, loss = 2328.88124346\n",
      "Iteration 118, loss = 866.30720480\n",
      "Iteration 24, loss = 1325.56840733\n",
      "Iteration 77, loss = 897.50992784\n",
      "Iteration 82, loss = 928.22464446\n",
      "Iteration 77, loss = 932.24908638\n",
      "Iteration 33, loss = 1114.54078001\n",
      "Iteration 119, loss = 866.56842191\n",
      "Iteration 25, loss = 1296.64836953\n",
      "Iteration 78, loss = 894.19646933\n",
      "Iteration 83, loss = 928.90013534\n",
      "Iteration 78, loss = 926.54417118\n",
      "Iteration 34, loss = 1109.52043648\n",
      "Iteration 120, loss = 865.97896028\n",
      "Iteration 129, loss = 2687.92413168\n",
      "Iteration 26, loss = 1273.25240358\n",
      "Iteration 84, loss = 926.65240392\n",
      "Iteration 79, loss = 891.55228540\n",
      "Iteration 121, loss = 865.54542248\n",
      "Iteration 79, loss = 926.10516758\n",
      "Iteration 35, loss = 1100.67863384\n",
      "Iteration 27, loss = 1248.08402419\n",
      "Iteration 80, loss = 888.53171155\n",
      "Iteration 85, loss = 925.32417998\n",
      "Iteration 155, loss = 2310.69361077\n",
      "Iteration 122, loss = 864.21025572\n",
      "Iteration 80, loss = 922.54078898\n",
      "Iteration 36, loss = 1093.07616055\n",
      "Iteration 28, loss = 1233.23845317\n",
      "Iteration 86, loss = 920.77298181\n",
      "Iteration 81, loss = 885.60900572\n",
      "Iteration 123, loss = 862.85251031\n",
      "Iteration 37, loss = 1085.27937613\n",
      "Iteration 81, loss = 919.00282695\n",
      "Iteration 29, loss = 1219.34297003\n",
      "Iteration 130, loss = 2669.36714710\n",
      "Iteration 82, loss = 882.65572126\n",
      "Iteration 87, loss = 919.77932984\n",
      "Iteration 124, loss = 860.46674126\n",
      "Iteration 38, loss = 1080.34684874\n",
      "Iteration 82, loss = 915.12545978\n",
      "Iteration 30, loss = 1205.95952613\n",
      "Iteration 156, loss = 2298.90110910\n",
      "Iteration 125, loss = 860.57420776\n",
      "Iteration 83, loss = 879.96010732\n",
      "Iteration 88, loss = 916.37058947\n",
      "Iteration 39, loss = 1074.19960871\n",
      "Iteration 31, loss = 1194.69023220\n",
      "Iteration 83, loss = 910.96969055\n",
      "Iteration 126, loss = 857.22134474\n",
      "Iteration 84, loss = 877.41441901\n",
      "Iteration 89, loss = 916.81225564\n",
      "Iteration 40, loss = 1067.68068964\n",
      "Iteration 32, loss = 1185.24028573\n",
      "Iteration 127, loss = 860.97080303\n",
      "Iteration 131, loss = 2653.29607304\n",
      "Iteration 84, loss = 909.32667520\n",
      "Iteration 85, loss = 873.42322891\n",
      "Iteration 90, loss = 912.33923755\n",
      "Iteration 128, loss = 857.44036942\n",
      "Iteration 41, loss = 1062.91900956\n",
      "Iteration 157, loss = 2286.23239903\n",
      "Iteration 85, loss = 906.89799388\n",
      "Iteration 33, loss = 1172.87532205\n",
      "Iteration 86, loss = 872.40803901\n",
      "Iteration 129, loss = 856.93863529\n",
      "Iteration 91, loss = 909.77676105\n",
      "Iteration 42, loss = 1056.08871079\n",
      "Iteration 34, loss = 1166.93720042\n",
      "Iteration 86, loss = 904.43913855\n",
      "Iteration 87, loss = 868.87623323\n",
      "Iteration 130, loss = 856.23259197\n",
      "Iteration 92, loss = 909.70046565\n",
      "Iteration 43, loss = 1051.91480460\n",
      "Iteration 35, loss = 1156.69601488\n",
      "Iteration 132, loss = 2639.21901563\n",
      "Iteration 87, loss = 902.32776222\n",
      "Iteration 131, loss = 855.19287081\n",
      "Iteration 88, loss = 868.89342585\n",
      "Iteration 93, loss = 905.00654373\n",
      "Iteration 36, loss = 1147.97047144\n",
      "Iteration 158, loss = 2281.55361681\n",
      "Iteration 44, loss = 1044.19197922\n",
      "Iteration 132, loss = 853.41694605\n",
      "Iteration 88, loss = 901.30467678\n",
      "Iteration 89, loss = 864.39375965\n",
      "Iteration 94, loss = 903.66504959\n",
      "Iteration 45, loss = 1037.78329414\n",
      "Iteration 133, loss = 854.05016724\n",
      "Iteration 37, loss = 1139.57508879\n",
      "Iteration 89, loss = 898.40500808\n",
      "Iteration 90, loss = 862.73131952\n",
      "Iteration 134, loss = 853.35842640\n",
      "Iteration 95, loss = 901.48516463\n",
      "Iteration 38, loss = 1133.49445318\n",
      "Iteration 46, loss = 1034.42072270\n",
      "Iteration 133, loss = 2627.66175153\n",
      "Iteration 90, loss = 896.34999119\n",
      "Iteration 135, loss = 852.61844429\n",
      "Iteration 91, loss = 859.56827274\n",
      "Iteration 96, loss = 898.03246401\n",
      "Iteration 39, loss = 1125.92070266\n",
      "Iteration 159, loss = 2258.46254738\n",
      "Iteration 47, loss = 1027.91188526\n",
      "Iteration 136, loss = 851.84518653\n",
      "Iteration 91, loss = 893.47317415\n",
      "Iteration 97, loss = 897.29741737\n",
      "Iteration 92, loss = 855.60296734\n",
      "Iteration 48, loss = 1021.40694802\n",
      "Iteration 40, loss = 1118.12714648\n",
      "Iteration 137, loss = 850.30774003\n",
      "Iteration 92, loss = 889.54304561\n",
      "Iteration 49, loss = 1018.62145182\n",
      "Iteration 98, loss = 895.69568616\n",
      "Iteration 41, loss = 1112.66243492\n",
      "Iteration 93, loss = 855.54976404\n",
      "Iteration 138, loss = 849.98152119\n",
      "Iteration 134, loss = 2607.10579128\n",
      "Iteration 93, loss = 889.77377150\n",
      "Iteration 160, loss = 2245.93986839\n",
      "Iteration 139, loss = 848.73459678\n",
      "Iteration 94, loss = 853.58237955\n",
      "Iteration 50, loss = 1015.41457741\n",
      "Iteration 42, loss = 1106.37592679\n",
      "Iteration 99, loss = 893.87968505\n",
      "Iteration 140, loss = 847.71583896\n",
      "Iteration 94, loss = 888.05023095\n",
      "Iteration 43, loss = 1100.03291386\n",
      "Iteration 95, loss = 850.06224119\n",
      "Iteration 51, loss = 1008.09401661\n",
      "Iteration 100, loss = 891.27867492\n",
      "Iteration 141, loss = 848.18667217\n",
      "Iteration 95, loss = 884.42535203\n",
      "Iteration 96, loss = 849.84554374\n",
      "Iteration 135, loss = 2591.46044788\n",
      "Iteration 52, loss = 1005.03347047\n",
      "Iteration 44, loss = 1093.73057165\n",
      "Iteration 101, loss = 890.61721997\n",
      "Iteration 161, loss = 2234.37283493\n",
      "Iteration 142, loss = 845.95452227\n",
      "Iteration 96, loss = 884.19198560\n",
      "Iteration 97, loss = 845.98756985\n",
      "Iteration 45, loss = 1088.67360742\n",
      "Iteration 53, loss = 1000.83560689\n",
      "Iteration 143, loss = 846.38906048\n",
      "Iteration 102, loss = 888.08656563\n",
      "Iteration 97, loss = 881.68389562\n",
      "Iteration 98, loss = 843.47516107\n",
      "Iteration 46, loss = 1084.18663653\n",
      "Iteration 54, loss = 997.76332696\n",
      "Iteration 144, loss = 846.14417081\n",
      "Iteration 103, loss = 887.18914757\n",
      "Iteration 98, loss = 878.43723460\n",
      "Iteration 136, loss = 2576.56227051\n",
      "Iteration 99, loss = 842.39345589\n",
      "Iteration 47, loss = 1078.59481524\n",
      "Iteration 55, loss = 993.37497150\n",
      "Iteration 145, loss = 844.40452423\n",
      "Iteration 162, loss = 2223.61090925\n",
      "Iteration 104, loss = 885.56606374\n",
      "Iteration 99, loss = 877.42158407\n",
      "Iteration 48, loss = 1071.96363560\n",
      "Iteration 56, loss = 987.95226331\n",
      "Iteration 100, loss = 844.08766333\n",
      "Iteration 146, loss = 843.96706266\n",
      "Iteration 105, loss = 882.76007581\n",
      "Iteration 100, loss = 877.68052759\n",
      "Iteration 49, loss = 1068.33046800\n",
      "Iteration 147, loss = 843.30433907\n",
      "Iteration 57, loss = 981.96917744\n",
      "Iteration 101, loss = 838.26687354\n",
      "Iteration 106, loss = 882.39657495\n",
      "Iteration 101, loss = 874.90293565\n",
      "Iteration 50, loss = 1062.64223836\n",
      "Iteration 148, loss = 841.60584213\n",
      "Iteration 137, loss = 2564.20717370\n",
      "Iteration 58, loss = 979.57554719\n",
      "Iteration 102, loss = 836.63134432\n",
      "Iteration 163, loss = 2214.55257981\n",
      "Iteration 107, loss = 879.05014045\n",
      "Iteration 149, loss = 842.87330795\n",
      "Iteration 102, loss = 871.43224108\n",
      "Iteration 51, loss = 1055.82212394\n",
      "Iteration 59, loss = 975.57360961\n",
      "Iteration 103, loss = 839.13934520\n",
      "Iteration 150, loss = 840.71755292\n",
      "Iteration 108, loss = 879.65158828\n",
      "Iteration 103, loss = 871.54227328\n",
      "Iteration 52, loss = 1051.80077710\n",
      "Iteration 60, loss = 971.35380605\n",
      "Iteration 104, loss = 834.61538674\n",
      "Iteration 151, loss = 841.76232248\n",
      "Iteration 109, loss = 876.86532683\n",
      "Iteration 138, loss = 2545.35933650\n",
      "Iteration 104, loss = 868.95961867\n",
      "Iteration 53, loss = 1047.72676932\n",
      "Iteration 61, loss = 967.01414429\n",
      "Iteration 152, loss = 841.39455497\n",
      "Iteration 105, loss = 832.21725064\n",
      "Iteration 164, loss = 2205.49964653\n",
      "Iteration 110, loss = 875.17356673\n",
      "Iteration 105, loss = 868.30166106\n",
      "Iteration 153, loss = 842.42602518\n",
      "Iteration 62, loss = 961.51332917\n",
      "Iteration 54, loss = 1043.91756804\n",
      "Iteration 106, loss = 831.19734348\n",
      "Iteration 63, loss = 960.48668814\n",
      "Iteration 154, loss = 839.84431318\n",
      "Iteration 106, loss = 867.29708912\n",
      "Iteration 111, loss = 874.70812440\n",
      "Iteration 55, loss = 1039.40813428\n",
      "Iteration 107, loss = 829.53057370\n",
      "Iteration 139, loss = 2531.16215696\n",
      "Iteration 155, loss = 838.33581131\n",
      "Iteration 64, loss = 957.90858712\n",
      "Iteration 165, loss = 2186.96919425\n",
      "Iteration 107, loss = 866.05617712\n",
      "Iteration 112, loss = 871.37123744\n",
      "Iteration 56, loss = 1033.11668061\n",
      "Iteration 108, loss = 828.56020516\n",
      "Iteration 156, loss = 839.04353473\n",
      "Iteration 65, loss = 954.05135821\n",
      "Iteration 108, loss = 865.38615180\n",
      "Iteration 113, loss = 871.68520611\n",
      "Iteration 57, loss = 1028.09588501\n",
      "Iteration 109, loss = 826.45625607\n",
      "Iteration 157, loss = 838.35095393\n",
      "Iteration 66, loss = 951.92224758\n",
      "Iteration 109, loss = 862.01171406\n",
      "Iteration 58, loss = 1025.62483634\n",
      "Iteration 158, loss = 835.76821535\n",
      "Iteration 114, loss = 869.45333614\n",
      "Iteration 110, loss = 824.47658840\n",
      "Iteration 140, loss = 2516.80369800\n",
      "Iteration 67, loss = 948.41003062\n",
      "Iteration 166, loss = 2174.01743897\n",
      "Iteration 159, loss = 835.92671476\n",
      "Iteration 110, loss = 861.16735919\n",
      "Iteration 111, loss = 824.49181786\n",
      "Iteration 59, loss = 1019.85564181\n",
      "Iteration 115, loss = 867.08650890\n",
      "Iteration 68, loss = 944.97465194\n",
      "Iteration 160, loss = 837.78097066\n",
      "Iteration 112, loss = 823.18825048\n",
      "Iteration 111, loss = 860.80301334\n",
      "Iteration 60, loss = 1015.13351869\n",
      "Iteration 116, loss = 866.44152703\n",
      "Iteration 69, loss = 941.13172775\n",
      "Iteration 161, loss = 836.91032631\n",
      "Iteration 112, loss = 859.56736417\n",
      "Iteration 113, loss = 821.12956837\n",
      "Iteration 61, loss = 1010.68024982\n",
      "Iteration 117, loss = 866.14290409\n",
      "Iteration 141, loss = 2497.71549950\n",
      "Iteration 70, loss = 938.29732119\n",
      "Iteration 167, loss = 2169.51476417\n",
      "Iteration 162, loss = 835.54928665\n",
      "Iteration 113, loss = 859.13019554\n",
      "Iteration 62, loss = 1004.00308402\n",
      "Iteration 114, loss = 818.88538806\n",
      "Iteration 163, loss = 836.44678737\n",
      "Iteration 118, loss = 862.91997304\n",
      "Iteration 71, loss = 936.18043017\n",
      "Iteration 164, loss = 831.04228811\n",
      "Iteration 114, loss = 856.91292051\n",
      "Iteration 63, loss = 1003.91562168\n",
      "Iteration 115, loss = 816.34194487\n",
      "Iteration 119, loss = 862.70427879\n",
      "Iteration 72, loss = 932.32144755\n",
      "Iteration 165, loss = 833.94771022\n",
      "Iteration 142, loss = 2488.07990721\n",
      "Iteration 115, loss = 854.87807849\n",
      "Iteration 116, loss = 816.75417253\n",
      "Iteration 64, loss = 999.80230873\n",
      "Iteration 73, loss = 930.14418624\n",
      "Iteration 168, loss = 2156.98486505\n",
      "Iteration 120, loss = 861.10450816\n",
      "Iteration 166, loss = 833.52950252\n",
      "Iteration 116, loss = 854.44831386\n",
      "Iteration 117, loss = 813.37665552\n",
      "Iteration 65, loss = 996.74133032\n",
      "Iteration 74, loss = 926.35924553\n",
      "Iteration 121, loss = 861.06119375\n",
      "Iteration 167, loss = 834.17967140\n",
      "Iteration 117, loss = 852.70759407\n",
      "Iteration 66, loss = 993.25027371\n",
      "Iteration 75, loss = 922.85762457\n",
      "Iteration 118, loss = 813.75859819\n",
      "Iteration 122, loss = 858.40589558\n",
      "Iteration 168, loss = 833.33829767\n",
      "Iteration 143, loss = 2471.81071846\n",
      "Iteration 118, loss = 851.46485337\n",
      "Iteration 76, loss = 920.97300098\n",
      "Iteration 169, loss = 2143.68605068\n",
      "Iteration 169, loss = 832.97163976\n",
      "Iteration 67, loss = 989.08647984\n",
      "Iteration 123, loss = 859.08519433\n",
      "Iteration 119, loss = 812.60027245\n",
      "Iteration 119, loss = 850.81370443\n",
      "Iteration 170, loss = 833.10099066\n",
      "Iteration 77, loss = 918.91890056\n",
      "Iteration 68, loss = 984.71326606\n",
      "Iteration 124, loss = 855.10743015\n",
      "Iteration 120, loss = 811.55301998\n",
      "Iteration 120, loss = 851.31727901\n",
      "Iteration 171, loss = 833.14262060\n",
      "Iteration 78, loss = 913.63947087\n",
      "Iteration 69, loss = 980.72001552\n",
      "Iteration 144, loss = 2463.28070096\n",
      "Iteration 125, loss = 855.09232577\n",
      "Iteration 121, loss = 807.63035587\n",
      "Iteration 172, loss = 831.73329808\n",
      "Iteration 121, loss = 848.59199481\n",
      "Iteration 170, loss = 2130.57821757\n",
      "Iteration 79, loss = 913.89056094\n",
      "Iteration 70, loss = 977.57650001\n",
      "Iteration 126, loss = 852.73645270\n",
      "Iteration 122, loss = 808.75994163\n",
      "Iteration 173, loss = 832.86586439\n",
      "Iteration 122, loss = 849.61605257\n",
      "Iteration 127, loss = 854.20393450\n",
      "Iteration 71, loss = 974.34068773\n",
      "Iteration 174, loss = 829.06427496\n",
      "Iteration 80, loss = 911.64257113\n",
      "Iteration 123, loss = 807.91601979\n",
      "Iteration 123, loss = 848.92000415\n",
      "Iteration 175, loss = 829.03261705\n",
      "Iteration 72, loss = 969.83922574\n",
      "Iteration 145, loss = 2441.39079185\n",
      "Iteration 128, loss = 851.48522371\n",
      "Iteration 81, loss = 907.29608771\n",
      "Iteration 124, loss = 806.49044183\n",
      "Iteration 124, loss = 846.75473800\n",
      "Iteration 176, loss = 830.40387998\n",
      "Iteration 129, loss = 850.48976007\n",
      "Iteration 171, loss = 2126.52792769\n",
      "Iteration 82, loss = 904.52304614\n",
      "Iteration 73, loss = 966.81018384\n",
      "Iteration 125, loss = 805.76206353\n",
      "Iteration 177, loss = 830.29809283\n",
      "Iteration 125, loss = 846.42875049\n",
      "Iteration 83, loss = 902.33774843\n",
      "Iteration 130, loss = 850.28132678\n",
      "Iteration 74, loss = 962.88295545\n",
      "Iteration 126, loss = 805.79136790\n",
      "Iteration 178, loss = 829.70787246\n",
      "Iteration 146, loss = 2432.99833669\n",
      "Iteration 84, loss = 901.21456836\n",
      "Iteration 126, loss = 846.70571931\n",
      "Iteration 131, loss = 848.19521206\n",
      "Iteration 75, loss = 959.68966742\n",
      "Iteration 179, loss = 828.75940971\n",
      "Iteration 127, loss = 803.95805850\n",
      "Iteration 172, loss = 2119.49590288\n",
      "Iteration 132, loss = 847.48651568\n",
      "Iteration 85, loss = 899.33853541\n",
      "Iteration 127, loss = 844.35186669\n",
      "Iteration 76, loss = 957.27261444\n",
      "Iteration 180, loss = 828.61061628\n",
      "Iteration 128, loss = 802.30580210\n",
      "Iteration 86, loss = 896.59572842\n",
      "Iteration 77, loss = 952.43453186\n",
      "Iteration 133, loss = 847.40310668\n",
      "Iteration 181, loss = 827.40427167\n",
      "Iteration 128, loss = 843.51208290\n",
      "Iteration 147, loss = 2410.41190275\n",
      "Iteration 129, loss = 802.91032857\n",
      "Iteration 87, loss = 895.25032270\n",
      "Iteration 182, loss = 826.44517837\n",
      "Iteration 134, loss = 846.65991327\n",
      "Iteration 78, loss = 950.09499897\n",
      "Iteration 129, loss = 842.65620378\n",
      "Iteration 130, loss = 802.36691389\n",
      "Iteration 183, loss = 827.35522504\n",
      "Iteration 173, loss = 2097.60734400\n",
      "Iteration 135, loss = 845.25603183\n",
      "Iteration 88, loss = 893.33501743\n",
      "Iteration 79, loss = 948.09570549\n",
      "Iteration 130, loss = 843.40492926\n",
      "Iteration 131, loss = 800.90938111\n",
      "Iteration 184, loss = 826.77003905\n",
      "Iteration 136, loss = 844.99763178\n",
      "Iteration 89, loss = 891.19152383\n",
      "Iteration 80, loss = 945.26640813\n",
      "Iteration 131, loss = 843.11964010\n",
      "Iteration 148, loss = 2398.09495612\n",
      "Iteration 185, loss = 828.34908105\n",
      "Iteration 132, loss = 798.15831815\n",
      "Iteration 137, loss = 842.49531909\n",
      "Iteration 90, loss = 888.10721286\n",
      "Iteration 81, loss = 941.07875269\n",
      "Iteration 186, loss = 825.17332048\n",
      "Iteration 132, loss = 839.36800200\n",
      "Iteration 133, loss = 798.69422507\n",
      "Iteration 138, loss = 843.20089920\n",
      "Iteration 91, loss = 885.40562756\n",
      "Iteration 174, loss = 2096.84821928\n",
      "Iteration 187, loss = 824.04307350\n",
      "Iteration 82, loss = 938.06307513\n",
      "Iteration 133, loss = 838.85978832\n",
      "Iteration 92, loss = 883.94136047\n",
      "Iteration 139, loss = 841.20643835\n",
      "Iteration 188, loss = 824.93542963\n",
      "Iteration 149, loss = 2389.83790712\n",
      "Iteration 134, loss = 796.62783839\n",
      "Iteration 83, loss = 936.13553450\n",
      "Iteration 134, loss = 838.78424005\n",
      "Iteration 140, loss = 839.88856960\n",
      "Iteration 189, loss = 825.56564222\n",
      "Iteration 93, loss = 881.49958600\n",
      "Iteration 84, loss = 933.04032372\n",
      "Iteration 135, loss = 796.84319926\n",
      "Iteration 135, loss = 837.28261869\n",
      "Iteration 175, loss = 2085.99507323\n",
      "Iteration 94, loss = 879.67459730\n",
      "Iteration 141, loss = 840.31646421\n",
      "Iteration 190, loss = 826.63088596\n",
      "Iteration 136, loss = 838.01421959\n",
      "Iteration 85, loss = 931.02767885\n",
      "Iteration 136, loss = 796.37969649\n",
      "Iteration 150, loss = 2374.36071142\n",
      "Iteration 191, loss = 823.45076122\n",
      "Iteration 142, loss = 838.57645414\n",
      "Iteration 95, loss = 876.16343857\n",
      "Iteration 137, loss = 838.88126001\n",
      "Iteration 86, loss = 928.67929344\n",
      "Iteration 137, loss = 796.19342556\n",
      "Iteration 143, loss = 838.31725449\n",
      "Iteration 192, loss = 825.01574568\n",
      "Iteration 96, loss = 878.22740714\n",
      "Iteration 138, loss = 836.06504362\n",
      "Iteration 176, loss = 2064.57589014\n",
      "Iteration 87, loss = 927.06932947\n",
      "Iteration 193, loss = 823.77535874\n",
      "Iteration 144, loss = 837.68912595\n",
      "Iteration 138, loss = 795.43714814\n",
      "Iteration 97, loss = 873.30461046\n",
      "Iteration 139, loss = 837.01112296\n",
      "Iteration 151, loss = 2365.31473366\n",
      "Iteration 145, loss = 837.72544217\n",
      "Iteration 88, loss = 924.16305561\n",
      "Iteration 194, loss = 825.97077649\n",
      "Iteration 98, loss = 870.54840895\n",
      "Iteration 140, loss = 836.27898560\n",
      "Iteration 139, loss = 795.74265606\n",
      "Iteration 146, loss = 836.45140364\n",
      "Iteration 89, loss = 922.39440184\n",
      "Iteration 195, loss = 823.89968838\n",
      "Iteration 141, loss = 835.13520704\n",
      "Iteration 99, loss = 869.28590622\n",
      "Iteration 177, loss = 2060.75798189\n",
      "Iteration 140, loss = 794.56611304\n",
      "Iteration 90, loss = 919.92441643\n",
      "Iteration 147, loss = 835.67702240\n",
      "Iteration 196, loss = 823.66351733\n",
      "Iteration 142, loss = 834.15565099\n",
      "Iteration 100, loss = 868.14799502\n",
      "Iteration 152, loss = 2348.22144384\n",
      "Iteration 141, loss = 793.94856024\n",
      "Iteration 148, loss = 835.00954681\n",
      "Iteration 91, loss = 916.43037922\n",
      "Iteration 197, loss = 822.34890829\n",
      "Iteration 143, loss = 832.97300948\n",
      "Iteration 101, loss = 866.08639797\n",
      "Iteration 142, loss = 792.22923509\n",
      "Iteration 149, loss = 833.57340533\n",
      "Iteration 198, loss = 824.23206125\n",
      "Iteration 92, loss = 913.98711797\n",
      "Iteration 144, loss = 832.42762322\n",
      "Iteration 178, loss = 2049.97027871\n",
      "Iteration 102, loss = 864.77809357\n",
      "Iteration 153, loss = 2337.67085697\n",
      "Iteration 199, loss = 822.25892699\n",
      "Iteration 143, loss = 790.52139123\n",
      "Iteration 150, loss = 832.27768936\n",
      "Iteration 93, loss = 912.11981722\n",
      "Iteration 145, loss = 831.99677195\n",
      "Iteration 103, loss = 863.18718318\n",
      "Iteration 200, loss = 823.44394429\n",
      "Iteration 144, loss = 791.04448626\n",
      "Iteration 151, loss = 833.58815377\n",
      "Iteration 146, loss = 832.91255129\n",
      "Iteration 94, loss = 909.19875359\n",
      "Iteration 104, loss = 859.74469915\n",
      "Iteration 179, loss = 2040.22451496\n",
      "Iteration 201, loss = 821.95738057\n",
      "Iteration 152, loss = 833.22388013\n",
      "Iteration 147, loss = 831.21374623\n",
      "Iteration 145, loss = 790.67493216\n",
      "Iteration 95, loss = 907.38460598\n",
      "Iteration 105, loss = 860.14778119\n",
      "Iteration 154, loss = 2326.90958501\n",
      "Iteration 202, loss = 822.10447586\n",
      "Iteration 148, loss = 831.97390853\n",
      "Iteration 153, loss = 833.31168129\n",
      "Iteration 96, loss = 907.29255504\n",
      "Iteration 106, loss = 857.70137363\n",
      "Iteration 146, loss = 790.42171688\n",
      "Iteration 203, loss = 821.98671124\n",
      "Iteration 149, loss = 831.61816710\n",
      "Iteration 154, loss = 831.69469803\n",
      "Iteration 107, loss = 857.07604431\n",
      "Iteration 97, loss = 903.49436947\n",
      "Iteration 147, loss = 788.19277049\n",
      "Iteration 204, loss = 820.43156819\n",
      "Iteration 150, loss = 829.53161811\n",
      "Iteration 180, loss = 2024.69100938\n",
      "Iteration 155, loss = 2316.45395314\n",
      "Iteration 155, loss = 830.59508716\n",
      "Iteration 108, loss = 855.27318427\n",
      "Iteration 98, loss = 899.75159809\n",
      "Iteration 205, loss = 820.90906024\n",
      "Iteration 148, loss = 790.82189585\n",
      "Iteration 151, loss = 830.21688281\n",
      "Iteration 156, loss = 830.32397618\n",
      "Iteration 109, loss = 851.69943503\n",
      "Iteration 99, loss = 898.84003835\n",
      "Iteration 206, loss = 820.90637991\n",
      "Iteration 152, loss = 827.68233152\n",
      "Iteration 149, loss = 789.44336045\n",
      "Iteration 110, loss = 850.29730665\n",
      "Iteration 157, loss = 830.03812507\n",
      "Iteration 100, loss = 898.20875637\n",
      "Iteration 156, loss = 2301.86634873\n",
      "Iteration 181, loss = 2015.52877902\n",
      "Iteration 153, loss = 826.17099026\n",
      "Iteration 207, loss = 821.82475764\n",
      "Iteration 150, loss = 787.68161789\n",
      "Iteration 111, loss = 850.13224813\n",
      "Iteration 158, loss = 827.51726096\n",
      "Iteration 101, loss = 895.08381348\n",
      "Iteration 154, loss = 828.94183164\n",
      "Iteration 208, loss = 820.72311308\n",
      "Iteration 112, loss = 848.76026345\n",
      "Iteration 159, loss = 827.18090361\n",
      "Iteration 151, loss = 789.20929789\n",
      "Iteration 102, loss = 893.83121007\n",
      "Iteration 155, loss = 828.44302038\n",
      "Iteration 209, loss = 821.56703412\n",
      "Iteration 113, loss = 848.82003989\n",
      "Iteration 157, loss = 2287.09908494\n",
      "Iteration 160, loss = 828.46548518\n",
      "Iteration 182, loss = 2008.25566703\n",
      "Iteration 103, loss = 892.04814517\n",
      "Iteration 152, loss = 787.59722258\n",
      "Iteration 210, loss = 818.90722755\n",
      "Iteration 156, loss = 826.52900633\n",
      "Iteration 114, loss = 844.77460653\n",
      "Iteration 161, loss = 828.30377660\n",
      "Iteration 211, loss = 819.11961072\n",
      "Iteration 104, loss = 888.87154681\n",
      "Iteration 153, loss = 785.80487225\n",
      "Iteration 157, loss = 828.95140181\n",
      "Iteration 115, loss = 844.70309521\n",
      "Iteration 162, loss = 826.97745238\n",
      "Iteration 212, loss = 818.52653537\n",
      "Iteration 105, loss = 888.79931815\n",
      "Iteration 158, loss = 826.75405966\n",
      "Iteration 154, loss = 786.53320326\n",
      "Iteration 158, loss = 2281.16027968\n",
      "Iteration 116, loss = 842.89162059\n",
      "Iteration 183, loss = 1999.53730522\n",
      "Iteration 163, loss = 827.99474771\n",
      "Iteration 159, loss = 827.04699438\n",
      "Iteration 213, loss = 820.55871411\n",
      "Iteration 106, loss = 886.39749425\n",
      "Iteration 155, loss = 786.50094590\n",
      "Iteration 117, loss = 841.61475476\n",
      "Iteration 164, loss = 822.20888448\n",
      "Iteration 214, loss = 819.87759707\n",
      "Iteration 160, loss = 825.00017695\n",
      "Iteration 107, loss = 885.43739405\n",
      "Iteration 118, loss = 839.42560733\n",
      "Iteration 156, loss = 785.65649279\n",
      "Iteration 215, loss = 817.40966152\n",
      "Iteration 159, loss = 2269.21177582\n",
      "Iteration 165, loss = 826.28844826\n",
      "Iteration 161, loss = 823.95963987\n",
      "Iteration 108, loss = 881.81242899\n",
      "Iteration 184, loss = 1985.64908948\n",
      "Iteration 119, loss = 838.02546103\n",
      "Iteration 216, loss = 819.47773128\n",
      "Iteration 157, loss = 787.23831748\n",
      "Iteration 166, loss = 824.21260179\n",
      "Iteration 162, loss = 824.26319691\n",
      "Iteration 109, loss = 879.21343181\n",
      "Iteration 120, loss = 839.12593849\n",
      "Iteration 217, loss = 818.35420416\n",
      "Iteration 163, loss = 823.72611852\n",
      "Iteration 167, loss = 825.93144312\n",
      "Iteration 158, loss = 785.46018150\n",
      "Iteration 121, loss = 834.63987359\n",
      "Iteration 110, loss = 877.67709448\n",
      "Iteration 160, loss = 2250.41941968\n",
      "Iteration 218, loss = 817.30540543\n",
      "Iteration 164, loss = 825.58605421\n",
      "Iteration 168, loss = 825.22905051\n",
      "Iteration 185, loss = 1977.67994531\n",
      "Iteration 111, loss = 877.70981528\n",
      "Iteration 122, loss = 836.97297032\n",
      "Iteration 159, loss = 784.45307353\n",
      "Iteration 219, loss = 817.92105753\n",
      "Iteration 165, loss = 822.14263774\n",
      "Iteration 169, loss = 824.90429085\n",
      "Iteration 112, loss = 875.72183148\n",
      "Iteration 123, loss = 834.36212717\n",
      "Iteration 160, loss = 782.85069013\n",
      "Iteration 220, loss = 816.08438646\n",
      "Iteration 166, loss = 823.82457519\n",
      "Iteration 161, loss = 2230.68736267\n",
      "Iteration 170, loss = 824.35189650\n",
      "Iteration 124, loss = 833.11919737\n",
      "Iteration 113, loss = 875.96089423\n",
      "Iteration 161, loss = 783.06179278\n",
      "Iteration 221, loss = 816.39573236\n",
      "Iteration 186, loss = 1974.91437318\n",
      "Iteration 167, loss = 823.12023412\n",
      "Iteration 171, loss = 825.04443534\n",
      "Iteration 125, loss = 831.57318012\n",
      "Iteration 114, loss = 872.83835387\n",
      "Iteration 162, loss = 783.09693495\n",
      "Iteration 222, loss = 816.71477428\n",
      "Iteration 168, loss = 822.33750212\n",
      "Iteration 172, loss = 822.93522869\n",
      "Iteration 126, loss = 832.47606480\n",
      "Iteration 115, loss = 872.31123902\n",
      "Iteration 162, loss = 2226.23808142\n",
      "Iteration 223, loss = 816.26803829\n",
      "Iteration 163, loss = 781.89615057\n",
      "Iteration 169, loss = 822.37182347\n",
      "Iteration 127, loss = 830.27346176\n",
      "Iteration 173, loss = 824.31301532\n",
      "Iteration 116, loss = 870.73106418\n",
      "Iteration 224, loss = 815.86633016\n",
      "Iteration 187, loss = 1958.06687073\n",
      "Iteration 170, loss = 822.21718815\n",
      "Iteration 164, loss = 782.37882240\n",
      "Iteration 128, loss = 828.80880688\n",
      "Iteration 174, loss = 821.60355888\n",
      "Iteration 117, loss = 868.61255334\n",
      "Iteration 225, loss = 818.30276549\n",
      "Iteration 171, loss = 822.35912578\n",
      "Iteration 165, loss = 779.84213875\n",
      "Iteration 163, loss = 2220.85576405\n",
      "Iteration 129, loss = 828.95950413\n",
      "Iteration 175, loss = 820.40715751\n",
      "Iteration 118, loss = 867.22472556\n",
      "Iteration 226, loss = 817.15073789\n",
      "Iteration 172, loss = 820.78616392\n",
      "Iteration 130, loss = 826.97363885\n",
      "Iteration 166, loss = 782.78912954\n",
      "Iteration 188, loss = 1957.50017615\n",
      "Iteration 176, loss = 822.09538483\n",
      "Iteration 119, loss = 865.32795246\n",
      "Iteration 227, loss = 814.90370138\n",
      "Iteration 173, loss = 822.15256270\n",
      "Iteration 131, loss = 827.10209603\n",
      "Iteration 167, loss = 780.82793919\n",
      "Iteration 177, loss = 821.44559490\n",
      "Iteration 228, loss = 814.36633469\n",
      "Iteration 164, loss = 2206.00146265\n",
      "Iteration 174, loss = 820.88179722\n",
      "Iteration 120, loss = 867.51341061\n",
      "Iteration 132, loss = 823.02260423\n",
      "Iteration 229, loss = 815.81270236\n",
      "Iteration 178, loss = 820.58553435\n",
      "Iteration 175, loss = 819.39270002\n",
      "Iteration 168, loss = 780.53753518\n",
      "Iteration 189, loss = 1941.27841526\n",
      "Iteration 121, loss = 862.26988960\n",
      "Iteration 133, loss = 822.83262952\n",
      "Iteration 179, loss = 821.55031556\n",
      "Iteration 230, loss = 815.33797330\n",
      "Iteration 176, loss = 817.68487235\n",
      "Iteration 165, loss = 2193.81453131\n",
      "Iteration 134, loss = 823.01535328\n",
      "Iteration 169, loss = 781.31028860\n",
      "Iteration 122, loss = 864.96427163\n",
      "Iteration 231, loss = 815.63752035\n",
      "Iteration 180, loss = 819.35572265\n",
      "Iteration 177, loss = 819.24391021\n",
      "Iteration 135, loss = 822.81581554\n",
      "Iteration 123, loss = 862.16403265\n",
      "Iteration 170, loss = 780.57217018\n",
      "Iteration 190, loss = 1929.79515888\n",
      "Iteration 181, loss = 819.26431545\n",
      "Iteration 232, loss = 815.29186978\n",
      "Iteration 178, loss = 818.47791944\n",
      "Iteration 136, loss = 821.41290379\n",
      "Iteration 124, loss = 861.59651514\n",
      "Iteration 233, loss = 814.07141033\n",
      "Iteration 166, loss = 2192.85191429\n",
      "Iteration 171, loss = 781.42383524\n",
      "Iteration 182, loss = 817.64346141\n",
      "Iteration 179, loss = 818.64581425\n",
      "Iteration 137, loss = 821.15849626\n",
      "Iteration 125, loss = 859.48900271\n",
      "Iteration 234, loss = 815.07234199\n",
      "Iteration 180, loss = 818.98661765\n",
      "Iteration 183, loss = 819.82994448\n",
      "Iteration 172, loss = 780.49247448\n",
      "Iteration 138, loss = 819.19155657\n",
      "Iteration 191, loss = 1930.51414966\n",
      "Iteration 235, loss = 814.67256907\n",
      "Iteration 126, loss = 859.79442116\n",
      "Iteration 181, loss = 817.05724245\n",
      "Iteration 184, loss = 816.65539846\n",
      "Iteration 173, loss = 780.28667285\n",
      "Iteration 167, loss = 2166.67220402\n",
      "Iteration 139, loss = 821.04866287\n",
      "Iteration 182, loss = 816.29689845\n",
      "Iteration 236, loss = 812.77305880\n",
      "Iteration 127, loss = 858.97853745\n",
      "Iteration 185, loss = 819.50354610\n",
      "Iteration 140, loss = 820.33426706\n",
      "Iteration 174, loss = 778.88263585\n",
      "Iteration 183, loss = 816.31805844\n",
      "Iteration 237, loss = 814.86350441\n",
      "Iteration 128, loss = 857.43209389\n",
      "Iteration 186, loss = 817.72732359\n",
      "Iteration 141, loss = 817.50577613\n",
      "Iteration 192, loss = 1916.07969533\n",
      "Iteration 175, loss = 777.99232944\n",
      "Iteration 184, loss = 818.59691642\n",
      "Iteration 238, loss = 812.93932245\n",
      "Iteration 129, loss = 856.95085756\n",
      "Iteration 168, loss = 2160.65288029\n",
      "Iteration 187, loss = 816.16485205\n",
      "Iteration 142, loss = 817.82877232\n",
      "Iteration 176, loss = 776.98265165\n",
      "Iteration 185, loss = 815.09631005\n",
      "Iteration 239, loss = 813.85050744\n",
      "Iteration 130, loss = 855.71726291\n",
      "Iteration 143, loss = 815.45551487\n",
      "Iteration 188, loss = 816.88980679\n",
      "Iteration 240, loss = 813.43444022\n",
      "Iteration 186, loss = 816.16903506\n",
      "Iteration 177, loss = 778.38724464\n",
      "Iteration 131, loss = 854.65651918\n",
      "Iteration 193, loss = 1921.80832314\n",
      "Iteration 144, loss = 814.38057316\n",
      "Iteration 189, loss = 817.02911137\n",
      "Iteration 241, loss = 813.31501299\n",
      "Iteration 187, loss = 815.37930136\n",
      "Iteration 169, loss = 2147.91298003\n",
      "Iteration 178, loss = 776.25929292\n",
      "Iteration 132, loss = 852.64974859\n",
      "Iteration 145, loss = 813.76985956\n",
      "Iteration 190, loss = 818.52507541\n",
      "Iteration 242, loss = 812.41879593\n",
      "Iteration 188, loss = 815.64496926\n",
      "Iteration 133, loss = 850.84171536\n",
      "Iteration 179, loss = 778.41287433\n",
      "Iteration 146, loss = 814.93043578\n",
      "Iteration 243, loss = 811.80235264\n",
      "Iteration 191, loss = 815.65983230\n",
      "Iteration 189, loss = 815.82789318\n",
      "Iteration 194, loss = 1917.85447208\n",
      "Iteration 134, loss = 852.14755112\n",
      "Iteration 147, loss = 812.95494821\n",
      "Iteration 170, loss = 2134.45318478\n",
      "Iteration 244, loss = 812.11021345\n",
      "Iteration 180, loss = 778.31191158\n",
      "Iteration 192, loss = 816.62528949\n",
      "Iteration 190, loss = 816.00473279\n",
      "Iteration 135, loss = 850.33845820\n",
      "Iteration 245, loss = 812.07393617\n",
      "Iteration 148, loss = 812.97616760\n",
      "Iteration 181, loss = 776.34800490\n",
      "Iteration 191, loss = 815.10459820\n",
      "Iteration 193, loss = 815.68180918\n",
      "Iteration 136, loss = 850.19267917\n",
      "Iteration 246, loss = 812.70041791\n",
      "Iteration 182, loss = 775.05997542\n",
      "Iteration 149, loss = 811.88933271\n",
      "Iteration 195, loss = 1903.19882846\n",
      "Iteration 192, loss = 813.98865969\n",
      "Iteration 194, loss = 817.29222927\n",
      "Iteration 171, loss = 2132.40112231\n",
      "Iteration 137, loss = 848.44616040\n",
      "Iteration 247, loss = 812.47857667\n",
      "Iteration 150, loss = 811.02002598\n",
      "Iteration 183, loss = 775.81116487\n",
      "Iteration 195, loss = 816.86517300\n",
      "Iteration 193, loss = 814.50592995\n",
      "Iteration 138, loss = 848.74298405\n",
      "Iteration 248, loss = 812.18540638\n",
      "Iteration 151, loss = 810.27149728\n",
      "Iteration 184, loss = 778.76403874\n",
      "Iteration 194, loss = 811.85644983\n",
      "Iteration 196, loss = 815.63327111\n",
      "Iteration 139, loss = 848.62197896\n",
      "Iteration 152, loss = 808.83931834\n",
      "Iteration 249, loss = 811.73043227\n",
      "Iteration 196, loss = 1889.14616737\n",
      "Iteration 185, loss = 774.85881236\n",
      "Iteration 172, loss = 2118.13961794\n",
      "Iteration 195, loss = 812.47344133\n",
      "Iteration 197, loss = 814.47091829\n",
      "Iteration 153, loss = 808.59702204\n",
      "Iteration 250, loss = 809.81286588\n",
      "Iteration 140, loss = 847.86767955\n",
      "Iteration 196, loss = 813.09585452\n",
      "Iteration 198, loss = 815.69646018\n",
      "Iteration 186, loss = 776.79565217\n",
      "Iteration 154, loss = 809.11974508\n",
      "Iteration 251, loss = 811.19363531\n",
      "Iteration 141, loss = 844.66793050\n",
      "Iteration 197, loss = 812.37520800\n",
      "Iteration 199, loss = 814.21344401\n",
      "Iteration 197, loss = 1875.88968760\n",
      "Iteration 187, loss = 775.16436328\n",
      "Iteration 155, loss = 809.27089999\n",
      "Iteration 252, loss = 810.08211498\n",
      "Iteration 142, loss = 846.11067186\n",
      "Iteration 173, loss = 2107.75903771\n",
      "Iteration 198, loss = 812.26195870\n",
      "Iteration 200, loss = 813.82214918\n",
      "Iteration 253, loss = 809.96955823\n",
      "Iteration 188, loss = 774.81809119Iteration 156, loss = 806.86666755\n",
      "\n",
      "Iteration 143, loss = 844.66447706\n",
      "Iteration 199, loss = 810.89141030\n",
      "Iteration 254, loss = 809.98098214\n",
      "Iteration 157, loss = 807.74996726\n",
      "Iteration 201, loss = 814.26263504\n",
      "Iteration 189, loss = 775.42340738\n",
      "Iteration 144, loss = 843.93382535\n",
      "Iteration 200, loss = 811.57891639\n",
      "Iteration 198, loss = 1867.75911709\n",
      "Iteration 174, loss = 2111.14836060\n",
      "Iteration 255, loss = 809.02139659\n",
      "Iteration 158, loss = 805.57504863\n",
      "Iteration 202, loss = 814.40646612\n",
      "Iteration 145, loss = 843.08885387\n",
      "Iteration 190, loss = 775.24341614\n",
      "Iteration 201, loss = 810.66838298\n",
      "Iteration 159, loss = 807.24918090\n",
      "Iteration 256, loss = 808.91616799\n",
      "Iteration 146, loss = 842.28626698\n",
      "Iteration 203, loss = 814.60702280\n",
      "Iteration 191, loss = 774.47809867\n",
      "Iteration 202, loss = 811.48063981\n",
      "Iteration 160, loss = 804.96520564\n",
      "Iteration 257, loss = 811.58249442\n",
      "Iteration 147, loss = 842.34500594\n",
      "Iteration 204, loss = 811.88905122\n",
      "Iteration 175, loss = 2089.84509338\n",
      "Iteration 199, loss = 1861.24987444\n",
      "Iteration 192, loss = 773.91838665\n",
      "Iteration 203, loss = 810.68484165\n",
      "Iteration 161, loss = 804.44933342\n",
      "Iteration 258, loss = 809.68507686\n",
      "Iteration 148, loss = 840.95192683\n",
      "Iteration 205, loss = 813.02605835\n",
      "Iteration 204, loss = 810.38363616\n",
      "Iteration 193, loss = 775.55683294\n",
      "Iteration 162, loss = 803.37118785\n",
      "Iteration 259, loss = 808.64313426\n",
      "Iteration 149, loss = 839.26563146\n",
      "Iteration 206, loss = 812.99618257\n",
      "Iteration 205, loss = 811.08961833\n",
      "Iteration 163, loss = 802.88861068\n",
      "Iteration 194, loss = 772.33925847\n",
      "Iteration 200, loss = 1859.91480151\n",
      "Iteration 260, loss = 809.64265813\n",
      "Iteration 150, loss = 839.88698252\n",
      "Iteration 176, loss = 2077.60030005\n",
      "Iteration 207, loss = 813.67611254\n",
      "Iteration 206, loss = 809.62690778\n",
      "Iteration 164, loss = 805.79514301\n",
      "Iteration 195, loss = 772.84470728\n",
      "Iteration 261, loss = 810.05948459\n",
      "Iteration 151, loss = 837.77629288\n",
      "Iteration 208, loss = 811.99185895\n",
      "Iteration 207, loss = 808.24419855\n",
      "Iteration 165, loss = 800.93486857\n",
      "Iteration 262, loss = 807.83956194\n",
      "Iteration 196, loss = 774.99787901\n",
      "Iteration 208, loss = 808.14326545\n",
      "Iteration 209, loss = 813.02743913\n",
      "Iteration 152, loss = 836.72048389\n",
      "Iteration 166, loss = 801.12929564\n",
      "Iteration 201, loss = 1850.93086047\n",
      "Iteration 263, loss = 810.17402921\n",
      "Iteration 197, loss = 773.26697421\n",
      "Iteration 177, loss = 2065.28481262\n",
      "Iteration 209, loss = 807.56307809\n",
      "Iteration 153, loss = 836.66629296\n",
      "Iteration 210, loss = 810.90128289\n",
      "Iteration 167, loss = 802.71944118\n",
      "Iteration 264, loss = 808.50008912\n",
      "Iteration 198, loss = 773.02612640\n",
      "Iteration 210, loss = 808.50526277\n",
      "Iteration 211, loss = 810.66571689\n",
      "Iteration 154, loss = 838.40272889\n",
      "Iteration 168, loss = 801.10212976\n",
      "Iteration 265, loss = 807.23945611\n",
      "Iteration 211, loss = 806.52576017\n",
      "Iteration 199, loss = 770.92249398\n",
      "Iteration 155, loss = 837.07644275\n",
      "Iteration 202, loss = 1842.14015472\n",
      "Iteration 169, loss = 800.91879694\n",
      "Iteration 212, loss = 810.00242146\n",
      "Iteration 178, loss = 2052.64682400\n",
      "Iteration 266, loss = 808.21751965\n",
      "Iteration 212, loss = 807.61256808\n",
      "Iteration 170, loss = 798.56025501\n",
      "Iteration 156, loss = 835.39908145\n",
      "Iteration 200, loss = 772.66643990\n",
      "Iteration 213, loss = 812.44506198\n",
      "Iteration 267, loss = 805.82387063\n",
      "Iteration 213, loss = 807.84075578\n",
      "Iteration 171, loss = 800.13803421\n",
      "Iteration 214, loss = 812.47899316\n",
      "Iteration 157, loss = 835.77830924\n",
      "Iteration 201, loss = 771.98251605\n",
      "Iteration 268, loss = 805.31288515\n",
      "Iteration 214, loss = 807.86717468\n",
      "Iteration 203, loss = 1831.80319257\n",
      "Iteration 179, loss = 2057.50138925\n",
      "Iteration 172, loss = 799.48948778\n",
      "Iteration 158, loss = 833.83378270\n",
      "Iteration 215, loss = 809.56586039\n",
      "Iteration 269, loss = 805.97474451\n",
      "Iteration 215, loss = 807.28753723\n",
      "Iteration 202, loss = 771.81996055\n",
      "Iteration 173, loss = 798.56254163\n",
      "Iteration 159, loss = 836.93547262\n",
      "Iteration 216, loss = 811.18965572\n",
      "Iteration 270, loss = 805.94930284\n",
      "Iteration 216, loss = 805.93693779\n",
      "Iteration 203, loss = 771.95288516\n",
      "Iteration 174, loss = 799.37533844\n",
      "Iteration 217, loss = 809.55055982\n",
      "Iteration 160, loss = 834.15475532\n",
      "Iteration 217, loss = 805.99568502\n",
      "Iteration 271, loss = 806.54835447\n",
      "Iteration 180, loss = 2038.78738616\n",
      "Iteration 204, loss = 1823.30062104\n",
      "Iteration 204, loss = 771.67141679\n",
      "Iteration 175, loss = 797.86129550\n",
      "Iteration 161, loss = 832.76018630\n",
      "Iteration 218, loss = 808.37150559\n",
      "Iteration 218, loss = 805.04598385\n",
      "Iteration 272, loss = 806.16590885\n",
      "Iteration 205, loss = 771.73777893\n",
      "Iteration 176, loss = 795.60345706\n",
      "Iteration 219, loss = 805.29903578\n",
      "Iteration 219, loss = 809.94424193\n",
      "Iteration 162, loss = 831.47663041\n",
      "Iteration 273, loss = 807.10389593\n",
      "Iteration 177, loss = 797.87365000\n",
      "Iteration 206, loss = 769.97819959\n",
      "Iteration 181, loss = 2027.42648577\n",
      "Iteration 205, loss = 1811.21275563\n",
      "Iteration 163, loss = 831.80366922\n",
      "Iteration 274, loss = 805.85498331\n",
      "Iteration 220, loss = 805.62877654\n",
      "Iteration 220, loss = 808.60584117\n",
      "Iteration 178, loss = 795.48821130\n",
      "Iteration 221, loss = 804.40495397\n",
      "Iteration 207, loss = 771.00327773\n",
      "Iteration 275, loss = 806.02443330\n",
      "Iteration 164, loss = 833.14386743\n",
      "Iteration 221, loss = 808.29798664\n",
      "Iteration 179, loss = 795.55545459\n",
      "Iteration 222, loss = 802.82543875\n",
      "Iteration 276, loss = 804.63784701\n",
      "Iteration 165, loss = 830.98312693\n",
      "Iteration 208, loss = 768.43869931\n",
      "Iteration 222, loss = 808.79019740\n",
      "Iteration 182, loss = 2022.84871939\n",
      "Iteration 180, loss = 796.68077390\n",
      "Iteration 206, loss = 1820.81301957\n",
      "Iteration 223, loss = 808.10868296\n",
      "Iteration 277, loss = 805.96949401\n",
      "Iteration 166, loss = 830.33589537\n",
      "Iteration 209, loss = 769.24255319\n",
      "Iteration 223, loss = 807.93271040\n",
      "Iteration 181, loss = 795.11429652\n",
      "Iteration 224, loss = 803.97775116\n",
      "Iteration 167, loss = 830.93830944\n",
      "Iteration 278, loss = 804.75220306\n",
      "Iteration 182, loss = 793.89961202\n",
      "Iteration 224, loss = 807.73241753\n",
      "Iteration 210, loss = 770.78541900\n",
      "Iteration 225, loss = 805.00826421\n",
      "Iteration 279, loss = 806.94640938\n",
      "Iteration 183, loss = 2015.81956293\n",
      "Iteration 168, loss = 830.17440797\n",
      "Iteration 183, loss = 793.93364903\n",
      "Iteration 225, loss = 809.65138984\n",
      "Iteration 207, loss = 1798.03809633\n",
      "Iteration 211, loss = 768.11151249\n",
      "Iteration 226, loss = 803.78473700\n",
      "Iteration 280, loss = 804.57312703\n",
      "Iteration 184, loss = 794.44946472\n",
      "Iteration 169, loss = 830.81506392\n",
      "Iteration 226, loss = 807.89849380\n",
      "Iteration 227, loss = 802.67855054\n",
      "Iteration 212, loss = 770.18586737\n",
      "Iteration 281, loss = 806.26688333\n",
      "Iteration 185, loss = 791.85055423\n",
      "Iteration 170, loss = 828.32737887\n",
      "Iteration 228, loss = 803.56924656\n",
      "Iteration 227, loss = 807.34655628\n",
      "Iteration 184, loss = 2001.89117350\n",
      "Iteration 282, loss = 805.62482278\n",
      "Iteration 213, loss = 768.91179809\n",
      "Iteration 208, loss = 1791.20665104\n",
      "Iteration 186, loss = 792.57166679\n",
      "Iteration 229, loss = 803.02358419\n",
      "Iteration 171, loss = 829.45219114\n",
      "Iteration 228, loss = 807.13695844\n",
      "Iteration 283, loss = 805.41956138\n",
      "Iteration 230, loss = 802.67580225\n",
      "Iteration 187, loss = 792.09252964\n",
      "Iteration 214, loss = 769.63755666\n",
      "Iteration 172, loss = 828.33942487\n",
      "Iteration 229, loss = 807.35808450\n",
      "Iteration 284, loss = 804.49684939\n",
      "Iteration 231, loss = 803.32322445\n",
      "Iteration 185, loss = 1986.23525275\n",
      "Iteration 188, loss = 791.41308738\n",
      "Iteration 215, loss = 769.44143104\n",
      "Iteration 173, loss = 826.51410729\n",
      "Iteration 285, loss = 803.76818243\n",
      "Iteration 230, loss = 807.21463237\n",
      "Iteration 209, loss = 1781.87518838\n",
      "Iteration 232, loss = 803.26044985\n",
      "Iteration 189, loss = 791.63669104\n",
      "Iteration 174, loss = 828.43052133\n",
      "Iteration 216, loss = 768.90377589\n",
      "Iteration 286, loss = 804.34702703\n",
      "Iteration 231, loss = 808.08106846\n",
      "Iteration 233, loss = 803.74280440\n",
      "Iteration 190, loss = 791.99818920\n",
      "Iteration 175, loss = 826.89268041\n",
      "Iteration 217, loss = 769.11067952\n",
      "Iteration 287, loss = 803.60884194\n",
      "Iteration 186, loss = 1990.52187938\n",
      "Iteration 232, loss = 806.42243932\n",
      "Iteration 234, loss = 803.25223719\n",
      "Iteration 191, loss = 791.02032939\n",
      "Iteration 176, loss = 825.63425381\n",
      "Iteration 210, loss = 1772.34365008\n",
      "Iteration 288, loss = 802.94218043\n",
      "Iteration 235, loss = 802.66328844\n",
      "Iteration 218, loss = 767.31123109\n",
      "Iteration 233, loss = 804.13179742\n",
      "Iteration 192, loss = 790.11877329\n",
      "Iteration 177, loss = 826.65588433\n",
      "Iteration 289, loss = 803.21427677\n",
      "Iteration 236, loss = 801.67445748\n",
      "Iteration 234, loss = 807.05821545\n",
      "Iteration 193, loss = 791.22050181\n",
      "Iteration 219, loss = 766.63488303\n",
      "Iteration 187, loss = 1987.82964645\n",
      "Iteration 290, loss = 802.78160877\n",
      "Iteration 178, loss = 823.95308647\n",
      "Iteration 237, loss = 802.51446976\n",
      "Iteration 235, loss = 806.05378744\n",
      "Iteration 194, loss = 788.59993573\n",
      "Iteration 220, loss = 767.66014482\n",
      "Iteration 291, loss = 801.62725033\n",
      "Iteration 211, loss = 1764.34600200\n",
      "Iteration 179, loss = 824.97956053\n",
      "Iteration 238, loss = 802.39806998\n",
      "Iteration 195, loss = 788.75245713\n",
      "Iteration 236, loss = 804.50546129\n",
      "Iteration 292, loss = 803.09566962\n",
      "Iteration 239, loss = 801.58957896\n",
      "Iteration 221, loss = 766.86396483\n",
      "Iteration 180, loss = 824.70419649\n",
      "Iteration 188, loss = 1964.98883553\n",
      "Iteration 237, loss = 806.58262508\n",
      "Iteration 196, loss = 789.94836651\n",
      "Iteration 293, loss = 802.78155779\n",
      "Iteration 240, loss = 800.81046897\n",
      "Iteration 222, loss = 766.07455304\n",
      "Iteration 181, loss = 823.88076688\n",
      "Iteration 294, loss = 804.43730663\n",
      "Iteration 238, loss = 803.88189963\n",
      "Iteration 197, loss = 788.88259953\n",
      "Iteration 212, loss = 1769.56946121\n",
      "Iteration 241, loss = 802.57222091\n",
      "Iteration 223, loss = 768.24095990\n",
      "Iteration 182, loss = 822.46288695\n",
      "Iteration 295, loss = 799.74958958\n",
      "Iteration 198, loss = 788.67640684\n",
      "Iteration 239, loss = 805.65120373\n",
      "Iteration 189, loss = 1951.32866047\n",
      "Iteration 242, loss = 802.13775393\n",
      "Iteration 224, loss = 766.55915537\n",
      "Iteration 183, loss = 823.42921417\n",
      "Iteration 296, loss = 804.24819703\n",
      "Iteration 240, loss = 805.20952713\n",
      "Iteration 199, loss = 787.09014303\n",
      "Iteration 243, loss = 801.71702251\n",
      "Iteration 184, loss = 823.92056626\n",
      "Iteration 213, loss = 1775.17489798\n",
      "Iteration 297, loss = 802.75165508\n",
      "Iteration 225, loss = 767.92645504\n",
      "Iteration 241, loss = 805.05467076\n",
      "Iteration 200, loss = 787.89496725\n",
      "Iteration 244, loss = 800.80108981\n",
      "Iteration 298, loss = 803.33190894\n",
      "Iteration 190, loss = 1946.25874670\n",
      "Iteration 185, loss = 819.80523699\n",
      "Iteration 242, loss = 803.87058372\n",
      "Iteration 201, loss = 788.03664026\n",
      "Iteration 226, loss = 766.37648056\n",
      "Iteration 245, loss = 797.10955508\n",
      "Iteration 299, loss = 801.46676938\n",
      "Iteration 186, loss = 821.61935389\n",
      "Iteration 243, loss = 804.52212091\n",
      "Iteration 202, loss = 788.20735621\n",
      "Iteration 246, loss = 802.10124812\n",
      "Iteration 227, loss = 765.14054170\n",
      "Iteration 214, loss = 1767.34498727\n",
      "Iteration 187, loss = 821.44519098\n",
      "Iteration 300, loss = 801.60032475\n",
      "Iteration 244, loss = 803.99416931\n",
      "Iteration 203, loss = 786.77750296\n",
      "Iteration 247, loss = 800.25085892\n",
      "Iteration 191, loss = 1940.49149583\n",
      "Iteration 228, loss = 764.31279594\n",
      "Iteration 301, loss = 800.86982745\n",
      "Iteration 188, loss = 820.57156489\n",
      "Iteration 245, loss = 803.76281482\n",
      "Iteration 204, loss = 786.38928689\n",
      "Iteration 248, loss = 801.25417689\n",
      "Iteration 229, loss = 766.13164386\n",
      "Iteration 302, loss = 801.75723437\n",
      "Iteration 189, loss = 820.51173646\n",
      "Iteration 205, loss = 787.87706549\n",
      "Iteration 249, loss = 799.07121440\n",
      "Iteration 246, loss = 804.81190416\n",
      "Iteration 215, loss = 1752.12249496\n",
      "Iteration 303, loss = 801.68827677\n",
      "Iteration 230, loss = 765.10828792\n",
      "Iteration 190, loss = 820.31224883\n",
      "Iteration 192, loss = 1922.92212911\n",
      "Iteration 206, loss = 786.36769867\n",
      "Iteration 250, loss = 800.72465278\n",
      "Iteration 247, loss = 804.03651689\n",
      "Iteration 304, loss = 802.45391789\n",
      "Iteration 231, loss = 766.72685791\n",
      "Iteration 251, loss = 799.00894680\n",
      "Iteration 207, loss = 784.95612930\n",
      "Iteration 191, loss = 820.57469475\n",
      "Iteration 248, loss = 803.82472920\n",
      "Iteration 305, loss = 801.34789730\n",
      "Iteration 252, loss = 799.91361135\n",
      "Iteration 208, loss = 785.86800911\n",
      "Iteration 232, loss = 764.94112130\n",
      "Iteration 192, loss = 820.36381186\n",
      "Iteration 249, loss = 803.96093179\n",
      "Iteration 216, loss = 1735.14063144\n",
      "Iteration 193, loss = 1920.48226226\n",
      "Iteration 306, loss = 802.04702054\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 253, loss = 799.25080367\n",
      "Iteration 209, loss = 784.49342738\n",
      "Iteration 193, loss = 819.59962064\n",
      "Iteration 233, loss = 764.61217322\n",
      "Iteration 250, loss = 802.61719090\n",
      "Iteration 254, loss = 797.54899899\n",
      "Iteration 210, loss = 784.45079120\n",
      "Iteration 1, loss = 10684.33639786\n",
      "Iteration 194, loss = 819.02667410\n",
      "Iteration 234, loss = 765.36292266\n",
      "Iteration 251, loss = 802.79886970\n",
      "Iteration 255, loss = 798.51407891\n",
      "Iteration 194, loss = 1910.39497325\n",
      "Iteration 211, loss = 783.05269888\n",
      "Iteration 217, loss = 1738.09772684\n",
      "Iteration 2, loss = 6804.97826889\n",
      "Iteration 195, loss = 818.51519012\n",
      "Iteration 252, loss = 802.03044073\n",
      "Iteration 235, loss = 765.44337724\n",
      "Iteration 256, loss = 797.86212099\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 212, loss = 784.82120015\n",
      "Iteration 3, loss = 5781.57999177\n",
      "Iteration 196, loss = 819.04695277\n",
      "Iteration 253, loss = 802.00422081\n",
      "Iteration 236, loss = 764.50869757\n",
      "Iteration 213, loss = 784.08814012\n",
      "Iteration 1, loss = 10618.87278501\n",
      "Iteration 197, loss = 817.85513889\n",
      "Iteration 4, loss = 5226.02138605\n",
      "Iteration 254, loss = 802.07909690\n",
      "Iteration 195, loss = 1898.82147038\n",
      "Iteration 218, loss = 1724.15947166\n",
      "Iteration 237, loss = 765.65316974\n",
      "Iteration 214, loss = 783.90509995\n",
      "Iteration 2, loss = 6804.40288331\n",
      "Iteration 255, loss = 799.92028952\n",
      "Iteration 5, loss = 4744.21198015\n",
      "Iteration 198, loss = 818.87988904\n",
      "Iteration 215, loss = 783.28801475\n",
      "Iteration 3, loss = 5822.35727805\n",
      "Iteration 238, loss = 765.00332875\n",
      "Iteration 6, loss = 4319.35100272\n",
      "Iteration 256, loss = 800.34888017\n",
      "Iteration 199, loss = 816.24991556\n",
      "Iteration 4, loss = 5266.28582095\n",
      "Iteration 196, loss = 1894.80713220\n",
      "Iteration 216, loss = 782.92065352\n",
      "Iteration 239, loss = 764.66490351\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 257, loss = 804.31780074\n",
      "Iteration 7, loss = 3935.65313254\n",
      "Iteration 219, loss = 1719.66465657\n",
      "Iteration 200, loss = 816.03926007\n",
      "Iteration 5, loss = 4775.21089600\n",
      "Iteration 217, loss = 782.24721806\n",
      "Iteration 8, loss = 3603.10822947\n",
      "Iteration 258, loss = 802.16551241\n",
      "Iteration 1, loss = 10670.62875349\n",
      "Iteration 201, loss = 817.73703584\n",
      "Iteration 6, loss = 4341.35308421\n",
      "Iteration 218, loss = 782.14120214\n",
      "Iteration 9, loss = 3311.64787203\n",
      "Iteration 259, loss = 800.12008658\n",
      "Iteration 2, loss = 6824.14313281\n",
      "Iteration 197, loss = 1884.54379322\n",
      "Iteration 7, loss = 3951.20861699\n",
      "Iteration 202, loss = 818.32565461\n",
      "Iteration 219, loss = 782.03396671\n",
      "Iteration 10, loss = 3044.05820432\n",
      "Iteration 260, loss = 801.31970011\n",
      "Iteration 220, loss = 1711.33117050\n",
      "Iteration 8, loss = 3611.96576972\n",
      "Iteration 3, loss = 5842.66469549\n",
      "Iteration 203, loss = 815.62870091\n",
      "Iteration 220, loss = 781.66073556\n",
      "Iteration 11, loss = 2787.50664126\n",
      "Iteration 261, loss = 802.70048582\n",
      "Iteration 9, loss = 3312.69188594\n",
      "Iteration 4, loss = 5298.60027069\n",
      "Iteration 204, loss = 815.93276618\n",
      "Iteration 221, loss = 781.88950227\n",
      "Iteration 12, loss = 2570.39933239\n",
      "Iteration 10, loss = 3042.12002231\n",
      "Iteration 198, loss = 1874.06745108\n",
      "Iteration 262, loss = 800.66376743\n",
      "Iteration 5, loss = 4813.45865857\n",
      "Iteration 205, loss = 817.13573093\n",
      "Iteration 222, loss = 780.93269370\n",
      "Iteration 221, loss = 1705.17268795\n",
      "Iteration 11, loss = 2783.72169630\n",
      "Iteration 13, loss = 2363.60697245\n",
      "Iteration 263, loss = 802.79520533\n",
      "Iteration 6, loss = 4379.16005731\n",
      "Iteration 206, loss = 815.49387223\n",
      "Iteration 223, loss = 783.41367277\n",
      "Iteration 12, loss = 2558.92393135\n",
      "Iteration 7, loss = 3977.79859195\n",
      "Iteration 14, loss = 2183.72564225\n",
      "Iteration 264, loss = 800.03741422\n",
      "Iteration 199, loss = 1877.84405093\n",
      "Iteration 207, loss = 813.63740256\n",
      "Iteration 224, loss = 781.11039517\n",
      "Iteration 13, loss = 2350.61252797\n",
      "Iteration 8, loss = 3623.05118957\n",
      "Iteration 15, loss = 2026.26564585\n",
      "Iteration 265, loss = 799.19904307\n",
      "Iteration 222, loss = 1690.85765283\n",
      "Iteration 225, loss = 781.67993425\n",
      "Iteration 208, loss = 815.64423185\n",
      "Iteration 14, loss = 2171.72882158\n",
      "Iteration 16, loss = 1893.07278271\n",
      "Iteration 9, loss = 3301.49308771\n",
      "Iteration 266, loss = 800.50906054\n",
      "Iteration 15, loss = 2013.22800919\n",
      "Iteration 226, loss = 780.45310071\n",
      "Iteration 209, loss = 814.62771477\n",
      "Iteration 10, loss = 3015.18519072\n",
      "Iteration 17, loss = 1770.27279142\n",
      "Iteration 200, loss = 1868.63858234\n",
      "Iteration 267, loss = 797.77763295\n",
      "Iteration 16, loss = 1881.01948388\n",
      "Iteration 227, loss = 779.74828632\n",
      "Iteration 11, loss = 2748.18137643\n",
      "Iteration 210, loss = 813.08293653\n",
      "Iteration 18, loss = 1664.02012819\n",
      "Iteration 223, loss = 1690.22607792\n",
      "Iteration 268, loss = 798.66370387\n",
      "Iteration 17, loss = 1767.00836843\n",
      "Iteration 228, loss = 779.76013354\n",
      "Iteration 269, loss = 798.19844130\n",
      "Iteration 12, loss = 2525.82275794\n",
      "Iteration 211, loss = 813.19636395\n",
      "Iteration 19, loss = 1583.31184596\n",
      "Iteration 18, loss = 1664.65792450\n",
      "Iteration 229, loss = 779.99313450\n",
      "Iteration 201, loss = 1857.41017333\n",
      "Iteration 19, loss = 1584.14454885\n",
      "Iteration 13, loss = 2325.84188774\n",
      "Iteration 20, loss = 1512.15021339\n",
      "Iteration 212, loss = 813.62296514\n",
      "Iteration 270, loss = 799.17859307\n",
      "Iteration 230, loss = 779.84153104\n",
      "Iteration 20, loss = 1514.30066168\n",
      "Iteration 224, loss = 1678.99473292\n",
      "Iteration 14, loss = 2152.47915445\n",
      "Iteration 213, loss = 813.60741273\n",
      "Iteration 21, loss = 1450.52619721\n",
      "Iteration 271, loss = 799.06839396\n",
      "Iteration 231, loss = 779.97647402\n",
      "Iteration 21, loss = 1453.73973147\n",
      "Iteration 15, loss = 2007.70377153\n",
      "Iteration 202, loss = 1854.14951937\n",
      "Iteration 214, loss = 814.22976735\n",
      "Iteration 22, loss = 1401.65428486\n",
      "Iteration 272, loss = 797.18668726\n",
      "Iteration 232, loss = 779.85848280\n",
      "Iteration 22, loss = 1405.36787861\n",
      "Iteration 16, loss = 1881.25091225\n",
      "Iteration 215, loss = 811.86507580\n",
      "Iteration 273, loss = 798.72898039\n",
      "Iteration 23, loss = 1359.42032252\n",
      "Iteration 233, loss = 780.42572661\n",
      "Iteration 225, loss = 1674.89331179\n",
      "Iteration 23, loss = 1365.36803776\n",
      "Iteration 17, loss = 1768.24933676\n",
      "Iteration 216, loss = 812.43845923\n",
      "Iteration 234, loss = 778.82147041\n",
      "Iteration 24, loss = 1324.25067929\n",
      "Iteration 24, loss = 1332.26459896\n",
      "Iteration 274, loss = 798.63582134\n",
      "Iteration 203, loss = 1836.20289312\n",
      "Iteration 18, loss = 1662.60966485\n",
      "Iteration 217, loss = 811.09648771\n",
      "Iteration 235, loss = 779.48355616\n",
      "Iteration 25, loss = 1304.65360281\n",
      "Iteration 25, loss = 1295.69449904\n",
      "Iteration 275, loss = 797.64131153\n",
      "Iteration 19, loss = 1578.05316550\n",
      "Iteration 26, loss = 1279.73729916\n",
      "Iteration 218, loss = 811.51454327\n",
      "Iteration 236, loss = 778.43771728\n",
      "Iteration 226, loss = 1677.43145185\n",
      "Iteration 276, loss = 797.36772958\n",
      "Iteration 26, loss = 1271.66144576\n",
      "Iteration 204, loss = 1820.45308125\n",
      "Iteration 27, loss = 1259.40208411\n",
      "Iteration 20, loss = 1504.44223339\n",
      "Iteration 219, loss = 810.54268962\n",
      "Iteration 237, loss = 778.69880854\n",
      "Iteration 277, loss = 798.18919352\n",
      "Iteration 27, loss = 1250.37482682\n",
      "Iteration 21, loss = 1440.33861911\n",
      "Iteration 28, loss = 1241.19016016\n",
      "Iteration 220, loss = 812.04328665\n",
      "Iteration 238, loss = 778.26113575\n",
      "Iteration 278, loss = 795.99619994\n",
      "Iteration 28, loss = 1232.61781293\n",
      "Iteration 22, loss = 1389.51496600\n",
      "Iteration 29, loss = 1228.31476488\n",
      "Iteration 227, loss = 1660.14709300\n",
      "Iteration 221, loss = 811.47675135\n",
      "Iteration 239, loss = 776.94181205\n",
      "Iteration 205, loss = 1830.10836165\n",
      "Iteration 279, loss = 797.29769324\n",
      "Iteration 29, loss = 1219.65065733\n",
      "Iteration 30, loss = 1214.41043350\n",
      "Iteration 23, loss = 1343.71775256\n",
      "Iteration 222, loss = 809.47941196\n",
      "Iteration 240, loss = 775.94632613\n",
      "Iteration 30, loss = 1205.75580954\n",
      "Iteration 280, loss = 796.77830022\n",
      "Iteration 31, loss = 1203.55801908\n",
      "Iteration 24, loss = 1305.27387143\n",
      "Iteration 241, loss = 778.35948623\n",
      "Iteration 223, loss = 810.99971733\n",
      "Iteration 228, loss = 1655.83798436\n",
      "Iteration 32, loss = 1195.61556491\n",
      "Iteration 281, loss = 798.36155144\n",
      "Iteration 31, loss = 1194.89035759\n",
      "Iteration 206, loss = 1821.62556357\n",
      "Iteration 25, loss = 1276.34684418\n",
      "Iteration 242, loss = 777.69772011\n",
      "Iteration 224, loss = 810.17906348\n",
      "Iteration 33, loss = 1184.37785936\n",
      "Iteration 282, loss = 797.89398484\n",
      "Iteration 32, loss = 1185.68346753\n",
      "Iteration 26, loss = 1249.97793348\n",
      "Iteration 243, loss = 776.62166240\n",
      "Iteration 225, loss = 810.16417876\n",
      "Iteration 34, loss = 1178.65135047\n",
      "Iteration 283, loss = 798.03941031\n",
      "Iteration 33, loss = 1174.67851318\n",
      "Iteration 229, loss = 1649.77776825\n",
      "Iteration 244, loss = 776.38608366\n",
      "Iteration 27, loss = 1229.91715811\n",
      "Iteration 35, loss = 1168.13519053\n",
      "Iteration 226, loss = 809.91764792\n",
      "Iteration 207, loss = 1802.55422872\n",
      "Iteration 284, loss = 797.40586694\n",
      "Iteration 34, loss = 1168.16213335\n",
      "Iteration 245, loss = 772.14416622\n",
      "Iteration 28, loss = 1208.76227115\n",
      "Iteration 36, loss = 1159.86281642\n",
      "Iteration 227, loss = 809.69202764\n",
      "Iteration 285, loss = 796.36313740\n",
      "Iteration 35, loss = 1159.37446983\n",
      "Iteration 37, loss = 1152.50639540\n",
      "Iteration 246, loss = 779.59795507\n",
      "Iteration 29, loss = 1194.81811192\n",
      "Iteration 228, loss = 807.75074457\n",
      "Iteration 230, loss = 1648.65287161\n",
      "Iteration 286, loss = 796.66911504\n",
      "Iteration 36, loss = 1151.15982560\n",
      "Iteration 38, loss = 1146.32091916\n",
      "Iteration 208, loss = 1797.28148158\n",
      "Iteration 247, loss = 776.83561635\n",
      "Iteration 30, loss = 1179.98573781\n",
      "Iteration 229, loss = 808.78598237\n",
      "Iteration 287, loss = 796.72836274\n",
      "Iteration 37, loss = 1143.19169192\n",
      "Iteration 39, loss = 1137.41140134\n",
      "Iteration 248, loss = 777.08905608\n",
      "Iteration 31, loss = 1167.75677482\n",
      "Iteration 230, loss = 807.89555752\n",
      "Iteration 288, loss = 795.40746195\n",
      "Iteration 40, loss = 1130.18498504\n",
      "Iteration 38, loss = 1137.53781630\n",
      "Iteration 249, loss = 774.94262013\n",
      "Iteration 231, loss = 1644.71055806\n",
      "Iteration 32, loss = 1156.80768530\n",
      "Iteration 231, loss = 807.89995713\n",
      "Iteration 41, loss = 1124.13612805\n",
      "Iteration 209, loss = 1790.83851136\n",
      "Iteration 289, loss = 795.09315865\n",
      "Iteration 39, loss = 1130.40040988\n",
      "Iteration 250, loss = 776.68430635\n",
      "Iteration 33, loss = 1145.64809703\n",
      "Iteration 42, loss = 1119.37190343\n",
      "Iteration 232, loss = 808.13800024\n",
      "Iteration 290, loss = 795.72052532\n",
      "Iteration 40, loss = 1122.42355278\n",
      "Iteration 251, loss = 775.16486145\n",
      "Iteration 43, loss = 1113.61402241\n",
      "Iteration 34, loss = 1138.24914250\n",
      "Iteration 233, loss = 809.31383559\n",
      "Iteration 291, loss = 794.77063228\n",
      "Iteration 252, loss = 775.52238873\n",
      "Iteration 232, loss = 1636.68928419\n",
      "Iteration 41, loss = 1117.03793818\n",
      "Iteration 210, loss = 1790.94143295\n",
      "Iteration 44, loss = 1106.50480704\n",
      "Iteration 35, loss = 1128.36596255\n",
      "Iteration 234, loss = 809.37188678\n",
      "Iteration 292, loss = 795.33379330\n",
      "Iteration 253, loss = 775.90898333\n",
      "Iteration 42, loss = 1111.31287709\n",
      "Iteration 45, loss = 1102.48753432\n",
      "Iteration 36, loss = 1118.76956708\n",
      "Iteration 235, loss = 807.89098194\n",
      "Iteration 293, loss = 794.36503550\n",
      "Iteration 254, loss = 773.55679675\n",
      "Iteration 46, loss = 1097.30644133\n",
      "Iteration 43, loss = 1105.13489311\n",
      "Iteration 37, loss = 1111.81928273\n",
      "Iteration 236, loss = 807.16317837\n",
      "Iteration 294, loss = 796.47308834\n",
      "Iteration 233, loss = 1626.27842594\n",
      "Iteration 211, loss = 1774.23167349\n",
      "Iteration 255, loss = 774.60449817\n",
      "Iteration 47, loss = 1091.91088220\n",
      "Iteration 38, loss = 1105.40223611\n",
      "Iteration 44, loss = 1098.42447135\n",
      "Iteration 237, loss = 807.36119046\n",
      "Iteration 295, loss = 792.96739436\n",
      "Iteration 48, loss = 1085.62836137\n",
      "Iteration 256, loss = 773.77953128\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 39, loss = 1097.29587972\n",
      "Iteration 45, loss = 1093.64325409\n",
      "Iteration 238, loss = 805.96797864\n",
      "Iteration 296, loss = 796.28783437\n",
      "Iteration 49, loss = 1081.30614016\n",
      "Iteration 1, loss = 10614.79866664\n",
      "Iteration 40, loss = 1089.02120411\n",
      "Iteration 234, loss = 1620.90071148\n",
      "Iteration 212, loss = 1783.88830178\n",
      "Iteration 46, loss = 1087.59336608\n",
      "Iteration 239, loss = 805.73418306\n",
      "Iteration 50, loss = 1075.45040189\n",
      "Iteration 297, loss = 795.06699054\n",
      "Iteration 2, loss = 6749.36182035\n",
      "Iteration 41, loss = 1084.11326624\n",
      "Iteration 47, loss = 1082.19745266\n",
      "Iteration 51, loss = 1069.49844921\n",
      "Iteration 240, loss = 805.20155571\n",
      "Iteration 298, loss = 795.28057793\n",
      "Iteration 3, loss = 5771.62962001\n",
      "Iteration 42, loss = 1078.35964510\n",
      "Iteration 48, loss = 1075.98172450\n",
      "Iteration 52, loss = 1064.95431001\n",
      "Iteration 213, loss = 1773.81597008\n",
      "Iteration 299, loss = 793.94155848\n",
      "Iteration 241, loss = 806.61679405\n",
      "Iteration 235, loss = 1608.99316707\n",
      "Iteration 43, loss = 1072.04633751\n",
      "Iteration 4, loss = 5227.14369341\n",
      "Iteration 53, loss = 1061.32758189\n",
      "Iteration 49, loss = 1072.74557805\n",
      "Iteration 300, loss = 793.83098819\n",
      "Iteration 242, loss = 807.51586183\n",
      "Iteration 5, loss = 4748.98463952\n",
      "Iteration 54, loss = 1057.77570517\n",
      "Iteration 44, loss = 1064.72354173\n",
      "Iteration 50, loss = 1065.93199248\n",
      "Iteration 243, loss = 805.36653952\n",
      "Iteration 301, loss = 793.18618600\n",
      "Iteration 6, loss = 4327.99950133\n",
      "Iteration 214, loss = 1763.77603016\n",
      "Iteration 55, loss = 1053.19139767\n",
      "Iteration 45, loss = 1059.16966688\n",
      "Iteration 51, loss = 1060.13662330\n",
      "Iteration 236, loss = 1622.40737486\n",
      "Iteration 244, loss = 806.16870613\n",
      "Iteration 7, loss = 3945.53200553\n",
      "Iteration 302, loss = 793.88320564\n",
      "Iteration 56, loss = 1046.09221114\n",
      "Iteration 46, loss = 1053.72486255\n",
      "Iteration 52, loss = 1055.77216749\n",
      "Iteration 303, loss = 793.45192985\n",
      "Iteration 8, loss = 3607.19353991\n",
      "Iteration 245, loss = 799.72567686\n",
      "Iteration 57, loss = 1040.99821100\n",
      "Iteration 47, loss = 1048.32883263\n",
      "Iteration 53, loss = 1051.97356970\n",
      "Iteration 215, loss = 1756.11006430\n",
      "Iteration 304, loss = 794.27194933\n",
      "Iteration 58, loss = 1039.67167611\n",
      "Iteration 9, loss = 3305.85401022\n",
      "Iteration 246, loss = 808.01253924\n",
      "Iteration 237, loss = 1596.78853506\n",
      "Iteration 48, loss = 1041.94154951\n",
      "Iteration 54, loss = 1047.73647436\n",
      "Iteration 59, loss = 1034.15079747\n",
      "Iteration 305, loss = 794.15155984\n",
      "Iteration 10, loss = 3016.26281206\n",
      "Iteration 247, loss = 804.95056258\n",
      "Iteration 49, loss = 1035.88188387\n",
      "Iteration 55, loss = 1043.87958108\n",
      "Iteration 60, loss = 1029.15121018\n",
      "Iteration 306, loss = 794.63736746\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 2760.30096200\n",
      "Iteration 216, loss = 1748.28415280\n",
      "Iteration 248, loss = 804.84274954\n",
      "Iteration 50, loss = 1031.62804134\n",
      "Iteration 61, loss = 1024.81366041\n",
      "Iteration 56, loss = 1037.19822865\n",
      "Iteration 238, loss = 1593.27218435\n",
      "Iteration 12, loss = 2528.28063303\n",
      "Iteration 249, loss = 802.50645816\n",
      "Iteration 51, loss = 1024.28132235\n",
      "Iteration 62, loss = 1018.83291120\n",
      "Iteration 57, loss = 1032.52152126\n",
      "Iteration 1, loss = 2943.18520839\n",
      "Iteration 13, loss = 2313.44749555\n",
      "Iteration 250, loss = 803.94459015\n",
      "Iteration 52, loss = 1020.29632339\n",
      "Iteration 63, loss = 1018.18841919\n",
      "Iteration 58, loss = 1029.97668530\n",
      "Iteration 217, loss = 1741.89023269\n",
      "Iteration 2, loss = 1377.12133909\n",
      "Iteration 251, loss = 804.11331562\n",
      "Iteration 53, loss = 1014.88156787\n",
      "Iteration 14, loss = 2132.28966233\n",
      "Iteration 64, loss = 1013.38000554\n",
      "Iteration 59, loss = 1023.94380167\n",
      "Iteration 239, loss = 1594.31401621\n",
      "Iteration 3, loss = 1257.67209589\n",
      "Iteration 252, loss = 804.27523821\n",
      "Iteration 65, loss = 1010.32084280\n",
      "Iteration 54, loss = 1010.42026076\n",
      "Iteration 15, loss = 1976.25417245\n",
      "Iteration 60, loss = 1018.96733876\n",
      "Iteration 218, loss = 1735.24459268\n",
      "Iteration 4, loss = 1150.82780212\n",
      "Iteration 253, loss = 804.01872332\n",
      "Iteration 66, loss = 1006.28532625\n",
      "Iteration 55, loss = 1005.84524479\n",
      "Iteration 16, loss = 1846.22037339\n",
      "Iteration 61, loss = 1015.08424591\n",
      "Iteration 67, loss = 1003.48263727\n",
      "Iteration 5, loss = 1104.46301141\n",
      "Iteration 240, loss = 1597.11593289\n",
      "Iteration 254, loss = 802.76627713\n",
      "Iteration 56, loss = 998.50117416\n",
      "Iteration 17, loss = 1733.06950505\n",
      "Iteration 62, loss = 1008.26319191\n",
      "Iteration 68, loss = 999.90320277\n",
      "Iteration 219, loss = 1737.14832092\n",
      "Iteration 255, loss = 802.54757288\n",
      "Iteration 6, loss = 1052.12025704\n",
      "Iteration 57, loss = 994.62726898\n",
      "Iteration 63, loss = 1009.10656038\n",
      "Iteration 18, loss = 1626.21935323\n",
      "Iteration 69, loss = 994.82930737\n",
      "Iteration 256, loss = 803.07345771\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 7, loss = 1068.02409139\n",
      "Iteration 58, loss = 990.24057807\n",
      "Iteration 64, loss = 1003.49870450\n",
      "Iteration 19, loss = 1539.31222006\n",
      "Iteration 70, loss = 992.17901968\n",
      "Iteration 241, loss = 1583.94168074\n",
      "Iteration 59, loss = 985.14750640\n",
      "Iteration 220, loss = 1712.36948360\n",
      "Iteration 20, loss = 1464.37192468\n",
      "Iteration 8, loss = 992.15736915\n",
      "Iteration 65, loss = 1000.24057416\n",
      "Iteration 71, loss = 989.67135047\n",
      "Iteration 1, loss = 3030.14339483\n",
      "Iteration 60, loss = 980.05500595\n",
      "Iteration 72, loss = 984.76173360\n",
      "Iteration 21, loss = 1400.12169781\n",
      "Iteration 66, loss = 997.22723321\n",
      "Iteration 9, loss = 998.13421467\n",
      "Iteration 2, loss = 1238.87298301\n",
      "Iteration 73, loss = 982.00358298\n",
      "Iteration 61, loss = 975.78585733\n",
      "Iteration 22, loss = 1351.00750331\n",
      "Iteration 242, loss = 1568.01525001\n",
      "Iteration 67, loss = 993.18540416\n",
      "Iteration 221, loss = 1717.31535834\n",
      "Iteration 10, loss = 961.97877330\n",
      "Iteration 74, loss = 978.25681348\n",
      "Iteration 3, loss = 1106.28084504\n",
      "Iteration 62, loss = 968.04788624\n",
      "Iteration 23, loss = 1306.97700134\n",
      "Iteration 68, loss = 989.19839033\n",
      "Iteration 75, loss = 975.67660444\n",
      "Iteration 11, loss = 964.62994838\n",
      "Iteration 63, loss = 967.62382102\n",
      "Iteration 4, loss = 1025.69869823\n",
      "Iteration 24, loss = 1270.73746157\n",
      "Iteration 69, loss = 984.09513853\n",
      "Iteration 76, loss = 973.45383161\n",
      "Iteration 243, loss = 1563.15844349\n",
      "Iteration 222, loss = 1714.78961887\n",
      "Iteration 64, loss = 962.69481401\n",
      "Iteration 12, loss = 931.85864799\n",
      "Iteration 25, loss = 1240.57589372\n",
      "Iteration 5, loss = 999.16276317\n",
      "Iteration 70, loss = 981.00081403\n",
      "Iteration 77, loss = 968.41817114\n",
      "Iteration 65, loss = 959.14839779\n",
      "Iteration 26, loss = 1214.07785556\n",
      "Iteration 78, loss = 965.87629313\n",
      "Iteration 71, loss = 977.80518128\n",
      "Iteration 13, loss = 908.93726524\n",
      "Iteration 6, loss = 973.06590830\n",
      "Iteration 66, loss = 954.76341792\n",
      "Iteration 27, loss = 1192.73063635\n",
      "Iteration 79, loss = 964.80513604\n",
      "Iteration 244, loss = 1566.10115332\n",
      "Iteration 72, loss = 973.93126581\n",
      "Iteration 223, loss = 1704.00036167\n",
      "Iteration 7, loss = 948.29429747\n",
      "Iteration 14, loss = 938.29140702\n",
      "Iteration 80, loss = 960.58221863\n",
      "Iteration 67, loss = 951.97022255\n",
      "Iteration 28, loss = 1172.09259409\n",
      "Iteration 73, loss = 970.50394038\n",
      "Iteration 15, loss = 917.85094571\n",
      "Iteration 8, loss = 942.31412300\n",
      "Iteration 81, loss = 956.01102310\n",
      "Iteration 68, loss = 947.91980893\n",
      "Iteration 29, loss = 1158.69128475\n",
      "Iteration 74, loss = 966.53263132\n",
      "Iteration 82, loss = 953.52377085\n",
      "Iteration 16, loss = 924.62761715\n",
      "Iteration 245, loss = 1556.35975106\n",
      "Iteration 69, loss = 942.87477102\n",
      "Iteration 30, loss = 1144.41011371\n",
      "Iteration 9, loss = 955.37155023\n",
      "Iteration 224, loss = 1687.02897205\n",
      "Iteration 75, loss = 963.74847188\n",
      "Iteration 83, loss = 951.18210179\n",
      "Iteration 70, loss = 939.40624704\n",
      "Iteration 31, loss = 1132.06177709\n",
      "Iteration 17, loss = 896.61780101\n",
      "Iteration 10, loss = 931.01824556\n",
      "Iteration 84, loss = 948.57081529\n",
      "Iteration 76, loss = 962.13695260\n",
      "Iteration 71, loss = 935.55525773\n",
      "Iteration 32, loss = 1124.42852617\n",
      "Iteration 85, loss = 945.04569496\n",
      "Iteration 18, loss = 890.89291341\n",
      "Iteration 11, loss = 951.54714783\n",
      "Iteration 77, loss = 956.55945827\n",
      "Iteration 246, loss = 1560.15118559\n",
      "Iteration 225, loss = 1690.03374582\n",
      "Iteration 72, loss = 931.60428557\n",
      "Iteration 33, loss = 1112.35275856\n",
      "Iteration 86, loss = 944.78335174\n",
      "Iteration 19, loss = 897.49368974\n",
      "Iteration 78, loss = 954.87449654\n",
      "Iteration 12, loss = 924.37599417\n",
      "Iteration 73, loss = 928.35606474\n",
      "Iteration 87, loss = 941.52996932\n",
      "Iteration 34, loss = 1104.70127398\n",
      "Iteration 20, loss = 886.62868967\n",
      "Iteration 79, loss = 954.04223285\n",
      "Iteration 74, loss = 924.85743163\n",
      "Iteration 88, loss = 938.96473579\n",
      "Iteration 13, loss = 914.73216579\n",
      "Iteration 247, loss = 1541.08328854\n",
      "Iteration 226, loss = 1682.30931688\n",
      "Iteration 35, loss = 1096.06771720\n",
      "Iteration 75, loss = 921.85931323\n",
      "Iteration 80, loss = 949.71187392\n",
      "Iteration 21, loss = 865.42996930\n",
      "Iteration 89, loss = 937.90329852\n",
      "Iteration 36, loss = 1087.20393322\n",
      "Iteration 14, loss = 921.00428982\n",
      "Iteration 90, loss = 933.98614287\n",
      "Iteration 76, loss = 918.84740775\n",
      "Iteration 81, loss = 945.04158149\n",
      "Iteration 22, loss = 872.35110251\n",
      "Iteration 37, loss = 1080.64618581\n",
      "Iteration 15, loss = 903.56745253\n",
      "Iteration 91, loss = 931.30117644\n",
      "Iteration 77, loss = 914.00093919\n",
      "Iteration 82, loss = 942.69172030\n",
      "Iteration 248, loss = 1556.04814083\n",
      "Iteration 227, loss = 1669.02346754\n",
      "Iteration 23, loss = 886.29102317\n",
      "Iteration 38, loss = 1072.54261991\n",
      "Iteration 92, loss = 928.00506549\n",
      "Iteration 78, loss = 912.71108337\n",
      "Iteration 16, loss = 919.06204281\n",
      "Iteration 83, loss = 941.12520579\n",
      "Iteration 39, loss = 1065.46278826\n",
      "Iteration 24, loss = 872.96946661\n",
      "Iteration 93, loss = 927.83667632\n",
      "Iteration 79, loss = 912.13293554\n",
      "Iteration 84, loss = 938.05926480\n",
      "Iteration 17, loss = 887.45211454\n",
      "Iteration 40, loss = 1057.42246810\n",
      "Iteration 25, loss = 867.56787587\n",
      "Iteration 94, loss = 924.01399189\n",
      "Iteration 249, loss = 1529.62353798\n",
      "Iteration 228, loss = 1672.89133730\n",
      "Iteration 80, loss = 906.20697230\n",
      "Iteration 41, loss = 1053.09846005\n",
      "Iteration 85, loss = 934.43844617\n",
      "Iteration 18, loss = 893.84160439\n",
      "Iteration 95, loss = 920.80489400\n",
      "Iteration 26, loss = 879.06328351\n",
      "Iteration 81, loss = 902.98948417\n",
      "Iteration 42, loss = 1047.27955192\n",
      "Iteration 86, loss = 934.02692715\n",
      "Iteration 96, loss = 920.03718453\n",
      "Iteration 82, loss = 900.70610081\n",
      "Iteration 19, loss = 893.34299082\n",
      "Iteration 27, loss = 856.94563666\n",
      "Iteration 250, loss = 1532.57142423\n",
      "Iteration 43, loss = 1042.47221751\n",
      "Iteration 87, loss = 931.22035471\n",
      "Iteration 229, loss = 1661.87257924\n",
      "Iteration 97, loss = 917.18589121\n",
      "Iteration 83, loss = 898.48550686\n",
      "Iteration 20, loss = 885.95508636\n",
      "Iteration 44, loss = 1035.00162731\n",
      "Iteration 28, loss = 897.31272024\n",
      "Iteration 98, loss = 914.27978139\n",
      "Iteration 88, loss = 928.33523469\n",
      "Iteration 84, loss = 896.74777936\n",
      "Iteration 99, loss = 913.27847176\n",
      "Iteration 45, loss = 1028.87840016\n",
      "Iteration 21, loss = 867.14562728\n",
      "Iteration 89, loss = 926.70994999\n",
      "Iteration 29, loss = 885.22273988\n",
      "Iteration 85, loss = 893.15300451\n",
      "Iteration 230, loss = 1654.11776668\n",
      "Iteration 251, loss = 1520.10645693\n",
      "Iteration 46, loss = 1023.35181634\n",
      "Iteration 100, loss = 911.25734545\n",
      "Iteration 22, loss = 895.65709364\n",
      "Iteration 90, loss = 924.36904206\n",
      "Iteration 30, loss = 870.37537589\n",
      "Iteration 86, loss = 893.43832142\n",
      "Iteration 101, loss = 908.32279177\n",
      "Iteration 47, loss = 1018.51452365\n",
      "Iteration 91, loss = 920.63935205\n",
      "Iteration 23, loss = 901.22685016\n",
      "Iteration 87, loss = 890.49707879\n",
      "Iteration 31, loss = 879.76745038\n",
      "Iteration 102, loss = 906.14408659\n",
      "Iteration 48, loss = 1013.74206300\n",
      "Iteration 231, loss = 1670.31398725\n",
      "Iteration 92, loss = 918.65585364\n",
      "Iteration 88, loss = 888.78724610\n",
      "Iteration 252, loss = 1543.14632318\n",
      "Iteration 103, loss = 905.26904563\n",
      "Iteration 24, loss = 881.45822322\n",
      "Iteration 32, loss = 849.95319747\n",
      "Iteration 49, loss = 1007.86569910\n",
      "Iteration 93, loss = 916.70602989\n",
      "Iteration 89, loss = 887.77616306\n",
      "Iteration 104, loss = 901.67397800\n",
      "Iteration 25, loss = 877.60573830\n",
      "Iteration 50, loss = 1002.72292485\n",
      "Iteration 94, loss = 914.21853167\n",
      "Iteration 33, loss = 863.31969822\n",
      "Iteration 90, loss = 884.25825302\n",
      "Iteration 105, loss = 902.77531314\n",
      "Iteration 232, loss = 1641.72669459\n",
      "Iteration 253, loss = 1514.94839677\n",
      "Iteration 26, loss = 869.60093436\n",
      "Iteration 51, loss = 997.85771477\n",
      "Iteration 91, loss = 883.63036499\n",
      "Iteration 106, loss = 898.80508870\n",
      "Iteration 95, loss = 911.86703521\n",
      "Iteration 34, loss = 880.37699039\n",
      "Iteration 52, loss = 994.74304507\n",
      "Iteration 107, loss = 898.84451995\n",
      "Iteration 27, loss = 867.78366678\n",
      "Iteration 92, loss = 880.25928642\n",
      "Iteration 96, loss = 910.86635489\n",
      "Iteration 35, loss = 851.68384155\n",
      "Iteration 233, loss = 1633.70775898\n",
      "Iteration 108, loss = 895.04819309\n",
      "Iteration 53, loss = 989.80596694\n",
      "Iteration 254, loss = 1511.49748354\n",
      "Iteration 93, loss = 879.34728942\n",
      "Iteration 97, loss = 907.97320691\n",
      "Iteration 28, loss = 885.42810117\n",
      "Iteration 36, loss = 850.12122064\n",
      "Iteration 109, loss = 892.12274603\n",
      "Iteration 54, loss = 984.67328962\n",
      "Iteration 94, loss = 876.75331074\n",
      "Iteration 98, loss = 905.09212088\n",
      "Iteration 110, loss = 891.63044019\n",
      "Iteration 29, loss = 879.94015517\n",
      "Iteration 55, loss = 981.28241463\n",
      "Iteration 37, loss = 844.28650376\n",
      "Iteration 95, loss = 874.50719630\n",
      "Iteration 99, loss = 903.84910844\n",
      "Iteration 234, loss = 1631.03031757\n",
      "Iteration 111, loss = 890.53100376\n",
      "Iteration 56, loss = 976.41666177\n",
      "Iteration 255, loss = 1504.17851198\n",
      "Iteration 30, loss = 862.02209058\n",
      "Iteration 38, loss = 837.02569303\n",
      "Iteration 96, loss = 873.43176882\n",
      "Iteration 100, loss = 902.43628825\n",
      "Iteration 112, loss = 888.36376825\n",
      "Iteration 57, loss = 971.65543202\n",
      "Iteration 97, loss = 871.44050844\n",
      "Iteration 31, loss = 857.36393931\n",
      "Iteration 113, loss = 888.49300140\n",
      "Iteration 39, loss = 859.35725692\n",
      "Iteration 101, loss = 900.49331604\n",
      "Iteration 235, loss = 1632.05175625\n",
      "Iteration 58, loss = 967.89936490\n",
      "Iteration 98, loss = 869.88072678\n",
      "Iteration 114, loss = 886.16963433\n",
      "Iteration 256, loss = 1502.08048713\n",
      "Iteration 102, loss = 898.02086593\n",
      "Iteration 32, loss = 856.96081692\n",
      "Iteration 40, loss = 862.88057301\n",
      "Iteration 59, loss = 963.02828057\n",
      "Iteration 115, loss = 885.04759286\n",
      "Iteration 99, loss = 868.17343891\n",
      "Iteration 103, loss = 897.05574028\n",
      "Iteration 60, loss = 958.57739352\n",
      "Iteration 33, loss = 828.09300747\n",
      "Iteration 41, loss = 853.46761879\n",
      "Iteration 116, loss = 883.02853151\n",
      "Iteration 236, loss = 1633.92155298\n",
      "Iteration 100, loss = 865.82047592\n",
      "Iteration 104, loss = 893.65695030\n",
      "Iteration 61, loss = 954.75775453\n",
      "Iteration 257, loss = 1493.35171190\n",
      "Iteration 117, loss = 880.47823508\n",
      "Iteration 34, loss = 883.41024333\n",
      "Iteration 42, loss = 833.20032581\n",
      "Iteration 101, loss = 863.68986060\n",
      "Iteration 105, loss = 894.46324516\n",
      "Iteration 62, loss = 950.00135501\n",
      "Iteration 118, loss = 879.41156293\n",
      "Iteration 35, loss = 838.63483890\n",
      "Iteration 102, loss = 861.61412078\n",
      "Iteration 43, loss = 836.08367306\n",
      "Iteration 106, loss = 891.74424592\n",
      "Iteration 63, loss = 946.60875187\n",
      "Iteration 119, loss = 877.73777403\n",
      "Iteration 237, loss = 1614.96766397\n",
      "Iteration 103, loss = 861.55327861\n",
      "Iteration 44, loss = 860.11428468\n",
      "Iteration 36, loss = 837.48859074\n",
      "Iteration 107, loss = 890.78189261Iteration 120, loss = 877.73250906\n",
      "\n",
      "Iteration 258, loss = 1489.18705138\n",
      "Iteration 64, loss = 942.08233245\n",
      "Iteration 104, loss = 858.80903865\n",
      "Iteration 121, loss = 876.23755615\n",
      "Iteration 108, loss = 887.43559124\n",
      "Iteration 45, loss = 828.23742027\n",
      "Iteration 37, loss = 839.47625236\n",
      "Iteration 65, loss = 938.39850288\n",
      "Iteration 105, loss = 860.92546882\n",
      "Iteration 122, loss = 875.60273911\n",
      "Iteration 238, loss = 1609.76252534\n",
      "Iteration 109, loss = 884.97949429\n",
      "Iteration 66, loss = 934.51248133\n",
      "Iteration 46, loss = 848.92767412\n",
      "Iteration 38, loss = 834.91384038\n",
      "Iteration 106, loss = 856.88907699\n",
      "Iteration 123, loss = 872.93403850\n",
      "Iteration 259, loss = 1477.37841399\n",
      "Iteration 110, loss = 883.98970908\n",
      "Iteration 67, loss = 931.91722940\n",
      "Iteration 47, loss = 829.41249064\n",
      "Iteration 124, loss = 872.44479201\n",
      "Iteration 39, loss = 844.46596743\n",
      "Iteration 107, loss = 856.99520256\n",
      "Iteration 111, loss = 883.92191095\n",
      "Iteration 68, loss = 927.93129641\n",
      "Iteration 239, loss = 1605.39440251\n",
      "Iteration 125, loss = 869.96246968\n",
      "Iteration 108, loss = 853.60135638\n",
      "Iteration 48, loss = 826.22156768\n",
      "Iteration 40, loss = 844.45095119\n",
      "Iteration 260, loss = 1483.72993806\n",
      "Iteration 69, loss = 924.32464367\n",
      "Iteration 126, loss = 869.81226065\n",
      "Iteration 112, loss = 881.16987657\n",
      "Iteration 109, loss = 851.86269210\n",
      "Iteration 49, loss = 836.57622155\n",
      "Iteration 41, loss = 830.18739559\n",
      "Iteration 127, loss = 869.08648752\n",
      "Iteration 70, loss = 920.45077493\n",
      "Iteration 113, loss = 881.29453984\n",
      "Iteration 240, loss = 1595.48379360\n",
      "Iteration 110, loss = 851.56882006\n",
      "Iteration 128, loss = 868.42280541\n",
      "Iteration 50, loss = 837.17728280\n",
      "Iteration 42, loss = 813.96273052\n",
      "Iteration 114, loss = 879.46041268\n",
      "Iteration 71, loss = 916.54686902\n",
      "Iteration 261, loss = 1478.23270599\n",
      "Iteration 129, loss = 865.94100446\n",
      "Iteration 111, loss = 850.38262206\n",
      "Iteration 51, loss = 823.25363353\n",
      "Iteration 72, loss = 913.15606065\n",
      "Iteration 115, loss = 878.59843476\n",
      "Iteration 43, loss = 826.60461284\n",
      "Iteration 130, loss = 865.34712553\n",
      "Iteration 112, loss = 848.26617680\n",
      "Iteration 241, loss = 1596.81262094\n",
      "Iteration 73, loss = 909.14043624\n",
      "Iteration 116, loss = 875.36377284\n",
      "Iteration 52, loss = 836.34224714\n",
      "Iteration 44, loss = 842.88386094\n",
      "Iteration 131, loss = 864.91671801\n",
      "Iteration 113, loss = 848.86891859\n",
      "Iteration 74, loss = 907.89223135\n",
      "Iteration 262, loss = 1461.78420097\n",
      "Iteration 117, loss = 874.94706906\n",
      "Iteration 132, loss = 862.18477402\n",
      "Iteration 53, loss = 822.17160008\n",
      "Iteration 114, loss = 847.80675034\n",
      "Iteration 45, loss = 823.05405951\n",
      "Iteration 75, loss = 905.19682795\n",
      "Iteration 118, loss = 872.54585681\n",
      "Iteration 133, loss = 860.94111584\n",
      "Iteration 242, loss = 1585.86899531\n",
      "Iteration 115, loss = 846.65873951\n",
      "Iteration 54, loss = 858.55029892\n",
      "Iteration 46, loss = 831.04643665\n",
      "Iteration 76, loss = 901.28801868\n",
      "Iteration 119, loss = 871.45637836\n",
      "Iteration 134, loss = 861.15058109\n",
      "Iteration 116, loss = 844.87040809\n",
      "Iteration 55, loss = 861.08001613\n",
      "Iteration 47, loss = 829.61626207\n",
      "Iteration 263, loss = 1485.33277106\n",
      "Iteration 77, loss = 896.41917044\n",
      "Iteration 120, loss = 871.83181287\n",
      "Iteration 135, loss = 861.02870564\n",
      "Iteration 117, loss = 843.39855820\n",
      "Iteration 243, loss = 1583.96668433\n",
      "Iteration 56, loss = 816.59611537\n",
      "Iteration 78, loss = 893.76191274\n",
      "Iteration 48, loss = 815.52530886\n",
      "Iteration 136, loss = 860.13910788\n",
      "Iteration 121, loss = 868.58747602\n",
      "Iteration 118, loss = 841.12911903\n",
      "Iteration 137, loss = 857.91864367\n",
      "Iteration 57, loss = 812.45767899\n",
      "Iteration 122, loss = 869.64591073\n",
      "Iteration 79, loss = 894.21107876\n",
      "Iteration 49, loss = 828.52739590\n",
      "Iteration 119, loss = 841.42603950\n",
      "Iteration 264, loss = 1452.57329660\n",
      "Iteration 138, loss = 859.16594190\n",
      "Iteration 244, loss = 1570.02551722\n",
      "Iteration 58, loss = 800.90026151\n",
      "Iteration 80, loss = 888.23120660\n",
      "Iteration 123, loss = 866.67632465\n",
      "Iteration 120, loss = 841.31999017\n",
      "Iteration 50, loss = 836.51031893\n",
      "Iteration 139, loss = 858.01240747\n",
      "Iteration 124, loss = 866.45217485\n",
      "Iteration 81, loss = 884.81562412\n",
      "Iteration 140, loss = 857.33760958\n",
      "Iteration 121, loss = 840.59715356\n",
      "Iteration 59, loss = 816.11893575\n",
      "Iteration 51, loss = 813.95012744\n",
      "Iteration 265, loss = 1451.04355216\n",
      "Iteration 125, loss = 864.60043017\n",
      "Iteration 82, loss = 882.38623276\n",
      "Iteration 141, loss = 854.44036478\n",
      "Iteration 122, loss = 839.70786335\n",
      "Iteration 60, loss = 807.97986039\n",
      "Iteration 245, loss = 1565.85635656\n",
      "Iteration 52, loss = 816.25074555\n",
      "Iteration 142, loss = 855.73118350\n",
      "Iteration 126, loss = 863.92458365\n",
      "Iteration 83, loss = 880.15473447\n",
      "Iteration 123, loss = 837.56315156\n",
      "Iteration 61, loss = 815.13550081\n",
      "Iteration 143, loss = 855.55238579\n",
      "Iteration 127, loss = 863.87644522\n",
      "Iteration 53, loss = 815.85518306\n",
      "Iteration 84, loss = 876.86138950\n",
      "Iteration 124, loss = 836.64827421\n",
      "Iteration 266, loss = 1450.61678277\n",
      "Iteration 144, loss = 853.88536570\n",
      "Iteration 246, loss = 1581.99254906\n",
      "Iteration 85, loss = 873.42788776\n",
      "Iteration 62, loss = 793.46743578\n",
      "Iteration 128, loss = 862.69371545\n",
      "Iteration 125, loss = 835.05840591\n",
      "Iteration 54, loss = 833.00141591\n",
      "Iteration 145, loss = 851.98725067\n",
      "Iteration 129, loss = 860.90253638\n",
      "Iteration 86, loss = 874.10193155\n",
      "Iteration 146, loss = 852.43644024\n",
      "Iteration 126, loss = 835.19091725\n",
      "Iteration 63, loss = 824.58285976\n",
      "Iteration 55, loss = 827.89775214\n",
      "Iteration 130, loss = 859.83669957\n",
      "Iteration 87, loss = 870.46352287\n",
      "Iteration 267, loss = 1446.91767366\n",
      "Iteration 247, loss = 1553.27135847\n",
      "Iteration 147, loss = 852.60490182\n",
      "Iteration 127, loss = 834.38111905\n",
      "Iteration 64, loss = 823.16214548\n",
      "Iteration 131, loss = 859.70929124\n",
      "Iteration 56, loss = 816.94917177\n",
      "Iteration 148, loss = 850.50589444\n",
      "Iteration 88, loss = 867.67933892\n",
      "Iteration 128, loss = 834.43579053\n",
      "Iteration 132, loss = 856.61748924\n",
      "Iteration 65, loss = 830.96397721\n",
      "Iteration 149, loss = 849.62756824\n",
      "Iteration 57, loss = 807.65630616\n",
      "Iteration 129, loss = 832.36429038\n",
      "Iteration 89, loss = 867.49158859\n",
      "Iteration 268, loss = 1426.76833360\n",
      "Iteration 248, loss = 1549.97579141\n",
      "Iteration 133, loss = 855.03595938\n",
      "Iteration 150, loss = 848.52168786\n",
      "Iteration 66, loss = 817.15904566\n",
      "Iteration 130, loss = 832.50920911\n",
      "Iteration 90, loss = 864.33871105\n",
      "Iteration 58, loss = 801.07657029\n",
      "Iteration 151, loss = 847.09500065\n",
      "Iteration 134, loss = 855.79945248\n",
      "Iteration 131, loss = 830.66575676\n",
      "Iteration 67, loss = 832.70039161\n",
      "Iteration 91, loss = 863.61994545\n",
      "Iteration 59, loss = 818.56538418\n",
      "Iteration 152, loss = 845.59180522\n",
      "Iteration 132, loss = 829.36677105\n",
      "Iteration 135, loss = 855.16827898\n",
      "Iteration 249, loss = 1557.32022968\n",
      "Iteration 269, loss = 1456.28086589\n",
      "Iteration 92, loss = 859.47696668\n",
      "Iteration 68, loss = 828.30076693\n",
      "Iteration 60, loss = 796.85438510\n",
      "Iteration 153, loss = 846.49520291\n",
      "Iteration 133, loss = 829.20630846\n",
      "Iteration 136, loss = 854.05930084\n",
      "Iteration 93, loss = 857.68623286\n",
      "Iteration 69, loss = 802.58420229\n",
      "Iteration 154, loss = 847.65356185\n",
      "Iteration 134, loss = 828.14374508\n",
      "Iteration 61, loss = 806.71092207\n",
      "Iteration 137, loss = 852.43030284\n",
      "Iteration 94, loss = 855.77131934\n",
      "Iteration 155, loss = 846.05323393\n",
      "Iteration 250, loss = 1536.58551296\n",
      "Iteration 135, loss = 829.30027888\n",
      "Iteration 70, loss = 802.04625853\n",
      "Iteration 138, loss = 852.52069924\n",
      "Iteration 270, loss = 1431.24943174\n",
      "Iteration 62, loss = 791.45012250\n",
      "Iteration 156, loss = 845.27721396\n",
      "Iteration 95, loss = 853.17086181\n",
      "Iteration 136, loss = 828.00522141\n",
      "Iteration 139, loss = 852.15563293\n",
      "Iteration 71, loss = 791.85991690\n",
      "Iteration 157, loss = 844.20869901\n",
      "Iteration 63, loss = 808.91985790\n",
      "Iteration 96, loss = 851.90975168\n",
      "Iteration 137, loss = 825.66393853\n",
      "Iteration 140, loss = 851.54704827\n",
      "Iteration 158, loss = 842.95776946\n",
      "Iteration 251, loss = 1532.66641462\n",
      "Iteration 72, loss = 794.63530025\n",
      "Iteration 97, loss = 850.53821587\n",
      "Iteration 138, loss = 827.43388295\n",
      "Iteration 271, loss = 1459.74898323\n",
      "Iteration 64, loss = 818.34068894\n",
      "Iteration 141, loss = 848.75029869\n",
      "Iteration 159, loss = 845.27705936\n",
      "Iteration 139, loss = 826.08698222\n",
      "Iteration 98, loss = 848.03481353\n",
      "Iteration 73, loss = 831.03475549\n",
      "Iteration 160, loss = 843.62209127\n",
      "Iteration 142, loss = 849.82564378\n",
      "Iteration 65, loss = 807.89989894\n",
      "Iteration 140, loss = 824.67838326\n",
      "Iteration 99, loss = 846.60508631\n",
      "Iteration 74, loss = 787.88857857\n",
      "Iteration 252, loss = 1529.24394617\n",
      "Iteration 161, loss = 842.85327674\n",
      "Iteration 143, loss = 849.58454059\n",
      "Iteration 66, loss = 802.55195562\n",
      "Iteration 272, loss = 1421.56861993\n",
      "Iteration 141, loss = 821.86662277\n",
      "Iteration 162, loss = 841.10499076\n",
      "Iteration 100, loss = 844.30453093\n",
      "Iteration 144, loss = 847.41083071\n",
      "Iteration 75, loss = 807.42556486\n",
      "Iteration 67, loss = 822.85064239\n",
      "Iteration 142, loss = 824.26825608\n",
      "Iteration 101, loss = 841.99888103\n",
      "Iteration 163, loss = 841.43708579\n",
      "Iteration 145, loss = 846.07903679\n",
      "Iteration 76, loss = 828.29180260\n",
      "Iteration 143, loss = 823.76771182\n",
      "Iteration 253, loss = 1524.17976888\n",
      "Iteration 102, loss = 839.86826147\n",
      "Iteration 164, loss = 842.28806117\n",
      "Iteration 68, loss = 814.64939523\n",
      "Iteration 146, loss = 846.67924198\n",
      "Iteration 273, loss = 1412.97088834\n",
      "Iteration 144, loss = 821.30191777\n",
      "Iteration 165, loss = 840.20335714\n",
      "Iteration 77, loss = 815.50678973\n",
      "Iteration 103, loss = 838.68516322\n",
      "Iteration 147, loss = 846.44719684\n",
      "Iteration 69, loss = 790.04348794\n",
      "Iteration 145, loss = 821.48222841\n",
      "Iteration 166, loss = 840.60667387\n",
      "Iteration 104, loss = 837.84376396\n",
      "Iteration 78, loss = 800.59325370\n",
      "Iteration 148, loss = 844.99629447\n",
      "Iteration 254, loss = 1523.83260467\n",
      "Iteration 167, loss = 839.51837823\n",
      "Iteration 70, loss = 785.00365989\n",
      "Iteration 146, loss = 821.90359521\n",
      "Iteration 105, loss = 836.96467280\n",
      "Iteration 79, loss = 798.06529344\n",
      "Iteration 274, loss = 1409.21366590\n",
      "Iteration 149, loss = 843.03004687\n",
      "Iteration 168, loss = 839.48567063\n",
      "Iteration 147, loss = 820.07993698\n",
      "Iteration 71, loss = 790.28694451\n",
      "Iteration 106, loss = 835.13100315\n",
      "Iteration 80, loss = 803.93598556\n",
      "Iteration 150, loss = 843.19502464\n",
      "Iteration 169, loss = 840.32963017\n",
      "Iteration 148, loss = 819.73527604\n",
      "Iteration 255, loss = 1517.75051043\n",
      "Iteration 107, loss = 834.21783554\n",
      "Iteration 72, loss = 783.89329850\n",
      "Iteration 170, loss = 837.65632490\n",
      "Iteration 81, loss = 815.31393750\n",
      "Iteration 151, loss = 840.28171306\n",
      "Iteration 149, loss = 818.46918479\n",
      "Iteration 275, loss = 1401.96387726\n",
      "Iteration 108, loss = 832.21000556\n",
      "Iteration 73, loss = 813.95039928\n",
      "Iteration 171, loss = 839.00087055\n",
      "Iteration 82, loss = 799.38705353\n",
      "Iteration 150, loss = 817.63776286\n",
      "Iteration 152, loss = 840.15055112\n",
      "Iteration 109, loss = 829.53879491\n",
      "Iteration 172, loss = 837.55816344\n",
      "Iteration 74, loss = 776.36290457\n",
      "Iteration 256, loss = 1510.31745207\n",
      "Iteration 151, loss = 816.22293718\n",
      "Iteration 153, loss = 839.58564850\n",
      "Iteration 83, loss = 804.24253955\n",
      "Iteration 110, loss = 828.95156593\n",
      "Iteration 173, loss = 836.81993429\n",
      "Iteration 152, loss = 815.29858749\n",
      "Iteration 75, loss = 789.28365153\n",
      "Iteration 276, loss = 1400.16090741\n",
      "Iteration 174, loss = 837.55045885\n",
      "Iteration 154, loss = 841.80539106\n",
      "Iteration 111, loss = 827.31682253\n",
      "Iteration 84, loss = 791.36816875\n",
      "Iteration 153, loss = 816.22568022\n",
      "Iteration 175, loss = 837.27685398\n",
      "Iteration 112, loss = 825.67475011\n",
      "Iteration 76, loss = 817.27608640\n",
      "Iteration 155, loss = 840.46837576\n",
      "Iteration 257, loss = 1510.13980121\n",
      "Iteration 85, loss = 782.46902300\n",
      "Iteration 176, loss = 836.60041252\n",
      "Iteration 154, loss = 815.79708389\n",
      "Iteration 113, loss = 824.98574686\n",
      "Iteration 156, loss = 839.12514933\n",
      "Iteration 77, loss = 798.40561896\n",
      "Iteration 277, loss = 1401.89803723\n",
      "Iteration 86, loss = 786.70897202\n",
      "Iteration 177, loss = 835.98258851\n",
      "Iteration 155, loss = 815.85614903\n",
      "Iteration 114, loss = 825.83164882\n",
      "Iteration 157, loss = 838.08206306\n",
      "Iteration 78, loss = 789.77233667\n",
      "Iteration 178, loss = 832.99223447\n",
      "Iteration 156, loss = 815.21915737\n",
      "Iteration 258, loss = 1509.34502475\n",
      "Iteration 87, loss = 812.10501836\n",
      "Iteration 115, loss = 822.86276629\n",
      "Iteration 158, loss = 836.81987303\n",
      "Iteration 179, loss = 834.65295784\n",
      "Iteration 157, loss = 814.21699949\n",
      "Iteration 79, loss = 777.70556871\n",
      "Iteration 116, loss = 822.09484833\n",
      "Iteration 88, loss = 798.83889658\n",
      "Iteration 278, loss = 1387.63602746\n",
      "Iteration 180, loss = 833.96145280\n",
      "Iteration 159, loss = 839.64178677\n",
      "Iteration 158, loss = 813.13375077\n",
      "Iteration 117, loss = 818.96390409\n",
      "Iteration 80, loss = 790.59033876\n",
      "Iteration 89, loss = 803.01872024\n",
      "Iteration 181, loss = 833.52405409\n",
      "Iteration 259, loss = 1498.72311030\n",
      "Iteration 160, loss = 836.65865966\n",
      "Iteration 159, loss = 814.78773078\n",
      "Iteration 118, loss = 818.34492662\n",
      "Iteration 182, loss = 832.53070481\n",
      "Iteration 81, loss = 803.48700209\n",
      "Iteration 90, loss = 799.13859058\n",
      "Iteration 161, loss = 836.40535841\n",
      "Iteration 160, loss = 813.02647685\n",
      "Iteration 279, loss = 1386.46699142\n",
      "Iteration 119, loss = 818.79709204\n",
      "Iteration 183, loss = 833.60638745\n",
      "Iteration 162, loss = 835.36975246\n",
      "Iteration 82, loss = 793.57145799\n",
      "Iteration 161, loss = 812.25444183\n",
      "Iteration 260, loss = 1495.88943449\n",
      "Iteration 91, loss = 796.04090425\n",
      "Iteration 184, loss = 833.40483418\n",
      "Iteration 120, loss = 818.46072815\n",
      "Iteration 163, loss = 835.44943956\n",
      "Iteration 162, loss = 811.32987602\n",
      "Iteration 83, loss = 788.36945347\n",
      "Iteration 185, loss = 830.70314424\n",
      "Iteration 92, loss = 798.94420874\n",
      "Iteration 121, loss = 817.52263211\n",
      "Iteration 280, loss = 1388.75735408\n",
      "Iteration 164, loss = 836.68615914\n",
      "Iteration 163, loss = 811.49839227\n",
      "Iteration 186, loss = 831.93325371\n",
      "Iteration 84, loss = 775.51674186\n",
      "Iteration 122, loss = 816.26240773\n",
      "Iteration 261, loss = 1488.31534382\n",
      "Iteration 93, loss = 790.13827909\n",
      "Iteration 165, loss = 834.42800693\n",
      "Iteration 164, loss = 812.36588782\n",
      "Iteration 187, loss = 832.04738522\n",
      "Iteration 123, loss = 814.41140362\n",
      "Iteration 85, loss = 777.90244486\n",
      "Iteration 166, loss = 833.83979932\n",
      "Iteration 94, loss = 793.78601546\n",
      "Iteration 188, loss = 831.29332777\n",
      "Iteration 165, loss = 810.65831035\n",
      "Iteration 124, loss = 812.87938874\n",
      "Iteration 281, loss = 1380.19118991\n",
      "Iteration 189, loss = 830.98798339\n",
      "Iteration 86, loss = 778.17807079\n",
      "Iteration 167, loss = 833.84787295\n",
      "Iteration 95, loss = 783.29638998\n",
      "Iteration 166, loss = 810.45451625\n",
      "Iteration 262, loss = 1481.76374406\n",
      "Iteration 125, loss = 811.84141072\n",
      "Iteration 190, loss = 830.36752416\n",
      "Iteration 168, loss = 833.98541527\n",
      "Iteration 167, loss = 810.23549510\n",
      "Iteration 87, loss = 796.35776820\n",
      "Iteration 126, loss = 811.27025826\n",
      "Iteration 96, loss = 794.94098000\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 191, loss = 831.38824621\n",
      "Iteration 282, loss = 1373.98807958\n",
      "Iteration 168, loss = 810.56474316\n",
      "Iteration 169, loss = 833.97608166\n",
      "Iteration 88, loss = 781.92496180\n",
      "Iteration 127, loss = 811.00145981\n",
      "Iteration 192, loss = 829.60265666\n",
      "Iteration 263, loss = 1488.23510420\n",
      "Iteration 169, loss = 811.91043445\n",
      "Iteration 128, loss = 810.63704578\n",
      "Iteration 1, loss = 2960.62187454\n",
      "Iteration 170, loss = 830.73483199\n",
      "Iteration 89, loss = 794.56705916\n",
      "Iteration 193, loss = 828.86205890\n",
      "Iteration 170, loss = 808.45277634\n",
      "Iteration 2, loss = 1217.76855507\n",
      "Iteration 129, loss = 808.68440753\n",
      "Iteration 171, loss = 832.70652067\n",
      "Iteration 194, loss = 830.82286283\n",
      "Iteration 283, loss = 1365.17749207\n",
      "Iteration 90, loss = 783.77550975\n",
      "Iteration 171, loss = 809.41882534\n",
      "Iteration 130, loss = 808.86582166\n",
      "Iteration 3, loss = 1096.36001679\n",
      "Iteration 195, loss = 829.67719138\n",
      "Iteration 264, loss = 1486.75514034\n",
      "Iteration 172, loss = 831.04970081\n",
      "Iteration 172, loss = 808.83262925\n",
      "Iteration 91, loss = 773.56521008\n",
      "Iteration 196, loss = 828.99547572\n",
      "Iteration 131, loss = 807.35662111\n",
      "Iteration 173, loss = 829.29477624\n",
      "Iteration 4, loss = 976.93039376\n",
      "Iteration 173, loss = 807.92428504\n",
      "Iteration 197, loss = 828.68527658\n",
      "Iteration 284, loss = 1352.67861173\n",
      "Iteration 92, loss = 790.01527213\n",
      "Iteration 132, loss = 806.45359253\n",
      "Iteration 174, loss = 831.10120300\n",
      "Iteration 5, loss = 963.95755307\n",
      "Iteration 174, loss = 807.88270198\n",
      "Iteration 265, loss = 1462.48664713\n",
      "Iteration 198, loss = 830.80856490\n",
      "Iteration 133, loss = 806.83167122\n",
      "Iteration 175, loss = 829.96955547\n",
      "Iteration 175, loss = 808.30640175\n",
      "Iteration 93, loss = 780.60353359\n",
      "Iteration 6, loss = 908.49794360\n",
      "Iteration 199, loss = 827.25646208\n",
      "Iteration 134, loss = 804.18631350\n",
      "Iteration 176, loss = 807.95261310\n",
      "Iteration 176, loss = 829.14291397\n",
      "Iteration 285, loss = 1357.69868098\n",
      "Iteration 200, loss = 825.83555881\n",
      "Iteration 94, loss = 783.47288953\n",
      "Iteration 7, loss = 908.34960685\n",
      "Iteration 177, loss = 807.54875211\n",
      "Iteration 135, loss = 805.09161925\n",
      "Iteration 177, loss = 829.05359278\n",
      "Iteration 266, loss = 1466.57004511\n",
      "Iteration 201, loss = 828.25519908\n",
      "Iteration 95, loss = 776.97446078\n",
      "Iteration 8, loss = 922.55534386\n",
      "Iteration 136, loss = 804.06100981\n",
      "Iteration 178, loss = 805.90441033\n",
      "Iteration 178, loss = 826.46877819\n",
      "Iteration 202, loss = 828.73519011\n",
      "Iteration 137, loss = 801.91179771\n",
      "Iteration 9, loss = 905.82035258\n",
      "Iteration 96, loss = 789.80512867\n",
      "Iteration 286, loss = 1350.60260828\n",
      "Iteration 179, loss = 806.46499273\n",
      "Iteration 203, loss = 826.81706815\n",
      "Iteration 179, loss = 827.82903414\n",
      "Iteration 267, loss = 1465.18650665\n",
      "Iteration 138, loss = 803.70358405\n",
      "Iteration 180, loss = 804.80309010\n",
      "Iteration 10, loss = 895.18624696\n",
      "Iteration 97, loss = 777.27264031\n",
      "Iteration 204, loss = 826.87593737\n",
      "Iteration 180, loss = 827.04909495\n",
      "Iteration 139, loss = 801.64416332\n",
      "Iteration 181, loss = 804.58030496\n",
      "Iteration 181, loss = 826.57322611\n",
      "Iteration 205, loss = 828.79711456\n",
      "Iteration 98, loss = 792.14250692\n",
      "Iteration 11, loss = 876.50712770\n",
      "Iteration 287, loss = 1371.36154824\n",
      "Iteration 182, loss = 804.22516612\n",
      "Iteration 140, loss = 801.01042356\n",
      "Iteration 206, loss = 826.63098722\n",
      "Iteration 182, loss = 825.36401751\n",
      "Iteration 268, loss = 1463.14604296\n",
      "Iteration 12, loss = 866.93921799\n",
      "Iteration 99, loss = 783.66079069\n",
      "Iteration 183, loss = 805.61294871\n",
      "Iteration 141, loss = 799.04028836\n",
      "Iteration 207, loss = 825.82443773\n",
      "Iteration 183, loss = 826.63303468\n",
      "Iteration 184, loss = 804.16646040\n",
      "Iteration 142, loss = 801.05688427\n",
      "Iteration 100, loss = 783.79439132\n",
      "Iteration 13, loss = 840.66778305\n",
      "Iteration 208, loss = 827.97637133\n",
      "Iteration 184, loss = 826.15532250\n",
      "Iteration 288, loss = 1366.46188146\n",
      "Iteration 185, loss = 800.80514161\n",
      "Iteration 209, loss = 825.36810761\n",
      "Iteration 269, loss = 1454.07737161\n",
      "Iteration 143, loss = 799.72810415\n",
      "Iteration 101, loss = 797.21918949\n",
      "Iteration 14, loss = 878.52012027\n",
      "Iteration 185, loss = 822.03982185\n",
      "Iteration 210, loss = 824.89841630\n",
      "Iteration 186, loss = 803.90157681\n",
      "Iteration 144, loss = 798.99039344\n",
      "Iteration 186, loss = 824.03816851\n",
      "Iteration 102, loss = 771.32693296\n",
      "Iteration 15, loss = 849.74166433\n",
      "Iteration 211, loss = 824.93139315\n",
      "Iteration 187, loss = 804.00097906\n",
      "Iteration 145, loss = 799.10379042\n",
      "Iteration 270, loss = 1446.58872946\n",
      "Iteration 289, loss = 1331.16819398\n",
      "Iteration 187, loss = 824.80200252\n",
      "Iteration 212, loss = 824.09157813\n",
      "Iteration 103, loss = 773.17194500\n",
      "Iteration 188, loss = 803.22708575\n",
      "Iteration 16, loss = 859.42875460\n",
      "Iteration 146, loss = 798.15830656\n",
      "Iteration 213, loss = 825.51878791\n",
      "Iteration 188, loss = 824.60510904\n",
      "Iteration 189, loss = 803.95144706\n",
      "Iteration 104, loss = 773.69203328\n",
      "Iteration 17, loss = 850.58742472\n",
      "Iteration 147, loss = 797.10514000\n",
      "Iteration 214, loss = 826.02356871\n",
      "Iteration 189, loss = 823.57872893\n",
      "Iteration 190, loss = 803.31702084\n",
      "Iteration 271, loss = 1450.56126969\n",
      "Iteration 105, loss = 773.43601680\n",
      "Iteration 290, loss = 1348.78207767\n",
      "Iteration 148, loss = 797.05117168\n",
      "Iteration 215, loss = 823.26997125\n",
      "Iteration 18, loss = 830.62153006\n",
      "Iteration 191, loss = 804.03983975\n",
      "Iteration 190, loss = 822.52415295\n",
      "Iteration 106, loss = 769.58011998\n",
      "Iteration 216, loss = 823.94638710\n",
      "Iteration 149, loss = 794.27771327\n",
      "Iteration 19, loss = 846.34915260\n",
      "Iteration 192, loss = 802.38660116\n",
      "Iteration 191, loss = 823.81195255\n",
      "Iteration 217, loss = 822.88599233\n",
      "Iteration 150, loss = 794.93874526\n",
      "Iteration 107, loss = 766.93613368\n",
      "Iteration 272, loss = 1437.85833016\n",
      "Iteration 291, loss = 1345.08471715\n",
      "Iteration 20, loss = 821.46632537\n",
      "Iteration 192, loss = 822.62306083\n",
      "Iteration 193, loss = 801.20058304\n",
      "Iteration 218, loss = 822.29006783\n",
      "Iteration 151, loss = 794.19513722\n",
      "Iteration 193, loss = 822.13381185\n",
      "Iteration 108, loss = 794.19128403\n",
      "Iteration 194, loss = 803.56026784\n",
      "Iteration 219, loss = 822.18811317\n",
      "Iteration 21, loss = 826.40665501\n",
      "Iteration 152, loss = 792.95172847\n",
      "Iteration 195, loss = 802.85262706\n",
      "Iteration 194, loss = 822.19732842\n",
      "Iteration 220, loss = 824.00275093\n",
      "Iteration 109, loss = 773.00786428\n",
      "Iteration 22, loss = 848.56749987\n",
      "Iteration 273, loss = 1432.28741049\n",
      "Iteration 292, loss = 1328.24943887\n",
      "Iteration 153, loss = 792.58404879\n",
      "Iteration 221, loss = 821.96658077\n",
      "Iteration 196, loss = 801.66741653\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 195, loss = 821.83771602\n",
      "Iteration 110, loss = 772.21414990\n",
      "Iteration 23, loss = 815.78938695\n",
      "Iteration 154, loss = 793.43550236\n",
      "Iteration 222, loss = 821.38936698\n",
      "Iteration 196, loss = 821.64736964\n",
      "Iteration 111, loss = 755.50486204\n",
      "Iteration 24, loss = 816.54570935\n",
      "Iteration 155, loss = 793.17747539\n",
      "Iteration 274, loss = 1424.44931769\n",
      "Iteration 1, loss = 3164.29825467\n",
      "Iteration 223, loss = 821.67353373\n",
      "Iteration 197, loss = 820.43525924\n",
      "Iteration 293, loss = 1325.15424227\n",
      "Iteration 156, loss = 791.30234066\n",
      "Iteration 112, loss = 770.05412518\n",
      "Iteration 224, loss = 821.52391802\n",
      "Iteration 25, loss = 833.98125666\n",
      "Iteration 2, loss = 1216.71296850\n",
      "Iteration 198, loss = 822.48943025\n",
      "Iteration 157, loss = 790.79749165\n",
      "Iteration 225, loss = 822.65591293\n",
      "Iteration 113, loss = 792.12093330\n",
      "Iteration 199, loss = 819.80361051\n",
      "Iteration 275, loss = 1417.47520250\n",
      "Iteration 26, loss = 825.01013258\n",
      "Iteration 3, loss = 1118.24893181\n",
      "Iteration 158, loss = 788.94644649\n",
      "Iteration 226, loss = 821.67692942\n",
      "Iteration 294, loss = 1321.69120698\n",
      "Iteration 200, loss = 818.85718189\n",
      "Iteration 114, loss = 777.34779192\n",
      "Iteration 27, loss = 833.66393307\n",
      "Iteration 4, loss = 1012.09292066\n",
      "Iteration 227, loss = 822.06183371\n",
      "Iteration 159, loss = 791.74677969\n",
      "Iteration 201, loss = 820.27413569\n",
      "Iteration 228, loss = 819.97330697\n",
      "Iteration 115, loss = 768.72707061\n",
      "Iteration 28, loss = 851.77159364\n",
      "Iteration 5, loss = 999.99518863\n",
      "Iteration 276, loss = 1421.64195198\n",
      "Iteration 160, loss = 789.69879102\n",
      "Iteration 202, loss = 821.22138442\n",
      "Iteration 295, loss = 1320.07324548\n",
      "Iteration 229, loss = 821.02631029\n",
      "Iteration 116, loss = 765.96768914\n",
      "Iteration 161, loss = 790.13255334\n",
      "Iteration 29, loss = 805.87691994\n",
      "Iteration 6, loss = 955.16368784\n",
      "Iteration 203, loss = 818.91163318\n",
      "Iteration 230, loss = 819.88400287\n",
      "Iteration 162, loss = 789.37490132\n",
      "Iteration 117, loss = 771.30538391\n",
      "Iteration 7, loss = 961.55649405\n",
      "Iteration 277, loss = 1407.88601045\n",
      "Iteration 204, loss = 819.58732563\n",
      "Iteration 231, loss = 818.56579996\n",
      "Iteration 30, loss = 842.33997673\n",
      "Iteration 163, loss = 788.37977531\n",
      "Iteration 296, loss = 1326.57668288\n",
      "Iteration 118, loss = 767.63310467\n",
      "Iteration 8, loss = 941.49392434\n",
      "Iteration 205, loss = 820.13727165\n",
      "Iteration 232, loss = 821.17129884\n",
      "Iteration 31, loss = 818.55492714\n",
      "Iteration 164, loss = 787.97481364\n",
      "Iteration 233, loss = 820.61101530\n",
      "Iteration 206, loss = 818.44497288\n",
      "Iteration 9, loss = 939.63848081\n",
      "Iteration 119, loss = 785.55332624\n",
      "Iteration 278, loss = 1418.14411751\n",
      "Iteration 165, loss = 787.01611571\n",
      "Iteration 32, loss = 802.42108176\n",
      "Iteration 234, loss = 821.64153032\n",
      "Iteration 207, loss = 816.88153450\n",
      "Iteration 297, loss = 1316.57802575\n",
      "Iteration 10, loss = 941.12907003\n",
      "Iteration 120, loss = 772.98749583\n",
      "Iteration 166, loss = 788.03372792\n",
      "Iteration 235, loss = 819.93080477\n",
      "Iteration 33, loss = 812.73340314\n",
      "Iteration 208, loss = 818.86221899\n",
      "Iteration 11, loss = 934.69958783\n",
      "Iteration 167, loss = 786.82452870\n",
      "Iteration 121, loss = 758.48076801\n",
      "Iteration 236, loss = 819.98284972\n",
      "Iteration 209, loss = 817.74589555\n",
      "Iteration 34, loss = 833.96534481\n",
      "Iteration 279, loss = 1416.74174251\n",
      "Iteration 168, loss = 787.93723031\n",
      "Iteration 12, loss = 947.53460193\n",
      "Iteration 237, loss = 820.01611501\n",
      "Iteration 210, loss = 816.68442322\n",
      "Iteration 298, loss = 1315.45297187\n",
      "Iteration 122, loss = 752.96225460\n",
      "Iteration 35, loss = 796.55910486\n",
      "Iteration 169, loss = 787.68383271\n",
      "Iteration 238, loss = 818.63507986\n",
      "Iteration 211, loss = 815.92146313\n",
      "Iteration 13, loss = 902.45934651\n",
      "Iteration 123, loss = 770.47035053\n",
      "Iteration 36, loss = 826.45978024\n",
      "Iteration 170, loss = 785.58582388\n",
      "Iteration 280, loss = 1402.84782692\n",
      "Iteration 239, loss = 819.27464191\n",
      "Iteration 212, loss = 816.20165062\n",
      "Iteration 14, loss = 923.19527270\n",
      "Iteration 299, loss = 1308.43372335\n",
      "Iteration 124, loss = 760.98571414\n",
      "Iteration 171, loss = 784.15710856\n",
      "Iteration 240, loss = 819.16655630\n",
      "Iteration 37, loss = 816.24948135\n",
      "Iteration 213, loss = 816.95991556\n",
      "Iteration 15, loss = 907.41500238\n",
      "Iteration 241, loss = 818.73509034\n",
      "Iteration 172, loss = 785.36674591\n",
      "Iteration 125, loss = 767.14330362\n",
      "Iteration 214, loss = 817.69689765\n",
      "Iteration 38, loss = 790.86108269\n",
      "Iteration 281, loss = 1393.86434103\n",
      "Iteration 242, loss = 820.42785756\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 905.06036070\n",
      "Iteration 173, loss = 784.84060960\n",
      "Iteration 215, loss = 814.59032657\n",
      "Iteration 126, loss = 772.23069653\n",
      "Iteration 300, loss = 1308.59325690\n",
      "Iteration 39, loss = 791.73940774\n",
      "Iteration 216, loss = 814.78400453\n",
      "Iteration 17, loss = 907.55309045\n",
      "Iteration 174, loss = 785.20270507\n",
      "Iteration 40, loss = 791.19426609\n",
      "Iteration 127, loss = 764.35549222\n",
      "Iteration 1, loss = 3140.30655870\n",
      "Iteration 282, loss = 1376.97437453\n",
      "Iteration 217, loss = 813.98094335\n",
      "Iteration 175, loss = 784.18645679\n",
      "Iteration 18, loss = 869.23314696\n",
      "Iteration 41, loss = 793.85221123\n",
      "Iteration 128, loss = 765.82588255\n",
      "Iteration 301, loss = 1296.75730101\n",
      "Iteration 2, loss = 1190.54964062\n",
      "Iteration 176, loss = 784.01236298\n",
      "Iteration 218, loss = 813.65770948\n",
      "Iteration 19, loss = 895.51201632\n",
      "Iteration 42, loss = 802.63816933\n",
      "Iteration 177, loss = 783.49049075\n",
      "Iteration 3, loss = 1132.50988653\n",
      "Iteration 129, loss = 762.24806331\n",
      "Iteration 219, loss = 813.44071121\n",
      "Iteration 283, loss = 1396.45800606\n",
      "Iteration 20, loss = 868.48777119\n",
      "Iteration 43, loss = 802.28211525\n",
      "Iteration 130, loss = 757.86934514\n",
      "Iteration 178, loss = 782.86928557\n",
      "Iteration 4, loss = 1000.61029695\n",
      "Iteration 220, loss = 815.59640880\n",
      "Iteration 302, loss = 1287.15496814\n",
      "Iteration 21, loss = 876.45697554\n",
      "Iteration 179, loss = 782.80804475\n",
      "Iteration 221, loss = 813.00487372\n",
      "Iteration 44, loss = 802.07304636\n",
      "Iteration 5, loss = 969.58405218\n",
      "Iteration 131, loss = 774.30036121\n",
      "Iteration 284, loss = 1378.56759525\n",
      "Iteration 22, loss = 897.87346743\n",
      "Iteration 180, loss = 782.00571108\n",
      "Iteration 222, loss = 812.85239227\n",
      "Iteration 6, loss = 938.24918540\n",
      "Iteration 45, loss = 794.84167866\n",
      "Iteration 132, loss = 763.53717393\n",
      "Iteration 303, loss = 1279.41348878\n",
      "Iteration 181, loss = 781.28051395\n",
      "Iteration 223, loss = 812.83370706\n",
      "Iteration 23, loss = 875.93683113\n",
      "Iteration 46, loss = 807.52415974\n",
      "Iteration 7, loss = 912.57751672\n",
      "Iteration 133, loss = 749.29287631\n",
      "Iteration 182, loss = 781.29885761\n",
      "Iteration 285, loss = 1385.22223957\n",
      "Iteration 224, loss = 812.41072173\n",
      "Iteration 24, loss = 889.83281875\n",
      "Iteration 8, loss = 911.13460841\n",
      "Iteration 47, loss = 800.84764179\n",
      "Iteration 134, loss = 756.58740681\n",
      "Iteration 183, loss = 781.45782496\n",
      "Iteration 225, loss = 813.02107219\n",
      "Iteration 304, loss = 1292.85944757\n",
      "Iteration 25, loss = 887.87278436\n",
      "Iteration 9, loss = 900.44667471\n",
      "Iteration 184, loss = 780.37693427\n",
      "Iteration 48, loss = 761.65879809\n",
      "Iteration 226, loss = 812.34501166\n",
      "Iteration 135, loss = 763.46607136\n",
      "Iteration 185, loss = 778.01377055\n",
      "Iteration 286, loss = 1361.90689203\n",
      "Iteration 26, loss = 862.80600364\n",
      "Iteration 10, loss = 883.93137109\n",
      "Iteration 227, loss = 812.94024101\n",
      "Iteration 49, loss = 788.26012876\n",
      "Iteration 136, loss = 760.25155699\n",
      "Iteration 186, loss = 780.38086455\n",
      "Iteration 228, loss = 810.26633581\n",
      "Iteration 11, loss = 910.64158197\n",
      "Iteration 305, loss = 1285.10825868\n",
      "Iteration 27, loss = 863.82138364\n",
      "Iteration 50, loss = 776.18396682\n",
      "Iteration 137, loss = 758.42234583\n",
      "Iteration 187, loss = 779.27479278\n",
      "Iteration 229, loss = 810.75752139\n",
      "Iteration 12, loss = 939.11627858\n",
      "Iteration 287, loss = 1359.90096663\n",
      "Iteration 51, loss = 770.49974823\n",
      "Iteration 28, loss = 898.85941413\n",
      "Iteration 188, loss = 779.89563551\n",
      "Iteration 138, loss = 756.00931382\n",
      "Iteration 230, loss = 810.42955654\n",
      "Iteration 13, loss = 904.07217100\n",
      "Iteration 189, loss = 779.99011232\n",
      "Iteration 52, loss = 768.73016282\n",
      "Iteration 139, loss = 748.67040801\n",
      "Iteration 29, loss = 882.65179769\n",
      "Iteration 306, loss = 1292.48102611\n",
      "Iteration 231, loss = 810.08727875\n",
      "Iteration 14, loss = 888.67635220\n",
      "Iteration 190, loss = 778.86284400\n",
      "Iteration 53, loss = 782.93009062\n",
      "Iteration 288, loss = 1363.36139501\n",
      "Iteration 30, loss = 873.34315947\n",
      "Iteration 140, loss = 771.02683181\n",
      "Iteration 232, loss = 811.60514175\n",
      "Iteration 191, loss = 780.28132898\n",
      "Iteration 15, loss = 886.71187059\n",
      "Iteration 54, loss = 761.40209284\n",
      "Iteration 31, loss = 878.44399024\n",
      "Iteration 233, loss = 811.03002104\n",
      "Iteration 141, loss = 759.27234459\n",
      "Iteration 192, loss = 778.36974987\n",
      "Iteration 307, loss = 1286.23179351\n",
      "Iteration 16, loss = 898.83099052\n",
      "Iteration 234, loss = 811.49849284\n",
      "Iteration 289, loss = 1356.50824983\n",
      "Iteration 142, loss = 760.33449434\n",
      "Iteration 55, loss = 780.53517030\n",
      "Iteration 32, loss = 850.44328475\n",
      "Iteration 193, loss = 777.71378673\n",
      "Iteration 17, loss = 887.65591045\n",
      "Iteration 235, loss = 810.71257995\n",
      "Iteration 194, loss = 779.18657497\n",
      "Iteration 143, loss = 772.14710127\n",
      "Iteration 56, loss = 779.82199872\n",
      "Iteration 33, loss = 859.64129588\n",
      "Iteration 236, loss = 809.78219186\n",
      "Iteration 308, loss = 1275.11573156\n",
      "Iteration 18, loss = 852.90649357\n",
      "Iteration 195, loss = 778.73389892\n",
      "Iteration 290, loss = 1367.07271529\n",
      "Iteration 57, loss = 742.01627165\n",
      "Iteration 144, loss = 752.71396508\n",
      "Iteration 34, loss = 878.30558252\n",
      "Iteration 237, loss = 809.83823344\n",
      "Iteration 196, loss = 777.50999555\n",
      "Iteration 19, loss = 886.15552882\n",
      "Iteration 58, loss = 774.33472016\n",
      "Iteration 145, loss = 754.28824902\n",
      "Iteration 238, loss = 808.48099921\n",
      "Iteration 35, loss = 857.82528846\n",
      "Iteration 197, loss = 777.67925405\n",
      "Iteration 20, loss = 845.06484850\n",
      "Iteration 309, loss = 1261.85533758\n",
      "Iteration 291, loss = 1340.90076380\n",
      "Iteration 59, loss = 772.72281787\n",
      "Iteration 198, loss = 779.04398108\n",
      "Iteration 239, loss = 808.24666311\n",
      "Iteration 146, loss = 752.66161931\n",
      "Iteration 36, loss = 856.00361470\n",
      "Iteration 21, loss = 861.23879242\n",
      "Iteration 199, loss = 776.54204825\n",
      "Iteration 60, loss = 744.99309731\n",
      "Iteration 240, loss = 808.25146354\n",
      "Iteration 147, loss = 764.48106452\n",
      "Iteration 37, loss = 859.11592254\n",
      "Iteration 22, loss = 865.69619618\n",
      "Iteration 292, loss = 1343.24820475\n",
      "Iteration 200, loss = 775.90328872\n",
      "Iteration 310, loss = 1261.92824969\n",
      "Iteration 241, loss = 808.43228319\n",
      "Iteration 61, loss = 779.30422871\n",
      "Iteration 148, loss = 762.73506744\n",
      "Iteration 38, loss = 835.77825514\n",
      "Iteration 23, loss = 843.75710846\n",
      "Iteration 201, loss = 777.50655092\n",
      "Iteration 242, loss = 810.33582993\n",
      "Iteration 62, loss = 775.64281840\n",
      "Iteration 149, loss = 756.65676692\n",
      "Iteration 39, loss = 857.10505653\n",
      "Iteration 202, loss = 776.21771741\n",
      "Iteration 243, loss = 809.16146586\n",
      "Iteration 24, loss = 866.84123196\n",
      "Iteration 293, loss = 1363.58019434\n",
      "Iteration 150, loss = 767.61409781\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 63, loss = 783.03320110\n",
      "Iteration 311, loss = 1260.78535079\n",
      "Iteration 203, loss = 775.41567213\n",
      "Iteration 40, loss = 834.55473093\n",
      "Iteration 244, loss = 808.46002715\n",
      "Iteration 25, loss = 872.36975187\n",
      "Iteration 204, loss = 775.94088702\n",
      "Iteration 64, loss = 778.61331536\n",
      "Iteration 245, loss = 803.11093888\n",
      "Iteration 1, loss = 3243.45848274\n",
      "Iteration 41, loss = 843.11255639\n",
      "Iteration 26, loss = 831.66439518\n",
      "Iteration 205, loss = 777.00491330\n",
      "Iteration 65, loss = 773.93935387\n",
      "Iteration 294, loss = 1336.90912378\n",
      "Iteration 246, loss = 810.35111990\n",
      "Iteration 312, loss = 1252.98222352\n",
      "Iteration 2, loss = 1206.77792365\n",
      "Iteration 206, loss = 776.23772243\n",
      "Iteration 42, loss = 868.39807301\n",
      "Iteration 27, loss = 848.34319986\n",
      "Iteration 66, loss = 789.38678306\n",
      "Iteration 247, loss = 807.46780246\n",
      "Iteration 207, loss = 774.97342272\n",
      "Iteration 3, loss = 1120.17415106\n",
      "Iteration 28, loss = 874.65661705\n",
      "Iteration 43, loss = 834.28526709\n",
      "Iteration 67, loss = 772.57054175\n",
      "Iteration 248, loss = 807.36305027\n",
      "Iteration 295, loss = 1327.26498551\n",
      "Iteration 208, loss = 776.65967197\n",
      "Iteration 4, loss = 1028.18516185\n",
      "Iteration 313, loss = 1269.30592379\n",
      "Iteration 29, loss = 853.13812434\n",
      "Iteration 44, loss = 855.72918776\n",
      "Iteration 249, loss = 804.06484378\n",
      "Iteration 68, loss = 743.03564445\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 209, loss = 774.68798424\n",
      "Iteration 5, loss = 987.34128524\n",
      "Iteration 30, loss = 846.37424702\n",
      "Iteration 250, loss = 805.99325649\n",
      "Iteration 45, loss = 825.20135545\n",
      "Iteration 210, loss = 774.18273435\n",
      "Iteration 296, loss = 1335.56507947\n",
      "Iteration 1, loss = 3219.96498947\n",
      "Iteration 6, loss = 990.58488931\n",
      "Iteration 31, loss = 848.32415418\n",
      "Iteration 251, loss = 806.34321669\n",
      "Iteration 211, loss = 775.00929664\n",
      "Iteration 46, loss = 832.03726427\n",
      "Iteration 314, loss = 1249.62243397\n",
      "Iteration 2, loss = 1215.85779058\n",
      "Iteration 252, loss = 807.38505299\n",
      "Iteration 7, loss = 926.76469405\n",
      "Iteration 212, loss = 773.00985405\n",
      "Iteration 32, loss = 827.43308503\n",
      "Iteration 47, loss = 828.21314735\n",
      "Iteration 3, loss = 1131.22686398\n",
      "Iteration 253, loss = 806.51885862\n",
      "Iteration 213, loss = 775.31407034\n",
      "Iteration 297, loss = 1325.12570789\n",
      "Iteration 8, loss = 933.32242970\n",
      "Iteration 33, loss = 829.33657772\n",
      "Iteration 48, loss = 799.04821165\n",
      "Iteration 4, loss = 1053.74139271\n",
      "Iteration 315, loss = 1241.58110265\n",
      "Iteration 254, loss = 804.52376251\n",
      "Iteration 214, loss = 774.26976691\n",
      "Iteration 9, loss = 936.75842786\n",
      "Iteration 34, loss = 832.74550858\n",
      "Iteration 49, loss = 852.89791580\n",
      "Iteration 255, loss = 805.12340194\n",
      "Iteration 5, loss = 994.39067779\n",
      "Iteration 215, loss = 771.44868762\n",
      "Iteration 298, loss = 1320.48357028\n",
      "Iteration 35, loss = 825.70378568\n",
      "Iteration 10, loss = 918.31333709\n",
      "Iteration 256, loss = 805.47634969\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 50, loss = 817.90856362\n",
      "Iteration 216, loss = 774.09816541\n",
      "Iteration 6, loss = 999.50502772\n",
      "Iteration 316, loss = 1240.02735103\n",
      "Iteration 11, loss = 938.98176494\n",
      "Iteration 36, loss = 821.17773401\n",
      "Iteration 217, loss = 771.51639760\n",
      "Iteration 51, loss = 806.21810270\n",
      "Iteration 1, loss = 3325.93665050\n",
      "Iteration 7, loss = 950.88419482\n",
      "Iteration 299, loss = 1316.71646780\n",
      "Iteration 12, loss = 982.73892259\n",
      "Iteration 218, loss = 771.19748941\n",
      "Iteration 37, loss = 813.66691143\n",
      "Iteration 52, loss = 817.50184948\n",
      "Iteration 2, loss = 1257.68353799\n",
      "Iteration 8, loss = 935.74412732\n",
      "Iteration 317, loss = 1253.69146443\n",
      "Iteration 219, loss = 770.20062304\n",
      "Iteration 38, loss = 814.28814179\n",
      "Iteration 13, loss = 936.12524912\n",
      "Iteration 3, loss = 1156.61587287\n",
      "Iteration 300, loss = 1318.41998856\n",
      "Iteration 53, loss = 826.08313283\n",
      "Iteration 9, loss = 944.81927135\n",
      "Iteration 220, loss = 772.79794761\n",
      "Iteration 39, loss = 816.55315484\n",
      "Iteration 14, loss = 908.16511118\n",
      "Iteration 4, loss = 1064.30687929\n",
      "Iteration 10, loss = 926.72037460\n",
      "Iteration 54, loss = 797.78902291\n",
      "Iteration 221, loss = 770.72329941\n",
      "Iteration 40, loss = 811.43984785\n",
      "Iteration 15, loss = 899.58476119\n",
      "Iteration 318, loss = 1244.75805634\n",
      "Iteration 222, loss = 770.56736491\n",
      "Iteration 301, loss = 1296.72917219\n",
      "Iteration 55, loss = 827.49872864\n",
      "Iteration 5, loss = 997.04742616\n",
      "Iteration 11, loss = 930.94095220\n",
      "Iteration 41, loss = 810.93452992\n",
      "Iteration 223, loss = 768.71500722\n",
      "Iteration 16, loss = 937.45963886\n",
      "Iteration 56, loss = 815.99374505\n",
      "Iteration 12, loss = 948.13994567\n",
      "Iteration 6, loss = 1003.46083906\n",
      "Iteration 224, loss = 769.21523038\n",
      "Iteration 42, loss = 810.99114801\n",
      "Iteration 17, loss = 922.43060210\n",
      "Iteration 319, loss = 1237.74505846\n",
      "Iteration 13, loss = 924.46358705\n",
      "Iteration 57, loss = 800.35320722\n",
      "Iteration 302, loss = 1309.88674399\n",
      "Iteration 7, loss = 957.25369488\n",
      "Iteration 225, loss = 771.11987468\n",
      "Iteration 43, loss = 819.32488686\n",
      "Iteration 14, loss = 909.17133033\n",
      "Iteration 18, loss = 871.83117053\n",
      "Iteration 58, loss = 815.14997384\n",
      "Iteration 226, loss = 769.06219692\n",
      "Iteration 8, loss = 942.88134831\n",
      "Iteration 44, loss = 818.75152694\n",
      "Iteration 15, loss = 906.74076249\n",
      "Iteration 320, loss = 1234.54975685\n",
      "Iteration 19, loss = 899.29521629\n",
      "Iteration 227, loss = 769.68085500\n",
      "Iteration 59, loss = 824.02118253\n",
      "Iteration 303, loss = 1297.02965993\n",
      "Iteration 9, loss = 966.41263078\n",
      "Iteration 45, loss = 792.14991245\n",
      "Iteration 16, loss = 940.11798627\n",
      "Iteration 228, loss = 769.40416407\n",
      "Iteration 20, loss = 889.10026704\n",
      "Iteration 60, loss = 785.09964366\n",
      "Iteration 10, loss = 927.03705999\n",
      "Iteration 46, loss = 797.18325634\n",
      "Iteration 17, loss = 902.50016079\n",
      "Iteration 229, loss = 768.79562248\n",
      "Iteration 21, loss = 881.29618100\n",
      "Iteration 321, loss = 1239.54552193\n",
      "Iteration 304, loss = 1314.91016298\n",
      "Iteration 61, loss = 819.46773716\n",
      "Iteration 230, loss = 768.09671617\n",
      "Iteration 47, loss = 782.72334440\n",
      "Iteration 11, loss = 953.89714954\n",
      "Iteration 18, loss = 883.82992918\n",
      "Iteration 22, loss = 901.84747802\n",
      "Iteration 62, loss = 807.15963679\n",
      "Iteration 231, loss = 767.58972050\n",
      "Iteration 48, loss = 782.40603804\n",
      "Iteration 12, loss = 943.90484528\n",
      "Iteration 23, loss = 888.41809695\n",
      "Iteration 19, loss = 888.27902251\n",
      "Iteration 232, loss = 768.60057216\n",
      "Iteration 322, loss = 1229.73624742\n",
      "Iteration 63, loss = 829.32788584\n",
      "Iteration 305, loss = 1295.02174859\n",
      "Iteration 13, loss = 936.90376837\n",
      "Iteration 49, loss = 808.64782664\n",
      "Iteration 20, loss = 895.88544433\n",
      "Iteration 233, loss = 767.79714786\n",
      "Iteration 24, loss = 866.96521306\n",
      "Iteration 64, loss = 809.13019152\n",
      "Iteration 50, loss = 798.44773808\n",
      "Iteration 14, loss = 934.62417073\n",
      "Iteration 234, loss = 769.47426730\n",
      "Iteration 21, loss = 865.16148523\n",
      "Iteration 25, loss = 883.18628725\n",
      "Iteration 65, loss = 805.07459516\n",
      "Iteration 306, loss = 1283.41921035\n",
      "Iteration 323, loss = 1235.96115453\n",
      "Iteration 51, loss = 782.60817367\n",
      "Iteration 235, loss = 768.66537105\n",
      "Iteration 15, loss = 926.54031329\n",
      "Iteration 22, loss = 876.29664418\n",
      "Iteration 26, loss = 846.33426285\n",
      "Iteration 236, loss = 766.74684183\n",
      "Iteration 66, loss = 825.71344522\n",
      "Iteration 16, loss = 973.76464862\n",
      "Iteration 52, loss = 797.78484873\n",
      "Iteration 23, loss = 884.92803112\n",
      "Iteration 27, loss = 841.25940971\n",
      "Iteration 237, loss = 767.96065093\n",
      "Iteration 307, loss = 1299.61185759\n",
      "Iteration 67, loss = 806.85624661\n",
      "Iteration 17, loss = 926.02806225\n",
      "Iteration 24, loss = 867.39486413\n",
      "Iteration 53, loss = 784.65120317\n",
      "Iteration 324, loss = 1227.37889153\n",
      "Iteration 238, loss = 767.42894345\n",
      "Iteration 28, loss = 877.51399694\n",
      "Iteration 68, loss = 782.58597775\n",
      "Iteration 25, loss = 883.41582271\n",
      "Iteration 54, loss = 768.30852071\n",
      "Iteration 18, loss = 908.29819782\n",
      "Iteration 239, loss = 768.69371016\n",
      "Iteration 29, loss = 864.57436467\n",
      "Iteration 308, loss = 1272.98311060\n",
      "Iteration 69, loss = 786.33446738\n",
      "Iteration 240, loss = 766.27903527\n",
      "Iteration 19, loss = 912.44189965\n",
      "Iteration 55, loss = 806.59074050\n",
      "Iteration 26, loss = 856.47393158\n",
      "Iteration 325, loss = 1213.37322807\n",
      "Iteration 30, loss = 861.01063249\n",
      "Iteration 241, loss = 766.99933940\n",
      "Iteration 70, loss = 805.41331957\n",
      "Iteration 27, loss = 844.52551072\n",
      "Iteration 20, loss = 904.94932017\n",
      "Iteration 56, loss = 781.68745606\n",
      "Iteration 242, loss = 767.15444046\n",
      "Iteration 31, loss = 886.41318264\n",
      "Iteration 28, loss = 879.51714326\n",
      "Iteration 309, loss = 1270.67513217\n",
      "Iteration 71, loss = 797.46013320\n",
      "Iteration 57, loss = 765.49147265\n",
      "Iteration 21, loss = 875.33765865\n",
      "Iteration 243, loss = 768.23984111\n",
      "Iteration 326, loss = 1210.47630304\n",
      "Iteration 32, loss = 848.78557749\n",
      "Iteration 29, loss = 869.22745904\n",
      "Iteration 58, loss = 784.40354951\n",
      "Iteration 72, loss = 787.37546972\n",
      "Iteration 244, loss = 766.02233181\n",
      "Iteration 22, loss = 899.79035100\n",
      "Iteration 33, loss = 848.20927564\n",
      "Iteration 245, loss = 764.63154647\n",
      "Iteration 30, loss = 863.48286178\n",
      "Iteration 59, loss = 788.15275894\n",
      "Iteration 310, loss = 1268.37458475\n",
      "Iteration 73, loss = 798.97295182\n",
      "Iteration 23, loss = 896.99586398\n",
      "Iteration 246, loss = 767.12674571\n",
      "Iteration 34, loss = 851.50185736\n",
      "Iteration 31, loss = 888.58935010\n",
      "Iteration 327, loss = 1216.87680981\n",
      "Iteration 60, loss = 766.04845285\n",
      "Iteration 74, loss = 801.68293383\n",
      "Iteration 24, loss = 878.74769324\n",
      "Iteration 247, loss = 766.56295116\n",
      "Iteration 35, loss = 851.12515723\n",
      "Iteration 32, loss = 849.19756028\n",
      "Iteration 61, loss = 785.36871963\n",
      "Iteration 75, loss = 804.18718583\n",
      "Iteration 25, loss = 894.33986142\n",
      "Iteration 311, loss = 1270.59984687\n",
      "Iteration 248, loss = 766.46637039\n",
      "Iteration 328, loss = 1209.67822905\n",
      "Iteration 33, loss = 871.22932844\n",
      "Iteration 36, loss = 840.98486449\n",
      "Iteration 62, loss = 771.30045234\n",
      "Iteration 249, loss = 764.56415466\n",
      "Iteration 76, loss = 791.35936280\n",
      "Iteration 26, loss = 877.51743514\n",
      "Iteration 34, loss = 862.71639936\n",
      "Iteration 37, loss = 829.30677914\n",
      "Iteration 250, loss = 765.08796221\n",
      "Iteration 63, loss = 794.76188051\n",
      "Iteration 77, loss = 795.80316124\n",
      "Iteration 312, loss = 1274.74574147\n",
      "Iteration 27, loss = 876.21663188\n",
      "Iteration 251, loss = 764.37208795\n",
      "Iteration 35, loss = 848.40084161\n",
      "Iteration 38, loss = 847.64057724\n",
      "Iteration 329, loss = 1205.05261923\n",
      "Iteration 64, loss = 771.99634540\n",
      "Iteration 78, loss = 800.62226598\n",
      "Iteration 252, loss = 764.62593763\n",
      "Iteration 28, loss = 870.97574508\n",
      "Iteration 36, loss = 844.65880060\n",
      "Iteration 39, loss = 832.93934013\n",
      "Iteration 65, loss = 771.94689700\n",
      "Iteration 79, loss = 802.94210859\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 313, loss = 1265.84826800\n",
      "Iteration 253, loss = 764.30305959\n",
      "Iteration 29, loss = 889.27718216\n",
      "Iteration 40, loss = 834.79690680\n",
      "Iteration 37, loss = 845.34052721\n",
      "Iteration 66, loss = 781.13825063\n",
      "Iteration 254, loss = 765.09192936\n",
      "Iteration 330, loss = 1215.13366554\n",
      "Iteration 1, loss = 3301.86415974\n",
      "Iteration 30, loss = 877.62771408\n",
      "Iteration 38, loss = 839.47244582\n",
      "Iteration 41, loss = 836.66454186\n",
      "Iteration 255, loss = 764.56652618\n",
      "Iteration 67, loss = 766.32325376\n",
      "Iteration 2, loss = 1231.60368747\n",
      "Iteration 314, loss = 1254.54990778\n",
      "Iteration 39, loss = 843.46953746\n",
      "Iteration 31, loss = 899.99251380\n",
      "Iteration 256, loss = 764.91155658\n",
      "Iteration 42, loss = 842.75151043\n",
      "Iteration 68, loss = 750.16819125\n",
      "Iteration 3, loss = 1134.42877267\n",
      "Iteration 331, loss = 1198.03882317\n",
      "Iteration 40, loss = 840.59237317\n",
      "Iteration 257, loss = 763.26342806\n",
      "Iteration 32, loss = 856.03919677\n",
      "Iteration 43, loss = 867.69548860\n",
      "Iteration 69, loss = 767.46997652\n",
      "Iteration 315, loss = 1259.88783523\n",
      "Iteration 4, loss = 1040.94216428\n",
      "Iteration 41, loss = 837.14074765\n",
      "Iteration 258, loss = 763.50056799\n",
      "Iteration 33, loss = 895.83094905\n",
      "Iteration 70, loss = 760.84281666\n",
      "Iteration 44, loss = 853.15038222\n",
      "Iteration 5, loss = 994.38106924\n",
      "Iteration 259, loss = 763.36292290\n",
      "Iteration 42, loss = 839.12753057\n",
      "Iteration 332, loss = 1213.81650219\n",
      "Iteration 34, loss = 859.53414475\n",
      "Iteration 71, loss = 760.54025837\n",
      "Iteration 45, loss = 815.01604435\n",
      "Iteration 260, loss = 764.34926090\n",
      "Iteration 6, loss = 1001.60387998\n",
      "Iteration 43, loss = 861.61896742\n",
      "Iteration 316, loss = 1261.96904786\n",
      "Iteration 35, loss = 853.27764968\n",
      "Iteration 72, loss = 763.56365354\n",
      "Iteration 261, loss = 762.02499441\n",
      "Iteration 46, loss = 812.76754109\n",
      "Iteration 7, loss = 947.94019405\n",
      "Iteration 44, loss = 860.36012897\n",
      "Iteration 262, loss = 763.32108934\n",
      "Iteration 333, loss = 1202.63183444\n",
      "Iteration 36, loss = 862.38480453\n",
      "Iteration 73, loss = 796.44446475\n",
      "Iteration 8, loss = 921.51322945\n",
      "Iteration 47, loss = 807.46878664\n",
      "Iteration 45, loss = 817.88254258\n",
      "Iteration 263, loss = 763.89626590\n",
      "Iteration 317, loss = 1260.05803162\n",
      "Iteration 37, loss = 850.80130299\n",
      "Iteration 74, loss = 773.66168780\n",
      "Iteration 46, loss = 815.81755809\n",
      "Iteration 48, loss = 814.56400355\n",
      "Iteration 9, loss = 936.50289495\n",
      "Iteration 264, loss = 763.06567979\n",
      "Iteration 334, loss = 1188.63623368\n",
      "Iteration 75, loss = 759.97866556\n",
      "Iteration 38, loss = 846.80869885\n",
      "Iteration 265, loss = 764.46486389\n",
      "Iteration 47, loss = 824.48431089\n",
      "Iteration 49, loss = 830.17382066\n",
      "Iteration 10, loss = 915.03198397\n",
      "Iteration 318, loss = 1242.40419340\n",
      "Iteration 76, loss = 770.96588594\n",
      "Iteration 266, loss = 762.85712338\n",
      "Iteration 39, loss = 861.22728322\n",
      "Iteration 48, loss = 812.67860373\n",
      "Iteration 11, loss = 930.56104077\n",
      "Iteration 50, loss = 824.14540247\n",
      "Iteration 267, loss = 758.78330785\n",
      "Iteration 77, loss = 758.99249762\n",
      "Iteration 335, loss = 1189.45099580\n",
      "Iteration 49, loss = 829.23809780\n",
      "Iteration 40, loss = 848.16120475\n",
      "Iteration 51, loss = 797.13352976\n",
      "Iteration 12, loss = 942.92104657\n",
      "Iteration 268, loss = 763.06714435\n",
      "Iteration 319, loss = 1241.87586607\n",
      "Iteration 78, loss = 756.66947245\n",
      "Iteration 50, loss = 831.87526340\n",
      "Iteration 41, loss = 839.45462106\n",
      "Iteration 269, loss = 761.56523323\n",
      "Iteration 13, loss = 934.01251166\n",
      "Iteration 52, loss = 827.70968291\n",
      "Iteration 79, loss = 766.90440978\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 51, loss = 801.80140391\n",
      "Iteration 336, loss = 1187.36301380\n",
      "Iteration 42, loss = 845.27953029\n",
      "Iteration 270, loss = 761.40273510\n",
      "Iteration 53, loss = 810.80239506\n",
      "Iteration 14, loss = 939.18632596\n",
      "Iteration 320, loss = 1235.74349919\n",
      "Iteration 52, loss = 823.38739514\n",
      "Iteration 1, loss = 3465.74150518\n",
      "Iteration 271, loss = 762.57184904\n",
      "Iteration 43, loss = 899.71848661\n",
      "Iteration 54, loss = 816.74789738\n",
      "Iteration 15, loss = 913.00518286\n",
      "Iteration 272, loss = 762.13077968\n",
      "Iteration 53, loss = 809.48793668\n",
      "Iteration 44, loss = 857.86113718\n",
      "Iteration 2, loss = 1340.16880797\n",
      "Iteration 55, loss = 835.64525183\n",
      "Iteration 337, loss = 1201.99081115\n",
      "Iteration 16, loss = 941.84711949\n",
      "Iteration 321, loss = 1223.37560135\n",
      "Iteration 273, loss = 760.99304073\n",
      "Iteration 54, loss = 813.51675869\n",
      "Iteration 3, loss = 1229.30362375\n",
      "Iteration 45, loss = 832.62232563\n",
      "Iteration 56, loss = 814.35126975\n",
      "Iteration 17, loss = 912.50034855\n",
      "Iteration 274, loss = 760.17939950\n",
      "Iteration 55, loss = 822.16923151\n",
      "Iteration 4, loss = 1136.45369466\n",
      "Iteration 275, loss = 760.24421664\n",
      "Iteration 57, loss = 790.11788032Iteration 46, loss = 829.59745310\n",
      "Iteration 18, loss = 898.82233946\n",
      "\n",
      "Iteration 338, loss = 1192.36902317\n",
      "Iteration 5, loss = 1083.75856812\n",
      "Iteration 322, loss = 1242.83649293\n",
      "Iteration 56, loss = 816.29542910\n",
      "Iteration 276, loss = 761.73973065\n",
      "Iteration 19, loss = 874.32293925\n",
      "Iteration 47, loss = 831.48759315\n",
      "Iteration 6, loss = 1071.19773724\n",
      "Iteration 58, loss = 803.22249655\n",
      "Iteration 277, loss = 760.03017812\n",
      "Iteration 57, loss = 790.02109198\n",
      "Iteration 20, loss = 898.61519413\n",
      "Iteration 48, loss = 823.15457359\n",
      "Iteration 339, loss = 1180.83462716\n",
      "Iteration 7, loss = 992.37518771\n",
      "Iteration 59, loss = 829.26776174\n",
      "Iteration 278, loss = 759.34494744\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 323, loss = 1243.07427204\n",
      "Iteration 58, loss = 792.41882558\n",
      "Iteration 21, loss = 878.92419870\n",
      "Iteration 8, loss = 954.64771510\n",
      "Iteration 49, loss = 852.51338780\n",
      "Iteration 60, loss = 798.57035850\n",
      "Iteration 59, loss = 821.50422489\n",
      "Iteration 1, loss = 8058.76433504\n",
      "Iteration 22, loss = 905.04991918\n",
      "Iteration 9, loss = 941.61049751\n",
      "Iteration 340, loss = 1180.86306606\n",
      "Iteration 50, loss = 836.94966089\n",
      "Iteration 61, loss = 799.41316178\n",
      "Iteration 60, loss = 799.61364317\n",
      "Iteration 324, loss = 1235.04277209\n",
      "Iteration 2, loss = 4557.25501573\n",
      "Iteration 10, loss = 916.34498091\n",
      "Iteration 23, loss = 882.22413734\n",
      "Iteration 51, loss = 822.13240824\n",
      "Iteration 62, loss = 804.21165043\n",
      "Iteration 61, loss = 785.96551417\n",
      "Iteration 3, loss = 3092.51872312\n",
      "Iteration 11, loss = 919.39079031\n",
      "Iteration 24, loss = 884.16716316\n",
      "Iteration 52, loss = 844.41064768\n",
      "Iteration 63, loss = 809.32487780\n",
      "Iteration 62, loss = 804.23088034\n",
      "Iteration 341, loss = 1175.87331806\n",
      "Iteration 4, loss = 2079.67005734\n",
      "Iteration 325, loss = 1228.23385192\n",
      "Iteration 12, loss = 901.71259008\n",
      "Iteration 25, loss = 897.88601358\n",
      "Iteration 63, loss = 786.44973234\n",
      "Iteration 53, loss = 829.73827903\n",
      "Iteration 64, loss = 791.21643368\n",
      "Iteration 5, loss = 1585.13052721\n",
      "Iteration 13, loss = 899.08148731\n",
      "Iteration 26, loss = 882.10811101\n",
      "Iteration 54, loss = 837.30334522\n",
      "Iteration 64, loss = 796.59917487\n",
      "Iteration 6, loss = 1407.58682874\n",
      "Iteration 65, loss = 804.04090754\n",
      "Iteration 14, loss = 908.78594367\n",
      "Iteration 326, loss = 1218.40552520\n",
      "Iteration 342, loss = 1165.48610064\n",
      "Iteration 27, loss = 875.62571474\n",
      "Iteration 55, loss = 843.74217111\n",
      "Iteration 65, loss = 798.30342361\n",
      "Iteration 7, loss = 1355.47987626\n",
      "Iteration 66, loss = 837.76067157\n",
      "Iteration 15, loss = 877.62124241\n",
      "Iteration 28, loss = 869.11825056\n",
      "Iteration 56, loss = 817.67914968\n",
      "Iteration 66, loss = 840.19358165\n",
      "Iteration 8, loss = 1328.11073830\n",
      "Iteration 16, loss = 873.83142701\n",
      "Iteration 67, loss = 803.18399886\n",
      "Iteration 29, loss = 890.00183403\n",
      "Iteration 327, loss = 1205.82896353\n",
      "Iteration 343, loss = 1169.52896367\n",
      "Iteration 57, loss = 814.54584972\n",
      "Iteration 67, loss = 799.69436196\n",
      "Iteration 9, loss = 1290.46392165\n",
      "Iteration 17, loss = 879.63562144\n",
      "Iteration 68, loss = 783.79155586\n",
      "Iteration 30, loss = 876.93056955\n",
      "Iteration 68, loss = 778.29638761\n",
      "Iteration 58, loss = 808.73977614\n",
      "Iteration 10, loss = 1264.28240289\n",
      "Iteration 18, loss = 862.68244236\n",
      "Iteration 69, loss = 785.45837298\n",
      "Iteration 31, loss = 881.65510176\n",
      "Iteration 328, loss = 1200.34849833\n",
      "Iteration 344, loss = 1162.23556505\n",
      "Iteration 69, loss = 782.92568271\n",
      "Iteration 19, loss = 872.83430989\n",
      "Iteration 11, loss = 1238.03966123\n",
      "Iteration 59, loss = 841.50319038\n",
      "Iteration 32, loss = 850.11482689\n",
      "Iteration 70, loss = 797.39228561\n",
      "Iteration 20, loss = 854.93812096\n",
      "Iteration 70, loss = 784.17232962\n",
      "Iteration 12, loss = 1206.75338570\n",
      "Iteration 60, loss = 810.17191607\n",
      "Iteration 33, loss = 882.00385562\n",
      "Iteration 71, loss = 797.28402482\n",
      "Iteration 21, loss = 833.65115625\n",
      "Iteration 329, loss = 1217.78731906\n",
      "Iteration 71, loss = 789.62790579\n",
      "Iteration 345, loss = 1151.16565243\n",
      "Iteration 13, loss = 1157.13447964\n",
      "Iteration 61, loss = 808.65082392\n",
      "Iteration 34, loss = 860.25755201\n",
      "Iteration 72, loss = 797.69701882\n",
      "Iteration 22, loss = 848.65113182\n",
      "Iteration 72, loss = 788.61606837\n",
      "Iteration 14, loss = 1134.91474316\n",
      "Iteration 62, loss = 816.54942745\n",
      "Iteration 73, loss = 822.54847107\n",
      "Iteration 35, loss = 861.52615597\n",
      "Iteration 330, loss = 1210.72018637\n",
      "Iteration 23, loss = 826.93973006\n",
      "Iteration 73, loss = 819.19208516\n",
      "Iteration 346, loss = 1172.95156245\n",
      "Iteration 63, loss = 808.69048394\n",
      "Iteration 15, loss = 1092.76118675\n",
      "Iteration 36, loss = 854.59343716\n",
      "Iteration 74, loss = 806.90961666\n",
      "Iteration 24, loss = 842.64856686\n",
      "Iteration 74, loss = 792.44565427\n",
      "Iteration 16, loss = 1062.78683531\n",
      "Iteration 64, loss = 820.42584903\n",
      "Iteration 37, loss = 842.26714623\n",
      "Iteration 75, loss = 812.28211679\n",
      "Iteration 331, loss = 1191.58234749\n",
      "Iteration 25, loss = 838.78218531\n",
      "Iteration 75, loss = 806.60140951\n",
      "Iteration 347, loss = 1149.82194623\n",
      "Iteration 17, loss = 1043.01706642\n",
      "Iteration 65, loss = 822.98711824\n",
      "Iteration 38, loss = 833.38686620\n",
      "Iteration 76, loss = 800.88282030\n",
      "Iteration 26, loss = 849.10048397\n",
      "Iteration 76, loss = 791.76948108\n",
      "Iteration 18, loss = 1013.91908625\n",
      "Iteration 66, loss = 855.87216510\n",
      "Iteration 39, loss = 862.38279820\n",
      "Iteration 77, loss = 797.94974945\n",
      "Iteration 27, loss = 832.84805542\n",
      "Iteration 332, loss = 1182.36068443\n",
      "Iteration 77, loss = 782.50834515\n",
      "Iteration 19, loss = 993.31703604\n",
      "Iteration 348, loss = 1180.71435632\n",
      "Iteration 67, loss = 818.82723853\n",
      "Iteration 40, loss = 855.85912615\n",
      "Iteration 28, loss = 825.66036743\n",
      "Iteration 78, loss = 786.34191969\n",
      "Iteration 78, loss = 795.22827596\n",
      "Iteration 20, loss = 970.94222754\n",
      "Iteration 41, loss = 834.86863521\n",
      "Iteration 68, loss = 796.98727796\n",
      "Iteration 29, loss = 860.27453531\n",
      "Iteration 79, loss = 803.92457229\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 79, loss = 789.44326461\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 333, loss = 1181.47677775\n",
      "Iteration 21, loss = 949.93300438\n",
      "Iteration 42, loss = 840.95680621\n",
      "Iteration 69, loss = 795.96081703\n",
      "Iteration 30, loss = 825.23314257\n",
      "Iteration 349, loss = 1144.40179174\n",
      "Iteration 1, loss = 8294.31970522\n",
      "Iteration 1, loss = 8144.78355546\n",
      "Iteration 22, loss = 934.01376233\n",
      "Iteration 43, loss = 875.81757034\n",
      "Iteration 31, loss = 831.03880558\n",
      "Iteration 70, loss = 802.15427298\n",
      "Iteration 334, loss = 1196.34783724\n",
      "Iteration 2, loss = 4633.01312056\n",
      "Iteration 2, loss = 4408.35086326\n",
      "Iteration 23, loss = 919.88181063\n",
      "Iteration 32, loss = 807.92745557\n",
      "Iteration 44, loss = 838.31796822\n",
      "Iteration 71, loss = 812.40642789\n",
      "Iteration 350, loss = 1163.46972183\n",
      "Iteration 3, loss = 3087.69149754\n",
      "Iteration 3, loss = 2921.33879411\n",
      "Iteration 24, loss = 902.88609618\n",
      "Iteration 33, loss = 844.69153113\n",
      "Iteration 45, loss = 817.69208169\n",
      "Iteration 72, loss = 804.51862966\n",
      "Iteration 4, loss = 1938.66899233\n",
      "Iteration 335, loss = 1188.18282614\n",
      "Iteration 4, loss = 2052.30407032\n",
      "Iteration 34, loss = 809.87351467\n",
      "Iteration 25, loss = 901.69502689\n",
      "Iteration 46, loss = 817.72221876\n",
      "Iteration 73, loss = 832.68672495\n",
      "Iteration 351, loss = 1140.17989610\n",
      "Iteration 5, loss = 1485.83310952\n",
      "Iteration 5, loss = 1583.00580547\n",
      "Iteration 35, loss = 805.29734483\n",
      "Iteration 26, loss = 887.60873250\n",
      "Iteration 47, loss = 826.04644333\n",
      "Iteration 74, loss = 804.46798704\n",
      "Iteration 6, loss = 1331.27581411\n",
      "Iteration 6, loss = 1416.52784313\n",
      "Iteration 336, loss = 1183.16673861\n",
      "Iteration 36, loss = 826.93132750\n",
      "Iteration 27, loss = 874.21134902\n",
      "Iteration 48, loss = 820.27107260\n",
      "Iteration 75, loss = 819.51552153\n",
      "Iteration 7, loss = 1270.71448127\n",
      "Iteration 7, loss = 1366.01375137\n",
      "Iteration 37, loss = 811.78596024\n",
      "Iteration 28, loss = 880.51930733\n",
      "Iteration 49, loss = 846.70195406\n",
      "Iteration 352, loss = 1143.43293573\n",
      "Iteration 76, loss = 799.45071060\n",
      "Iteration 8, loss = 1339.87974284\n",
      "Iteration 337, loss = 1178.70528687\n",
      "Iteration 8, loss = 1244.39986145\n",
      "Iteration 38, loss = 805.56679976\n",
      "Iteration 50, loss = 820.93018571\n",
      "Iteration 29, loss = 867.04864990\n",
      "Iteration 77, loss = 801.52410204\n",
      "Iteration 9, loss = 1310.92654466\n",
      "Iteration 39, loss = 814.53093781\n",
      "Iteration 9, loss = 1221.59106520\n",
      "Iteration 51, loss = 817.10303959\n",
      "Iteration 30, loss = 862.46373781\n",
      "Iteration 78, loss = 807.56439531\n",
      "Iteration 353, loss = 1149.09537595\n",
      "Iteration 10, loss = 1289.10607894\n",
      "Iteration 40, loss = 825.55934365\n",
      "Iteration 10, loss = 1204.45102229\n",
      "Iteration 338, loss = 1174.77734227\n",
      "Iteration 31, loss = 858.53899354\n",
      "Iteration 52, loss = 833.70911440\n",
      "Iteration 79, loss = 800.47216762\n",
      "Iteration 11, loss = 1254.75181236\n",
      "Iteration 41, loss = 806.49273457\n",
      "Iteration 11, loss = 1171.84293451\n",
      "Iteration 32, loss = 853.27703261\n",
      "Iteration 53, loss = 817.11059829\n",
      "Iteration 80, loss = 790.21104366\n",
      "Iteration 12, loss = 1226.11092501\n",
      "Iteration 42, loss = 796.21320295\n",
      "Iteration 354, loss = 1155.99482532\n",
      "Iteration 12, loss = 1149.95785958\n",
      "Iteration 339, loss = 1202.79021647\n",
      "Iteration 54, loss = 816.66074431\n",
      "Iteration 33, loss = 853.18655256\n",
      "Iteration 13, loss = 1176.68019898\n",
      "Iteration 43, loss = 848.61479855\n",
      "Iteration 81, loss = 802.06552167\n",
      "Iteration 13, loss = 1116.08081332\n",
      "Iteration 55, loss = 823.14051945\n",
      "Iteration 34, loss = 851.71277689\n",
      "Iteration 44, loss = 804.23581533\n",
      "Iteration 14, loss = 1146.68123141\n",
      "Iteration 14, loss = 1090.70073210\n",
      "Iteration 82, loss = 802.12781346\n",
      "Iteration 355, loss = 1161.83277627\n",
      "Iteration 340, loss = 1175.40419303\n",
      "Iteration 56, loss = 818.70951576\n",
      "Iteration 35, loss = 850.14999319\n",
      "Iteration 45, loss = 787.93646151\n",
      "Iteration 15, loss = 1104.95804977\n",
      "Iteration 15, loss = 1059.91287981\n",
      "Iteration 83, loss = 794.70807194\n",
      "Iteration 57, loss = 812.63983145\n",
      "Iteration 36, loss = 841.03580005\n",
      "Iteration 46, loss = 802.09180913\n",
      "Iteration 16, loss = 1071.62876472\n",
      "Iteration 16, loss = 1037.94272137\n",
      "Iteration 84, loss = 811.69179781\n",
      "Iteration 356, loss = 1133.49918272\n",
      "Iteration 58, loss = 800.23451523\n",
      "Iteration 341, loss = 1162.60867970\n",
      "Iteration 47, loss = 785.80930491\n",
      "Iteration 17, loss = 1051.11594156\n",
      "Iteration 37, loss = 841.43929069\n",
      "Iteration 17, loss = 1017.00825012\n",
      "Iteration 85, loss = 816.49542279\n",
      "Iteration 59, loss = 820.60516133\n",
      "Iteration 48, loss = 795.17671022\n",
      "Iteration 18, loss = 1022.57169779\n",
      "Iteration 38, loss = 835.02409537\n",
      "Iteration 18, loss = 992.08435779\n",
      "Iteration 86, loss = 800.12840378\n",
      "Iteration 357, loss = 1143.75912813\n",
      "Iteration 342, loss = 1181.81831902\n",
      "Iteration 60, loss = 802.30125374\n",
      "Iteration 19, loss = 1000.79766230\n",
      "Iteration 49, loss = 795.92838982\n",
      "Iteration 39, loss = 835.86374435\n",
      "Iteration 19, loss = 966.03979218\n",
      "Iteration 87, loss = 802.58220979\n",
      "Iteration 61, loss = 801.23491099\n",
      "Iteration 20, loss = 974.26528967\n",
      "Iteration 50, loss = 780.09451670\n",
      "Iteration 40, loss = 836.56276277\n",
      "Iteration 88, loss = 799.62667894\n",
      "Iteration 20, loss = 944.00132697\n",
      "Iteration 358, loss = 1129.05351685\n",
      "Iteration 62, loss = 802.89608819\n",
      "Iteration 343, loss = 1164.71550915\n",
      "Iteration 21, loss = 951.20171077\n",
      "Iteration 51, loss = 790.08203465\n",
      "Iteration 41, loss = 836.25771298\n",
      "Iteration 89, loss = 798.32902981\n",
      "Iteration 21, loss = 927.94013901\n",
      "Iteration 63, loss = 793.82642334\n",
      "Iteration 22, loss = 932.20174464\n",
      "Iteration 52, loss = 800.08560527\n",
      "Iteration 42, loss = 827.86268387\n",
      "Iteration 90, loss = 798.47620724\n",
      "Iteration 22, loss = 906.28280976\n",
      "Iteration 64, loss = 807.66848164\n",
      "Iteration 23, loss = 917.04931790\n",
      "Iteration 53, loss = 774.35105257\n",
      "Iteration 344, loss = 1158.91405518\n",
      "Iteration 359, loss = 1130.57737669\n",
      "Iteration 43, loss = 831.65621816\n",
      "Iteration 23, loss = 885.70223880\n",
      "Iteration 91, loss = 792.42169575\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 65, loss = 814.52748556\n",
      "Iteration 24, loss = 901.77734623\n",
      "Iteration 44, loss = 832.25253811\n",
      "Iteration 54, loss = 781.01625262\n",
      "Iteration 24, loss = 877.18558605\n",
      "Iteration 66, loss = 823.55736665\n",
      "Iteration 1, loss = 8376.79629327\n",
      "Iteration 25, loss = 898.37794014\n",
      "Iteration 55, loss = 784.79516235\n",
      "Iteration 345, loss = 1143.41196416\n",
      "Iteration 45, loss = 823.46366356\n",
      "Iteration 360, loss = 1130.47869919\n",
      "Iteration 25, loss = 858.39385852\n",
      "Iteration 2, loss = 4491.79104702\n",
      "Iteration 67, loss = 798.81446110\n",
      "Iteration 26, loss = 884.74827144\n",
      "Iteration 46, loss = 829.22549757\n",
      "Iteration 56, loss = 774.83974145\n",
      "Iteration 27, loss = 873.13916173\n",
      "Iteration 26, loss = 846.54027296\n",
      "Iteration 3, loss = 2974.44859513\n",
      "Iteration 68, loss = 774.58062872\n",
      "Iteration 346, loss = 1178.80817190\n",
      "Iteration 47, loss = 820.76367271\n",
      "Iteration 57, loss = 785.42479153\n",
      "Iteration 361, loss = 1128.63255169\n",
      "Iteration 28, loss = 878.85166036\n",
      "Iteration 69, loss = 783.57571655\n",
      "Iteration 27, loss = 843.37948188\n",
      "Iteration 4, loss = 2000.93113461\n",
      "Iteration 58, loss = 764.68603742\n",
      "Iteration 48, loss = 823.61079460\n",
      "Iteration 29, loss = 867.15189829\n",
      "Iteration 5, loss = 1561.74315841\n",
      "Iteration 70, loss = 794.85411536\n",
      "Iteration 28, loss = 835.76647520\n",
      "Iteration 59, loss = 779.66087389\n",
      "Iteration 49, loss = 820.44340607\n",
      "Iteration 347, loss = 1133.38804833\n",
      "Iteration 30, loss = 859.42792811\n",
      "Iteration 362, loss = 1122.42655458\n",
      "Iteration 6, loss = 1408.80321152\n",
      "Iteration 71, loss = 789.88049147\n",
      "Iteration 29, loss = 822.35167822\n",
      "Iteration 60, loss = 770.55816185\n",
      "Iteration 50, loss = 818.31401375\n",
      "Iteration 31, loss = 853.59883963\n",
      "Iteration 7, loss = 1353.95957538\n",
      "Iteration 72, loss = 787.52615498\n",
      "Iteration 30, loss = 825.94150602\n",
      "Iteration 61, loss = 794.99369598\n",
      "Iteration 51, loss = 816.32823006\n",
      "Iteration 8, loss = 1326.33285011\n",
      "Iteration 348, loss = 1155.31951743\n",
      "Iteration 32, loss = 854.25711896\n",
      "Iteration 363, loss = 1140.65657008\n",
      "Iteration 73, loss = 804.19804989\n",
      "Iteration 62, loss = 771.77167184\n",
      "Iteration 31, loss = 813.33065463\n",
      "Iteration 52, loss = 824.25354790\n",
      "Iteration 9, loss = 1298.65850023\n",
      "Iteration 33, loss = 847.73545911\n",
      "Iteration 74, loss = 788.19374716\n",
      "Iteration 63, loss = 763.26057860\n",
      "Iteration 32, loss = 813.36648610\n",
      "Iteration 53, loss = 815.10956782\n",
      "Iteration 10, loss = 1273.25817285\n",
      "Iteration 34, loss = 848.60754925\n",
      "Iteration 349, loss = 1153.61517846\n",
      "Iteration 64, loss = 781.34170673\n",
      "Iteration 75, loss = 801.12998128\n",
      "Iteration 33, loss = 807.09803812\n",
      "Iteration 364, loss = 1111.81804140\n",
      "Iteration 54, loss = 819.50109191\n",
      "Iteration 11, loss = 1232.39026770\n",
      "Iteration 35, loss = 847.38188818\n",
      "Iteration 65, loss = 775.16148259\n",
      "Iteration 34, loss = 806.34757870\n",
      "Iteration 76, loss = 785.95512545\n",
      "Iteration 55, loss = 819.32208590\n",
      "Iteration 12, loss = 1198.18820978\n",
      "Iteration 36, loss = 837.02199309\n",
      "Iteration 350, loss = 1160.93655335\n",
      "Iteration 66, loss = 788.00636524\n",
      "Iteration 35, loss = 799.30956095\n",
      "Iteration 77, loss = 776.26176049\n",
      "Iteration 13, loss = 1151.55329491\n",
      "Iteration 56, loss = 814.40160402\n",
      "Iteration 365, loss = 1121.96115871\n",
      "Iteration 37, loss = 835.20336612\n",
      "Iteration 67, loss = 768.17484849\n",
      "Iteration 36, loss = 797.00806728\n",
      "Iteration 78, loss = 803.11927383\n",
      "Iteration 57, loss = 808.94585821\n",
      "Iteration 14, loss = 1119.91871395\n",
      "Iteration 38, loss = 831.70437998\n",
      "Iteration 68, loss = 750.63757286\n",
      "Iteration 351, loss = 1123.91780402\n",
      "Iteration 37, loss = 797.12259582\n",
      "Iteration 79, loss = 784.17730296\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 58, loss = 806.45722191\n",
      "Iteration 39, loss = 832.12277371\n",
      "Iteration 15, loss = 1082.45012292\n",
      "Iteration 366, loss = 1115.56540660\n",
      "Iteration 69, loss = 747.39204822\n",
      "Iteration 38, loss = 794.81195794\n",
      "Iteration 1, loss = 8351.01136083\n",
      "Iteration 59, loss = 807.98283797\n",
      "Iteration 16, loss = 1057.48754784\n",
      "Iteration 40, loss = 828.14806276\n",
      "Iteration 70, loss = 775.75525283\n",
      "Iteration 39, loss = 792.10365833\n",
      "Iteration 352, loss = 1149.28662930\n",
      "Iteration 2, loss = 4446.60762052\n",
      "Iteration 17, loss = 1033.35969643\n",
      "Iteration 60, loss = 809.12854516\n",
      "Iteration 41, loss = 832.86363887\n",
      "Iteration 367, loss = 1120.64600575\n",
      "Iteration 71, loss = 769.77511735\n",
      "Iteration 40, loss = 792.05738539\n",
      "Iteration 3, loss = 2954.96451196\n",
      "Iteration 18, loss = 1001.36319717\n",
      "Iteration 42, loss = 821.44363454\n",
      "Iteration 61, loss = 805.07646939\n",
      "Iteration 72, loss = 759.41499391\n",
      "Iteration 353, loss = 1126.78087879\n",
      "Iteration 4, loss = 1992.59441174\n",
      "Iteration 41, loss = 786.92380310\n",
      "Iteration 43, loss = 822.90874428\n",
      "Iteration 19, loss = 976.58721829\n",
      "Iteration 62, loss = 803.72910851\n",
      "Iteration 73, loss = 784.78474378\n",
      "Iteration 368, loss = 1124.50410823\n",
      "Iteration 5, loss = 1529.40709777\n",
      "Iteration 42, loss = 787.57498686\n",
      "Iteration 44, loss = 821.41467621\n",
      "Iteration 63, loss = 811.44660653\n",
      "Iteration 20, loss = 952.27216792\n",
      "Iteration 74, loss = 761.16526214\n",
      "Iteration 354, loss = 1120.86632124\n",
      "Iteration 6, loss = 1359.80740000\n",
      "Iteration 45, loss = 814.77851169\n",
      "Iteration 43, loss = 785.19452612\n",
      "Iteration 64, loss = 805.27737283\n",
      "Iteration 21, loss = 934.61434614\n",
      "Iteration 75, loss = 760.80778188\n",
      "Iteration 7, loss = 1294.21418598\n",
      "Iteration 46, loss = 814.22713140\n",
      "Iteration 369, loss = 1097.22606968\n",
      "Iteration 44, loss = 784.94744602\n",
      "Iteration 65, loss = 806.47233995\n",
      "Iteration 76, loss = 757.80501028\n",
      "Iteration 22, loss = 916.36729062\n",
      "Iteration 8, loss = 1264.03672489\n",
      "Iteration 47, loss = 812.92149373\n",
      "Iteration 355, loss = 1131.48497833\n",
      "Iteration 45, loss = 782.34806458\n",
      "Iteration 77, loss = 774.87483395\n",
      "Iteration 66, loss = 803.51852331\n",
      "Iteration 23, loss = 893.80594802\n",
      "Iteration 9, loss = 1241.44706292\n",
      "Iteration 48, loss = 813.95776149\n",
      "Iteration 370, loss = 1119.54388099\n",
      "Iteration 46, loss = 783.12107723\n",
      "Iteration 67, loss = 805.48826207\n",
      "Iteration 78, loss = 769.92180322\n",
      "Iteration 24, loss = 893.38159261\n",
      "Iteration 10, loss = 1220.84215075\n",
      "Iteration 49, loss = 809.72545783\n",
      "Iteration 356, loss = 1167.22436193\n",
      "Iteration 47, loss = 779.53080844\n",
      "Iteration 79, loss = 750.63185900\n",
      "Iteration 68, loss = 807.25256898\n",
      "Iteration 25, loss = 878.95043110\n",
      "Iteration 11, loss = 1193.94507398\n",
      "Iteration 50, loss = 808.99678761\n",
      "Iteration 371, loss = 1096.66240345\n",
      "Iteration 48, loss = 772.25120101\n",
      "Iteration 80, loss = 782.85969023\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 864.97777360\n",
      "Iteration 69, loss = 799.69096400\n",
      "Iteration 12, loss = 1167.48164562\n",
      "Iteration 51, loss = 806.00306513\n",
      "Iteration 49, loss = 776.62832407\n",
      "Iteration 357, loss = 1124.48377131\n",
      "Iteration 27, loss = 861.60104757\n",
      "Iteration 70, loss = 801.96232326\n",
      "Iteration 1, loss = 8348.30002671\n",
      "Iteration 52, loss = 810.93455014\n",
      "Iteration 13, loss = 1120.36782942\n",
      "Iteration 28, loss = 861.77733572\n",
      "Iteration 50, loss = 779.22770598\n",
      "Iteration 372, loss = 1103.74198265\n",
      "Iteration 71, loss = 798.52741343\n",
      "Iteration 2, loss = 4447.62616776\n",
      "Iteration 53, loss = 804.23156768\n",
      "Iteration 14, loss = 1079.10255885\n",
      "Iteration 29, loss = 856.33872491\n",
      "Iteration 358, loss = 1122.79556588\n",
      "Iteration 51, loss = 767.89217795\n",
      "Iteration 72, loss = 799.93255132\n",
      "Iteration 3, loss = 2956.17285709\n",
      "Iteration 54, loss = 805.13894050\n",
      "Iteration 15, loss = 1049.40165558\n",
      "Iteration 30, loss = 854.11440188\n",
      "Iteration 73, loss = 800.88015143\n",
      "Iteration 52, loss = 774.85002080\n",
      "Iteration 4, loss = 2020.09527999\n",
      "Iteration 373, loss = 1106.81687548\n",
      "Iteration 55, loss = 804.76578956\n",
      "Iteration 16, loss = 1015.14322964\n",
      "Iteration 31, loss = 849.07385053\n",
      "Iteration 74, loss = 795.09145502\n",
      "Iteration 359, loss = 1110.16461283\n",
      "Iteration 53, loss = 767.87806005\n",
      "Iteration 5, loss = 1570.76847290\n",
      "Iteration 56, loss = 802.62317946\n",
      "Iteration 17, loss = 991.95445715\n",
      "Iteration 32, loss = 846.71205085\n",
      "Iteration 75, loss = 800.30993647\n",
      "Iteration 6, loss = 1415.43602532\n",
      "Iteration 54, loss = 768.81039261\n",
      "Iteration 57, loss = 797.65574432\n",
      "Iteration 18, loss = 963.76707761\n",
      "Iteration 374, loss = 1116.43368762\n",
      "Iteration 33, loss = 842.05727039\n",
      "Iteration 76, loss = 799.78021301\n",
      "Iteration 360, loss = 1124.05929970\n",
      "Iteration 7, loss = 1350.81318452\n",
      "Iteration 19, loss = 946.36081427\n",
      "Iteration 55, loss = 768.55270000\n",
      "Iteration 58, loss = 793.55251666\n",
      "Iteration 34, loss = 840.25850357\n",
      "Iteration 20, loss = 921.02870385\n",
      "Iteration 77, loss = 799.13843866\n",
      "Iteration 8, loss = 1322.49326666\n",
      "Iteration 56, loss = 769.59275373\n",
      "Iteration 59, loss = 797.22100942\n",
      "Iteration 35, loss = 837.59440704\n",
      "Iteration 375, loss = 1102.42087862\n",
      "Iteration 21, loss = 903.33888345\n",
      "Iteration 78, loss = 791.08490798\n",
      "Iteration 9, loss = 1304.84283760\n",
      "Iteration 361, loss = 1120.96263825\n",
      "Iteration 57, loss = 761.30679225\n",
      "Iteration 60, loss = 794.28289311\n",
      "Iteration 36, loss = 832.05827160\n",
      "Iteration 79, loss = 795.06207853\n",
      "Iteration 22, loss = 884.55509645\n",
      "Iteration 10, loss = 1282.18317159\n",
      "Iteration 58, loss = 769.66822925\n",
      "Iteration 37, loss = 835.11711278\n",
      "Iteration 61, loss = 792.15050371\n",
      "Iteration 80, loss = 788.54001960\n",
      "Iteration 376, loss = 1092.34623930\n",
      "Iteration 23, loss = 863.83102635\n",
      "Iteration 11, loss = 1266.46709381\n",
      "Iteration 38, loss = 828.24284044\n",
      "Iteration 59, loss = 764.40724501\n",
      "Iteration 362, loss = 1115.53164930\n",
      "Iteration 62, loss = 793.55584936\n",
      "Iteration 81, loss = 800.33665175\n",
      "Iteration 12, loss = 1246.69609683\n",
      "Iteration 39, loss = 827.81336231\n",
      "Iteration 24, loss = 862.35589107\n",
      "Iteration 60, loss = 762.19724689\n",
      "Iteration 63, loss = 797.29794248\n",
      "Iteration 40, loss = 827.62283536\n",
      "Iteration 82, loss = 794.30520277\n",
      "Iteration 13, loss = 1212.74060726\n",
      "Iteration 25, loss = 851.30163128\n",
      "Iteration 377, loss = 1091.37666095\n",
      "Iteration 61, loss = 762.89017808\n",
      "Iteration 64, loss = 788.27920863\n",
      "Iteration 363, loss = 1113.75955514\n",
      "Iteration 41, loss = 820.62473808\n",
      "Iteration 83, loss = 795.52034671\n",
      "Iteration 14, loss = 1185.47919598\n",
      "Iteration 26, loss = 838.00183545\n",
      "Iteration 62, loss = 763.79606537\n",
      "Iteration 65, loss = 793.68329385\n",
      "Iteration 42, loss = 827.27322024\n",
      "Iteration 84, loss = 796.52698185\n",
      "Iteration 15, loss = 1163.44606429\n",
      "Iteration 27, loss = 836.15975624\n",
      "Iteration 364, loss = 1100.48581818\n",
      "Iteration 378, loss = 1094.28662485\n",
      "Iteration 66, loss = 789.51318749\n",
      "Iteration 63, loss = 763.77604069\n",
      "Iteration 43, loss = 820.46809174\n",
      "Iteration 85, loss = 790.92481635\n",
      "Iteration 16, loss = 1138.56219634\n",
      "Iteration 28, loss = 836.05207264\n",
      "Iteration 67, loss = 797.15977329\n",
      "Iteration 64, loss = 763.18849041\n",
      "Iteration 44, loss = 821.67367233\n",
      "Iteration 86, loss = 794.05877223\n",
      "Iteration 29, loss = 825.75954957\n",
      "Iteration 17, loss = 1115.71362430\n",
      "Iteration 365, loss = 1119.21733331\n",
      "Iteration 379, loss = 1079.50616355\n",
      "Iteration 68, loss = 791.55477169\n",
      "Iteration 45, loss = 818.06425296\n",
      "Iteration 65, loss = 760.90799001\n",
      "Iteration 87, loss = 791.26953838\n",
      "Iteration 30, loss = 821.96755085\n",
      "Iteration 18, loss = 1086.25856774\n",
      "Iteration 46, loss = 816.32771854\n",
      "Iteration 69, loss = 784.71499440\n",
      "Iteration 88, loss = 795.50695944\n",
      "Iteration 66, loss = 758.41732609\n",
      "Iteration 31, loss = 820.25404762\n",
      "Iteration 19, loss = 1063.04351759\n",
      "Iteration 366, loss = 1087.07194887\n",
      "Iteration 47, loss = 815.35880345\n",
      "Iteration 70, loss = 787.49669984\n",
      "Iteration 67, loss = 757.40006369\n",
      "Iteration 89, loss = 793.32481437\n",
      "Iteration 380, loss = 1098.78573383\n",
      "Iteration 32, loss = 815.95039995\n",
      "Iteration 20, loss = 1035.21446862\n",
      "Iteration 48, loss = 809.05972630\n",
      "Iteration 68, loss = 750.11196907\n",
      "Iteration 71, loss = 785.81019082\n",
      "Iteration 90, loss = 792.30312417\n",
      "Iteration 33, loss = 811.28758623\n",
      "Iteration 367, loss = 1115.82103379\n",
      "Iteration 21, loss = 1001.43279348\n",
      "Iteration 49, loss = 812.66735495\n",
      "Iteration 69, loss = 754.74724777\n",
      "Iteration 72, loss = 785.23005104\n",
      "Iteration 91, loss = 786.56784563\n",
      "Iteration 34, loss = 810.80435141Iteration 381, loss = 1077.56217025\n",
      "\n",
      "Iteration 22, loss = 982.49136077\n",
      "Iteration 50, loss = 814.00894189\n",
      "Iteration 73, loss = 788.29899497\n",
      "Iteration 70, loss = 754.92539903\n",
      "Iteration 92, loss = 792.33976258\n",
      "Iteration 35, loss = 805.52978712\n",
      "Iteration 368, loss = 1100.39227686\n",
      "Iteration 23, loss = 956.19849137\n",
      "Iteration 51, loss = 803.12464163\n",
      "Iteration 71, loss = 754.35083659\n",
      "Iteration 74, loss = 780.46540962\n",
      "Iteration 36, loss = 800.95976341\n",
      "Iteration 93, loss = 789.27994621\n",
      "Iteration 24, loss = 944.38657114\n",
      "Iteration 382, loss = 1082.34122455\n",
      "Iteration 52, loss = 811.20676700\n",
      "Iteration 75, loss = 784.59389470\n",
      "Iteration 72, loss = 751.36895952\n",
      "Iteration 37, loss = 800.41478569\n",
      "Iteration 94, loss = 789.84684475\n",
      "Iteration 369, loss = 1098.33819073\n",
      "Iteration 25, loss = 925.19114652\n",
      "Iteration 53, loss = 803.90944484\n",
      "Iteration 76, loss = 788.57238740\n",
      "Iteration 73, loss = 756.09442874\n",
      "Iteration 95, loss = 789.99538401\n",
      "Iteration 38, loss = 796.07633208\n",
      "Iteration 26, loss = 900.84283698\n",
      "Iteration 54, loss = 801.57939903\n",
      "Iteration 383, loss = 1073.02200399\n",
      "Iteration 77, loss = 785.14851397\n",
      "Iteration 74, loss = 749.27981738\n",
      "Iteration 96, loss = 787.52155137\n",
      "Iteration 39, loss = 797.52725101\n",
      "Iteration 55, loss = 805.27212654\n",
      "Iteration 27, loss = 893.24669175\n",
      "Iteration 370, loss = 1092.44118237\n",
      "Iteration 78, loss = 782.23962940\n",
      "Iteration 75, loss = 754.47482124\n",
      "Iteration 97, loss = 783.74413915\n",
      "Iteration 56, loss = 804.59600426\n",
      "Iteration 40, loss = 795.91164801\n",
      "Iteration 28, loss = 886.75520034\n",
      "Iteration 79, loss = 776.70678275\n",
      "Iteration 384, loss = 1079.99709015\n",
      "Iteration 76, loss = 752.02725340\n",
      "Iteration 98, loss = 797.71431771\n",
      "Iteration 41, loss = 790.01268087\n",
      "Iteration 57, loss = 799.95250723\n",
      "Iteration 371, loss = 1086.13809377\n",
      "Iteration 29, loss = 873.07781188\n",
      "Iteration 80, loss = 777.67689991\n",
      "Iteration 77, loss = 747.01541720\n",
      "Iteration 99, loss = 785.34743781\n",
      "Iteration 58, loss = 806.64484998\n",
      "Iteration 42, loss = 794.69133456\n",
      "Iteration 30, loss = 862.42976984\n",
      "Iteration 81, loss = 786.82484173\n",
      "Iteration 78, loss = 750.23325398\n",
      "Iteration 100, loss = 788.70469538\n",
      "Iteration 385, loss = 1083.53676051\n",
      "Iteration 59, loss = 801.73936315\n",
      "Iteration 43, loss = 788.16513336\n",
      "Iteration 31, loss = 864.17573182\n",
      "Iteration 372, loss = 1092.46256525\n",
      "Iteration 82, loss = 782.14553157\n",
      "Iteration 79, loss = 749.56226018\n",
      "Iteration 101, loss = 785.30433345\n",
      "Iteration 60, loss = 797.11900999\n",
      "Iteration 44, loss = 788.89899890\n",
      "Iteration 32, loss = 850.34550474\n",
      "Iteration 83, loss = 779.86435546\n",
      "Iteration 80, loss = 743.88183483\n",
      "Iteration 61, loss = 798.56566152\n",
      "Iteration 102, loss = 789.21893284\n",
      "Iteration 386, loss = 1082.22387536\n",
      "Iteration 45, loss = 784.68031804\n",
      "Iteration 373, loss = 1089.05483597\n",
      "Iteration 33, loss = 849.09124267\n",
      "Iteration 84, loss = 781.48801111\n",
      "Iteration 81, loss = 746.30918254\n",
      "Iteration 62, loss = 799.40544294\n",
      "Iteration 103, loss = 786.26546784\n",
      "Iteration 46, loss = 780.61800338\n",
      "Iteration 34, loss = 846.00622641\n",
      "Iteration 85, loss = 778.13348644\n",
      "Iteration 82, loss = 748.15939727\n",
      "Iteration 63, loss = 802.62212775\n",
      "Iteration 104, loss = 783.42575228\n",
      "Iteration 47, loss = 778.00173001\n",
      "Iteration 387, loss = 1091.48346771\n",
      "Iteration 35, loss = 840.57407309\n",
      "Iteration 86, loss = 777.80900529\n",
      "Iteration 374, loss = 1091.65312501\n",
      "Iteration 64, loss = 798.89967106\n",
      "Iteration 83, loss = 747.53056942\n",
      "Iteration 105, loss = 778.81151861\n",
      "Iteration 48, loss = 773.57830630\n",
      "Iteration 36, loss = 836.04404516\n",
      "Iteration 87, loss = 778.22843651\n",
      "Iteration 65, loss = 796.29822721\n",
      "Iteration 84, loss = 748.55428785\n",
      "Iteration 106, loss = 780.19060233\n",
      "Iteration 388, loss = 1069.96736973\n",
      "Iteration 49, loss = 780.38120655\n",
      "Iteration 37, loss = 833.58164040\n",
      "Iteration 66, loss = 797.45692452\n",
      "Iteration 88, loss = 778.91973123\n",
      "Iteration 375, loss = 1079.20838187\n",
      "Iteration 85, loss = 746.90194106\n",
      "Iteration 107, loss = 777.58456928\n",
      "Iteration 50, loss = 780.78843152\n",
      "Iteration 38, loss = 830.40869390\n",
      "Iteration 89, loss = 779.71721808\n",
      "Iteration 67, loss = 793.80877049\n",
      "Iteration 86, loss = 745.82760687\n",
      "Iteration 108, loss = 789.99305382\n",
      "Iteration 51, loss = 770.13249820\n",
      "Iteration 389, loss = 1089.82822133\n",
      "Iteration 39, loss = 832.57735839\n",
      "Iteration 90, loss = 776.98285050\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 376, loss = 1077.28204456\n",
      "Iteration 68, loss = 785.00502404\n",
      "Iteration 87, loss = 742.98463626\n",
      "Iteration 109, loss = 785.57313496\n",
      "Iteration 52, loss = 775.99548787\n",
      "Iteration 69, loss = 791.69374572\n",
      "Iteration 1, loss = 8363.25242505\n",
      "Iteration 40, loss = 830.77539955\n",
      "Iteration 88, loss = 740.95559810\n",
      "Iteration 110, loss = 782.95434132\n",
      "Iteration 53, loss = 769.85180703\n",
      "Iteration 70, loss = 791.32032474\n",
      "Iteration 2, loss = 4479.26674155\n",
      "Iteration 41, loss = 823.79666820\n",
      "Iteration 390, loss = 1087.71837599\n",
      "Iteration 89, loss = 742.62684747\n",
      "Iteration 377, loss = 1080.40484334\n",
      "Iteration 111, loss = 776.91143914\n",
      "Iteration 54, loss = 769.37290995\n",
      "Iteration 71, loss = 789.30119158\n",
      "Iteration 3, loss = 3027.13275318\n",
      "Iteration 42, loss = 831.56342298\n",
      "Iteration 90, loss = 748.96072636\n",
      "Iteration 112, loss = 788.29135088\n",
      "Iteration 55, loss = 772.05734222\n",
      "Iteration 72, loss = 789.64191733\n",
      "Iteration 4, loss = 2079.24901899\n",
      "Iteration 43, loss = 826.65876500\n",
      "Iteration 91, loss = 746.19317353\n",
      "Iteration 378, loss = 1071.28392380\n",
      "Iteration 391, loss = 1080.49352578\n",
      "Iteration 113, loss = 787.50809438\n",
      "Iteration 56, loss = 770.97522445\n",
      "Iteration 73, loss = 793.63092682\n",
      "Iteration 5, loss = 1600.19286681\n",
      "Iteration 44, loss = 825.84000830\n",
      "Iteration 92, loss = 743.08685653\n",
      "Iteration 57, loss = 765.86293612\n",
      "Iteration 114, loss = 782.18317843\n",
      "Iteration 74, loss = 789.66260348\n",
      "Iteration 6, loss = 1434.99615082\n",
      "Iteration 45, loss = 816.54767071\n",
      "Iteration 93, loss = 739.76067189\n",
      "Iteration 379, loss = 1089.36266533\n",
      "Iteration 392, loss = 1063.66428071\n",
      "Iteration 75, loss = 788.69783152\n",
      "Iteration 58, loss = 770.47497571\n",
      "Iteration 115, loss = 783.20574808\n",
      "Iteration 7, loss = 1366.45685019\n",
      "Iteration 46, loss = 812.76912195\n",
      "Iteration 94, loss = 744.44668053\n",
      "Iteration 76, loss = 787.80148208\n",
      "Iteration 59, loss = 766.61077249\n",
      "Iteration 116, loss = 781.49382216\n",
      "Iteration 8, loss = 1337.77194342\n",
      "Iteration 47, loss = 814.85322687\n",
      "Iteration 95, loss = 746.36859974\n",
      "Iteration 380, loss = 1069.66177445\n",
      "Iteration 77, loss = 783.56535406\n",
      "Iteration 60, loss = 763.62141141\n",
      "Iteration 9, loss = 1319.61341382\n",
      "Iteration 393, loss = 1077.17574664\n",
      "Iteration 117, loss = 779.53116702\n",
      "Iteration 48, loss = 810.98057823\n",
      "Iteration 96, loss = 739.33344727\n",
      "Iteration 78, loss = 785.22376338\n",
      "Iteration 10, loss = 1299.38247294\n",
      "Iteration 61, loss = 764.39890424\n",
      "Iteration 118, loss = 782.05637028\n",
      "Iteration 49, loss = 817.97888512\n",
      "Iteration 97, loss = 744.19533286\n",
      "Iteration 79, loss = 784.67860718\n",
      "Iteration 11, loss = 1280.35029265\n",
      "Iteration 381, loss = 1055.76149940\n",
      "Iteration 62, loss = 761.19478417\n",
      "Iteration 119, loss = 780.05597529\n",
      "Iteration 50, loss = 813.11358333\n",
      "Iteration 394, loss = 1060.61864011\n",
      "Iteration 98, loss = 738.94147602\n",
      "Iteration 80, loss = 781.46727705\n",
      "Iteration 63, loss = 768.43387709\n",
      "Iteration 120, loss = 783.95936847\n",
      "Iteration 12, loss = 1253.37246172\n",
      "Iteration 81, loss = 782.71090611\n",
      "Iteration 51, loss = 803.40879236\n",
      "Iteration 99, loss = 745.86127649\n",
      "Iteration 64, loss = 763.29096240\n",
      "Iteration 13, loss = 1216.14239873\n",
      "Iteration 382, loss = 1063.94335967\n",
      "Iteration 121, loss = 779.80069152\n",
      "Iteration 82, loss = 784.77337934\n",
      "Iteration 395, loss = 1047.16976344\n",
      "Iteration 52, loss = 812.82928249\n",
      "Iteration 100, loss = 739.18095793\n",
      "Iteration 65, loss = 761.32300147\n",
      "Iteration 14, loss = 1183.08901295\n",
      "Iteration 83, loss = 782.94271103\n",
      "Iteration 122, loss = 779.61015027\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 53, loss = 801.84721206\n",
      "Iteration 101, loss = 736.06710646\n",
      "Iteration 66, loss = 761.36340119\n",
      "Iteration 15, loss = 1157.53145890\n",
      "Iteration 383, loss = 1073.67342848\n",
      "Iteration 84, loss = 785.78064646\n",
      "Iteration 396, loss = 1054.54556339\n",
      "Iteration 54, loss = 811.10935619\n",
      "Iteration 102, loss = 740.72572028\n",
      "Iteration 1, loss = 8361.69399605\n",
      "Iteration 67, loss = 759.33612417\n",
      "Iteration 16, loss = 1127.12943580\n",
      "Iteration 85, loss = 783.93208898\n",
      "Iteration 103, loss = 736.14625037\n",
      "Iteration 2, loss = 4504.44796196\n",
      "Iteration 55, loss = 810.48584155\n",
      "Iteration 68, loss = 751.08082726\n",
      "Iteration 17, loss = 1099.14127125\n",
      "Iteration 86, loss = 780.87326483\n",
      "Iteration 384, loss = 1064.57260972\n",
      "Iteration 3, loss = 2995.53976471\n",
      "Iteration 104, loss = 736.54585861\n",
      "Iteration 56, loss = 806.81914829\n",
      "Iteration 69, loss = 756.80745252\n",
      "Iteration 397, loss = 1076.99904318\n",
      "Iteration 87, loss = 783.10894813\n",
      "Iteration 18, loss = 1066.93945919\n",
      "Iteration 4, loss = 2046.37055749\n",
      "Iteration 105, loss = 741.46581744\n",
      "Iteration 70, loss = 754.28879644\n",
      "Iteration 57, loss = 798.84931755\n",
      "Iteration 88, loss = 777.67992016\n",
      "Iteration 385, loss = 1058.20554520\n",
      "Iteration 19, loss = 1043.76197948\n",
      "Iteration 106, loss = 740.36444851\n",
      "Iteration 5, loss = 1585.42473380\n",
      "Iteration 71, loss = 756.04028051\n",
      "Iteration 89, loss = 779.31809628\n",
      "Iteration 58, loss = 802.38161298\n",
      "Iteration 20, loss = 1017.15429288\n",
      "Iteration 398, loss = 1045.59307970\n",
      "Iteration 107, loss = 734.73691299\n",
      "Iteration 6, loss = 1435.49871712\n",
      "Iteration 72, loss = 760.59145423\n",
      "Iteration 90, loss = 785.26144733\n",
      "Iteration 21, loss = 981.61048909\n",
      "Iteration 59, loss = 806.07875764\n",
      "Iteration 386, loss = 1115.53963187\n",
      "Iteration 7, loss = 1368.95173826\n",
      "Iteration 108, loss = 736.57909943\n",
      "Iteration 91, loss = 783.10856267\n",
      "Iteration 73, loss = 760.33079735\n",
      "Iteration 60, loss = 800.33633222\n",
      "Iteration 22, loss = 964.01449967\n",
      "Iteration 399, loss = 1065.57368607\n",
      "Iteration 8, loss = 1337.13983290\n",
      "Iteration 109, loss = 736.37387690\n",
      "Iteration 74, loss = 757.59017731\n",
      "Iteration 23, loss = 943.01729404\n",
      "Iteration 92, loss = 783.69536453\n",
      "Iteration 61, loss = 799.53766394\n",
      "Iteration 387, loss = 1059.49690446\n",
      "Iteration 9, loss = 1319.72492387\n",
      "Iteration 110, loss = 736.76229190\n",
      "Iteration 75, loss = 751.63416514\n",
      "Iteration 24, loss = 931.75693209\n",
      "Iteration 93, loss = 777.83950199\n",
      "Iteration 62, loss = 803.69771783\n",
      "Iteration 76, loss = 756.33173115\n",
      "Iteration 10, loss = 1297.20070364\n",
      "Iteration 111, loss = 733.05309736\n",
      "Iteration 25, loss = 915.79124150\n",
      "Iteration 400, loss = 1047.91459114\n",
      "Iteration 94, loss = 782.87563852\n",
      "Iteration 63, loss = 801.17863885\n",
      "Iteration 77, loss = 753.40445335\n",
      "Iteration 388, loss = 1067.75747034\n",
      "Iteration 11, loss = 1286.48775558\n",
      "Iteration 26, loss = 901.76435443\n",
      "Iteration 112, loss = 737.09018992\n",
      "Iteration 95, loss = 781.44825097\n",
      "Iteration 64, loss = 795.34644556\n",
      "Iteration 78, loss = 752.34278620\n",
      "Iteration 12, loss = 1264.25443960\n",
      "Iteration 113, loss = 731.13419446\n",
      "Iteration 401, loss = 1049.18358502\n",
      "Iteration 96, loss = 778.30296468\n",
      "Iteration 65, loss = 798.24279478\n",
      "Iteration 27, loss = 894.70079751\n",
      "Iteration 389, loss = 1046.41835743\n",
      "Iteration 79, loss = 752.57299510\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 13, loss = 1245.18148157\n",
      "Iteration 114, loss = 736.83101850\n",
      "Iteration 97, loss = 783.01083159\n",
      "Iteration 28, loss = 890.43475495\n",
      "Iteration 66, loss = 805.19982441\n",
      "Iteration 14, loss = 1220.91070111\n",
      "Iteration 98, loss = 777.42325252\n",
      "Iteration 1, loss = 8351.91459165\n",
      "Iteration 115, loss = 736.66910739\n",
      "Iteration 29, loss = 880.81441315\n",
      "Iteration 67, loss = 797.84506045\n",
      "Iteration 402, loss = 1048.73145894\n",
      "Iteration 15, loss = 1204.54144810\n",
      "Iteration 390, loss = 1059.43979984\n",
      "Iteration 99, loss = 782.23405411\n",
      "Iteration 2, loss = 4535.50713038\n",
      "Iteration 116, loss = 732.88859668\n",
      "Iteration 30, loss = 870.36181975\n",
      "Iteration 68, loss = 788.05262504\n",
      "Iteration 16, loss = 1179.06969327\n",
      "Iteration 3, loss = 3067.31405052\n",
      "Iteration 100, loss = 778.73756722\n",
      "Iteration 117, loss = 733.73945025\n",
      "Iteration 31, loss = 874.22137186\n",
      "Iteration 69, loss = 791.20351967\n",
      "Iteration 403, loss = 1045.64963491\n",
      "Iteration 17, loss = 1155.99165897\n",
      "Iteration 4, loss = 2081.79495775\n",
      "Iteration 101, loss = 776.06165065\n",
      "Iteration 391, loss = 1051.43297607\n",
      "Iteration 118, loss = 736.91010186\n",
      "Iteration 32, loss = 860.19735310\n",
      "Iteration 70, loss = 796.88289669\n",
      "Iteration 18, loss = 1129.63322123\n",
      "Iteration 5, loss = 1581.27923282\n",
      "Iteration 102, loss = 775.86634993\n",
      "Iteration 119, loss = 735.86202122\n",
      "Iteration 71, loss = 794.64053185\n",
      "Iteration 33, loss = 863.00398165\n",
      "Iteration 19, loss = 1120.87919490\n",
      "Iteration 6, loss = 1417.74847576\n",
      "Iteration 404, loss = 1044.17305213\n",
      "Iteration 392, loss = 1053.96957669\n",
      "Iteration 103, loss = 778.53130409\n",
      "Iteration 34, loss = 858.96745188\n",
      "Iteration 120, loss = 739.44638473\n",
      "Iteration 72, loss = 795.23020010\n",
      "Iteration 20, loss = 1095.69433797\n",
      "Iteration 7, loss = 1344.12357232\n",
      "Iteration 104, loss = 776.93156263\n",
      "Iteration 35, loss = 850.36711770\n",
      "Iteration 73, loss = 802.25588187\n",
      "Iteration 121, loss = 733.81632377\n",
      "Iteration 21, loss = 1059.96027000\n",
      "Iteration 8, loss = 1310.89727764\n",
      "Iteration 393, loss = 1052.29472427\n",
      "Iteration 105, loss = 781.50130529\n",
      "Iteration 36, loss = 848.10157625\n",
      "Iteration 74, loss = 794.58347407\n",
      "Iteration 405, loss = 1034.95198221\n",
      "Iteration 122, loss = 733.49326098\n",
      "Iteration 9, loss = 1287.85239250\n",
      "Iteration 22, loss = 1049.69338221\n",
      "Iteration 106, loss = 781.59046932\n",
      "Iteration 37, loss = 845.03924238\n",
      "Iteration 75, loss = 793.83920026\n",
      "Iteration 123, loss = 731.03376690\n",
      "Iteration 10, loss = 1265.99506502\n",
      "Iteration 107, loss = 772.86514140\n",
      "Iteration 23, loss = 1027.27640985\n",
      "Iteration 38, loss = 841.05019391\n",
      "Iteration 394, loss = 1047.40928765\n",
      "Iteration 76, loss = 791.84096899\n",
      "Iteration 124, loss = 737.06510566\n",
      "Iteration 406, loss = 1036.50108554\n",
      "Iteration 11, loss = 1246.37429178\n",
      "Iteration 108, loss = 777.22464671\n",
      "Iteration 24, loss = 1016.19660293\n",
      "Iteration 39, loss = 845.52136360\n",
      "Iteration 77, loss = 791.33603085\n",
      "Iteration 125, loss = 727.66069815\n",
      "Iteration 12, loss = 1220.08233549\n",
      "Iteration 109, loss = 775.77702387\n",
      "Iteration 25, loss = 995.37931298\n",
      "Iteration 40, loss = 841.73594163\n",
      "Iteration 395, loss = 1044.78204169\n",
      "Iteration 78, loss = 788.20451847\n",
      "Iteration 126, loss = 739.23678286\n",
      "Iteration 407, loss = 1033.76718592\n",
      "Iteration 13, loss = 1189.83133500\n",
      "Iteration 110, loss = 780.44441698\n",
      "Iteration 26, loss = 977.70569939\n",
      "Iteration 41, loss = 837.31592654\n",
      "Iteration 79, loss = 790.44651159\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 127, loss = 730.83445753\n",
      "Iteration 14, loss = 1160.93193522\n",
      "Iteration 111, loss = 773.12478876\n",
      "Iteration 27, loss = 969.23520084\n",
      "Iteration 42, loss = 843.04958737\n",
      "Iteration 396, loss = 1040.84487892\n",
      "Iteration 128, loss = 731.06577030\n",
      "Iteration 112, loss = 773.57232950\n",
      "Iteration 1, loss = 8322.16077699\n",
      "Iteration 15, loss = 1136.88007215\n",
      "Iteration 408, loss = 1032.34519860\n",
      "Iteration 43, loss = 838.69304658\n",
      "Iteration 28, loss = 954.85944866\n",
      "Iteration 129, loss = 730.72298731\n",
      "Iteration 113, loss = 771.81868276\n",
      "Iteration 2, loss = 4473.39839426\n",
      "Iteration 16, loss = 1109.49891794\n",
      "Iteration 44, loss = 836.42288665\n",
      "Iteration 29, loss = 940.31095383\n",
      "Iteration 397, loss = 1046.17973258\n",
      "Iteration 130, loss = 724.65255768\n",
      "Iteration 114, loss = 777.96407442\n",
      "Iteration 3, loss = 3027.00058276\n",
      "Iteration 17, loss = 1085.76825061\n",
      "Iteration 409, loss = 1038.17504223\n",
      "Iteration 45, loss = 826.01105217\n",
      "Iteration 30, loss = 924.85592268\n",
      "Iteration 115, loss = 776.12093016\n",
      "Iteration 131, loss = 733.93170395\n",
      "Iteration 4, loss = 2063.84689320\n",
      "Iteration 18, loss = 1055.48031652\n",
      "Iteration 46, loss = 824.11606099\n",
      "Iteration 31, loss = 922.46941373\n",
      "Iteration 398, loss = 1036.06364914\n",
      "Iteration 5, loss = 1557.70012754Iteration 116, loss = 772.92681387\n",
      "Iteration 132, loss = 729.75406943\n",
      "\n",
      "Iteration 19, loss = 1040.32773316\n",
      "Iteration 32, loss = 902.03337206\n",
      "Iteration 47, loss = 827.62364139\n",
      "Iteration 410, loss = 1038.74417480\n",
      "Iteration 6, loss = 1381.42447729\n",
      "Iteration 117, loss = 773.28028660\n",
      "Iteration 133, loss = 733.59554199\n",
      "Iteration 20, loss = 1014.73721747\n",
      "Iteration 33, loss = 903.02780974\n",
      "Iteration 48, loss = 824.03919024\n",
      "Iteration 7, loss = 1306.73817692\n",
      "Iteration 399, loss = 1033.86591393\n",
      "Iteration 118, loss = 775.20539984\n",
      "Iteration 21, loss = 974.26128488\n",
      "Iteration 134, loss = 725.64128517\n",
      "Iteration 34, loss = 891.22563466\n",
      "Iteration 49, loss = 828.83052594\n",
      "Iteration 411, loss = 1035.63769562\n",
      "Iteration 8, loss = 1269.35053645\n",
      "Iteration 119, loss = 775.49283170\n",
      "Iteration 135, loss = 731.68998070\n",
      "Iteration 35, loss = 876.58781657\n",
      "Iteration 22, loss = 964.47986444\n",
      "Iteration 50, loss = 824.33139593\n",
      "Iteration 9, loss = 1245.19345688\n",
      "Iteration 400, loss = 1033.16013943\n",
      "Iteration 120, loss = 777.94343293\n",
      "Iteration 136, loss = 730.33083372\n",
      "Iteration 36, loss = 876.66527126\n",
      "Iteration 23, loss = 936.12715865\n",
      "Iteration 51, loss = 814.39083251\n",
      "Iteration 412, loss = 1033.33387478\n",
      "Iteration 121, loss = 774.70298872\n",
      "Iteration 10, loss = 1213.28175565\n",
      "Iteration 24, loss = 929.83928347\n",
      "Iteration 137, loss = 730.59097742\n",
      "Iteration 37, loss = 870.44171077\n",
      "Iteration 52, loss = 822.54419339\n",
      "Iteration 122, loss = 774.54006791\n",
      "Iteration 11, loss = 1183.60224519\n",
      "Iteration 25, loss = 911.36540297\n",
      "Iteration 401, loss = 1039.95748119\n",
      "Iteration 138, loss = 729.11277663\n",
      "Iteration 38, loss = 864.07430738\n",
      "Iteration 53, loss = 813.66741918\n",
      "Iteration 123, loss = 770.75152048\n",
      "Iteration 12, loss = 1147.96501905\n",
      "Iteration 413, loss = 1107.27270170\n",
      "Iteration 26, loss = 896.79085762\n",
      "Iteration 39, loss = 867.65603425\n",
      "Iteration 139, loss = 730.09758484\n",
      "Iteration 54, loss = 819.64691123\n",
      "Iteration 13, loss = 1112.41334968\n",
      "Iteration 124, loss = 780.78773447\n",
      "Iteration 27, loss = 891.57577820\n",
      "Iteration 402, loss = 1035.53820141\n",
      "Iteration 40, loss = 861.01104967\n",
      "Iteration 140, loss = 729.59907689\n",
      "Iteration 55, loss = 817.90118339\n",
      "Iteration 125, loss = 765.18875851\n",
      "Iteration 14, loss = 1079.92082336\n",
      "Iteration 28, loss = 879.60986646\n",
      "Iteration 41, loss = 856.13235259\n",
      "Iteration 141, loss = 728.73046931\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 414, loss = 1045.44836068\n",
      "Iteration 56, loss = 813.34693140\n",
      "Iteration 15, loss = 1053.35243566\n",
      "Iteration 126, loss = 773.49617078\n",
      "Iteration 29, loss = 875.08732556\n",
      "Iteration 403, loss = 1017.63814109\n",
      "Iteration 16, loss = 1021.13890606\n",
      "Iteration 57, loss = 808.34138376\n",
      "Iteration 42, loss = 859.66695879\n",
      "Iteration 127, loss = 769.91044268\n",
      "Iteration 30, loss = 862.07593798\n",
      "Iteration 1, loss = 2348.38859411\n",
      "Iteration 17, loss = 998.44326610\n",
      "Iteration 128, loss = 769.45875201\n",
      "Iteration 58, loss = 812.78361488\n",
      "Iteration 415, loss = 1027.44863554\n",
      "Iteration 43, loss = 857.48110712\n",
      "Iteration 31, loss = 863.28849027\n",
      "Iteration 404, loss = 1021.96059358\n",
      "Iteration 129, loss = 772.70708959\n",
      "Iteration 59, loss = 813.04454601\n",
      "Iteration 18, loss = 969.92583880\n",
      "Iteration 44, loss = 855.76409478\n",
      "Iteration 32, loss = 851.73759646\n",
      "Iteration 2, loss = 1200.48051034\n",
      "Iteration 130, loss = 768.32403815\n",
      "Iteration 19, loss = 958.44597171\n",
      "Iteration 60, loss = 807.62234376\n",
      "Iteration 45, loss = 843.86878993\n",
      "Iteration 33, loss = 854.29946150\n",
      "Iteration 416, loss = 1036.05464372\n",
      "Iteration 131, loss = 773.32732843\n",
      "Iteration 405, loss = 1028.95554885\n",
      "Iteration 20, loss = 928.05596603\n",
      "Iteration 61, loss = 805.88521456\n",
      "Iteration 46, loss = 842.07469644\n",
      "Iteration 34, loss = 847.25982859\n",
      "Iteration 132, loss = 768.98777663\n",
      "Iteration 21, loss = 897.88138694\n",
      "Iteration 3, loss = 1111.43466677\n",
      "Iteration 62, loss = 809.57744578\n",
      "Iteration 47, loss = 842.57974136\n",
      "Iteration 35, loss = 839.67780179\n",
      "Iteration 133, loss = 773.60184452\n",
      "Iteration 417, loss = 1035.94343997\n",
      "Iteration 22, loss = 889.20252313\n",
      "Iteration 406, loss = 1027.81003176\n",
      "Iteration 48, loss = 838.78900528\n",
      "Iteration 63, loss = 803.21732594\n",
      "Iteration 36, loss = 839.54002472\n",
      "Iteration 134, loss = 766.89265781\n",
      "Iteration 23, loss = 866.54018934\n",
      "Iteration 4, loss = 1058.58833961\n",
      "Iteration 49, loss = 846.87348435\n",
      "Iteration 37, loss = 838.68544342\n",
      "Iteration 64, loss = 801.52274343\n",
      "Iteration 135, loss = 774.28752497\n",
      "Iteration 24, loss = 860.33566932\n",
      "Iteration 50, loss = 838.50457181\n",
      "Iteration 418, loss = 1022.00179213\n",
      "Iteration 407, loss = 1016.56107133\n",
      "Iteration 136, loss = 767.78687315\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 829.68000861\n",
      "Iteration 25, loss = 848.89094828\n",
      "Iteration 65, loss = 809.04188557\n",
      "Iteration 5, loss = 1113.18129519\n",
      "Iteration 51, loss = 834.78064755\n",
      "Iteration 39, loss = 840.97425292\n",
      "Iteration 26, loss = 844.04758961\n",
      "Iteration 66, loss = 809.88607315\n",
      "Iteration 52, loss = 839.87958016\n",
      "Iteration 408, loss = 1008.69668835\n",
      "Iteration 419, loss = 1036.25927841\n",
      "Iteration 40, loss = 829.91547954\n",
      "Iteration 27, loss = 840.36425876\n",
      "Iteration 6, loss = 977.78143141\n",
      "Iteration 1, loss = 2320.10218708\n",
      "Iteration 67, loss = 804.87482233\n",
      "Iteration 53, loss = 832.70369817\n",
      "Iteration 28, loss = 831.39848132\n",
      "Iteration 41, loss = 825.12651867\n",
      "Iteration 68, loss = 796.05296052\n",
      "Iteration 54, loss = 837.97048640\n",
      "Iteration 29, loss = 829.75448532\n",
      "Iteration 409, loss = 1000.12775585\n",
      "Iteration 42, loss = 829.36641938\n",
      "Iteration 420, loss = 1023.55880651\n",
      "Iteration 2, loss = 1135.08795977\n",
      "Iteration 7, loss = 970.47361197\n",
      "Iteration 69, loss = 797.83705681\n",
      "Iteration 55, loss = 834.41650366\n",
      "Iteration 30, loss = 818.00588191\n",
      "Iteration 43, loss = 826.01065078\n",
      "Iteration 70, loss = 799.43549989\n",
      "Iteration 3, loss = 1039.11198363\n",
      "Iteration 56, loss = 828.16940815\n",
      "Iteration 31, loss = 820.53060203\n",
      "Iteration 410, loss = 1029.10690486\n",
      "Iteration 44, loss = 824.47030665\n",
      "Iteration 421, loss = 1012.10687069\n",
      "Iteration 8, loss = 941.73283958\n",
      "Iteration 71, loss = 800.53655835\n",
      "Iteration 32, loss = 810.60587263\n",
      "Iteration 57, loss = 829.72688524\n",
      "Iteration 45, loss = 815.01840405\n",
      "Iteration 72, loss = 800.52853226\n",
      "Iteration 4, loss = 1011.87118989\n",
      "Iteration 33, loss = 818.70901267\n",
      "Iteration 411, loss = 1013.00620979\n",
      "Iteration 58, loss = 827.36892491\n",
      "Iteration 46, loss = 815.22914550\n",
      "Iteration 9, loss = 945.04481436\n",
      "Iteration 73, loss = 808.69341853\n",
      "Iteration 422, loss = 1028.67706327\n",
      "Iteration 34, loss = 806.73875887\n",
      "Iteration 59, loss = 830.23273082\n",
      "Iteration 47, loss = 814.03786394\n",
      "Iteration 5, loss = 1086.13573740\n",
      "Iteration 74, loss = 800.66313895\n",
      "Iteration 35, loss = 801.14903877\n",
      "Iteration 60, loss = 826.09433629\n",
      "Iteration 412, loss = 1008.15141749\n",
      "Iteration 10, loss = 950.72824051\n",
      "Iteration 48, loss = 814.44862947\n",
      "Iteration 75, loss = 799.78478654\n",
      "Iteration 423, loss = 1007.03674463\n",
      "Iteration 36, loss = 803.07130162\n",
      "Iteration 61, loss = 823.67280346\n",
      "Iteration 6, loss = 977.20946144\n",
      "Iteration 49, loss = 818.37544293\n",
      "Iteration 76, loss = 797.43088143\n",
      "Iteration 37, loss = 802.85085462\n",
      "Iteration 62, loss = 825.15630088\n",
      "Iteration 11, loss = 948.98048181\n",
      "Iteration 50, loss = 810.48123043\n",
      "Iteration 413, loss = 1011.70040756\n",
      "Iteration 77, loss = 796.70788136\n",
      "Iteration 38, loss = 793.45706139\n",
      "Iteration 7, loss = 969.02610945\n",
      "Iteration 424, loss = 1023.98755635\n",
      "Iteration 63, loss = 820.34948607\n",
      "Iteration 78, loss = 795.46641870\n",
      "Iteration 39, loss = 798.26401234\n",
      "Iteration 51, loss = 810.47595949\n",
      "Iteration 64, loss = 819.57637599\n",
      "Iteration 12, loss = 938.76401248\n",
      "Iteration 414, loss = 1006.95917273\n",
      "Iteration 40, loss = 796.31932797\n",
      "Iteration 79, loss = 795.34864580\n",
      "Iteration 52, loss = 813.55103380\n",
      "Iteration 8, loss = 932.26370452\n",
      "Iteration 80, loss = 795.26951333\n",
      "Iteration 65, loss = 823.50773140\n",
      "Iteration 425, loss = 1011.11566608\n",
      "Iteration 41, loss = 791.18409831\n",
      "Iteration 53, loss = 806.46235767\n",
      "Iteration 13, loss = 915.37450754\n",
      "Iteration 42, loss = 789.88559215\n",
      "Iteration 81, loss = 794.36859753\n",
      "Iteration 66, loss = 827.36465872\n",
      "Iteration 9, loss = 952.43512893\n",
      "Iteration 54, loss = 808.67476396\n",
      "Iteration 415, loss = 1003.62782124\n",
      "Iteration 43, loss = 794.08713307\n",
      "Iteration 82, loss = 797.11286594\n",
      "Iteration 67, loss = 823.95193179\n",
      "Iteration 55, loss = 807.24102541\n",
      "Iteration 426, loss = 1010.72115894\n",
      "Iteration 14, loss = 959.70437641\n",
      "Iteration 10, loss = 945.26467607\n",
      "Iteration 44, loss = 789.53049834\n",
      "Iteration 83, loss = 795.28471113\n",
      "Iteration 68, loss = 813.48774887\n",
      "Iteration 56, loss = 805.23194277\n",
      "Iteration 416, loss = 1002.40538891\n",
      "Iteration 45, loss = 777.66912104\n",
      "Iteration 84, loss = 794.49662748\n",
      "Iteration 69, loss = 811.82777551\n",
      "Iteration 57, loss = 805.10313425\n",
      "Iteration 15, loss = 960.72762061\n",
      "Iteration 427, loss = 1015.74207506\n",
      "Iteration 11, loss = 938.84580701\n",
      "Iteration 85, loss = 796.99949807\n",
      "Iteration 46, loss = 780.55765203\n",
      "Iteration 58, loss = 802.41641274\n",
      "Iteration 70, loss = 814.46267064\n",
      "Iteration 417, loss = 997.21182366\n",
      "Iteration 86, loss = 792.19007412\n",
      "Iteration 47, loss = 780.40504669\n",
      "Iteration 59, loss = 806.46996075\n",
      "Iteration 71, loss = 819.83268113\n",
      "Iteration 12, loss = 925.64142675\n",
      "Iteration 16, loss = 851.93103576\n",
      "Iteration 428, loss = 999.09428506\n",
      "Iteration 87, loss = 791.09435948\n",
      "Iteration 60, loss = 802.74780873\n",
      "Iteration 48, loss = 779.84212753\n",
      "Iteration 72, loss = 817.99032287\n",
      "Iteration 418, loss = 1010.11789397\n",
      "Iteration 88, loss = 794.69395741\n",
      "Iteration 13, loss = 891.85787431\n",
      "Iteration 61, loss = 800.56400358\n",
      "Iteration 17, loss = 884.36505012\n",
      "Iteration 49, loss = 783.29116617\n",
      "Iteration 73, loss = 822.18927906\n",
      "Iteration 89, loss = 791.27760644\n",
      "Iteration 429, loss = 999.29316003\n",
      "Iteration 62, loss = 800.29879471\n",
      "Iteration 50, loss = 775.61539810\n",
      "Iteration 74, loss = 814.33778406\n",
      "Iteration 14, loss = 929.78055211\n",
      "Iteration 419, loss = 996.01417099\n",
      "Iteration 90, loss = 789.18506435\n",
      "Iteration 18, loss = 885.99180387\n",
      "Iteration 63, loss = 794.60012426\n",
      "Iteration 51, loss = 776.45517245\n",
      "Iteration 75, loss = 815.55648720\n",
      "Iteration 91, loss = 791.98671974\n",
      "Iteration 430, loss = 1007.83582263\n",
      "Iteration 64, loss = 796.92108172\n",
      "Iteration 52, loss = 777.46853581\n",
      "Iteration 15, loss = 953.87275335\n",
      "Iteration 76, loss = 813.56089388\n",
      "Iteration 420, loss = 992.21216402\n",
      "Iteration 92, loss = 789.04677914\n",
      "Iteration 19, loss = 938.57059100\n",
      "Iteration 65, loss = 799.67558262\n",
      "Iteration 53, loss = 770.39388431\n",
      "Iteration 77, loss = 811.12309754\n",
      "Iteration 93, loss = 790.38026957\n",
      "Iteration 16, loss = 867.61943997\n",
      "Iteration 431, loss = 1005.45053074\n",
      "Iteration 66, loss = 802.36365818\n",
      "Iteration 54, loss = 772.83029105\n",
      "Iteration 78, loss = 813.10926720\n",
      "Iteration 20, loss = 913.30186940\n",
      "Iteration 94, loss = 792.89768934\n",
      "Iteration 421, loss = 987.11577103\n",
      "Iteration 55, loss = 773.24653847\n",
      "Iteration 67, loss = 798.59265819\n",
      "Iteration 79, loss = 809.05133593\n",
      "Iteration 17, loss = 881.13616591\n",
      "Iteration 95, loss = 788.06436105\n",
      "Iteration 68, loss = 788.32594515\n",
      "Iteration 56, loss = 769.43432367\n",
      "Iteration 432, loss = 1000.56710993\n",
      "Iteration 80, loss = 811.25348739\n",
      "Iteration 21, loss = 929.77032746\n",
      "Iteration 96, loss = 783.45162179\n",
      "Iteration 422, loss = 992.84550083\n",
      "Iteration 57, loss = 769.41136527\n",
      "Iteration 69, loss = 789.98633262\n",
      "Iteration 81, loss = 808.64300857\n",
      "Iteration 18, loss = 890.78882088\n",
      "Iteration 97, loss = 791.42229627\n",
      "Iteration 70, loss = 795.71087526\n",
      "Iteration 58, loss = 764.46768562\n",
      "Iteration 82, loss = 814.57449143\n",
      "Iteration 433, loss = 996.01374647\n",
      "Iteration 22, loss = 886.32535547\n",
      "Iteration 98, loss = 789.46158992\n",
      "Iteration 19, loss = 902.34234941\n",
      "Iteration 59, loss = 770.29698054\n",
      "Iteration 423, loss = 980.91816059\n",
      "Iteration 71, loss = 796.13031659\n",
      "Iteration 83, loss = 812.13664231\n",
      "Iteration 99, loss = 784.62499611\n",
      "Iteration 60, loss = 763.84235921\n",
      "Iteration 84, loss = 809.52966176\n",
      "Iteration 72, loss = 794.61371105\n",
      "Iteration 23, loss = 863.38112375\n",
      "Iteration 434, loss = 1003.92353038\n",
      "Iteration 100, loss = 784.88386095\n",
      "Iteration 20, loss = 923.64107311\n",
      "Iteration 61, loss = 772.09474935\n",
      "Iteration 424, loss = 978.37048464\n",
      "Iteration 73, loss = 796.72665164\n",
      "Iteration 85, loss = 811.80578845\n",
      "Iteration 101, loss = 788.35460314\n",
      "Iteration 74, loss = 791.91740365\n",
      "Iteration 62, loss = 766.64574039\n",
      "Iteration 86, loss = 808.18303609\n",
      "Iteration 24, loss = 896.88381988\n",
      "Iteration 21, loss = 905.43180445\n",
      "Iteration 102, loss = 782.91062320\n",
      "Iteration 435, loss = 994.96057305\n",
      "Iteration 75, loss = 792.61382283\n",
      "Iteration 63, loss = 762.14935238\n",
      "Iteration 87, loss = 805.60254466\n",
      "Iteration 103, loss = 779.90048143\n",
      "Iteration 425, loss = 984.48173095\n",
      "Iteration 25, loss = 888.43806094\n",
      "Iteration 76, loss = 789.94214057\n",
      "Iteration 22, loss = 868.20314154\n",
      "Iteration 64, loss = 758.53853782\n",
      "Iteration 88, loss = 809.14849916\n",
      "Iteration 104, loss = 784.64319446\n",
      "Iteration 77, loss = 787.54220953\n",
      "Iteration 436, loss = 1028.10075826\n",
      "Iteration 65, loss = 763.65482303\n",
      "Iteration 89, loss = 806.29112823\n",
      "Iteration 426, loss = 984.91670287\n",
      "Iteration 105, loss = 789.75163169\n",
      "Iteration 26, loss = 860.36171677\n",
      "Iteration 23, loss = 845.00808607\n",
      "Iteration 78, loss = 788.56010178\n",
      "Iteration 66, loss = 766.31442657\n",
      "Iteration 90, loss = 805.52846448\n",
      "Iteration 106, loss = 789.77521961\n",
      "Iteration 79, loss = 785.69024780\n",
      "Iteration 91, loss = 803.24064418\n",
      "Iteration 67, loss = 761.37917848\n",
      "Iteration 107, loss = 783.62116472\n",
      "Iteration 437, loss = 1007.87010437\n",
      "Iteration 427, loss = 970.79313990\n",
      "Iteration 24, loss = 886.25102985\n",
      "Iteration 27, loss = 906.72214103\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 80, loss = 793.23218719\n",
      "Iteration 68, loss = 753.53063020\n",
      "Iteration 92, loss = 804.47154713\n",
      "Iteration 108, loss = 778.42179736\n",
      "Iteration 81, loss = 785.69347088\n",
      "Iteration 69, loss = 754.15861836\n",
      "Iteration 93, loss = 806.98999815\n",
      "Iteration 25, loss = 861.89957906\n",
      "Iteration 109, loss = 785.51934048\n",
      "Iteration 438, loss = 998.81964909\n",
      "Iteration 428, loss = 995.34354232\n",
      "Iteration 1, loss = 2384.23923246\n",
      "Iteration 82, loss = 785.61786587\n",
      "Iteration 70, loss = 761.37719114\n",
      "Iteration 110, loss = 782.76833609\n",
      "Iteration 94, loss = 806.70118673\n",
      "Iteration 83, loss = 790.42353706\n",
      "Iteration 26, loss = 850.82679847\n",
      "Iteration 71, loss = 758.96638670\n",
      "Iteration 111, loss = 779.98966615\n",
      "Iteration 95, loss = 802.24763518\n",
      "Iteration 2, loss = 1075.50354985\n",
      "Iteration 439, loss = 1008.80240286\n",
      "Iteration 429, loss = 974.85575027\n",
      "Iteration 84, loss = 785.80669538\n",
      "Iteration 72, loss = 753.77144887\n",
      "Iteration 112, loss = 778.96424913\n",
      "Iteration 96, loss = 794.80948384\n",
      "Iteration 27, loss = 885.28989708\n",
      "Iteration 73, loss = 761.60807187\n",
      "Iteration 85, loss = 789.81540869\n",
      "Iteration 113, loss = 780.80862593\n",
      "Iteration 3, loss = 1002.73146978\n",
      "Iteration 97, loss = 802.31536253\n",
      "Iteration 74, loss = 753.39640995\n",
      "Iteration 430, loss = 986.43048855\n",
      "Iteration 86, loss = 784.55597274\n",
      "Iteration 440, loss = 984.75321274\n",
      "Iteration 114, loss = 777.90987926\n",
      "Iteration 28, loss = 853.98745155\n",
      "Iteration 98, loss = 805.86567550\n",
      "Iteration 75, loss = 754.13618496\n",
      "Iteration 87, loss = 783.60291333\n",
      "Iteration 4, loss = 1013.59963471\n",
      "Iteration 115, loss = 781.85774488\n",
      "Iteration 76, loss = 754.17389220\n",
      "Iteration 99, loss = 796.59243046\n",
      "Iteration 431, loss = 986.46594797\n",
      "Iteration 88, loss = 788.94186646\n",
      "Iteration 116, loss = 783.14963873\n",
      "Iteration 29, loss = 870.72544702\n",
      "Iteration 441, loss = 994.53052520\n",
      "Iteration 77, loss = 755.31004823\n",
      "Iteration 5, loss = 1036.43358555\n",
      "Iteration 100, loss = 797.60675210\n",
      "Iteration 89, loss = 781.04699258\n",
      "Iteration 117, loss = 778.42206404\n",
      "Iteration 78, loss = 751.39931607\n",
      "Iteration 90, loss = 783.71408226\n",
      "Iteration 101, loss = 802.24887942\n",
      "Iteration 118, loss = 778.49544629\n",
      "Iteration 432, loss = 954.54510946\n",
      "Iteration 30, loss = 864.48147034\n",
      "Iteration 6, loss = 967.15249704\n",
      "Iteration 91, loss = 782.19078171\n",
      "Iteration 79, loss = 751.20111521\n",
      "Iteration 442, loss = 979.87903197\n",
      "Iteration 102, loss = 795.97525667\n",
      "Iteration 119, loss = 775.71282589\n",
      "Iteration 80, loss = 759.17136832\n",
      "Iteration 92, loss = 781.93642051\n",
      "Iteration 103, loss = 795.68296750\n",
      "Iteration 31, loss = 869.40334977\n",
      "Iteration 433, loss = 971.42264338\n",
      "Iteration 120, loss = 774.87950140\n",
      "Iteration 7, loss = 919.66275334\n",
      "Iteration 81, loss = 750.87896774\n",
      "Iteration 93, loss = 787.37715873\n",
      "Iteration 104, loss = 798.87462553\n",
      "Iteration 443, loss = 979.67111910\n",
      "Iteration 121, loss = 777.48865457\n",
      "Iteration 82, loss = 751.15698299\n",
      "Iteration 32, loss = 844.03109223\n",
      "Iteration 94, loss = 784.02129394\n",
      "Iteration 8, loss = 914.51501844\n",
      "Iteration 105, loss = 799.73586137\n",
      "Iteration 122, loss = 777.61809123\n",
      "Iteration 434, loss = 970.60231270\n",
      "Iteration 83, loss = 754.78230336\n",
      "Iteration 95, loss = 782.01330835\n",
      "Iteration 123, loss = 775.59921872\n",
      "Iteration 106, loss = 801.60830595\n",
      "Iteration 33, loss = 858.33161995\n",
      "Iteration 444, loss = 986.04180086\n",
      "Iteration 84, loss = 750.46785073\n",
      "Iteration 96, loss = 772.82482634\n",
      "Iteration 9, loss = 893.38217049\n",
      "Iteration 435, loss = 966.54656403\n",
      "Iteration 124, loss = 780.12865650\n",
      "Iteration 107, loss = 796.86973431\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 97, loss = 781.86318651\n",
      "Iteration 85, loss = 756.15026120\n",
      "Iteration 125, loss = 776.37851519\n",
      "Iteration 34, loss = 818.25756377\n",
      "Iteration 98, loss = 784.66095713\n",
      "Iteration 86, loss = 750.69984239\n",
      "Iteration 10, loss = 895.12938801\n",
      "Iteration 445, loss = 987.40070765\n",
      "Iteration 126, loss = 774.30013173\n",
      "Iteration 436, loss = 963.78293494\n",
      "Iteration 1, loss = 2573.90832083\n",
      "Iteration 87, loss = 748.50890128\n",
      "Iteration 99, loss = 774.37634930\n",
      "Iteration 127, loss = 773.32906103\n",
      "Iteration 35, loss = 880.21866873\n",
      "Iteration 11, loss = 887.68961502\n",
      "Iteration 88, loss = 752.94696654\n",
      "Iteration 100, loss = 777.51203075\n",
      "Iteration 446, loss = 983.93302579\n",
      "Iteration 128, loss = 777.03813372\n",
      "Iteration 437, loss = 976.48489440\n",
      "Iteration 2, loss = 1152.70742856\n",
      "Iteration 89, loss = 748.44617719\n",
      "Iteration 101, loss = 778.49479568\n",
      "Iteration 36, loss = 812.02625937\n",
      "Iteration 12, loss = 883.51729038\n",
      "Iteration 129, loss = 774.42225555\n",
      "Iteration 90, loss = 748.06908939\n",
      "Iteration 102, loss = 777.51139647\n",
      "Iteration 3, loss = 1040.50127792\n",
      "Iteration 130, loss = 772.95074319\n",
      "Iteration 447, loss = 1034.85871331\n",
      "Iteration 438, loss = 964.01207131\n",
      "Iteration 91, loss = 746.59910258\n",
      "Iteration 103, loss = 774.89957852\n",
      "Iteration 37, loss = 848.12909625\n",
      "Iteration 13, loss = 898.31361230\n",
      "Iteration 131, loss = 775.22159053\n",
      "Iteration 92, loss = 748.25799907\n",
      "Iteration 104, loss = 775.69023462\n",
      "Iteration 4, loss = 1021.76548415\n",
      "Iteration 132, loss = 771.16458825\n",
      "Iteration 448, loss = 988.49385471\n",
      "Iteration 14, loss = 881.58102385\n",
      "Iteration 439, loss = 958.92611498\n",
      "Iteration 38, loss = 831.49783777\n",
      "Iteration 93, loss = 751.57365725\n",
      "Iteration 105, loss = 778.10814225\n",
      "Iteration 133, loss = 775.75128380\n",
      "Iteration 94, loss = 746.69989450\n",
      "Iteration 106, loss = 778.09395602\n",
      "Iteration 5, loss = 1058.52533553\n",
      "Iteration 134, loss = 772.98712696\n",
      "Iteration 15, loss = 883.40992373\n",
      "Iteration 39, loss = 863.31096255\n",
      "Iteration 95, loss = 742.36066227\n",
      "Iteration 107, loss = 780.41496733\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 449, loss = 987.75268879\n",
      "Iteration 440, loss = 973.31251418\n",
      "Iteration 135, loss = 770.56301812\n",
      "Iteration 96, loss = 740.18650520\n",
      "Iteration 6, loss = 1031.17886227\n",
      "Iteration 40, loss = 850.15449579\n",
      "Iteration 16, loss = 877.15006107\n",
      "Iteration 136, loss = 766.05143552\n",
      "Iteration 97, loss = 751.40628798\n",
      "Iteration 1, loss = 2365.86793946\n",
      "Iteration 441, loss = 953.51676180\n",
      "Iteration 450, loss = 975.43375655\n",
      "Iteration 137, loss = 774.75992639\n",
      "Iteration 7, loss = 967.86588688\n",
      "Iteration 98, loss = 751.21881796\n",
      "Iteration 41, loss = 848.25841493\n",
      "Iteration 17, loss = 867.22564644\n",
      "Iteration 138, loss = 767.73053890\n",
      "Iteration 99, loss = 742.42322307\n",
      "Iteration 442, loss = 957.45518694\n",
      "Iteration 2, loss = 1140.32921694\n",
      "Iteration 8, loss = 950.01024034\n",
      "Iteration 139, loss = 767.49356500\n",
      "Iteration 451, loss = 1001.75365666\n",
      "Iteration 100, loss = 738.71650346\n",
      "Iteration 42, loss = 853.59088344\n",
      "Iteration 18, loss = 864.87123540\n",
      "Iteration 140, loss = 774.88029991\n",
      "Iteration 101, loss = 742.83400769\n",
      "Iteration 3, loss = 1022.23517909\n",
      "Iteration 443, loss = 953.56302686\n",
      "Iteration 9, loss = 923.24116937\n",
      "Iteration 43, loss = 845.19761486\n",
      "Iteration 19, loss = 853.91057792\n",
      "Iteration 141, loss = 774.83215175\n",
      "Iteration 102, loss = 742.31465209\n",
      "Iteration 452, loss = 977.99863996\n",
      "Iteration 142, loss = 766.01775302\n",
      "Iteration 4, loss = 934.98436363\n",
      "Iteration 103, loss = 740.88627451\n",
      "Iteration 20, loss = 834.44252632\n",
      "Iteration 44, loss = 818.37102552\n",
      "Iteration 10, loss = 982.14891400\n",
      "Iteration 444, loss = 966.79310864\n",
      "Iteration 143, loss = 765.64808710\n",
      "Iteration 104, loss = 739.55166008\n",
      "Iteration 453, loss = 974.04838630\n",
      "Iteration 5, loss = 988.98473520\n",
      "Iteration 144, loss = 771.79887406\n",
      "Iteration 105, loss = 740.20929476\n",
      "Iteration 21, loss = 839.72838412\n",
      "Iteration 45, loss = 843.74530071\n",
      "Iteration 11, loss = 932.56629258\n",
      "Iteration 445, loss = 968.14617283\n",
      "Iteration 145, loss = 772.79550212\n",
      "Iteration 106, loss = 743.67119803\n",
      "Iteration 6, loss = 972.30658107\n",
      "Iteration 454, loss = 975.10354219\n",
      "Iteration 46, loss = 830.40399996\n",
      "Iteration 146, loss = 767.16814741\n",
      "Iteration 22, loss = 826.32583356\n",
      "Iteration 12, loss = 912.84973795\n",
      "Iteration 107, loss = 742.92858718\n",
      "Iteration 147, loss = 765.50203725\n",
      "Iteration 446, loss = 970.72946649\n",
      "Iteration 7, loss = 938.73430437\n",
      "Iteration 47, loss = 813.71822235\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 108, loss = 742.55629020\n",
      "Iteration 455, loss = 959.72096494\n",
      "Iteration 23, loss = 848.17368894\n",
      "Iteration 13, loss = 975.16382273\n",
      "Iteration 148, loss = 772.04651971\n",
      "Iteration 109, loss = 735.76397563\n",
      "Iteration 149, loss = 769.93706896\n",
      "Iteration 8, loss = 914.38932137\n",
      "Iteration 447, loss = 954.75604728\n",
      "Iteration 24, loss = 834.42559327\n",
      "Iteration 110, loss = 740.21525672\n",
      "Iteration 1, loss = 2379.65800725\n",
      "Iteration 456, loss = 966.70200100\n",
      "Iteration 150, loss = 769.97645243\n",
      "Iteration 14, loss = 913.72506348\n",
      "Iteration 111, loss = 731.80132605\n",
      "Iteration 151, loss = 769.83384986\n",
      "Iteration 25, loss = 837.01154257\n",
      "Iteration 9, loss = 885.78873189\n",
      "Iteration 2, loss = 1150.19439640\n",
      "Iteration 112, loss = 739.75088873\n",
      "Iteration 448, loss = 951.31925151\n",
      "Iteration 457, loss = 967.45494346\n",
      "Iteration 15, loss = 932.16314463\n",
      "Iteration 152, loss = 771.12868125\n",
      "Iteration 113, loss = 739.89331739\n",
      "Iteration 3, loss = 1054.18859609\n",
      "Iteration 26, loss = 874.46295140\n",
      "Iteration 10, loss = 937.01512398\n",
      "Iteration 153, loss = 769.84903793\n",
      "Iteration 114, loss = 734.53459177\n",
      "Iteration 16, loss = 888.92919910\n",
      "Iteration 449, loss = 964.47146422\n",
      "Iteration 458, loss = 965.34172561\n",
      "Iteration 154, loss = 768.48980108\n",
      "Iteration 115, loss = 736.73827781\n",
      "Iteration 4, loss = 979.81622998\n",
      "Iteration 27, loss = 809.87470685\n",
      "Iteration 11, loss = 900.69986769\n",
      "Iteration 155, loss = 771.22350980\n",
      "Iteration 116, loss = 740.43955453\n",
      "Iteration 17, loss = 904.01907861\n",
      "Iteration 450, loss = 938.60922105\n",
      "Iteration 156, loss = 768.98323709\n",
      "Iteration 5, loss = 1011.18409221\n",
      "Iteration 117, loss = 736.93728486\n",
      "Iteration 28, loss = 809.90047527\n",
      "Iteration 459, loss = 959.79372355\n",
      "Iteration 12, loss = 906.84892657\n",
      "Iteration 157, loss = 767.89570660\n",
      "Iteration 118, loss = 736.17368163\n",
      "Iteration 18, loss = 914.92382151\n",
      "Iteration 6, loss = 1013.62960594\n",
      "Iteration 158, loss = 768.50351103\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 823.82655832\n",
      "Iteration 451, loss = 937.47557729\n",
      "Iteration 119, loss = 739.43104251\n",
      "Iteration 460, loss = 949.88911321\n",
      "Iteration 13, loss = 890.57243189\n",
      "Iteration 19, loss = 890.64022823\n",
      "Iteration 120, loss = 738.17386823\n",
      "Iteration 7, loss = 938.32173633\n",
      "Iteration 30, loss = 870.91248980\n",
      "Iteration 121, loss = 733.99840621\n",
      "Iteration 452, loss = 934.10476314\n",
      "Iteration 1, loss = 2551.70625096\n",
      "Iteration 14, loss = 878.92188731\n",
      "Iteration 20, loss = 919.77864409\n",
      "Iteration 461, loss = 966.87514246\n",
      "Iteration 122, loss = 734.50625201\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 8, loss = 927.24775574\n",
      "Iteration 31, loss = 835.51278600\n",
      "Iteration 453, loss = 959.79509296\n",
      "Iteration 2, loss = 1145.98296885\n",
      "Iteration 15, loss = 866.66371871\n",
      "Iteration 21, loss = 881.49393211\n",
      "Iteration 462, loss = 972.54964816\n",
      "Iteration 9, loss = 950.86276427\n",
      "Iteration 1, loss = 2589.05089905\n",
      "Iteration 32, loss = 827.25888620\n",
      "Iteration 3, loss = 1110.62128599\n",
      "Iteration 454, loss = 947.62911261\n",
      "Iteration 16, loss = 870.53537853\n",
      "Iteration 22, loss = 884.97142407\n",
      "Iteration 10, loss = 944.88459438\n",
      "Iteration 33, loss = 863.95751660\n",
      "Iteration 2, loss = 1174.54048033\n",
      "Iteration 463, loss = 959.68776188\n",
      "Iteration 4, loss = 1021.26349802\n",
      "Iteration 17, loss = 876.46488413\n",
      "Iteration 23, loss = 887.58819896\n",
      "Iteration 455, loss = 936.06684142\n",
      "Iteration 34, loss = 812.95788740\n",
      "Iteration 11, loss = 967.82423382\n",
      "Iteration 3, loss = 1099.62436389\n",
      "Iteration 5, loss = 988.56786863\n",
      "Iteration 464, loss = 975.22894939\n",
      "Iteration 18, loss = 874.05200147\n",
      "Iteration 24, loss = 856.49301390\n",
      "Iteration 35, loss = 810.57131409\n",
      "Iteration 12, loss = 940.82487547\n",
      "Iteration 4, loss = 1035.77214059\n",
      "Iteration 456, loss = 933.15683058\n",
      "Iteration 6, loss = 1041.65689356\n",
      "Iteration 465, loss = 956.55020236\n",
      "Iteration 19, loss = 870.89206793\n",
      "Iteration 36, loss = 806.32671274\n",
      "Iteration 25, loss = 916.94027013\n",
      "Iteration 13, loss = 912.91668043\n",
      "Iteration 5, loss = 980.85467722\n",
      "Iteration 457, loss = 946.06011915\n",
      "Iteration 7, loss = 953.74590715\n",
      "Iteration 20, loss = 881.32682444\n",
      "Iteration 37, loss = 795.28347173\n",
      "Iteration 14, loss = 924.71354086\n",
      "Iteration 466, loss = 971.35415960\n",
      "Iteration 26, loss = 954.04200955\n",
      "Iteration 6, loss = 1054.66998331\n",
      "Iteration 8, loss = 957.29762582\n",
      "Iteration 458, loss = 936.28875422\n",
      "Iteration 38, loss = 794.43105995\n",
      "Iteration 21, loss = 887.20387485\n",
      "Iteration 15, loss = 934.22011805\n",
      "Iteration 27, loss = 837.18313174\n",
      "Iteration 467, loss = 950.84888224\n",
      "Iteration 7, loss = 942.54250387\n",
      "Iteration 9, loss = 921.18827131\n",
      "Iteration 39, loss = 832.23805837\n",
      "Iteration 459, loss = 925.57652142\n",
      "Iteration 16, loss = 907.37916937\n",
      "Iteration 22, loss = 843.74930104\n",
      "Iteration 28, loss = 866.49586606\n",
      "Iteration 8, loss = 995.48679601\n",
      "Iteration 10, loss = 931.12993233Iteration 468, loss = 951.33889711\n",
      "\n",
      "Iteration 40, loss = 816.78213868\n",
      "Iteration 17, loss = 895.67096214\n",
      "Iteration 23, loss = 865.14779957\n",
      "Iteration 29, loss = 884.20335543\n",
      "Iteration 460, loss = 952.31143565\n",
      "Iteration 9, loss = 928.56097157\n",
      "Iteration 11, loss = 957.68277249\n",
      "Iteration 41, loss = 805.96282356\n",
      "Iteration 18, loss = 900.54276171\n",
      "Iteration 469, loss = 942.80160986\n",
      "Iteration 24, loss = 839.19963479\n",
      "Iteration 30, loss = 911.19601512\n",
      "Iteration 10, loss = 953.90434830\n",
      "Iteration 461, loss = 954.63027340\n",
      "Iteration 12, loss = 941.25877605\n",
      "Iteration 42, loss = 788.52379238\n",
      "Iteration 19, loss = 875.75563700\n",
      "Iteration 25, loss = 866.86623341\n",
      "Iteration 31, loss = 875.64409370\n",
      "Iteration 470, loss = 956.62111107\n",
      "Iteration 11, loss = 928.64840944\n",
      "Iteration 13, loss = 929.10826742\n",
      "Iteration 462, loss = 939.28402355\n",
      "Iteration 43, loss = 802.43016556\n",
      "Iteration 20, loss = 896.09352588\n",
      "Iteration 26, loss = 896.73299444\n",
      "Iteration 32, loss = 859.49854599\n",
      "Iteration 12, loss = 969.33621634\n",
      "Iteration 471, loss = 954.44973457\n",
      "Iteration 14, loss = 948.42566323\n",
      "Iteration 44, loss = 777.98601711\n",
      "Iteration 21, loss = 918.64329630\n",
      "Iteration 463, loss = 940.61160051\n",
      "Iteration 27, loss = 812.71256533\n",
      "Iteration 33, loss = 905.83253955\n",
      "Iteration 13, loss = 928.98336902\n",
      "Iteration 15, loss = 923.57905464\n",
      "Iteration 45, loss = 808.39923559\n",
      "Iteration 22, loss = 893.71022757\n",
      "Iteration 472, loss = 950.48042935\n",
      "Iteration 28, loss = 865.98104373\n",
      "Iteration 464, loss = 936.17401271\n",
      "Iteration 34, loss = 858.10524766\n",
      "Iteration 16, loss = 913.05187431\n",
      "Iteration 14, loss = 985.16465291\n",
      "Iteration 46, loss = 788.50437749\n",
      "Iteration 23, loss = 887.87652171\n",
      "Iteration 29, loss = 864.60840040\n",
      "Iteration 473, loss = 977.22208546\n",
      "Iteration 465, loss = 918.43398912\n",
      "Iteration 35, loss = 884.05263878\n",
      "Iteration 17, loss = 900.83116993\n",
      "Iteration 15, loss = 954.67403999\n",
      "Iteration 24, loss = 861.69521331\n",
      "Iteration 47, loss = 787.35799049\n",
      "Iteration 30, loss = 854.65747615\n",
      "Iteration 36, loss = 859.30516852\n",
      "Iteration 18, loss = 889.56811202\n",
      "Iteration 474, loss = 964.83216987\n",
      "Iteration 466, loss = 922.01057583\n",
      "Iteration 16, loss = 919.19285213\n",
      "Iteration 48, loss = 799.15245141\n",
      "Iteration 25, loss = 880.45240659\n",
      "Iteration 31, loss = 815.96288598\n",
      "Iteration 19, loss = 896.07503507\n",
      "Iteration 37, loss = 847.55610754\n",
      "Iteration 17, loss = 947.95097102\n",
      "Iteration 26, loss = 913.25014084\n",
      "Iteration 475, loss = 945.51959770\n",
      "Iteration 49, loss = 770.75291234\n",
      "Iteration 467, loss = 924.18763323\n",
      "Iteration 32, loss = 834.67088362\n",
      "Iteration 38, loss = 817.66630657\n",
      "Iteration 20, loss = 908.75703526\n",
      "Iteration 18, loss = 888.22096181\n",
      "Iteration 50, loss = 788.00239466\n",
      "Iteration 27, loss = 838.04582285\n",
      "Iteration 468, loss = 912.58587403\n",
      "Iteration 476, loss = 952.41629975\n",
      "Iteration 33, loss = 844.50335911\n",
      "Iteration 21, loss = 909.63698586\n",
      "Iteration 39, loss = 868.52955147\n",
      "Iteration 19, loss = 903.99929817\n",
      "Iteration 28, loss = 902.30900024\n",
      "Iteration 51, loss = 775.07283897\n",
      "Iteration 469, loss = 934.53089579\n",
      "Iteration 34, loss = 822.45995762\n",
      "Iteration 477, loss = 949.17613958\n",
      "Iteration 22, loss = 927.61344701\n",
      "Iteration 40, loss = 848.17807750\n",
      "Iteration 29, loss = 845.68491520\n",
      "Iteration 52, loss = 825.41275857\n",
      "Iteration 20, loss = 919.95139129\n",
      "Iteration 35, loss = 854.62209356\n",
      "Iteration 470, loss = 943.06420718\n",
      "Iteration 23, loss = 893.00086007\n",
      "Iteration 478, loss = 944.92233514\n",
      "Iteration 41, loss = 868.57363915\n",
      "Iteration 30, loss = 883.80718336\n",
      "Iteration 53, loss = 783.33385905\n",
      "Iteration 21, loss = 916.34051311\n",
      "Iteration 36, loss = 798.42401130\n",
      "Iteration 24, loss = 856.45197829\n",
      "Iteration 471, loss = 924.08140593\n",
      "Iteration 31, loss = 843.30547955\n",
      "Iteration 42, loss = 830.70607359\n",
      "Iteration 54, loss = 786.26237637\n",
      "Iteration 479, loss = 936.00587207\n",
      "Iteration 22, loss = 953.44048006\n",
      "Iteration 37, loss = 816.13293974\n",
      "Iteration 25, loss = 881.74801735\n",
      "Iteration 32, loss = 856.08835607\n",
      "Iteration 55, loss = 787.30528968\n",
      "Iteration 43, loss = 834.46378999\n",
      "Iteration 472, loss = 907.90520035\n",
      "Iteration 23, loss = 909.79453302\n",
      "Iteration 480, loss = 935.32575063\n",
      "Iteration 38, loss = 762.95739008\n",
      "Iteration 26, loss = 916.16582041\n",
      "Iteration 56, loss = 793.76953602\n",
      "Iteration 33, loss = 861.91918968\n",
      "Iteration 44, loss = 814.92374702\n",
      "Iteration 473, loss = 908.67256891\n",
      "Iteration 24, loss = 879.06329108\n",
      "Iteration 27, loss = 849.98911881\n",
      "Iteration 39, loss = 815.32261933\n",
      "Iteration 481, loss = 984.35248147\n",
      "Iteration 57, loss = 788.06041208\n",
      "Iteration 34, loss = 860.83687956\n",
      "Iteration 45, loss = 851.23269425\n",
      "Iteration 474, loss = 916.97362585\n",
      "Iteration 25, loss = 888.56587295\n",
      "Iteration 28, loss = 889.27932425\n",
      "Iteration 40, loss = 827.94557324\n",
      "Iteration 58, loss = 777.00565424\n",
      "Iteration 35, loss = 879.02911802\n",
      "Iteration 46, loss = 811.70281677\n",
      "Iteration 482, loss = 952.84026762\n",
      "Iteration 26, loss = 933.55130918\n",
      "Iteration 475, loss = 927.34033908\n",
      "Iteration 29, loss = 847.71982096\n",
      "Iteration 59, loss = 772.65097623\n",
      "Iteration 36, loss = 805.12271821\n",
      "Iteration 41, loss = 811.58100055\n",
      "Iteration 47, loss = 826.48323481\n",
      "Iteration 483, loss = 938.56810830\n",
      "Iteration 27, loss = 868.48698831\n",
      "Iteration 30, loss = 880.34632487\n",
      "Iteration 60, loss = 780.63032211\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 37, loss = 849.34502529\n",
      "Iteration 476, loss = 893.13874514\n",
      "Iteration 42, loss = 816.84215729\n",
      "Iteration 48, loss = 835.86191980\n",
      "Iteration 28, loss = 889.84799413\n",
      "Iteration 484, loss = 934.10120509\n",
      "Iteration 31, loss = 856.44661165\n",
      "Iteration 38, loss = 800.65568286\n",
      "Iteration 43, loss = 797.23956445\n",
      "Iteration 477, loss = 916.74509474\n",
      "Iteration 1, loss = 2565.00428784\n",
      "Iteration 49, loss = 789.15840628\n",
      "Iteration 32, loss = 847.03613519\n",
      "Iteration 29, loss = 875.97997996\n",
      "Iteration 39, loss = 861.93953479\n",
      "Iteration 485, loss = 954.81278118\n",
      "Iteration 44, loss = 783.39001988\n",
      "Iteration 2, loss = 1138.30490793\n",
      "Iteration 478, loss = 914.13170157\n",
      "Iteration 50, loss = 835.83642460\n",
      "Iteration 40, loss = 847.81270902\n",
      "Iteration 33, loss = 848.51349872\n",
      "Iteration 30, loss = 896.53420298\n",
      "Iteration 45, loss = 812.40655153\n",
      "Iteration 486, loss = 944.94424980\n",
      "Iteration 3, loss = 1130.67491867\n",
      "Iteration 51, loss = 812.63827382\n",
      "Iteration 479, loss = 905.42176051\n",
      "Iteration 41, loss = 854.20598736\n",
      "Iteration 34, loss = 845.90813428\n",
      "Iteration 31, loss = 880.79870589\n",
      "Iteration 46, loss = 790.00973637\n",
      "Iteration 4, loss = 1030.73673965\n",
      "Iteration 487, loss = 935.12461326\n",
      "Iteration 52, loss = 845.34583409\n",
      "Iteration 42, loss = 839.48255789\n",
      "Iteration 35, loss = 849.65710845\n",
      "Iteration 480, loss = 936.05219876\n",
      "Iteration 32, loss = 848.66008858\n",
      "Iteration 47, loss = 810.12682931\n",
      "Iteration 5, loss = 980.98881332\n",
      "Iteration 43, loss = 831.38102885\n",
      "Iteration 53, loss = 812.63720930\n",
      "Iteration 36, loss = 810.78605629\n",
      "Iteration 488, loss = 940.86609396\n",
      "Iteration 33, loss = 869.26764328\n",
      "Iteration 481, loss = 925.22047989\n",
      "Iteration 48, loss = 816.45137670\n",
      "Iteration 6, loss = 968.08029341\n",
      "Iteration 44, loss = 805.96033461\n",
      "Iteration 54, loss = 829.11069557\n",
      "Iteration 37, loss = 843.33001617\n",
      "Iteration 34, loss = 855.48400835\n",
      "Iteration 482, loss = 895.92977885\n",
      "Iteration 489, loss = 938.12519249\n",
      "Iteration 49, loss = 771.23470854\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 7, loss = 927.37982124\n",
      "Iteration 45, loss = 843.65646698\n",
      "Iteration 55, loss = 821.43281468\n",
      "Iteration 38, loss = 814.59192807\n",
      "Iteration 35, loss = 860.11781620\n",
      "Iteration 483, loss = 909.87771071\n",
      "Iteration 490, loss = 929.22176956\n",
      "Iteration 46, loss = 814.88342232\n",
      "Iteration 1, loss = 2612.97221248\n",
      "Iteration 8, loss = 1015.53223959\n",
      "Iteration 56, loss = 818.22077483\n",
      "Iteration 39, loss = 868.27038954\n",
      "Iteration 36, loss = 823.24642921\n",
      "Iteration 47, loss = 850.76331686\n",
      "Iteration 484, loss = 893.41169782\n",
      "Iteration 9, loss = 925.77818443\n",
      "Iteration 2, loss = 1134.65796520\n",
      "Iteration 491, loss = 949.30397423\n",
      "Iteration 40, loss = 838.62517967\n",
      "Iteration 57, loss = 816.54194071\n",
      "Iteration 37, loss = 863.97001192\n",
      "Iteration 48, loss = 846.38922812\n",
      "Iteration 10, loss = 923.80214698\n",
      "Iteration 41, loss = 859.33719199\n",
      "Iteration 485, loss = 897.15358978\n",
      "Iteration 58, loss = 799.53051085\n",
      "Iteration 3, loss = 1072.48012224\n",
      "Iteration 38, loss = 834.93146022\n",
      "Iteration 492, loss = 931.08084934\n",
      "Iteration 49, loss = 808.46282958\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 11, loss = 930.65181350\n",
      "Iteration 42, loss = 822.06361766\n",
      "Iteration 59, loss = 785.13234662\n",
      "Iteration 39, loss = 873.67105658\n",
      "Iteration 4, loss = 1060.13448245\n",
      "Iteration 486, loss = 899.81634767\n",
      "Iteration 493, loss = 934.66448938\n",
      "Iteration 12, loss = 975.70345994\n",
      "Iteration 43, loss = 851.50577871\n",
      "Iteration 1, loss = 6216.15537685\n",
      "Iteration 60, loss = 815.90964993\n",
      "Iteration 40, loss = 849.25113042\n",
      "Iteration 5, loss = 925.63434162\n",
      "Iteration 487, loss = 891.16330452\n",
      "Iteration 494, loss = 919.29282905\n",
      "Iteration 13, loss = 894.17592013\n",
      "Iteration 44, loss = 817.01539124\n",
      "Iteration 2, loss = 1853.08005471\n",
      "Iteration 61, loss = 805.49830285\n",
      "Iteration 41, loss = 865.93426920\n",
      "Iteration 6, loss = 917.32117717\n",
      "Iteration 488, loss = 922.83077372\n",
      "Iteration 14, loss = 987.12149882\n",
      "Iteration 45, loss = 819.16404951\n",
      "Iteration 495, loss = 925.63469698\n",
      "Iteration 3, loss = 1200.08662241\n",
      "Iteration 62, loss = 787.88341742\n",
      "Iteration 42, loss = 844.17047809\n",
      "Iteration 7, loss = 899.67615496\n",
      "Iteration 489, loss = 905.07034720\n",
      "Iteration 15, loss = 934.70907373\n",
      "Iteration 46, loss = 813.79919996\n",
      "Iteration 4, loss = 1108.64705686\n",
      "Iteration 63, loss = 822.59604918\n",
      "Iteration 43, loss = 851.31104496\n",
      "Iteration 496, loss = 937.99701922\n",
      "Iteration 8, loss = 935.44650115\n",
      "Iteration 16, loss = 913.89493554\n",
      "Iteration 47, loss = 825.28380345\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 490, loss = 880.92845293\n",
      "Iteration 64, loss = 814.30679631\n",
      "Iteration 44, loss = 856.96263038\n",
      "Iteration 5, loss = 1027.21110495\n",
      "Iteration 9, loss = 871.33842998\n",
      "Iteration 497, loss = 936.65974065\n",
      "Iteration 17, loss = 899.84219410\n",
      "Iteration 1, loss = 6478.10120044\n",
      "Iteration 65, loss = 782.33025302\n",
      "Iteration 45, loss = 849.88183836\n",
      "Iteration 6, loss = 975.41082228\n",
      "Iteration 491, loss = 889.71371922\n",
      "Iteration 10, loss = 910.44335923\n",
      "Iteration 18, loss = 873.64462882\n",
      "Iteration 498, loss = 924.25733334\n",
      "Iteration 46, loss = 833.53377985\n",
      "Iteration 66, loss = 805.79084596\n",
      "Iteration 2, loss = 1928.85168635\n",
      "Iteration 7, loss = 943.11630854\n",
      "Iteration 11, loss = 874.37483785\n",
      "Iteration 492, loss = 904.60149358\n",
      "Iteration 19, loss = 876.95609052\n",
      "Iteration 47, loss = 832.14736349\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 499, loss = 947.16971912\n",
      "Iteration 3, loss = 1202.13129045\n",
      "Iteration 8, loss = 920.24320579\n",
      "Iteration 67, loss = 781.47408923\n",
      "Iteration 12, loss = 946.36048070\n",
      "Iteration 493, loss = 895.82888073\n",
      "Iteration 20, loss = 931.53041649\n",
      "Iteration 4, loss = 1102.19764852\n",
      "Iteration 9, loss = 894.25899986\n",
      "Iteration 1, loss = 6255.88220801\n",
      "Iteration 500, loss = 916.93148941\n",
      "Iteration 68, loss = 790.65598405\n",
      "Iteration 13, loss = 851.75956134\n",
      "Iteration 494, loss = 903.18010186\n",
      "Iteration 21, loss = 892.64887871\n",
      "Iteration 5, loss = 1022.83246952\n",
      "Iteration 2, loss = 1674.86750591\n",
      "Iteration 10, loss = 878.90746257\n",
      "Iteration 69, loss = 797.73965067\n",
      "Iteration 14, loss = 944.96976182\n",
      "Iteration 501, loss = 927.06191987\n",
      "Iteration 22, loss = 912.51177486\n",
      "Iteration 495, loss = 903.17015726\n",
      "Iteration 3, loss = 1138.13138918\n",
      "Iteration 6, loss = 967.59795997\n",
      "Iteration 11, loss = 880.20911624\n",
      "Iteration 70, loss = 769.85444080\n",
      "Iteration 15, loss = 907.25691840\n",
      "Iteration 502, loss = 919.78034641\n",
      "Iteration 23, loss = 885.29568108\n",
      "Iteration 496, loss = 866.95946944\n",
      "Iteration 4, loss = 1035.93967549\n",
      "Iteration 71, loss = 785.70599589\n",
      "Iteration 7, loss = 941.24723801\n",
      "Iteration 12, loss = 871.25562986\n",
      "Iteration 16, loss = 915.32110014\n",
      "Iteration 24, loss = 848.80527602\n",
      "Iteration 503, loss = 923.32347688\n",
      "Iteration 5, loss = 985.38493501\n",
      "Iteration 497, loss = 894.28820198\n",
      "Iteration 72, loss = 784.04327111\n",
      "Iteration 8, loss = 915.71019561\n",
      "Iteration 13, loss = 866.89427643\n",
      "Iteration 17, loss = 893.87648139\n",
      "Iteration 25, loss = 872.03946095\n",
      "Iteration 6, loss = 923.73769361\n",
      "Iteration 504, loss = 924.51161744\n",
      "Iteration 498, loss = 882.67431087\n",
      "Iteration 73, loss = 786.21612500\n",
      "Iteration 14, loss = 873.31956038\n",
      "Iteration 9, loss = 895.02854022\n",
      "Iteration 18, loss = 833.68961121\n",
      "Iteration 26, loss = 932.12641745\n",
      "Iteration 7, loss = 885.92876297\n",
      "Iteration 15, loss = 865.21506948\n",
      "Iteration 74, loss = 827.20796139\n",
      "Iteration 10, loss = 876.86393325\n",
      "Iteration 505, loss = 908.46575044\n",
      "Iteration 499, loss = 906.69946820\n",
      "Iteration 19, loss = 850.05728297\n",
      "Iteration 27, loss = 863.08312839\n",
      "Iteration 8, loss = 869.88569507\n",
      "Iteration 75, loss = 776.22524117\n",
      "Iteration 16, loss = 834.55428301\n",
      "Iteration 11, loss = 879.76793703\n",
      "Iteration 20, loss = 882.59872483\n",
      "Iteration 500, loss = 889.36953454\n",
      "Iteration 506, loss = 937.21138114\n",
      "Iteration 28, loss = 878.95060749\n",
      "Iteration 9, loss = 854.62059828\n",
      "Iteration 76, loss = 784.96085009\n",
      "Iteration 17, loss = 852.77816168\n",
      "Iteration 12, loss = 873.82514762\n",
      "Iteration 21, loss = 837.08137334\n",
      "Iteration 10, loss = 835.55684446\n",
      "Iteration 501, loss = 885.61138728\n",
      "Iteration 29, loss = 870.42379819\n",
      "Iteration 507, loss = 919.63077899\n",
      "Iteration 77, loss = 809.78825663\n",
      "Iteration 13, loss = 861.82401264\n",
      "Iteration 18, loss = 846.76417910\n",
      "Iteration 22, loss = 894.90529959\n",
      "Iteration 11, loss = 841.44287499\n",
      "Iteration 30, loss = 855.00439163\n",
      "Iteration 502, loss = 883.61528714\n",
      "Iteration 508, loss = 929.32015505\n",
      "Iteration 78, loss = 784.57068854\n",
      "Iteration 14, loss = 865.76923316\n",
      "Iteration 19, loss = 852.88111843\n",
      "Iteration 23, loss = 837.41340509\n",
      "Iteration 12, loss = 817.29322493\n",
      "Iteration 31, loss = 864.31482847\n",
      "Iteration 503, loss = 884.80560254\n",
      "Iteration 79, loss = 808.37918843\n",
      "Iteration 15, loss = 864.19002958\n",
      "Iteration 509, loss = 930.33369151\n",
      "Iteration 20, loss = 848.26608035\n",
      "Iteration 24, loss = 794.09829324\n",
      "Iteration 13, loss = 821.81555905\n",
      "Iteration 32, loss = 820.74805494\n",
      "Iteration 80, loss = 800.25380015\n",
      "Iteration 504, loss = 868.53422239\n",
      "Iteration 16, loss = 837.18022777\n",
      "Iteration 21, loss = 850.21205162\n",
      "Iteration 14, loss = 815.50255296\n",
      "Iteration 25, loss = 818.42174125\n",
      "Iteration 510, loss = 917.62659338\n",
      "Iteration 33, loss = 854.45963047\n",
      "Iteration 81, loss = 773.05775086\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 847.27896841\n",
      "Iteration 15, loss = 813.87016290\n",
      "Iteration 505, loss = 870.78370715\n",
      "Iteration 26, loss = 884.37747058\n",
      "Iteration 22, loss = 834.70955757\n",
      "Iteration 34, loss = 834.61012758\n",
      "Iteration 511, loss = 917.60330957\n",
      "Iteration 1, loss = 6517.22435453\n",
      "Iteration 18, loss = 842.17682477\n",
      "Iteration 16, loss = 810.93699135\n",
      "Iteration 23, loss = 843.39890090\n",
      "Iteration 35, loss = 851.10617459\n",
      "Iteration 27, loss = 843.31186594\n",
      "Iteration 506, loss = 884.50255292\n",
      "Iteration 512, loss = 905.00451078\n",
      "Iteration 17, loss = 806.07472930\n",
      "Iteration 2, loss = 1749.59038282\n",
      "Iteration 19, loss = 841.20537896\n",
      "Iteration 24, loss = 840.26299175\n",
      "Iteration 36, loss = 814.00314407\n",
      "Iteration 28, loss = 823.81805257\n",
      "Iteration 507, loss = 881.03779967\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 801.55024374\n",
      "Iteration 3, loss = 1195.60622191\n",
      "Iteration 20, loss = 846.14286988\n",
      "Iteration 513, loss = 922.17952488\n",
      "Iteration 25, loss = 835.02617348\n",
      "Iteration 37, loss = 848.55690040\n",
      "Iteration 29, loss = 830.41703717\n",
      "Iteration 19, loss = 800.16042026\n",
      "Iteration 1, loss = 6468.21852886\n",
      "Iteration 4, loss = 1086.51122124\n",
      "Iteration 21, loss = 842.88050771\n",
      "Iteration 38, loss = 814.82614428\n",
      "Iteration 514, loss = 911.11888497\n",
      "Iteration 26, loss = 828.03309118\n",
      "Iteration 30, loss = 804.94894251\n",
      "Iteration 20, loss = 798.17921432\n",
      "Iteration 2, loss = 1702.10704567\n",
      "Iteration 5, loss = 1013.74295754\n",
      "Iteration 22, loss = 829.31586606\n",
      "Iteration 39, loss = 846.58006423\n",
      "Iteration 31, loss = 820.84771597\n",
      "Iteration 27, loss = 837.74004999\n",
      "Iteration 515, loss = 927.92275462\n",
      "Iteration 21, loss = 796.66503227\n",
      "Iteration 3, loss = 1134.05706537\n",
      "Iteration 6, loss = 963.72213363\n",
      "Iteration 23, loss = 832.28151702\n",
      "Iteration 32, loss = 810.55625412\n",
      "Iteration 40, loss = 829.28446228\n",
      "Iteration 28, loss = 827.90545264\n",
      "Iteration 516, loss = 926.02344195\n",
      "Iteration 22, loss = 792.95452376\n",
      "Iteration 4, loss = 1041.87063646\n",
      "Iteration 7, loss = 921.45010815\n",
      "Iteration 24, loss = 832.61584361\n",
      "Iteration 41, loss = 833.31455586\n",
      "Iteration 33, loss = 859.09493062\n",
      "Iteration 29, loss = 835.17446381\n",
      "Iteration 23, loss = 796.55141672\n",
      "Iteration 5, loss = 984.60999665\n",
      "Iteration 517, loss = 931.63631968\n",
      "Iteration 8, loss = 904.90736539\n",
      "Iteration 25, loss = 825.43782990\n",
      "Iteration 42, loss = 822.14781681\n",
      "Iteration 34, loss = 816.77457695\n",
      "Iteration 30, loss = 826.52468746\n",
      "Iteration 6, loss = 937.86348799\n",
      "Iteration 24, loss = 789.84633938\n",
      "Iteration 9, loss = 886.46978735\n",
      "Iteration 518, loss = 907.75225862\n",
      "Iteration 26, loss = 825.11115159\n",
      "Iteration 43, loss = 840.21901955\n",
      "Iteration 35, loss = 817.79909892\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 31, loss = 827.44499723\n",
      "Iteration 7, loss = 897.21752311\n",
      "Iteration 25, loss = 790.89797307\n",
      "Iteration 10, loss = 876.56281882\n",
      "Iteration 27, loss = 830.16729592\n",
      "Iteration 44, loss = 833.89100170\n",
      "Iteration 519, loss = 921.17986065\n",
      "Iteration 32, loss = 829.81084143\n",
      "Iteration 1, loss = 6564.56035493\n",
      "Iteration 8, loss = 879.32020556\n",
      "Iteration 26, loss = 792.66400437\n",
      "Iteration 11, loss = 877.35509121\n",
      "Iteration 28, loss = 821.96736986\n",
      "Iteration 45, loss = 813.10173866\n",
      "Iteration 33, loss = 823.41016973\n",
      "Iteration 2, loss = 1839.21576171\n",
      "Iteration 520, loss = 903.47222939\n",
      "Iteration 9, loss = 854.51069760\n",
      "Iteration 27, loss = 780.40406067\n",
      "Iteration 12, loss = 853.81098939\n",
      "Iteration 46, loss = 826.05781796\n",
      "Iteration 29, loss = 826.01504193\n",
      "Iteration 34, loss = 813.56275344\n",
      "Iteration 3, loss = 1198.80099913\n",
      "Iteration 521, loss = 905.16058142\n",
      "Iteration 10, loss = 850.61958400\n",
      "Iteration 28, loss = 778.41615953\n",
      "Iteration 13, loss = 860.83668280\n",
      "Iteration 30, loss = 826.11078486\n",
      "Iteration 47, loss = 813.92649669\n",
      "Iteration 35, loss = 831.32759472\n",
      "Iteration 4, loss = 1095.60870789\n",
      "Iteration 11, loss = 841.07060295\n",
      "Iteration 29, loss = 778.62647005\n",
      "Iteration 522, loss = 888.90956415\n",
      "Iteration 14, loss = 852.54008396\n",
      "Iteration 31, loss = 822.66705753\n",
      "Iteration 48, loss = 804.27650662\n",
      "Iteration 36, loss = 815.54980062\n",
      "Iteration 12, loss = 830.78749291\n",
      "Iteration 30, loss = 802.04169326\n",
      "Iteration 5, loss = 1026.76405158\n",
      "Iteration 15, loss = 849.08086779\n",
      "Iteration 523, loss = 895.68114124\n",
      "Iteration 32, loss = 817.56862462\n",
      "Iteration 49, loss = 801.70558209\n",
      "Iteration 37, loss = 828.41121277\n",
      "Iteration 13, loss = 823.45019997\n",
      "Iteration 31, loss = 784.28685528\n",
      "Iteration 6, loss = 979.50100976\n",
      "Iteration 16, loss = 846.98497225\n",
      "Iteration 524, loss = 929.82582969\n",
      "Iteration 50, loss = 825.45399497\n",
      "Iteration 33, loss = 820.61075551\n",
      "Iteration 38, loss = 816.81144538\n",
      "Iteration 32, loss = 788.18511898\n",
      "Iteration 14, loss = 823.46650277\n",
      "Iteration 7, loss = 918.72846661\n",
      "Iteration 17, loss = 838.16919362\n",
      "Iteration 51, loss = 786.40272679\n",
      "Iteration 34, loss = 808.39462548\n",
      "Iteration 39, loss = 839.51765944\n",
      "Iteration 33, loss = 799.75309095\n",
      "Iteration 525, loss = 900.13029367\n",
      "Iteration 15, loss = 827.14360664\n",
      "Iteration 8, loss = 907.60642330\n",
      "Iteration 18, loss = 837.94036026\n",
      "Iteration 52, loss = 840.50317168\n",
      "Iteration 35, loss = 822.51448398\n",
      "Iteration 40, loss = 820.64637174\n",
      "Iteration 34, loss = 776.93292209\n",
      "Iteration 16, loss = 820.35456966\n",
      "Iteration 9, loss = 886.58730484\n",
      "Iteration 526, loss = 884.68514968\n",
      "Iteration 19, loss = 836.31636187\n",
      "Iteration 53, loss = 794.66122260\n",
      "Iteration 36, loss = 801.37161278\n",
      "Iteration 35, loss = 780.54997478\n",
      "Iteration 17, loss = 804.81446721\n",
      "Iteration 41, loss = 816.68933807\n",
      "Iteration 10, loss = 868.73518107\n",
      "Iteration 527, loss = 903.19854085\n",
      "Iteration 20, loss = 842.99248428\n",
      "Iteration 54, loss = 850.90773317\n",
      "Iteration 37, loss = 820.47618643\n",
      "Iteration 36, loss = 763.79994905\n",
      "Iteration 18, loss = 809.00594451\n",
      "Iteration 42, loss = 811.63019247\n",
      "Iteration 11, loss = 877.03007834\n",
      "Iteration 55, loss = 798.19828219\n",
      "Iteration 21, loss = 830.67763302\n",
      "Iteration 38, loss = 809.62857969\n",
      "Iteration 528, loss = 951.12237090\n",
      "Iteration 37, loss = 774.48949752\n",
      "Iteration 19, loss = 808.61609970\n",
      "Iteration 43, loss = 825.80010513\n",
      "Iteration 12, loss = 862.89313875\n",
      "Iteration 56, loss = 805.37987812\n",
      "Iteration 22, loss = 834.20633968\n",
      "Iteration 38, loss = 766.83317946\n",
      "Iteration 39, loss = 824.23764216\n",
      "Iteration 20, loss = 815.89667746\n",
      "Iteration 529, loss = 902.46094694\n",
      "Iteration 44, loss = 814.04116143\n",
      "Iteration 13, loss = 853.12023482\n",
      "Iteration 57, loss = 821.64779571\n",
      "Iteration 23, loss = 834.15476916\n",
      "Iteration 39, loss = 779.77019840\n",
      "Iteration 40, loss = 814.53270837\n",
      "Iteration 21, loss = 812.25315224\n",
      "Iteration 45, loss = 816.67895340\n",
      "Iteration 530, loss = 902.98304110\n",
      "Iteration 14, loss = 850.75374604\n",
      "Iteration 24, loss = 821.82284484\n",
      "Iteration 40, loss = 780.03536921\n",
      "Iteration 58, loss = 800.23235091\n",
      "Iteration 41, loss = 812.50780408\n",
      "Iteration 22, loss = 803.69663258\n",
      "Iteration 46, loss = 810.55027706\n",
      "Iteration 15, loss = 857.78225643\n",
      "Iteration 531, loss = 891.49938616\n",
      "Iteration 25, loss = 828.34437959\n",
      "Iteration 59, loss = 813.00383199\n",
      "Iteration 41, loss = 766.08651331\n",
      "Iteration 42, loss = 802.05567392\n",
      "Iteration 23, loss = 811.34711548\n",
      "Iteration 47, loss = 810.45069987\n",
      "Iteration 16, loss = 854.88875409\n",
      "Iteration 26, loss = 837.94075294\n",
      "Iteration 42, loss = 766.65884409\n",
      "Iteration 60, loss = 798.63910155\n",
      "Iteration 532, loss = 885.22446428\n",
      "Iteration 43, loss = 818.56932385\n",
      "Iteration 24, loss = 794.42997153\n",
      "Iteration 48, loss = 818.88967975\n",
      "Iteration 27, loss = 817.18977449\n",
      "Iteration 17, loss = 832.79876360\n",
      "Iteration 43, loss = 771.67433284\n",
      "Iteration 61, loss = 829.59310623\n",
      "Iteration 44, loss = 803.37429955\n",
      "Iteration 25, loss = 794.58945228\n",
      "Iteration 533, loss = 896.09633592\n",
      "Iteration 49, loss = 802.17576309\n",
      "Iteration 18, loss = 831.20912484\n",
      "Iteration 44, loss = 758.05420356\n",
      "Iteration 28, loss = 821.64873589\n",
      "Iteration 62, loss = 804.83150695\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 804.08289107\n",
      "Iteration 45, loss = 810.00828742\n",
      "Iteration 534, loss = 892.09876552\n",
      "Iteration 50, loss = 809.44167044\n",
      "Iteration 45, loss = 771.41234847\n",
      "Iteration 29, loss = 817.30261983\n",
      "Iteration 19, loss = 835.01668122\n",
      "Iteration 27, loss = 788.82009585\n",
      "Iteration 46, loss = 804.29931542\n",
      "Iteration 1, loss = 6588.75240698\n",
      "Iteration 535, loss = 883.01203930\n",
      "Iteration 51, loss = 823.01653754\n",
      "Iteration 46, loss = 762.95704458\n",
      "Iteration 30, loss = 833.15019014\n",
      "Iteration 20, loss = 845.75590345\n",
      "Iteration 28, loss = 797.46834955\n",
      "Iteration 47, loss = 798.28241895\n",
      "Iteration 2, loss = 1873.68672166\n",
      "Iteration 52, loss = 811.35401122\n",
      "Iteration 47, loss = 758.66640160\n",
      "Iteration 31, loss = 818.23523421\n",
      "Iteration 536, loss = 891.07082005\n",
      "Iteration 21, loss = 835.29474213\n",
      "Iteration 29, loss = 792.03259645\n",
      "Iteration 48, loss = 809.19725923\n",
      "Iteration 3, loss = 1222.14881327\n",
      "Iteration 48, loss = 771.46541317\n",
      "Iteration 53, loss = 808.51950020\n",
      "Iteration 32, loss = 820.83787567\n",
      "Iteration 22, loss = 840.39374968\n",
      "Iteration 537, loss = 902.83460664\n",
      "Iteration 30, loss = 797.30765948\n",
      "Iteration 49, loss = 792.14674444\n",
      "Iteration 49, loss = 760.66864679\n",
      "Iteration 4, loss = 1114.86433340\n",
      "Iteration 54, loss = 807.06763325\n",
      "Iteration 33, loss = 832.78944832\n",
      "Iteration 23, loss = 843.79927421\n",
      "Iteration 31, loss = 775.63186318\n",
      "Iteration 538, loss = 899.11865308\n",
      "Iteration 50, loss = 795.52425022\n",
      "Iteration 5, loss = 1041.00964698\n",
      "Iteration 50, loss = 763.14228647\n",
      "Iteration 55, loss = 808.73492789\n",
      "Iteration 34, loss = 817.46009488\n",
      "Iteration 24, loss = 819.54090335\n",
      "Iteration 32, loss = 782.21962355\n",
      "Iteration 51, loss = 752.86067374\n",
      "Iteration 51, loss = 816.46394916\n",
      "Iteration 6, loss = 993.19859309\n",
      "Iteration 539, loss = 918.12512640\n",
      "Iteration 56, loss = 808.27130471\n",
      "Iteration 35, loss = 825.37452593\n",
      "Iteration 25, loss = 820.08744837\n",
      "Iteration 33, loss = 789.50382740\n",
      "Iteration 52, loss = 768.09302775\n",
      "Iteration 52, loss = 804.76786280\n",
      "Iteration 7, loss = 928.99824887\n",
      "Iteration 57, loss = 807.95852080\n",
      "Iteration 540, loss = 894.67649707\n",
      "Iteration 36, loss = 807.43927320\n",
      "Iteration 26, loss = 837.42000093\n",
      "Iteration 34, loss = 780.84672075\n",
      "Iteration 53, loss = 755.94949168\n",
      "Iteration 53, loss = 796.19571691\n",
      "Iteration 8, loss = 919.62360244\n",
      "Iteration 58, loss = 805.69733651\n",
      "Iteration 37, loss = 818.14395751\n",
      "Iteration 541, loss = 883.62990086\n",
      "Iteration 54, loss = 760.09882465\n",
      "Iteration 27, loss = 810.70694902\n",
      "Iteration 35, loss = 803.99980503\n",
      "Iteration 54, loss = 800.24744729\n",
      "Iteration 9, loss = 894.61848834\n",
      "Iteration 59, loss = 803.07043006\n",
      "Iteration 38, loss = 798.76755243\n",
      "Iteration 55, loss = 762.06797789\n",
      "Iteration 36, loss = 769.38869233\n",
      "Iteration 28, loss = 828.56915447\n",
      "Iteration 542, loss = 893.97295431\n",
      "Iteration 55, loss = 801.64575188\n",
      "Iteration 10, loss = 880.87257046\n",
      "Iteration 60, loss = 810.70877910\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 39, loss = 813.59243523\n",
      "Iteration 56, loss = 761.52186144\n",
      "Iteration 37, loss = 784.01505510\n",
      "Iteration 29, loss = 815.90735735\n",
      "Iteration 56, loss = 795.68034462\n",
      "Iteration 543, loss = 887.30788809\n",
      "Iteration 11, loss = 881.63136722\n",
      "Iteration 57, loss = 762.07572798\n",
      "Iteration 40, loss = 818.48938276\n",
      "Iteration 1, loss = 6583.59318393\n",
      "Iteration 38, loss = 756.15487301\n",
      "Iteration 30, loss = 823.63234503\n",
      "Iteration 12, loss = 873.42510741\n",
      "Iteration 57, loss = 794.79748647\n",
      "Iteration 544, loss = 884.83839345\n",
      "Iteration 41, loss = 809.74524727\n",
      "Iteration 58, loss = 757.55205211\n",
      "Iteration 2, loss = 1931.98461113\n",
      "Iteration 31, loss = 805.41790472\n",
      "Iteration 39, loss = 777.99049843\n",
      "Iteration 58, loss = 792.62253200\n",
      "Iteration 13, loss = 861.63782866\n",
      "Iteration 59, loss = 752.23558606\n",
      "Iteration 42, loss = 806.02800646\n",
      "Iteration 545, loss = 884.23333638\n",
      "Iteration 3, loss = 1237.95656493\n",
      "Iteration 32, loss = 819.40577591\n",
      "Iteration 40, loss = 787.74594053\n",
      "Iteration 59, loss = 788.02257691\n",
      "Iteration 14, loss = 863.03328448\n",
      "Iteration 60, loss = 755.50391058\n",
      "Iteration 43, loss = 808.61267698\n",
      "Iteration 4, loss = 1125.23812354\n",
      "Iteration 41, loss = 775.61603780\n",
      "Iteration 546, loss = 882.29401598\n",
      "Iteration 33, loss = 816.50748460\n",
      "Iteration 15, loss = 864.46373067\n",
      "Iteration 60, loss = 798.87953162\n",
      "Iteration 61, loss = 757.84447383\n",
      "Iteration 44, loss = 798.67664390\n",
      "Iteration 5, loss = 1053.83850856\n",
      "Iteration 42, loss = 775.84858197\n",
      "Iteration 34, loss = 809.19238464\n",
      "Iteration 547, loss = 898.49784464\n",
      "Iteration 16, loss = 856.64964021\n",
      "Iteration 61, loss = 790.49708215\n",
      "Iteration 62, loss = 758.58582070\n",
      "Iteration 45, loss = 810.16753104\n",
      "Iteration 6, loss = 1001.81255261\n",
      "Iteration 43, loss = 776.70642029\n",
      "Iteration 35, loss = 824.99855626\n",
      "Iteration 17, loss = 841.96795286\n",
      "Iteration 548, loss = 889.56590014\n",
      "Iteration 62, loss = 796.00552277\n",
      "Iteration 63, loss = 763.28127273\n",
      "Iteration 46, loss = 797.94746356\n",
      "Iteration 7, loss = 943.13187938\n",
      "Iteration 44, loss = 768.33787858\n",
      "Iteration 36, loss = 793.75600643\n",
      "Iteration 18, loss = 837.45505172\n",
      "Iteration 63, loss = 780.45838716\n",
      "Iteration 64, loss = 752.21881713\n",
      "Iteration 549, loss = 888.66253968\n",
      "Iteration 47, loss = 800.83266464\n",
      "Iteration 8, loss = 932.32280173\n",
      "Iteration 45, loss = 785.68438575\n",
      "Iteration 37, loss = 814.38736318\n",
      "Iteration 19, loss = 844.78479075\n",
      "Iteration 65, loss = 751.63233779\n",
      "Iteration 64, loss = 797.53573523\n",
      "Iteration 550, loss = 885.68341122\n",
      "Iteration 48, loss = 813.30020852\n",
      "Iteration 9, loss = 903.06650381\n",
      "Iteration 46, loss = 769.15152710\n",
      "Iteration 38, loss = 788.22347115\n",
      "Iteration 20, loss = 858.03426382\n",
      "Iteration 66, loss = 749.46645551\n",
      "Iteration 65, loss = 789.19817849\n",
      "Iteration 49, loss = 793.62062621\n",
      "Iteration 10, loss = 891.26068320\n",
      "Iteration 47, loss = 772.16959047\n",
      "Iteration 551, loss = 895.84746764\n",
      "Iteration 39, loss = 806.43730034\n",
      "Iteration 21, loss = 840.34715047\n",
      "Iteration 67, loss = 749.44402709\n",
      "Iteration 66, loss = 788.32134127\n",
      "Iteration 50, loss = 812.75812999\n",
      "Iteration 11, loss = 884.63703703\n",
      "Iteration 48, loss = 782.59672151\n",
      "Iteration 552, loss = 887.57571400\n",
      "Iteration 40, loss = 805.77234177\n",
      "Iteration 22, loss = 846.73452453\n",
      "Iteration 68, loss = 742.93121997\n",
      "Iteration 67, loss = 797.19591638\n",
      "Iteration 12, loss = 889.50075389\n",
      "Iteration 51, loss = 793.93293344\n",
      "Iteration 49, loss = 763.19597032\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 41, loss = 808.66218288\n",
      "Iteration 23, loss = 841.85851336\n",
      "Iteration 69, loss = 752.43923949\n",
      "Iteration 553, loss = 874.48403313\n",
      "Iteration 68, loss = 779.97958293\n",
      "Iteration 13, loss = 873.43457793\n",
      "Iteration 52, loss = 806.88683044\n",
      "Iteration 1, loss = 6624.52835317\n",
      "Iteration 24, loss = 827.55009421\n",
      "Iteration 70, loss = 742.40049046\n",
      "Iteration 42, loss = 806.38712664\n",
      "Iteration 554, loss = 901.87138479\n",
      "Iteration 69, loss = 770.65541238\n",
      "Iteration 14, loss = 871.85480141\n",
      "Iteration 53, loss = 798.00384516\n",
      "Iteration 2, loss = 1860.89001602\n",
      "Iteration 71, loss = 747.22114175\n",
      "Iteration 25, loss = 826.30463610\n",
      "Iteration 43, loss = 806.40561851\n",
      "Iteration 70, loss = 788.59636451\n",
      "Iteration 555, loss = 868.79050847\n",
      "Iteration 54, loss = 805.68984576\n",
      "Iteration 15, loss = 877.53776384\n",
      "Iteration 3, loss = 1207.80869301\n",
      "Iteration 72, loss = 748.59598955\n",
      "Iteration 26, loss = 842.81225809\n",
      "Iteration 44, loss = 793.03298322\n",
      "Iteration 71, loss = 785.99453552\n",
      "Iteration 556, loss = 900.54495296\n",
      "Iteration 4, loss = 1102.83683463\n",
      "Iteration 55, loss = 800.73808036\n",
      "Iteration 16, loss = 864.88463759\n",
      "Iteration 73, loss = 743.49930567\n",
      "Iteration 27, loss = 828.80909748\n",
      "Iteration 45, loss = 813.66197840\n",
      "Iteration 72, loss = 783.37672079\n",
      "Iteration 5, loss = 1030.22982366\n",
      "Iteration 56, loss = 799.16236653Iteration 17, loss = 858.13232076\n",
      "\n",
      "Iteration 74, loss = 755.74663063\n",
      "Iteration 557, loss = 878.71681330\n",
      "Iteration 28, loss = 834.01764619\n",
      "Iteration 46, loss = 796.26959669\n",
      "Iteration 73, loss = 775.94882273\n",
      "Iteration 75, loss = 742.80249446\n",
      "Iteration 57, loss = 797.05088801\n",
      "Iteration 6, loss = 970.60811164\n",
      "Iteration 18, loss = 844.56232096\n",
      "Iteration 29, loss = 831.90907220\n",
      "Iteration 558, loss = 900.64758837\n",
      "Iteration 47, loss = 807.52329594\n",
      "Iteration 74, loss = 788.39893612\n",
      "Iteration 76, loss = 750.17500049\n",
      "Iteration 58, loss = 795.61680356\n",
      "Iteration 7, loss = 928.35111525\n",
      "Iteration 19, loss = 849.11439968\n",
      "Iteration 30, loss = 827.05514445\n",
      "Iteration 48, loss = 815.55631725\n",
      "Iteration 559, loss = 886.95226700\n",
      "Iteration 75, loss = 788.11956985\n",
      "Iteration 77, loss = 753.28530368\n",
      "Iteration 59, loss = 785.74821998\n",
      "Iteration 8, loss = 914.62498529\n",
      "Iteration 31, loss = 817.64668201\n",
      "Iteration 20, loss = 867.64284388\n",
      "Iteration 49, loss = 792.40993636\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 560, loss = 869.57207347\n",
      "Iteration 78, loss = 749.52408467\n",
      "Iteration 76, loss = 777.21908688\n",
      "Iteration 60, loss = 793.82348214\n",
      "Iteration 9, loss = 886.54904708\n",
      "Iteration 21, loss = 848.50082960\n",
      "Iteration 32, loss = 821.41748622\n",
      "Iteration 1, loss = 6589.83702037\n",
      "Iteration 561, loss = 883.45205384\n",
      "Iteration 79, loss = 744.67341813\n",
      "Iteration 61, loss = 796.29565090\n",
      "Iteration 10, loss = 871.49460448\n",
      "Iteration 77, loss = 782.71027667\n",
      "Iteration 22, loss = 857.72157223\n",
      "Iteration 33, loss = 823.46601516\n",
      "Iteration 2, loss = 1807.03960848\n",
      "Iteration 80, loss = 749.83693369\n",
      "Iteration 11, loss = 867.72817255\n",
      "Iteration 62, loss = 795.76733067\n",
      "Iteration 78, loss = 780.64142886\n",
      "Iteration 562, loss = 880.65827712\n",
      "Iteration 23, loss = 851.27588229\n",
      "Iteration 34, loss = 813.03771656\n",
      "Iteration 3, loss = 1148.45499279\n",
      "Iteration 81, loss = 741.17820882\n",
      "Iteration 12, loss = 876.74741291\n",
      "Iteration 79, loss = 792.62550245\n",
      "Iteration 63, loss = 805.54541968\n",
      "Iteration 24, loss = 837.47636072\n",
      "Iteration 35, loss = 822.82507400\n",
      "Iteration 563, loss = 865.35891657\n",
      "Iteration 82, loss = 747.25670405\n",
      "Iteration 4, loss = 1057.16719218\n",
      "Iteration 13, loss = 857.50375040\n",
      "Iteration 80, loss = 785.00230143\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 799.89935452\n",
      "Iteration 25, loss = 839.21700990\n",
      "Iteration 64, loss = 797.58995214\n",
      "Iteration 564, loss = 872.86156783\n",
      "Iteration 83, loss = 741.14737417\n",
      "Iteration 14, loss = 859.64532193\n",
      "Iteration 5, loss = 975.73122502\n",
      "Iteration 37, loss = 818.26365570\n",
      "Iteration 26, loss = 850.33526926\n",
      "Iteration 65, loss = 792.54810646\n",
      "Iteration 84, loss = 741.60533652\n",
      "Iteration 565, loss = 881.63547253\n",
      "Iteration 15, loss = 861.29497307\n",
      "Iteration 6, loss = 923.34876416\n",
      "Iteration 38, loss = 796.72453003\n",
      "Iteration 27, loss = 834.88830010\n",
      "Iteration 66, loss = 788.98148848\n",
      "Iteration 85, loss = 743.49298063\n",
      "Iteration 16, loss = 850.72676146\n",
      "Iteration 566, loss = 873.29440815\n",
      "Iteration 7, loss = 890.76890343\n",
      "Iteration 39, loss = 811.68517520\n",
      "Iteration 28, loss = 837.32334763\n",
      "Iteration 67, loss = 782.42292043\n",
      "Iteration 86, loss = 737.94262905\n",
      "Iteration 17, loss = 835.43427535\n",
      "Iteration 8, loss = 875.41630216\n",
      "Iteration 40, loss = 811.52576774\n",
      "Iteration 567, loss = 883.42862676\n",
      "Iteration 29, loss = 848.17192400\n",
      "Iteration 68, loss = 785.89927845\n",
      "Iteration 87, loss = 740.63627626\n",
      "Iteration 18, loss = 826.19452189\n",
      "Iteration 9, loss = 851.50652028\n",
      "Iteration 41, loss = 820.38216746\n",
      "Iteration 69, loss = 794.95033629\n",
      "Iteration 30, loss = 833.40380436\n",
      "Iteration 568, loss = 886.79952172\n",
      "Iteration 88, loss = 742.72066091\n",
      "Iteration 19, loss = 827.24563076\n",
      "Iteration 10, loss = 844.76712803\n",
      "Iteration 42, loss = 811.13559387\n",
      "Iteration 70, loss = 779.33338756\n",
      "Iteration 31, loss = 833.15115285\n",
      "Iteration 89, loss = 739.46731768\n",
      "Iteration 569, loss = 875.59814976\n",
      "Iteration 20, loss = 860.75754018\n",
      "Iteration 43, loss = 815.14563130\n",
      "Iteration 11, loss = 835.79747835\n",
      "Iteration 71, loss = 791.07557062\n",
      "Iteration 32, loss = 826.04880899\n",
      "Iteration 90, loss = 745.88797497\n",
      "Iteration 570, loss = 890.23410172\n",
      "Iteration 21, loss = 827.13177883\n",
      "Iteration 44, loss = 806.87107937\n",
      "Iteration 12, loss = 838.44301433\n",
      "Iteration 72, loss = 787.37112918\n",
      "Iteration 33, loss = 836.48830016\n",
      "Iteration 91, loss = 736.70566477\n",
      "Iteration 22, loss = 837.12058641\n",
      "Iteration 571, loss = 864.30511566\n",
      "Iteration 45, loss = 812.79323457\n",
      "Iteration 13, loss = 820.93718311\n",
      "Iteration 73, loss = 793.25305030\n",
      "Iteration 34, loss = 825.53723261\n",
      "Iteration 92, loss = 737.06046284\n",
      "Iteration 23, loss = 830.99631750\n",
      "Iteration 46, loss = 801.45381960\n",
      "Iteration 572, loss = 869.69897064\n",
      "Iteration 93, loss = 745.28672694\n",
      "Iteration 14, loss = 829.85544059\n",
      "Iteration 74, loss = 800.06956470\n",
      "Iteration 35, loss = 830.11826264\n",
      "Iteration 24, loss = 820.66649942\n",
      "Iteration 47, loss = 807.36838127\n",
      "Iteration 94, loss = 738.53542545\n",
      "Iteration 573, loss = 853.53693504\n",
      "Iteration 15, loss = 823.45693744\n",
      "Iteration 75, loss = 778.23324245\n",
      "Iteration 36, loss = 808.34437796\n",
      "Iteration 25, loss = 822.78656273\n",
      "Iteration 48, loss = 813.87613946\n",
      "Iteration 95, loss = 734.18792526\n",
      "Iteration 76, loss = 788.73735386\n",
      "Iteration 574, loss = 866.58453097\n",
      "Iteration 16, loss = 818.39445207\n",
      "Iteration 37, loss = 829.59595482\n",
      "Iteration 26, loss = 834.36211278\n",
      "Iteration 49, loss = 792.56055817\n",
      "Iteration 96, loss = 738.34441710\n",
      "Iteration 77, loss = 799.95044403\n",
      "Iteration 17, loss = 807.15038296\n",
      "Iteration 575, loss = 866.65905826\n",
      "Iteration 38, loss = 807.02689938\n",
      "Iteration 27, loss = 824.19941440\n",
      "Iteration 50, loss = 814.76545636\n",
      "Iteration 97, loss = 743.70221487\n",
      "Iteration 78, loss = 793.62536915\n",
      "Iteration 39, loss = 825.43057172\n",
      "Iteration 18, loss = 794.06332712\n",
      "Iteration 28, loss = 820.50865163\n",
      "Iteration 576, loss = 866.99910590\n",
      "Iteration 51, loss = 802.95051486\n",
      "Iteration 98, loss = 734.77445599\n",
      "Iteration 79, loss = 790.59574271\n",
      "Iteration 40, loss = 822.20905510\n",
      "Iteration 19, loss = 796.52835665\n",
      "Iteration 29, loss = 832.45787105\n",
      "Iteration 52, loss = 813.97360028\n",
      "Iteration 577, loss = 878.00751288\n",
      "Iteration 99, loss = 735.81847233\n",
      "Iteration 80, loss = 792.76941712\n",
      "Iteration 41, loss = 828.46969789\n",
      "Iteration 30, loss = 811.46042733\n",
      "Iteration 20, loss = 814.83467015\n",
      "Iteration 53, loss = 794.15266783\n",
      "Iteration 100, loss = 745.80362286\n",
      "Iteration 578, loss = 885.83868940\n",
      "Iteration 81, loss = 782.64992999\n",
      "Iteration 42, loss = 819.73293718\n",
      "Iteration 31, loss = 813.75865644\n",
      "Iteration 21, loss = 792.79411463\n",
      "Iteration 54, loss = 807.53873199\n",
      "Iteration 101, loss = 744.65389043\n",
      "Iteration 82, loss = 798.14015660\n",
      "Iteration 579, loss = 860.30360709\n",
      "Iteration 32, loss = 805.40499079\n",
      "Iteration 43, loss = 825.91346489\n",
      "Iteration 22, loss = 810.79649553\n",
      "Iteration 55, loss = 785.78452708\n",
      "Iteration 102, loss = 739.15496150\n",
      "Iteration 83, loss = 782.06247682\n",
      "Iteration 580, loss = 878.35749595\n",
      "Iteration 33, loss = 816.76135424\n",
      "Iteration 44, loss = 823.56161567\n",
      "Iteration 23, loss = 801.70265534\n",
      "Iteration 56, loss = 805.10294923\n",
      "Iteration 103, loss = 737.54661129\n",
      "Iteration 84, loss = 784.64951000\n",
      "Iteration 34, loss = 808.03475971\n",
      "Iteration 581, loss = 870.23573785\n",
      "Iteration 24, loss = 782.97706027\n",
      "Iteration 45, loss = 824.23832988\n",
      "Iteration 57, loss = 801.47891920\n",
      "Iteration 104, loss = 743.47823867\n",
      "Iteration 85, loss = 786.83967481\n",
      "Iteration 35, loss = 813.63778772\n",
      "Iteration 46, loss = 812.59588029\n",
      "Iteration 58, loss = 798.27614696\n",
      "Iteration 105, loss = 732.07585181\n",
      "Iteration 25, loss = 784.34328145\n",
      "Iteration 582, loss = 870.51155098\n",
      "Iteration 86, loss = 783.06768523\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 793.22587898\n",
      "Iteration 106, loss = 729.29090964\n",
      "Iteration 59, loss = 793.85091563\n",
      "Iteration 47, loss = 813.07213866\n",
      "Iteration 26, loss = 803.60056028\n",
      "Iteration 583, loss = 869.86117584\n",
      "Iteration 37, loss = 808.68404255\n",
      "Iteration 107, loss = 731.03148401\n",
      "Iteration 60, loss = 790.37890001\n",
      "Iteration 48, loss = 815.48832851\n",
      "Iteration 27, loss = 792.40369338\n",
      "Iteration 584, loss = 870.00431689\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 790.78080395\n",
      "Iteration 108, loss = 736.83297926\n",
      "Iteration 61, loss = 800.91602536\n",
      "Iteration 49, loss = 803.01850725\n",
      "Iteration 28, loss = 785.93304040\n",
      "Iteration 39, loss = 800.43917836\n",
      "Iteration 109, loss = 741.51208557\n",
      "Iteration 62, loss = 793.97948606\n",
      "Iteration 50, loss = 822.84746784\n",
      "Iteration 29, loss = 798.96296039\n",
      "Iteration 110, loss = 741.40468030\n",
      "Iteration 40, loss = 800.95861972\n",
      "Iteration 63, loss = 803.11243781\n",
      "Iteration 51, loss = 814.01107771\n",
      "Iteration 30, loss = 769.83867907\n",
      "Iteration 111, loss = 730.92682479\n",
      "Iteration 41, loss = 803.76980429\n",
      "Iteration 64, loss = 808.48312294\n",
      "Iteration 52, loss = 818.79813289\n",
      "Iteration 31, loss = 780.65665097\n",
      "Iteration 112, loss = 736.15947746\n",
      "Iteration 42, loss = 799.17304246\n",
      "Iteration 65, loss = 791.15206488\n",
      "Iteration 53, loss = 807.35527943\n",
      "Iteration 32, loss = 780.89863607\n",
      "Iteration 113, loss = 726.34060625\n",
      "Iteration 43, loss = 804.69118428\n",
      "Iteration 66, loss = 794.17040163\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 54, loss = 820.21293384\n",
      "Iteration 33, loss = 795.17929658\n",
      "Iteration 114, loss = 740.44605050\n",
      "Iteration 44, loss = 806.92304628\n",
      "Iteration 55, loss = 793.54555581\n",
      "Iteration 34, loss = 779.56701481\n",
      "Iteration 115, loss = 732.14129079\n",
      "Iteration 45, loss = 801.37150800\n",
      "Iteration 56, loss = 808.91562480\n",
      "Iteration 35, loss = 780.09835500\n",
      "Iteration 116, loss = 737.37152601\n",
      "Iteration 46, loss = 799.00101743\n",
      "Iteration 57, loss = 811.36865369\n",
      "Iteration 36, loss = 760.13842737\n",
      "Iteration 117, loss = 731.96472889\n",
      "Iteration 47, loss = 796.98736848\n",
      "Iteration 58, loss = 804.62589715\n",
      "Iteration 37, loss = 771.17692362\n",
      "Iteration 118, loss = 729.79991029\n",
      "Iteration 48, loss = 791.17498687\n",
      "Iteration 59, loss = 808.17640658\n",
      "Iteration 119, loss = 733.05610634\n",
      "Iteration 38, loss = 767.84306744\n",
      "Iteration 49, loss = 785.73751487\n",
      "Iteration 60, loss = 802.52543842\n",
      "Iteration 120, loss = 737.66534285\n",
      "Iteration 39, loss = 765.82565340\n",
      "Iteration 50, loss = 802.90741884\n",
      "Iteration 61, loss = 812.64675569\n",
      "Iteration 121, loss = 729.28742442\n",
      "Iteration 40, loss = 775.65122417\n",
      "Iteration 51, loss = 787.57443145\n",
      "Iteration 62, loss = 806.37112228\n",
      "Iteration 122, loss = 734.31974173\n",
      "Iteration 41, loss = 774.45664991\n",
      "Iteration 52, loss = 804.07399062\n",
      "Iteration 63, loss = 814.57328954\n",
      "Iteration 123, loss = 729.72280732\n",
      "Iteration 42, loss = 761.56895939\n",
      "Iteration 53, loss = 787.69300239\n",
      "Iteration 124, loss = 721.00470259\n",
      "Iteration 64, loss = 820.06074300\n",
      "Iteration 43, loss = 761.24888577\n",
      "Iteration 54, loss = 802.73420969\n",
      "Iteration 125, loss = 734.38431613\n",
      "Iteration 65, loss = 796.86592816\n",
      "Iteration 44, loss = 776.69344146\n",
      "Iteration 126, loss = 728.65120330\n",
      "Iteration 55, loss = 783.03335581\n",
      "Iteration 66, loss = 802.72116060\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 45, loss = 766.86484582\n",
      "Iteration 127, loss = 737.05456371\n",
      "Iteration 56, loss = 791.05083535\n",
      "Iteration 46, loss = 767.44621105\n",
      "Iteration 128, loss = 735.33791170\n",
      "Iteration 57, loss = 801.20471644\n",
      "Iteration 47, loss = 764.83480612\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 129, loss = 727.12308125\n",
      "Iteration 58, loss = 784.79328118\n",
      "Iteration 130, loss = 725.22351923\n",
      "Iteration 59, loss = 792.68868109\n",
      "Iteration 131, loss = 732.16386433\n",
      "Iteration 60, loss = 783.23211359\n",
      "Iteration 132, loss = 733.38759734\n",
      "Iteration 61, loss = 792.57018723\n",
      "Iteration 133, loss = 732.76224662\n",
      "Iteration 62, loss = 786.70256991\n",
      "Iteration 134, loss = 737.63459728\n",
      "Iteration 63, loss = 793.59879693\n",
      "Iteration 135, loss = 733.15682968\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 64, loss = 798.47270587\n",
      "Iteration 65, loss = 780.96247662\n",
      "Iteration 66, loss = 784.11124564\n",
      "Iteration 67, loss = 775.99278786\n",
      "Iteration 68, loss = 804.35571858\n",
      "Iteration 69, loss = 791.10260364\n",
      "Iteration 70, loss = 785.64532673\n",
      "Iteration 71, loss = 783.93540837\n",
      "Iteration 72, loss = 784.41867846\n",
      "Iteration 73, loss = 795.82506290\n",
      "Iteration 74, loss = 790.14024926\n",
      "Iteration 75, loss = 784.28200003\n",
      "Iteration 76, loss = 789.60214992\n",
      "Iteration 77, loss = 778.48499253\n",
      "Iteration 78, loss = 789.04020655\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 1, loss = 7907.36174814\n",
      "Iteration 2, loss = 4258.02078951\n",
      "Iteration 3, loss = 2683.12701078\n",
      "Iteration 4, loss = 1762.97258545\n",
      "Iteration 5, loss = 1434.36804956\n",
      "Iteration 6, loss = 1341.31026037\n",
      "Iteration 7, loss = 1306.10489927\n",
      "Iteration 8, loss = 1277.30902190\n",
      "Iteration 9, loss = 1247.51083672\n",
      "Iteration 10, loss = 1221.53169073\n",
      "Iteration 11, loss = 1191.31064929\n",
      "Iteration 12, loss = 1152.31439455\n",
      "Iteration 13, loss = 1118.67587505\n",
      "Iteration 14, loss = 1079.35467472\n",
      "Iteration 15, loss = 1056.94415369\n",
      "Iteration 16, loss = 1023.35592702\n",
      "Iteration 17, loss = 996.32269760\n",
      "Iteration 18, loss = 963.54261534\n",
      "Iteration 19, loss = 946.47792084\n",
      "Iteration 20, loss = 926.30610945\n",
      "Iteration 21, loss = 906.15171009\n",
      "Iteration 22, loss = 890.40394125\n",
      "Iteration 23, loss = 877.24250127\n",
      "Iteration 24, loss = 871.16478132\n",
      "Iteration 25, loss = 860.57649646\n",
      "Iteration 26, loss = 852.26505237\n",
      "Iteration 27, loss = 848.83704873\n",
      "Iteration 28, loss = 839.28203477\n",
      "Iteration 29, loss = 843.38792816\n",
      "Iteration 30, loss = 832.42539927\n",
      "Iteration 31, loss = 831.35725432\n",
      "Iteration 32, loss = 821.91040222\n",
      "Iteration 33, loss = 824.03855625\n",
      "Iteration 34, loss = 825.32906825\n",
      "Iteration 35, loss = 820.61886708\n",
      "Iteration 36, loss = 820.19078386\n",
      "Iteration 37, loss = 814.68366460\n",
      "Iteration 38, loss = 811.35569690\n",
      "Iteration 39, loss = 810.38955082\n",
      "Iteration 40, loss = 806.02920046\n",
      "Iteration 41, loss = 809.40395052\n",
      "Iteration 42, loss = 802.65707819\n",
      "Iteration 43, loss = 804.40586172\n",
      "Iteration 44, loss = 801.13332366\n",
      "Iteration 45, loss = 809.46198642\n",
      "Iteration 46, loss = 800.01610684\n",
      "Iteration 47, loss = 796.58051908\n",
      "Iteration 48, loss = 796.24446164\n",
      "Iteration 49, loss = 792.71452079\n",
      "Iteration 50, loss = 793.13929584\n",
      "Iteration 51, loss = 797.35387300\n",
      "Iteration 52, loss = 788.37571317\n",
      "Iteration 53, loss = 792.13782343\n",
      "Iteration 54, loss = 792.31224158\n",
      "Iteration 55, loss = 786.86873690\n",
      "Iteration 56, loss = 791.23510769\n",
      "Iteration 57, loss = 786.87451008\n",
      "Iteration 58, loss = 790.02705577\n",
      "Iteration 59, loss = 782.89533040\n",
      "Iteration 60, loss = 789.53662444\n",
      "Iteration 61, loss = 778.74246694\n",
      "Iteration 62, loss = 783.59576526\n",
      "Iteration 63, loss = 781.34410181\n",
      "Iteration 64, loss = 782.58481448\n",
      "Iteration 65, loss = 785.99499776\n",
      "Iteration 66, loss = 786.76903082\n",
      "Iteration 67, loss = 778.94637451\n",
      "Iteration 68, loss = 778.14741443\n",
      "Iteration 69, loss = 774.79615828\n",
      "Iteration 70, loss = 775.31405868\n",
      "Iteration 71, loss = 777.82822220\n",
      "Iteration 72, loss = 775.57382556\n",
      "Iteration 73, loss = 778.16129515\n",
      "Iteration 74, loss = 776.60045554\n",
      "Iteration 75, loss = 772.02404466\n",
      "Iteration 76, loss = 772.59117043\n",
      "Iteration 77, loss = 773.12440943\n",
      "Iteration 78, loss = 773.01024375\n",
      "Iteration 79, loss = 774.26985251\n",
      "Iteration 80, loss = 773.15457510\n",
      "Iteration 81, loss = 770.27100421\n",
      "Iteration 82, loss = 772.17441415\n",
      "Iteration 83, loss = 767.41588481\n",
      "Iteration 84, loss = 766.87205994\n",
      "Iteration 85, loss = 770.77106560\n",
      "Iteration 86, loss = 765.53333835\n",
      "Iteration 87, loss = 777.61815797\n",
      "Iteration 88, loss = 767.72147175\n",
      "Iteration 89, loss = 764.78306469\n",
      "Iteration 90, loss = 767.89568426\n",
      "Iteration 91, loss = 764.15904113\n",
      "Iteration 92, loss = 768.96236176\n",
      "Iteration 93, loss = 768.43457241\n",
      "Iteration 94, loss = 762.59141237\n",
      "Iteration 95, loss = 758.67758108\n",
      "Iteration 96, loss = 765.52277220\n",
      "Iteration 97, loss = 767.85776601\n",
      "Iteration 98, loss = 756.49597892\n",
      "Iteration 99, loss = 764.58425503\n",
      "Iteration 100, loss = 759.89475825\n",
      "Iteration 101, loss = 764.88454629\n",
      "Iteration 102, loss = 760.29141989\n",
      "Iteration 103, loss = 762.56113557\n",
      "Iteration 104, loss = 756.34975501\n",
      "Iteration 105, loss = 763.76470763\n",
      "Iteration 106, loss = 757.96902111\n",
      "Iteration 107, loss = 762.14626362\n",
      "Iteration 108, loss = 759.41505426\n",
      "Iteration 109, loss = 758.05429874\n",
      "Iteration 110, loss = 759.91355055\n",
      "Iteration 111, loss = 760.14770845\n",
      "Iteration 112, loss = 760.46654551\n",
      "Iteration 113, loss = 757.87598245\n",
      "Iteration 114, loss = 759.04098474\n",
      "Iteration 115, loss = 759.47052813\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['../models/MLP_dense_moreParams.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Create a preprocessor to perform the steps defined above\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, INPUTS)\n",
    "        ])\n",
    "\n",
    "param = {'MLP__alpha': [0.001], # Initial value of regularization\n",
    "         'MLP__hidden_layer_sizes': [\n",
    "                (80,),          # 1 capa con 50 neuronas\n",
    "                (40, 40),      # 2 capas: 40 → 40\n",
    "                (80, 40, 20),   # 3 capas: 80 → 40 → 20\n",
    "        ],\n",
    "         'MLP__learning_rate_init': [0.01, 0.001], # Initial learning rate\n",
    "         'MLP__activation': ['tanh', 'relu'], # Activation function\n",
    "}\n",
    "\n",
    "pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('MLP', MLPRegressor(solver='adam', \n",
    "                max_iter=2000, # Maximum number of iterations\n",
    "                tol=1e-4, # Tolerance for the optimization\n",
    "                random_state=150,\n",
    "                verbose = True))]) # For replication\n",
    "\n",
    "# We use Grid Search Cross Validation to find the best parameter for the model in the grid defined \n",
    "nFolds = 10\n",
    "MLP_fit = GridSearchCV(estimator=pipe, # Structure of the model to use\n",
    "                       param_grid=param, # Defined grid to search in\n",
    "                       n_jobs=-1, # Number of cores to use (parallelize)\n",
    "                       scoring='neg_mean_squared_error', # RMSE https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "                       cv=nFolds,\n",
    "                       verbose=2) # Number of Folds \n",
    "MLP_fit.fit(X_train[INPUTS], y_train) # Search in grid\n",
    "\n",
    "\n",
    "# Save the model\n",
    "import joblib\n",
    "joblib.dump(MLP_fit, '../models/MLP_dense_moreParams.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75d588e",
   "metadata": {},
   "source": [
    "##### NoGRIDSEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc4ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/MLP_dense_BSParams.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Create the preprocessor pipeline\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, INPUTS)\n",
    "])\n",
    "\n",
    "# Create the full pipeline with best hyperparameters\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('MLP', MLPRegressor(\n",
    "        hidden_layer_sizes=(80, 40, 20),\n",
    "        activation='relu',\n",
    "        alpha=0.001,\n",
    "        learning_rate_init=0.01,\n",
    "        solver='adam',\n",
    "        max_iter=2000,\n",
    "        tol=1e-4,\n",
    "        random_state=150,\n",
    "        verbose=True\n",
    "    ))\n",
    "])\n",
    "\n",
    "# Fit the model\n",
    "pipe.fit(X_train[INPUTS], y_train)\n",
    "\n",
    "# Save the trained pipeline\n",
    "joblib.dump(pipe, '../models/MLP_dense_BSParams.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb3f3e0",
   "metadata": {},
   "source": [
    "#### B. Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9d6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Cargamos el modelo guardado\n",
    "MLP_fit = joblib.load('../models/MLP_dense_moreParams.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03abbc62",
   "metadata": {},
   "source": [
    "### 3. MLP vs Black-Scholes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cb2639",
   "metadata": {},
   "source": [
    "#### A. Graphic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dcb4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "def plotModelGridError(MLP_fit):\n",
    "    results = MLP_fit.cv_results_\n",
    "    mean_test_scores = results['mean_test_score']\n",
    "    params = results['params']\n",
    "\n",
    "    # Convertir a error (RMSE)\n",
    "    errors = np.sqrt(-mean_test_scores)\n",
    "\n",
    "    # Etiquetas incluyendo todos los hiperparámetros relevantes\n",
    "    param_labels = [\n",
    "        f\"act: {p['MLP__activation']}, alpha: {p['MLP__alpha']}, size: {p['MLP__hidden_layer_sizes']}, lr: {p['MLP__learning_rate_init']}\"\n",
    "        for p in params\n",
    "    ]\n",
    "\n",
    "    # Obtener todos los learning rates únicos para codificarlos por color\n",
    "    lrs = [p['MLP__learning_rate_init'] for p in params]\n",
    "    unique_lrs = sorted(set(lrs))\n",
    "    lr_color_map = {lr: cm.viridis(i / len(unique_lrs)) for i, lr in enumerate(unique_lrs)}\n",
    "    bar_colors = [lr_color_map[lr] for lr in lrs]\n",
    "\n",
    "    # Ordenar por error creciente\n",
    "    sorted_indices = np.argsort(errors)\n",
    "    errors_sorted = errors[sorted_indices]\n",
    "    param_labels_sorted = [param_labels[i] for i in sorted_indices]\n",
    "    bar_colors_sorted = [bar_colors[i] for i in sorted_indices]\n",
    "\n",
    "    # Crear el gráfico\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    bars = plt.barh(param_labels_sorted, errors_sorted, color=bar_colors_sorted)\n",
    "    plt.xlabel(\"RMSE\")\n",
    "    plt.title(\"Model Grid Search Errors (RMSE), grouped by Learning Rate\")\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Crear leyenda manual\n",
    "    legend_handles = [\n",
    "        plt.Rectangle((0, 0), 1, 1, color=lr_color_map[lr]) for lr in unique_lrs\n",
    "    ]\n",
    "    legend_labels = [f\"lr: {lr}\" for lr in unique_lrs]\n",
    "    legend = plt.legend(legend_handles, legend_labels, title=\"Learning Rate\", loc=\"upper right\")\n",
    "\n",
    "    # Quitar fondo de la leyenda\n",
    "    legend.get_frame().set_facecolor('none')\n",
    "\n",
    "    # Estética general\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor('white')\n",
    "    ax.grid(False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('black')\n",
    "        spine.set_linewidth(0.5)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "567dbb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotModelGridError(MLP_fit)\n",
    "# La mejor combinación es ReLu, alpha=0.001, size=(80, 40, 20), lr=0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4a3fc",
   "metadata": {},
   "source": [
    "#### B. Comparison of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce1acdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the predictions on the training set using Black-Scholes formula\n",
    "dfTR_eval['BS_predict'] = black_scholes_call_option(\n",
    "    dfTR_eval['S'],\n",
    "    dfTR_eval['K'],\n",
    "    dfTR_eval['T'],\n",
    "    0.045,  # Assuming a risk-free interest rate of 5%\n",
    "    dfTR_eval['sigma']\n",
    ")\n",
    "\n",
    "# Calculate the predictions on the test set using Black-Scholes formula\n",
    "dfTS_eval['BS_predict'] = black_scholes_call_option(\n",
    "    dfTS_eval['S'],\n",
    "    dfTS_eval['K'],\n",
    "    dfTS_eval['T'],\n",
    "    0.045,  # Assuming a risk-free interest rate of 5%\n",
    "    dfTS_eval['sigma']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ca043fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTR_eval['MLP_pred'] = MLP_fit.predict(X_train[INPUTS])\n",
    "dfTS_eval['MLP_pred'] = MLP_fit.predict(X_test[INPUTS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "dde923e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Predictions\n",
      "Training MAE: 7.223884845206329\n",
      "Test MAE: 7.202581578422414\n",
      "Training RMSE: 38.635822219795436\n",
      "Test RMSE: 41.91976538075246\n",
      "Training R2: 0.9322188515065822\n",
      "Test R2: 0.920752400804147\n"
     ]
    }
   ],
   "source": [
    "#Training and test MAE - Mean Absolute error\n",
    "print('MLP Predictions')\n",
    "print('Training MAE:',mean_absolute_error(dfTR_eval['midPrice'], dfTR_eval['MLP_pred']))\n",
    "print('Test MAE:',mean_absolute_error(dfTS_eval['midPrice'], dfTS_eval['MLP_pred']))\n",
    "#Training and test RMSE - Root Mean Square Error\n",
    "print('Training RMSE:',math.sqrt(mean_squared_error(dfTR_eval['midPrice'], dfTR_eval['MLP_pred'])))\n",
    "print('Test RMSE:',math.sqrt(mean_squared_error(dfTS_eval['midPrice'], dfTS_eval['MLP_pred'])))\n",
    "#Training and test r^2 \n",
    "print('Training R2:',r2_score(dfTR_eval['midPrice'], dfTR_eval['MLP_pred']))\n",
    "print('Test R2:',r2_score(dfTS_eval['midPrice'], dfTS_eval['MLP_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bfee0ef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black-Scholes Predictions\n",
      "Training MAE: 8.873040536740485\n",
      "Test MAE: 9.146334975830321\n",
      "Training RMSE: 65.63617705197352\n",
      "Test RMSE: 72.9164782442016\n",
      "Training R2: 0.8043791413045844\n",
      "Test R2: 0.7602272650786238\n"
     ]
    }
   ],
   "source": [
    "print('Black-Scholes Predictions')\n",
    "#Training and test MAE - Mean Absolute error\n",
    "print('Training MAE:',mean_absolute_error(dfTR_eval['midPrice'], dfTR_eval['BS_predict']))\n",
    "print('Test MAE:',mean_absolute_error(dfTS_eval['midPrice'], dfTS_eval['BS_predict']))\n",
    "#Training and test RMSE - Root Mean Square Error\n",
    "print('Training RMSE:',math.sqrt(mean_squared_error(dfTR_eval['midPrice'], dfTR_eval['BS_predict'])))\n",
    "print('Test RMSE:',math.sqrt(mean_squared_error(dfTS_eval['midPrice'], dfTS_eval['BS_predict'])))\n",
    "#Training and test r^2 \n",
    "print('Training R2:',r2_score(dfTR_eval['midPrice'], dfTR_eval['BS_predict']))\n",
    "print('Test R2:',r2_score(dfTS_eval['midPrice'], dfTS_eval['BS_predict']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71a7680",
   "metadata": {},
   "source": [
    "#### C. Case to case comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "73566e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "BS ha aproximado mejor que MLP en 62903 casos.\n",
      "   Media de mejora: -4.396186300237753\n",
      "   Mediana de mejora: -1.6620642582273484\n",
      "MLP ha aproximado mejor que BS en 38289 casos.\n",
      "   Media de mejora: -11.58073257545456\n",
      "   Mediana de mejora: -2.1654219113990187\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "dfTR_eval['MLP_diff'] = np.abs(dfTR_eval['midPrice'] - dfTR_eval['MLP_pred'])\n",
    "dfTR_eval['BS_diff'] = np.abs(dfTR_eval['midPrice'] - dfTR_eval['BS_predict'])\n",
    "dfTR_eval['MLP_better'] = dfTR_eval['MLP_diff'] < dfTR_eval['BS_diff']\n",
    "\n",
    "# Casos en los que MLP es mejor\n",
    "mlp_better_cases = dfTR_eval[dfTR_eval['MLP_better']]\n",
    "bs_better_cases = dfTR_eval[~dfTR_eval['MLP_better']]\n",
    "\n",
    "# Diferencias de error entre ambos modelos\n",
    "mlp_margin = bs_better_cases['BS_diff'] - bs_better_cases['MLP_diff']\n",
    "bs_margin = mlp_better_cases['MLP_diff'] - mlp_better_cases['BS_diff']\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "print(\"Test set:\")\n",
    "print(\"BS ha aproximado mejor que MLP en\", len(bs_better_cases), \"casos.\")\n",
    "print(\"   Media de mejora:\", mlp_margin.mean())\n",
    "print(\"   Mediana de mejora:\", mlp_margin.median())\n",
    "\n",
    "print(\"MLP ha aproximado mejor que BS en\", len(mlp_better_cases), \"casos.\")\n",
    "print(\"   Media de mejora:\", bs_margin.mean())\n",
    "print(\"   Mediana de mejora:\", bs_margin.median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fa481e12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      "BS ha aproximado mejor que MLP en 15742 casos.\n",
      "   Media de mejora: -4.23924560171897\n",
      "   Mediana de mejora: -1.6646841893345374\n",
      "MLP ha aproximado mejor que BS en 9557 casos.\n",
      "   Media de mejora: -12.128201471516446\n",
      "   Mediana de mejora: -2.0965356890559974\n"
     ]
    }
   ],
   "source": [
    "dfTS_eval['MLP_diff'] = np.abs(dfTS_eval['midPrice'] - dfTS_eval['MLP_pred'])\n",
    "dfTS_eval['BS_diff'] = np.abs(dfTS_eval['midPrice'] - dfTS_eval['BS_predict'])\n",
    "dfTS_eval['MLP_better'] = dfTS_eval['MLP_diff'] < dfTS_eval['BS_diff']\n",
    "\n",
    "# Casos en los que MLP es mejor\n",
    "mlp_better_cases = dfTS_eval[dfTS_eval['MLP_better']]\n",
    "bs_better_cases = dfTS_eval[~dfTS_eval['MLP_better']]\n",
    "\n",
    "# Diferencias de error entre ambos modelos\n",
    "mlp_margin = bs_better_cases['BS_diff'] - bs_better_cases['MLP_diff']\n",
    "bs_margin = mlp_better_cases['MLP_diff'] - mlp_better_cases['BS_diff']\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "print(\"Test set:\")\n",
    "print(\"BS ha aproximado mejor que MLP en\", len(bs_better_cases), \"casos.\")\n",
    "print(\"   Media de mejora:\", mlp_margin.mean())\n",
    "print(\"   Mediana de mejora:\", mlp_margin.median())\n",
    "\n",
    "print(\"MLP ha aproximado mejor que BS en\", len(mlp_better_cases), \"casos.\")\n",
    "print(\"   Media de mejora:\", bs_margin.mean())\n",
    "print(\"   Mediana de mejora:\", bs_margin.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cd989f",
   "metadata": {},
   "source": [
    "### 4. Neuralsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f3e74831",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP_fit.best_estimator_['MLP']\n",
    "wts = mlp.coefs_\n",
    "bias = mlp.intercepts_\n",
    "actfunc = ['identity',MLP_fit.best_estimator_['MLP'].get_params()['activation'],mlp.out_activation_]\n",
    "X = MLP_fit.best_estimator_['preprocessor'].transform(X_train) # Preprocess the variables\n",
    "coefnames = MLP_fit.best_estimator_['preprocessor'].get_feature_names_out(INPUTS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4030c929",
   "metadata": {},
   "outputs": [],
   "source": [
    "actfunc = ['identity', 'relu', 'relu', 'identity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "40e9fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(X, columns=coefnames)\n",
    "y = pd.DataFrame(y_train, columns=[TARGET])\n",
    "sens_end_layer = 'last'\n",
    "sens_end_input = False\n",
    "sens_origin_layer = 0\n",
    "sens_origin_input = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1e95d0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sensmlp = ns.jacobian_mlp(wts, bias, actfunc, X, y,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "aa7a5085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity analysis of [7, 40, 40, 1] MLP network.\n",
      "\n",
      "Sensitivity measures of each output:\n",
      "\n",
      "$call_price \n",
      "\n",
      "                         mean         std  mean_squared\n",
      "num__S             277.466972  183.167666    332.473028\n",
      "num__K            -225.306202  166.911063    280.396483\n",
      "num__T              23.084730   42.281022     48.172498\n",
      "num__sigma          41.869189   83.710556     93.597469\n",
      "num__openInterest   -0.188977    0.914965      0.934276\n",
      "num__volume          0.989610    2.512269      2.700153\n",
      "num__inTheMoney     39.914061  102.665196    110.151145\n"
     ]
    }
   ],
   "source": [
    "sensmlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c9818821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity analysis of [7, 40, 40, 1] MLP network.\n",
      "\n",
      "101192 samples\n",
      "\n",
      "Sensitivities of each output (only 5 first samples):\n",
      "\n",
      "$call_price \n",
      "\n",
      "       num__S      num__K     num__T  num__sigma  num__openInterest  \\\n",
      "0   72.685679  -52.180917  14.841730    3.551779           0.016046   \n",
      "1  141.713604  -95.726598  18.286511   28.450128          -0.316081   \n",
      "2  514.322638 -436.596055   0.582152   58.791729          -0.278513   \n",
      "3   -2.069361   -3.154332   2.363303    1.521308           0.299499   \n",
      "4   32.619028  -18.672995   0.322163   33.627357          -0.184647   \n",
      "\n",
      "   num__volume  num__inTheMoney  \n",
      "0    -0.049834         0.956260  \n",
      "1    -0.565755       -27.217809  \n",
      "2     1.948780       125.435071  \n",
      "3     0.415613         0.177775  \n",
      "4    -1.422913       -34.528073  \n"
     ]
    }
   ],
   "source": [
    "sensmlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0ef4dc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/juan/anaconda3/envs/TFM/lib/python3.10/site-packages/neuralsens/partial_derivatives.py:1749: UserWarning: Numpy array is not a supported type for `palette`. Please convert your palette to a list. This will become an error in v0.14\n",
      "  sns.barplot(\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1072.892344pt\" height=\"709.354219pt\" viewBox=\"0 0 1072.892344 709.354219\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-06-08T16:44:43.346101</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 709.354219 \n",
       "L 1072.892344 709.354219 \n",
       "L 1072.892344 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 50.312344 220.3525 \n",
       "L 1065.692344 220.3525 \n",
       "L 1065.692344 42.05625 \n",
       "L 50.312344 42.05625 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 183.983973 220.3525 \n",
       "L 183.983973 42.05625 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- −200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(171.596082 237.726094) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2212\" d=\"M 3381 1997 \n",
       "L 356 1997 \n",
       "L 356 2522 \n",
       "L 3381 2522 \n",
       "L 3381 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 349.419984 220.3525 \n",
       "L 349.419984 42.05625 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- −100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(337.032093 237.726094) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-31\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 514.855995 220.3525 \n",
       "L 514.855995 42.05625 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(511.79748 237.726094) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 680.292006 220.3525 \n",
       "L 680.292006 42.05625 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(671.116459 237.726094) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 845.728017 220.3525 \n",
       "L 845.728017 42.05625 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(836.552471 237.726094) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 1011.164029 220.3525 \n",
       "L 1011.164029 42.05625 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 300 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(1001.988482 237.726094) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_7\">\n",
       "     <!-- mean(Sens) -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(525.323906 252.647969) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 925 3319 \n",
       "L 925 2853 \n",
       "Q 1081 3097 1340 3245 \n",
       "Q 1600 3394 1931 3394 \n",
       "Q 2300 3394 2536 3241 \n",
       "Q 2772 3088 2869 2813 \n",
       "Q 3263 3394 3894 3394 \n",
       "Q 4388 3394 4653 3120 \n",
       "Q 4919 2847 4919 2278 \n",
       "L 4919 0 \n",
       "L 4359 0 \n",
       "L 4359 2091 \n",
       "Q 4359 2428 4304 2576 \n",
       "Q 4250 2725 4106 2815 \n",
       "Q 3963 2906 3769 2906 \n",
       "Q 3419 2906 3187 2673 \n",
       "Q 2956 2441 2956 1928 \n",
       "L 2956 0 \n",
       "L 2394 0 \n",
       "L 2394 2156 \n",
       "Q 2394 2531 2256 2718 \n",
       "Q 2119 2906 1806 2906 \n",
       "Q 1569 2906 1367 2781 \n",
       "Q 1166 2656 1075 2415 \n",
       "Q 984 2175 984 1722 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-28\" d=\"M 1497 -1347 \n",
       "Q 1031 -759 709 28 \n",
       "Q 388 816 388 1659 \n",
       "Q 388 2403 628 3084 \n",
       "Q 909 3875 1497 4659 \n",
       "L 1900 4659 \n",
       "Q 1522 4009 1400 3731 \n",
       "Q 1209 3300 1100 2831 \n",
       "Q 966 2247 966 1656 \n",
       "Q 966 153 1900 -1347 \n",
       "L 1497 -1347 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-53\" d=\"M 288 1472 \n",
       "L 859 1522 \n",
       "Q 900 1178 1048 958 \n",
       "Q 1197 738 1509 602 \n",
       "Q 1822 466 2213 466 \n",
       "Q 2559 466 2825 569 \n",
       "Q 3091 672 3220 851 \n",
       "Q 3350 1031 3350 1244 \n",
       "Q 3350 1459 3225 1620 \n",
       "Q 3100 1781 2813 1891 \n",
       "Q 2628 1963 1997 2114 \n",
       "Q 1366 2266 1113 2400 \n",
       "Q 784 2572 623 2826 \n",
       "Q 463 3081 463 3397 \n",
       "Q 463 3744 659 4045 \n",
       "Q 856 4347 1234 4503 \n",
       "Q 1613 4659 2075 4659 \n",
       "Q 2584 4659 2973 4495 \n",
       "Q 3363 4331 3572 4012 \n",
       "Q 3781 3694 3797 3291 \n",
       "L 3216 3247 \n",
       "Q 3169 3681 2898 3903 \n",
       "Q 2628 4125 2100 4125 \n",
       "Q 1550 4125 1298 3923 \n",
       "Q 1047 3722 1047 3438 \n",
       "Q 1047 3191 1225 3031 \n",
       "Q 1400 2872 2139 2705 \n",
       "Q 2878 2538 3153 2413 \n",
       "Q 3553 2228 3743 1945 \n",
       "Q 3934 1663 3934 1294 \n",
       "Q 3934 928 3725 604 \n",
       "Q 3516 281 3123 101 \n",
       "Q 2731 -78 2241 -78 \n",
       "Q 1619 -78 1198 103 \n",
       "Q 778 284 539 648 \n",
       "Q 300 1013 288 1472 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-29\" d=\"M 791 -1347 \n",
       "L 388 -1347 \n",
       "Q 1322 153 1322 1656 \n",
       "Q 1322 2244 1188 2822 \n",
       "Q 1081 3291 891 3722 \n",
       "Q 769 4003 388 4659 \n",
       "L 791 4659 \n",
       "Q 1378 3875 1659 3084 \n",
       "Q 1900 2403 1900 1659 \n",
       "Q 1900 816 1576 28 \n",
       "Q 1253 -759 791 -1347 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-6d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-28\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-53\" transform=\"translate(283.447266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(350.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(405.761719 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(461.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-29\" transform=\"translate(511.376953 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 50.312344 212.248125 \n",
       "L 1065.692344 212.248125 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(34.695312 216.184922) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 50.312344 175.376738 \n",
       "L 1065.692344 175.376738 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 50 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.578281 179.313535) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 50.312344 138.505352 \n",
       "L 1065.692344 138.505352 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 142.442148) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 50.312344 101.633965 \n",
       "L 1065.692344 101.633965 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 150 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 105.570762) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 50.312344 64.762578 \n",
       "L 1065.692344 64.762578 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 68.699375) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_13\">\n",
       "     <!-- std(Sens) -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(15.935625 156.87875) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
       "L 1731 6 \n",
       "Q 1494 -44 1306 -44 \n",
       "Q 1000 -44 831 53 \n",
       "Q 663 150 594 308 \n",
       "Q 525 466 525 972 \n",
       "L 525 2881 \n",
       "L 113 2881 \n",
       "L 113 3319 \n",
       "L 525 3319 \n",
       "L 525 4141 \n",
       "L 1084 4478 \n",
       "L 1084 3319 \n",
       "L 1650 3319 \n",
       "L 1650 2881 \n",
       "L 1084 2881 \n",
       "L 1084 941 \n",
       "Q 1084 700 1114 631 \n",
       "Q 1144 563 1211 522 \n",
       "Q 1278 481 1403 481 \n",
       "Q 1497 481 1650 503 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-64\" d=\"M 2575 0 \n",
       "L 2575 419 \n",
       "Q 2259 -75 1647 -75 \n",
       "Q 1250 -75 917 144 \n",
       "Q 584 363 401 755 \n",
       "Q 219 1147 219 1656 \n",
       "Q 219 2153 384 2558 \n",
       "Q 550 2963 881 3178 \n",
       "Q 1213 3394 1622 3394 \n",
       "Q 1922 3394 2156 3267 \n",
       "Q 2391 3141 2538 2938 \n",
       "L 2538 4581 \n",
       "L 3097 4581 \n",
       "L 3097 0 \n",
       "L 2575 0 \n",
       "z\n",
       "M 797 1656 \n",
       "Q 797 1019 1065 703 \n",
       "Q 1334 388 1700 388 \n",
       "Q 2069 388 2326 689 \n",
       "Q 2584 991 2584 1609 \n",
       "Q 2584 2291 2321 2609 \n",
       "Q 2059 2928 1675 2928 \n",
       "Q 1300 2928 1048 2622 \n",
       "Q 797 2316 797 1656 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-73\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" transform=\"translate(50 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(77.783203 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-28\" transform=\"translate(133.398438 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-53\" transform=\"translate(166.699219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(233.398438 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(289.013672 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(344.628906 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-29\" transform=\"translate(394.628906 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m16927585b3\" d=\"M 0 6.123724 \n",
       "C 1.624031 6.123724 3.181764 5.47849 4.330127 4.330127 \n",
       "C 5.47849 3.181764 6.123724 1.624031 6.123724 0 \n",
       "C 6.123724 -1.624031 5.47849 -3.181764 4.330127 -4.330127 \n",
       "C 3.181764 -5.47849 1.624031 -6.123724 0 -6.123724 \n",
       "C -1.624031 -6.123724 -3.181764 -5.47849 -4.330127 -4.330127 \n",
       "C -5.47849 -3.181764 -6.123724 -1.624031 -6.123724 0 \n",
       "C -6.123724 1.624031 -5.47849 3.181764 -4.330127 4.330127 \n",
       "C -3.181764 5.47849 -1.624031 6.123724 0 6.123724 \n",
       "z\n",
       "\" style=\"stroke: #0000ff; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#p9d8cece06e)\">\n",
       "     <use xlink:href=\"#m16927585b3\" x=\"514.855995\" y=\"212.248125\" style=\"fill: #0000ff; stroke: #0000ff; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"LineCollection_1\">\n",
       "    <path d=\"M 50.312344 212.248125 \n",
       "L 1065.692344 212.248125 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"LineCollection_2\">\n",
       "    <path d=\"M 514.855995 212.248125 \n",
       "L 514.855995 50.160625 \n",
       "\" clip-path=\"url(#p9d8cece06e)\" style=\"fill: none; stroke: #0000ff; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 50.312344 220.3525 \n",
       "L 50.312344 42.05625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 1065.692344 220.3525 \n",
       "L 1065.692344 42.05625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 50.312344 220.3525 \n",
       "L 1065.692344 220.3525 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 50.312344 42.05625 \n",
       "L 1065.692344 42.05625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_14\">\n",
       "    <g id=\"patch_7\">\n",
       "     <path d=\"M 951.540036 86.335521 \n",
       "L 996.232536 86.335521 \n",
       "Q 999.832536 86.335521 999.832536 82.735521 \n",
       "L 999.832536 71.614896 \n",
       "Q 999.832536 68.014896 996.232536 68.014896 \n",
       "L 951.540036 68.014896 \n",
       "Q 947.940036 68.014896 947.940036 71.614896 \n",
       "L 947.940036 82.735521 \n",
       "Q 947.940036 86.335521 951.540036 86.335521 \n",
       "z\n",
       "\" style=\"fill: #ffffff; stroke: #808080; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__S -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(951.540036 80.350521) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-75\" d=\"M 2597 0 \n",
       "L 2597 488 \n",
       "Q 2209 -75 1544 -75 \n",
       "Q 1250 -75 995 37 \n",
       "Q 741 150 617 320 \n",
       "Q 494 491 444 738 \n",
       "Q 409 903 409 1263 \n",
       "L 409 3319 \n",
       "L 972 3319 \n",
       "L 972 1478 \n",
       "Q 972 1038 1006 884 \n",
       "Q 1059 663 1231 536 \n",
       "Q 1403 409 1656 409 \n",
       "Q 1909 409 2131 539 \n",
       "Q 2353 669 2445 892 \n",
       "Q 2538 1116 2538 1541 \n",
       "L 2538 3319 \n",
       "L 3100 3319 \n",
       "L 3100 0 \n",
       "L 2597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-5f\" d=\"M -97 -1272 \n",
       "L -97 -866 \n",
       "L 3631 -866 \n",
       "L 3631 -1272 \n",
       "L -97 -1272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-53\" transform=\"translate(305.761719 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_15\">\n",
       "    <g id=\"patch_8\">\n",
       "     <path d=\"M 119.772152 98.250466 \n",
       "L 164.464652 98.250466 \n",
       "Q 168.064652 98.250466 168.064652 94.650466 \n",
       "L 168.064652 83.676091 \n",
       "Q 168.064652 80.076091 164.464652 80.076091 \n",
       "L 119.772152 80.076091 \n",
       "Q 116.172152 80.076091 116.172152 83.676091 \n",
       "L 116.172152 94.650466 \n",
       "Q 116.172152 98.250466 119.772152 98.250466 \n",
       "z\n",
       "\" style=\"fill: #ffffff; stroke: #808080; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__K -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(119.772152 92.265466) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-4b\" d=\"M 469 0 \n",
       "L 469 4581 \n",
       "L 1075 4581 \n",
       "L 1075 2309 \n",
       "L 3350 4581 \n",
       "L 4172 4581 \n",
       "L 2250 2725 \n",
       "L 4256 0 \n",
       "L 3456 0 \n",
       "L 1825 2319 \n",
       "L 1075 1588 \n",
       "L 1075 0 \n",
       "L 469 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4b\" transform=\"translate(305.761719 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_16\">\n",
       "    <g id=\"patch_9\">\n",
       "     <path d=\"M 531.037702 190.156114 \n",
       "L 575.055202 190.156114 \n",
       "Q 578.655202 190.156114 578.655202 186.556114 \n",
       "L 578.655202 175.581739 \n",
       "Q 578.655202 171.981739 575.055202 171.981739 \n",
       "L 531.037702 171.981739 \n",
       "Q 527.437702 171.981739 527.437702 175.581739 \n",
       "L 527.437702 186.556114 \n",
       "Q 527.437702 190.156114 531.037702 190.156114 \n",
       "z\n",
       "\" style=\"fill: #ffffff; stroke: #808080; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__T -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(531.037702 184.171114) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-54\" d=\"M 1659 0 \n",
       "L 1659 4041 \n",
       "L 150 4041 \n",
       "L 150 4581 \n",
       "L 3781 4581 \n",
       "L 3781 4041 \n",
       "L 2266 4041 \n",
       "L 2266 0 \n",
       "L 1659 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-54\" transform=\"translate(305.761719 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_17\">\n",
       "    <g id=\"patch_10\">\n",
       "     <path d=\"M 549.774587 159.67514 \n",
       "L 618.470837 159.67514 \n",
       "Q 622.070837 159.67514 622.070837 156.07514 \n",
       "L 622.070837 144.96014 \n",
       "Q 622.070837 141.36014 618.470837 141.36014 \n",
       "L 549.774587 141.36014 \n",
       "Q 546.174587 141.36014 546.174587 144.96014 \n",
       "L 546.174587 156.07514 \n",
       "Q 546.174587 159.67514 549.774587 159.67514 \n",
       "z\n",
       "\" style=\"fill: #ffffff; stroke: #808080; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__sigma -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(549.774587 153.549515) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-67\" d=\"M 319 -275 \n",
       "L 866 -356 \n",
       "Q 900 -609 1056 -725 \n",
       "Q 1266 -881 1628 -881 \n",
       "Q 2019 -881 2231 -725 \n",
       "Q 2444 -569 2519 -288 \n",
       "Q 2563 -116 2559 434 \n",
       "Q 2191 0 1641 0 \n",
       "Q 956 0 581 494 \n",
       "Q 206 988 206 1678 \n",
       "Q 206 2153 378 2554 \n",
       "Q 550 2956 876 3175 \n",
       "Q 1203 3394 1644 3394 \n",
       "Q 2231 3394 2613 2919 \n",
       "L 2613 3319 \n",
       "L 3131 3319 \n",
       "L 3131 450 \n",
       "Q 3131 -325 2973 -648 \n",
       "Q 2816 -972 2473 -1159 \n",
       "Q 2131 -1347 1631 -1347 \n",
       "Q 1038 -1347 672 -1080 \n",
       "Q 306 -813 319 -275 \n",
       "z\n",
       "M 784 1719 \n",
       "Q 784 1066 1043 766 \n",
       "Q 1303 466 1694 466 \n",
       "Q 2081 466 2343 764 \n",
       "Q 2606 1063 2606 1700 \n",
       "Q 2606 2309 2336 2618 \n",
       "Q 2066 2928 1684 2928 \n",
       "Q 1309 2928 1046 2623 \n",
       "Q 784 2319 784 1719 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(355.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-67\" transform=\"translate(377.978516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(433.59375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" transform=\"translate(516.894531 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_18\">\n",
       "    <g id=\"patch_11\">\n",
       "     <path d=\"M 462.844922 220.660592 \n",
       "L 566.241797 220.660592 \n",
       "Q 569.841797 220.660592 569.841797 217.060592 \n",
       "L 569.841797 206.086217 \n",
       "Q 569.841797 202.486217 566.241797 202.486217 \n",
       "L 462.844922 202.486217 \n",
       "Q 459.244922 202.486217 459.244922 206.086217 \n",
       "L 459.244922 217.060592 \n",
       "Q 459.244922 220.660592 462.844922 220.660592 \n",
       "z\n",
       "\" style=\"fill: #ffffff; stroke: #808080; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__openInterest -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(462.844922 214.675592) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-49\" d=\"M 597 0 \n",
       "L 597 4581 \n",
       "L 1203 4581 \n",
       "L 1203 0 \n",
       "L 597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" transform=\"translate(361.376953 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(416.992188 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(472.607422 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-49\" transform=\"translate(528.222656 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(556.005859 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(611.621094 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(639.404297 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(695.019531 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(728.320312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(783.935547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(833.935547 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_19\">\n",
       "    <g id=\"patch_12\">\n",
       "     <path d=\"M 478.808479 219.482696 \n",
       "L 554.177854 219.482696 \n",
       "Q 557.777854 219.482696 557.777854 215.882696 \n",
       "L 557.777854 204.908321 \n",
       "Q 557.777854 201.308321 554.177854 201.308321 \n",
       "L 478.808479 201.308321 \n",
       "Q 475.208479 201.308321 475.208479 204.908321 \n",
       "L 475.208479 215.882696 \n",
       "Q 475.208479 219.482696 478.808479 219.482696 \n",
       "z\n",
       "\" style=\"fill: #ffffff; stroke: #808080; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__volume -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(478.808479 213.497696) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-76\" d=\"M 1344 0 \n",
       "L 81 3319 \n",
       "L 675 3319 \n",
       "L 1388 1331 \n",
       "Q 1503 1009 1600 663 \n",
       "Q 1675 925 1809 1294 \n",
       "L 2547 3319 \n",
       "L 3125 3319 \n",
       "L 1869 0 \n",
       "L 1344 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(355.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" transform=\"translate(411.376953 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(433.59375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(489.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(572.509766 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_20\">\n",
       "    <g id=\"patch_13\">\n",
       "     <path d=\"M 529.529163 145.697462 \n",
       "L 632.247288 145.697462 \n",
       "Q 635.847288 145.697462 635.847288 142.097462 \n",
       "L 635.847288 130.982462 \n",
       "Q 635.847288 127.382462 632.247288 127.382462 \n",
       "L 529.529163 127.382462 \n",
       "Q 525.929163 127.382462 525.929163 130.982462 \n",
       "L 525.929163 142.097462 \n",
       "Q 525.929163 145.697462 529.529163 145.697462 \n",
       "z\n",
       "\" style=\"fill: #ffffff; stroke: #808080; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__inTheMoney -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(529.529163 139.571837) scale(0.12 -0.12)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-68\" d=\"M 422 0 \n",
       "L 422 4581 \n",
       "L 984 4581 \n",
       "L 984 2938 \n",
       "Q 1378 3394 1978 3394 \n",
       "Q 2347 3394 2619 3248 \n",
       "Q 2891 3103 3008 2847 \n",
       "Q 3125 2591 3125 2103 \n",
       "L 3125 0 \n",
       "L 2563 0 \n",
       "L 2563 2103 \n",
       "Q 2563 2525 2380 2717 \n",
       "Q 2197 2909 1863 2909 \n",
       "Q 1613 2909 1392 2779 \n",
       "Q 1172 2650 1078 2428 \n",
       "Q 984 2206 984 1816 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-4d\" d=\"M 475 0 \n",
       "L 475 4581 \n",
       "L 1388 4581 \n",
       "L 2472 1338 \n",
       "Q 2622 884 2691 659 \n",
       "Q 2769 909 2934 1394 \n",
       "L 4031 4581 \n",
       "L 4847 4581 \n",
       "L 4847 0 \n",
       "L 4263 0 \n",
       "L 4263 3834 \n",
       "L 2931 0 \n",
       "L 2384 0 \n",
       "L 1059 3900 \n",
       "L 1059 0 \n",
       "L 475 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-79\" d=\"M 397 -1278 \n",
       "L 334 -750 \n",
       "Q 519 -800 656 -800 \n",
       "Q 844 -800 956 -737 \n",
       "Q 1069 -675 1141 -563 \n",
       "Q 1194 -478 1313 -144 \n",
       "Q 1328 -97 1363 -6 \n",
       "L 103 3319 \n",
       "L 709 3319 \n",
       "L 1400 1397 \n",
       "Q 1534 1031 1641 628 \n",
       "Q 1738 1016 1872 1384 \n",
       "L 2581 3319 \n",
       "L 3144 3319 \n",
       "L 1881 -56 \n",
       "Q 1678 -603 1566 -809 \n",
       "Q 1416 -1088 1222 -1217 \n",
       "Q 1028 -1347 759 -1347 \n",
       "Q 597 -1347 397 -1278 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(327.978516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-54\" transform=\"translate(383.59375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-68\" transform=\"translate(444.677734 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(500.292969 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4d\" transform=\"translate(555.908203 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(639.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(694.824219 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(750.439453 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-79\" transform=\"translate(806.054688 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_21\">\n",
       "    <!-- Sensitivity plots for output 0 -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(469.962094 36.05625) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-66\" d=\"M 556 0 \n",
       "L 556 2881 \n",
       "L 59 2881 \n",
       "L 59 3319 \n",
       "L 556 3319 \n",
       "L 556 3672 \n",
       "Q 556 4006 616 4169 \n",
       "Q 697 4388 901 4523 \n",
       "Q 1106 4659 1475 4659 \n",
       "Q 1713 4659 2000 4603 \n",
       "L 1916 4113 \n",
       "Q 1741 4144 1584 4144 \n",
       "Q 1328 4144 1222 4034 \n",
       "Q 1116 3925 1116 3625 \n",
       "L 1116 3319 \n",
       "L 1763 3319 \n",
       "L 1763 2881 \n",
       "L 1116 2881 \n",
       "L 1116 0 \n",
       "L 556 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-53\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(66.699219 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(122.314453 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(177.929688 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(227.929688 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(277.929688 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" transform=\"translate(300.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(350.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(372.363281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-79\" transform=\"translate(400.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(450.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" transform=\"translate(477.929688 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" transform=\"translate(533.544922 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(555.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(611.376953 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(639.160156 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(689.160156 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-66\" transform=\"translate(716.943359 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(744.726562 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(800.341797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(833.642578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(861.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(917.041016 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(972.65625 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" transform=\"translate(1000.439453 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(1056.054688 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(1111.669922 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(1139.453125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-30\" transform=\"translate(1167.236328 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 50.312344 443.98625 \n",
       "L 1065.692344 443.98625 \n",
       "L 1065.692344 265.69 \n",
       "L 50.312344 265.69 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\">\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"text_22\">\n",
       "      <!-- num__openInterest -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(75.449252 461.359844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-6e\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6f\" transform=\"translate(305.761719 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-70\" transform=\"translate(361.376953 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" transform=\"translate(416.992188 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6e\" transform=\"translate(472.607422 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-49\" transform=\"translate(528.222656 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6e\" transform=\"translate(556.005859 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-74\" transform=\"translate(611.621094 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" transform=\"translate(639.404297 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-72\" transform=\"translate(695.019531 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" transform=\"translate(728.320312 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-73\" transform=\"translate(783.935547 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-74\" transform=\"translate(833.935547 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"text_23\">\n",
       "      <!-- num__volume -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(233.349475 461.359844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-6e\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-76\" transform=\"translate(305.761719 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6f\" transform=\"translate(355.761719 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6c\" transform=\"translate(411.376953 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(433.59375 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(489.208984 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" transform=\"translate(572.509766 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"text_24\">\n",
       "      <!-- num__T -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(392.773371 461.359844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-6e\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-54\" transform=\"translate(305.761719 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"text_25\">\n",
       "      <!-- num__sigma -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.516562 461.359844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-6e\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-73\" transform=\"translate(305.761719 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" transform=\"translate(355.761719 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-67\" transform=\"translate(377.978516 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(433.59375 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-61\" transform=\"translate(516.894531 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"text_26\">\n",
       "      <!-- num__inTheMoney -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(655.977489 461.359844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-6e\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-69\" transform=\"translate(305.761719 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6e\" transform=\"translate(327.978516 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-54\" transform=\"translate(383.59375 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-68\" transform=\"translate(444.677734 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" transform=\"translate(500.292969 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-4d\" transform=\"translate(555.908203 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6f\" transform=\"translate(639.208984 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6e\" transform=\"translate(694.824219 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-65\" transform=\"translate(750.439453 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-79\" transform=\"translate(806.054688 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"text_27\">\n",
       "      <!-- num__K -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(827.626853 461.359844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-6e\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-4b\" transform=\"translate(305.761719 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"text_28\">\n",
       "      <!-- num__S -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(972.681138 461.493906) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-6e\"/>\n",
       "       <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-53\" transform=\"translate(305.761719 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_29\">\n",
       "     <!-- Input variables -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(518.981719 476.269531) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-62\" d=\"M 941 0 \n",
       "L 419 0 \n",
       "L 419 4581 \n",
       "L 981 4581 \n",
       "L 981 2947 \n",
       "Q 1338 3394 1891 3394 \n",
       "Q 2197 3394 2470 3270 \n",
       "Q 2744 3147 2920 2923 \n",
       "Q 3097 2700 3197 2384 \n",
       "Q 3297 2069 3297 1709 \n",
       "Q 3297 856 2875 390 \n",
       "Q 2453 -75 1863 -75 \n",
       "Q 1275 -75 941 416 \n",
       "L 941 0 \n",
       "z\n",
       "M 934 1684 \n",
       "Q 934 1088 1097 822 \n",
       "Q 1363 388 1816 388 \n",
       "Q 2184 388 2453 708 \n",
       "Q 2722 1028 2722 1663 \n",
       "Q 2722 2313 2464 2622 \n",
       "Q 2206 2931 1841 2931 \n",
       "Q 1472 2931 1203 2611 \n",
       "Q 934 2291 934 1684 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-49\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(27.783203 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(83.398438 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(139.013672 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" transform=\"translate(194.628906 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(222.412109 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(250.195312 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(300.195312 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(355.810547 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(389.111328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(411.328125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-62\" transform=\"translate(466.943359 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(522.558594 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(544.775391 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(600.390625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path d=\"M 50.312344 443.98625 \n",
       "L 1065.692344 443.98625 \n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_30\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(34.695312 447.923047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 50.312344 418.449449 \n",
       "L 1065.692344 418.449449 \n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_31\">\n",
       "      <!-- 50 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.578281 422.386246) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <path d=\"M 50.312344 392.912648 \n",
       "L 1065.692344 392.912648 \n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_32\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 396.849444) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 50.312344 367.375846 \n",
       "L 1065.692344 367.375846 \n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_33\">\n",
       "      <!-- 150 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 371.312643) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <path d=\"M 50.312344 341.839045 \n",
       "L 1065.692344 341.839045 \n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_34\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 345.775842) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 50.312344 316.302244 \n",
       "L 1065.692344 316.302244 \n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_35\">\n",
       "      <!-- 250 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 320.239041) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <path d=\"M 50.312344 290.765443 \n",
       "L 1065.692344 290.765443 \n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_36\">\n",
       "      <!-- 300 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.46125 294.70224) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_37\">\n",
       "     <!-- sqrt(mean(S^2)) -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(15.935625 397.992188) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-71\" d=\"M 2538 -1272 \n",
       "L 2538 353 \n",
       "Q 2406 169 2170 47 \n",
       "Q 1934 -75 1669 -75 \n",
       "Q 1078 -75 651 397 \n",
       "Q 225 869 225 1691 \n",
       "Q 225 2191 398 2587 \n",
       "Q 572 2984 901 3189 \n",
       "Q 1231 3394 1625 3394 \n",
       "Q 2241 3394 2594 2875 \n",
       "L 2594 3319 \n",
       "L 3100 3319 \n",
       "L 3100 -1272 \n",
       "L 2538 -1272 \n",
       "z\n",
       "M 803 1669 \n",
       "Q 803 1028 1072 708 \n",
       "Q 1341 388 1716 388 \n",
       "Q 2075 388 2334 692 \n",
       "Q 2594 997 2594 1619 \n",
       "Q 2594 2281 2320 2615 \n",
       "Q 2047 2950 1678 2950 \n",
       "Q 1313 2950 1058 2639 \n",
       "Q 803 2328 803 1669 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-5e\" d=\"M 747 2156 \n",
       "L 169 2156 \n",
       "L 1272 4659 \n",
       "L 1725 4659 \n",
       "L 2834 2156 \n",
       "L 2269 2156 \n",
       "L 1497 4022 \n",
       "L 747 2156 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-73\"/>\n",
       "      <use xlink:href=\"#ArialMT-71\" transform=\"translate(50 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(105.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-28\" transform=\"translate(166.699219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(283.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(338.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(394.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-28\" transform=\"translate(450.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-53\" transform=\"translate(483.447266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5e\" transform=\"translate(550.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(597.070312 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-29\" transform=\"translate(652.685547 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-29\" transform=\"translate(685.986328 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 935.143487 443.98625 \n",
       "L 1051.186915 443.98625 \n",
       "L 1051.186915 274.180298 \n",
       "L 935.143487 274.180298 \n",
       "z\n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: #010000; stroke: #eeeeee; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 790.089201 443.98625 \n",
       "L 906.132629 443.98625 \n",
       "L 906.132629 300.777665 \n",
       "L 790.089201 300.777665 \n",
       "z\n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: #000101; stroke: #eeeeee; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 354.926344 443.98625 \n",
       "L 470.969772 443.98625 \n",
       "L 470.969772 419.38282 \n",
       "L 354.926344 419.38282 \n",
       "z\n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: #031212; stroke: #eeeeee; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 499.980629 443.98625 \n",
       "L 616.024058 443.98625 \n",
       "L 616.024058 396.182651 \n",
       "L 499.980629 396.182651 \n",
       "z\n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: #052222; stroke: #eeeeee; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 64.817772 443.98625 \n",
       "L 180.861201 443.98625 \n",
       "L 180.861201 443.509081 \n",
       "L 64.817772 443.509081 \n",
       "z\n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: #052020; stroke: #eeeeee; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 209.872058 443.98625 \n",
       "L 325.915487 443.98625 \n",
       "L 325.915487 442.607185 \n",
       "L 209.872058 442.607185 \n",
       "z\n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: #b51a1a; stroke: #eeeeee; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 645.034915 443.98625 \n",
       "L 761.078344 443.98625 \n",
       "L 761.078344 387.728092 \n",
       "L 645.034915 387.728092 \n",
       "z\n",
       "\" clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: #20dfdf; stroke: #eeeeee; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_19\">\n",
       "    <path clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_20\">\n",
       "    <path clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_21\">\n",
       "    <path clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_22\">\n",
       "    <path clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_23\">\n",
       "    <path clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_24\">\n",
       "    <path clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path clip-path=\"url(#pb02bb5d1ed)\" style=\"fill: none; stroke: #424242; stroke-width: 2.25; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 50.312344 443.98625 \n",
       "L 50.312344 265.69 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 1065.692344 443.98625 \n",
       "L 1065.692344 265.69 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 50.312344 443.98625 \n",
       "L 1065.692344 443.98625 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 50.312344 265.69 \n",
       "L 1065.692344 265.69 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_1\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 50.312344 667.62 \n",
       "L 1065.692344 667.62 \n",
       "L 1065.692344 489.32375 \n",
       "L 50.312344 489.32375 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_5\">\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_26\">\n",
       "      <path d=\"M 198.4226 667.62 \n",
       "L 198.4226 489.32375 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_38\">\n",
       "      <!-- −500 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(186.034709 684.993594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 374.706332 667.62 \n",
       "L 374.706332 489.32375 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_39\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(371.647817 684.993594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_16\">\n",
       "     <g id=\"line2d_28\">\n",
       "      <path d=\"M 550.990065 667.62 \n",
       "L 550.990065 489.32375 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_40\">\n",
       "      <!-- 500 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(541.814518 684.993594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_17\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path d=\"M 727.273798 667.62 \n",
       "L 727.273798 489.32375 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_41\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(715.039735 684.993594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_18\">\n",
       "     <g id=\"line2d_30\">\n",
       "      <path d=\"M 903.55753 667.62 \n",
       "L 903.55753 489.32375 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_42\">\n",
       "      <!-- 1500 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(891.323468 684.993594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_43\">\n",
       "     <!-- Sens -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(544.327031 699.769219) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-53\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(66.699219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(122.314453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(177.929688 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_6\">\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_31\">\n",
       "      <path d=\"M 50.312344 659.515625 \n",
       "L 1065.692344 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_44\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.522344 663.452422) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
       "L 581 641 \n",
       "L 1222 641 \n",
       "L 1222 0 \n",
       "L 581 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_32\">\n",
       "      <path d=\"M 50.312344 634.50243 \n",
       "L 1065.692344 634.50243 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_45\">\n",
       "      <!-- 0.1 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.522344 638.439227) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-31\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_33\">\n",
       "      <path d=\"M 50.312344 609.489235 \n",
       "L 1065.692344 609.489235 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_46\">\n",
       "      <!-- 0.2 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.522344 613.426031) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_34\">\n",
       "      <path d=\"M 50.312344 584.476039 \n",
       "L 1065.692344 584.476039 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_47\">\n",
       "      <!-- 0.3 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.522344 588.412836) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <path d=\"M 50.312344 559.462844 \n",
       "L 1065.692344 559.462844 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_48\">\n",
       "      <!-- 0.4 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.522344 563.399641) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_36\">\n",
       "      <path d=\"M 50.312344 534.449649 \n",
       "L 1065.692344 534.449649 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_49\">\n",
       "      <!-- 0.5 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.522344 538.386446) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <path d=\"M 50.312344 509.436454 \n",
       "L 1065.692344 509.436454 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_50\">\n",
       "      <!-- 0.6 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.522344 513.373251) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_51\">\n",
       "     <!-- density(Sens) -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(18.996719 615.1525) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-64\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(166.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(216.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" transform=\"translate(239.0625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-79\" transform=\"translate(266.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-28\" transform=\"translate(316.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-53\" transform=\"translate(350.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(472.460938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(528.076172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-29\" transform=\"translate(578.076172 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_38\">\n",
       "    <path d=\"M 254.260214 659.515625 \n",
       "L 374.118645 659.40876 \n",
       "L 383.440968 659.163895 \n",
       "L 402.085613 658.450046 \n",
       "L 408.300494 658.640386 \n",
       "L 418.066737 658.943362 \n",
       "L 446.033704 659.307761 \n",
       "L 484.654754 659.467346 \n",
       "L 502.855479 659.373571 \n",
       "L 511.289961 659.14867 \n",
       "L 526.827166 658.62127 \n",
       "L 539.256929 658.555582 \n",
       "L 545.915731 658.814713 \n",
       "L 553.462373 659.056323 \n",
       "L 589.863822 659.508647 \n",
       "L 650.236958 659.515625 \n",
       "L 697.73641 659.515625 \n",
       "L 697.73641 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_39\">\n",
       "    <path d=\"M 96.46598 659.515625 \n",
       "L 200.348879 659.405647 \n",
       "L 214.80877 659.043893 \n",
       "L 233.454419 658.481386 \n",
       "L 239.16227 658.589334 \n",
       "L 250.958497 658.89416 \n",
       "L 261.23263 659.068641 \n",
       "L 275.311997 659.462013 \n",
       "L 290.913458 659.513059 \n",
       "L 313.364341 659.403672 \n",
       "L 334.29313 659.023625 \n",
       "L 344.18674 658.536277 \n",
       "L 353.699826 658.093555 \n",
       "L 357.885584 658.154115 \n",
       "L 362.832389 658.489789 \n",
       "L 371.584428 659.101814 \n",
       "L 379.57542 659.393391 \n",
       "L 388.707982 659.506419 \n",
       "L 425.238233 659.515625 \n",
       "L 476.608897 659.515625 \n",
       "L 476.608897 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #348abd; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_40\">\n",
       "    <path d=\"M 280.077517 659.515625 \n",
       "L 358.414861 659.411065 \n",
       "L 364.464076 659.27832 \n",
       "L 366.278841 659.182284 \n",
       "L 368.396066 658.785902 \n",
       "L 370.513292 658.220738 \n",
       "L 371.723135 657.613555 \n",
       "L 372.630517 656.959602 \n",
       "L 373.5379 656.024079 \n",
       "L 374.445282 654.716724 \n",
       "L 375.655125 652.837501 \n",
       "L 376.260047 652.219185 \n",
       "L 376.864968 652.005475 \n",
       "L 377.46989 652.210671 \n",
       "L 378.074812 652.735285 \n",
       "L 381.40188 656.296308 \n",
       "L 382.309263 656.815037 \n",
       "L 383.216645 657.041383 \n",
       "L 386.846174 657.53697 \n",
       "L 388.660939 657.85071 \n",
       "L 390.475704 658.158023 \n",
       "L 393.802772 658.925263 \n",
       "L 398.339684 659.344126 \n",
       "L 400.45691 659.326593 \n",
       "L 403.179057 659.257806 \n",
       "L 407.413508 659.328883 \n",
       "L 413.765184 659.235195 \n",
       "L 415.88241 659.288804 \n",
       "L 418.907018 659.326618 \n",
       "L 424.048851 659.282748 \n",
       "L 426.770998 659.437297 \n",
       "L 437.054665 659.48208 \n",
       "L 504.200959 659.512768 \n",
       "L 582.235841 659.515625 \n",
       "L 582.235841 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #988ed5; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_41\">\n",
       "    <path d=\"M 110.435933 659.515625 \n",
       "L 359.779437 659.420157 \n",
       "L 363.419488 659.213789 \n",
       "L 366.149526 658.873094 \n",
       "L 367.969552 658.486767 \n",
       "L 369.789577 657.923781 \n",
       "L 372.519616 656.746022 \n",
       "L 374.339641 656.014212 \n",
       "L 375.249654 655.801874 \n",
       "L 376.159667 655.735096 \n",
       "L 377.979692 655.988985 \n",
       "L 380.709731 656.646555 \n",
       "L 382.529756 656.879814 \n",
       "L 386.169808 657.175236 \n",
       "L 389.809859 657.851416 \n",
       "L 391.629884 658.109046 \n",
       "L 404.370063 659.0533 \n",
       "L 411.650166 659.063748 \n",
       "L 418.020255 659.28728 \n",
       "L 479.901125 659.491529 \n",
       "L 497.191368 659.506906 \n",
       "L 703.76427 659.515336 \n",
       "L 1019.538707 659.515625 \n",
       "L 1019.538707 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #777777; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_42\">\n",
       "    <path d=\"M 370.957652 659.515625 \n",
       "L 372.857558 659.413242 \n",
       "L 372.935832 658.727948 \n",
       "L 373.049684 658.979595 \n",
       "L 373.170651 658.812278 \n",
       "L 373.120841 659.056344 \n",
       "L 373.184883 658.853707 \n",
       "L 373.270272 659.485524 \n",
       "L 373.34143 659.225582 \n",
       "L 373.398356 659.022711 \n",
       "L 373.448166 659.197404 \n",
       "L 373.483745 659.25968 \n",
       "L 373.526439 659.105305 \n",
       "L 373.661638 658.368301 \n",
       "L 373.690101 658.583895 \n",
       "L 373.72568 658.856913 \n",
       "L 373.761259 658.146769 \n",
       "L 374.017426 643.696448 \n",
       "L 374.181088 615.532865 \n",
       "L 374.230899 627.781409 \n",
       "L 374.259362 632.456485 \n",
       "L 374.302056 618.020719 \n",
       "L 374.423024 570.916661 \n",
       "L 374.458603 589.59943 \n",
       "L 374.487066 603.378578 \n",
       "L 374.52976 573.910968 \n",
       "L 374.593802 497.428125 \n",
       "L 374.686307 502.584296 \n",
       "L 374.707654 500.247491 \n",
       "L 374.757464 509.480181 \n",
       "L 375.177294 641.285673 \n",
       "L 375.376535 653.008381 \n",
       "L 375.412114 650.628173 \n",
       "L 375.454808 645.949918 \n",
       "L 375.504619 652.615448 \n",
       "L 375.56866 656.773745 \n",
       "L 375.639818 656.75815 \n",
       "L 375.917332 659.20103 \n",
       "L 375.995606 659.064144 \n",
       "L 376.123689 659.39364 \n",
       "L 376.201962 659.3603 \n",
       "L 376.828149 659.515625 \n",
       "L 378.06629 659.515625 \n",
       "L 378.06629 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #fbc15e; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_43\">\n",
       "    <path d=\"M 368.441796 659.515625 \n",
       "L 372.271598 659.407094 \n",
       "L 372.52855 658.94555 \n",
       "L 372.6142 659.087432 \n",
       "L 372.809973 659.241678 \n",
       "L 372.956803 659.194136 \n",
       "L 373.238226 658.643962 \n",
       "L 373.385055 657.397675 \n",
       "L 373.617535 655.993257 \n",
       "L 373.727657 654.611754 \n",
       "L 373.996845 646.784998 \n",
       "L 374.168146 634.295362 \n",
       "L 374.339447 604.229222 \n",
       "L 374.535219 576.444381 \n",
       "L 374.559691 576.809506 \n",
       "L 374.645342 584.074967 \n",
       "L 375.122537 639.798821 \n",
       "L 375.134773 639.663118 \n",
       "L 375.195952 636.079002 \n",
       "L 375.355017 617.822188 \n",
       "L 375.416196 623.421514 \n",
       "L 375.697619 655.708142 \n",
       "L 375.991278 656.971567 \n",
       "L 376.027986 656.917703 \n",
       "L 376.113636 656.227224 \n",
       "L 376.211523 652.746188 \n",
       "L 376.456238 632.082628 \n",
       "L 376.578596 634.096323 \n",
       "L 376.664247 638.44598 \n",
       "L 376.908963 650.716793 \n",
       "L 376.982377 651.223506 \n",
       "L 377.679817 659.413739 \n",
       "L 377.863354 659.514942 \n",
       "L 380.66535 659.515625 \n",
       "L 380.66535 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #8eba42; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_44\">\n",
       "    <path d=\"M 164.764412 659.515625 \n",
       "L 280.251185 659.406417 \n",
       "L 287.017988 659.380595 \n",
       "L 300.551594 659.490297 \n",
       "L 333.934489 659.339013 \n",
       "L 355.137138 658.729565 \n",
       "L 368.219624 657.96537 \n",
       "L 371.377466 657.751779 \n",
       "L 373.633067 657.826024 \n",
       "L 375.888668 658.169232 \n",
       "L 381.753231 659.284195 \n",
       "L 384.459952 659.459139 \n",
       "L 389.873394 659.513102 \n",
       "L 403.407 659.418068 \n",
       "L 407.467082 659.220233 \n",
       "L 410.173803 658.864638 \n",
       "L 412.429404 658.327329 \n",
       "L 416.940606 657.095701 \n",
       "L 418.293967 656.956826 \n",
       "L 420.098448 657.03271 \n",
       "L 422.354049 657.421254 \n",
       "L 428.218612 658.56061 \n",
       "L 431.376453 658.903388 \n",
       "L 435.887655 659.090707 \n",
       "L 448.0679 659.466035 \n",
       "L 485.059757 659.506539 \n",
       "L 615.433496 659.515625 \n",
       "L 615.433496 659.515625 \n",
       "\" clip-path=\"url(#p27d7657353)\" style=\"fill: none; stroke: #ffb5b8; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_27\">\n",
       "    <path d=\"M 50.312344 667.62 \n",
       "L 50.312344 489.32375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path d=\"M 1065.692344 667.62 \n",
       "L 1065.692344 489.32375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path d=\"M 50.312344 667.62 \n",
       "L 1065.692344 667.62 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path d=\"M 50.312344 489.32375 \n",
       "L 1065.692344 489.32375 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"legend_2\">\n",
       "    <g id=\"patch_31\">\n",
       "     <path d=\"M 928.011875 607.434531 \n",
       "L 1057.992344 607.434531 \n",
       "Q 1060.192344 607.434531 1060.192344 605.234531 \n",
       "L 1060.192344 497.02375 \n",
       "Q 1060.192344 494.82375 1057.992344 494.82375 \n",
       "L 928.011875 494.82375 \n",
       "Q 925.811875 494.82375 925.811875 497.02375 \n",
       "L 925.811875 605.234531 \n",
       "Q 925.811875 607.434531 928.011875 607.434531 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_45\">\n",
       "     <path d=\"M 930.211875 503.381406 \n",
       "L 941.211875 503.381406 \n",
       "L 952.211875 503.381406 \n",
       "\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_52\">\n",
       "     <!-- num__S -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(961.011875 507.231406) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-6e\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-53\" transform=\"translate(305.761719 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_46\">\n",
       "     <path d=\"M 930.211875 518.94125 \n",
       "L 941.211875 518.94125 \n",
       "L 952.211875 518.94125 \n",
       "\" style=\"fill: none; stroke: #348abd; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_53\">\n",
       "     <!-- num__K -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(961.011875 522.79125) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-6e\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-4b\" transform=\"translate(305.761719 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_47\">\n",
       "     <path d=\"M 930.211875 534.501094 \n",
       "L 941.211875 534.501094 \n",
       "L 952.211875 534.501094 \n",
       "\" style=\"fill: none; stroke: #988ed5; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_54\">\n",
       "     <!-- num__T -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(961.011875 538.351094) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-6e\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-54\" transform=\"translate(305.761719 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_48\">\n",
       "     <path d=\"M 930.211875 550.060938 \n",
       "L 941.211875 550.060938 \n",
       "L 952.211875 550.060938 \n",
       "\" style=\"fill: none; stroke: #777777; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_55\">\n",
       "     <!-- num__sigma -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(961.011875 553.910938) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-6e\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(305.761719 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(355.761719 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-67\" transform=\"translate(377.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(433.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(516.894531 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_49\">\n",
       "     <path d=\"M 930.211875 565.749687 \n",
       "L 941.211875 565.749687 \n",
       "L 952.211875 565.749687 \n",
       "\" style=\"fill: none; stroke: #fbc15e; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_56\">\n",
       "     <!-- num__openInterest -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(961.011875 569.599687) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-6e\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(305.761719 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(361.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(416.992188 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(472.607422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-49\" transform=\"translate(528.222656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(556.005859 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" transform=\"translate(611.621094 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(639.404297 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(695.019531 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(728.320312 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-73\" transform=\"translate(783.935547 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-74\" transform=\"translate(833.935547 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_50\">\n",
       "     <path d=\"M 930.211875 581.309531 \n",
       "L 941.211875 581.309531 \n",
       "L 952.211875 581.309531 \n",
       "\" style=\"fill: none; stroke: #8eba42; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_57\">\n",
       "     <!-- num__volume -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(961.011875 585.159531) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-6e\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(305.761719 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(355.761719 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(433.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(489.208984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(572.509766 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_51\">\n",
       "     <path d=\"M 930.211875 596.869375 \n",
       "L 941.211875 596.869375 \n",
       "L 952.211875 596.869375 \n",
       "\" style=\"fill: none; stroke: #ffb5b8; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "    </g>\n",
       "    <g id=\"text_58\">\n",
       "     <!-- num__inTheMoney -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(961.011875 600.719375) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-6e\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(305.761719 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-54\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-68\" transform=\"translate(444.677734 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(500.292969 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-4d\" transform=\"translate(555.908203 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(639.208984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(694.824219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(750.439453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-79\" transform=\"translate(806.054688 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"text_59\">\n",
       "   <!-- Sensitivity plots -->\n",
       "   <g style=\"fill: #262626\" transform=\"translate(495.143906 15.935625) scale(0.12 -0.12)\">\n",
       "    <use xlink:href=\"#ArialMT-53\"/>\n",
       "    <use xlink:href=\"#ArialMT-65\" transform=\"translate(66.699219 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-6e\" transform=\"translate(122.314453 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-73\" transform=\"translate(177.929688 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-69\" transform=\"translate(227.929688 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-74\" transform=\"translate(250.146484 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-69\" transform=\"translate(277.929688 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-76\" transform=\"translate(300.146484 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-69\" transform=\"translate(350.146484 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-74\" transform=\"translate(372.363281 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-79\" transform=\"translate(400.146484 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-20\" transform=\"translate(450.146484 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-70\" transform=\"translate(477.929688 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-6c\" transform=\"translate(533.544922 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-6f\" transform=\"translate(555.761719 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-74\" transform=\"translate(611.376953 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-73\" transform=\"translate(639.160156 0)\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"p9d8cece06e\">\n",
       "   <rect x=\"50.312344\" y=\"42.05625\" width=\"1015.38\" height=\"178.29625\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pb02bb5d1ed\">\n",
       "   <rect x=\"50.312344\" y=\"265.69\" width=\"1015.38\" height=\"178.29625\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p27d7657353\">\n",
       "   <rect x=\"50.312344\" y=\"489.32375\" width=\"1015.38\" height=\"178.29625\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1500x1000 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sensmlp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9df03583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: xlabel='$\\\\alpha$', ylabel='$(ms_{X,j}^\\\\alpha(f))$'>,\n",
       "       <Axes: >], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"677.37625pt\" height=\"550.054219pt\" viewBox=\"0 0 677.37625 550.054219\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-06-08T16:44:48.804470</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 550.054219 \n",
       "L 677.37625 550.054219 \n",
       "L 677.37625 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 59.688125 508.32 \n",
       "L 484.830982 508.32 \n",
       "L 484.830982 64.8 \n",
       "L 59.688125 64.8 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 79.0128 508.32 \n",
       "L 79.0128 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 1 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(75.954285 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 104.779034 508.32 \n",
       "L 104.779034 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(101.720518 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 130.545268 508.32 \n",
       "L 130.545268 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 3 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(127.486752 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 156.311502 508.32 \n",
       "L 156.311502 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 4 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(153.252986 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 182.077735 508.32 \n",
       "L 182.077735 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 5 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(179.01922 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 207.843969 508.32 \n",
       "L 207.843969 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 6 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(204.785454 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 233.610203 508.32 \n",
       "L 233.610203 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 7 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(230.551687 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-37\" d=\"M 303 3981 \n",
       "L 303 4522 \n",
       "L 3269 4522 \n",
       "L 3269 4084 \n",
       "Q 2831 3619 2401 2847 \n",
       "Q 1972 2075 1738 1259 \n",
       "Q 1569 684 1522 0 \n",
       "L 944 0 \n",
       "Q 953 541 1156 1306 \n",
       "Q 1359 2072 1739 2783 \n",
       "Q 2119 3494 2547 3981 \n",
       "L 303 3981 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-37\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 259.376437 508.32 \n",
       "L 259.376437 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_8\">\n",
       "      <!-- 8 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(256.317921 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-38\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 285.14267 508.32 \n",
       "L 285.14267 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 9 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(282.084155 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-39\" d=\"M 350 1059 \n",
       "L 891 1109 \n",
       "Q 959 728 1153 556 \n",
       "Q 1347 384 1650 384 \n",
       "Q 1909 384 2104 503 \n",
       "Q 2300 622 2425 820 \n",
       "Q 2550 1019 2634 1356 \n",
       "Q 2719 1694 2719 2044 \n",
       "Q 2719 2081 2716 2156 \n",
       "Q 2547 1888 2255 1720 \n",
       "Q 1963 1553 1622 1553 \n",
       "Q 1053 1553 659 1965 \n",
       "Q 266 2378 266 3053 \n",
       "Q 266 3750 677 4175 \n",
       "Q 1088 4600 1706 4600 \n",
       "Q 2153 4600 2523 4359 \n",
       "Q 2894 4119 3086 3673 \n",
       "Q 3278 3228 3278 2384 \n",
       "Q 3278 1506 3087 986 \n",
       "Q 2897 466 2520 194 \n",
       "Q 2144 -78 1638 -78 \n",
       "Q 1100 -78 759 220 \n",
       "Q 419 519 350 1059 \n",
       "z\n",
       "M 2653 3081 \n",
       "Q 2653 3566 2395 3850 \n",
       "Q 2138 4134 1775 4134 \n",
       "Q 1400 4134 1122 3828 \n",
       "Q 844 3522 844 3034 \n",
       "Q 844 2597 1108 2323 \n",
       "Q 1372 2050 1759 2050 \n",
       "Q 2150 2050 2401 2323 \n",
       "Q 2653 2597 2653 3081 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-39\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 310.908904 508.32 \n",
       "L 310.908904 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 10 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(304.791873 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 336.675138 508.32 \n",
       "L 336.675138 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 11 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(330.963732 525.693594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-31\" transform=\"translate(48.240234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path d=\"M 362.441372 508.32 \n",
       "L 362.441372 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 12 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(356.324341 525.693594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 388.207606 508.32 \n",
       "L 388.207606 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 13 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(382.090574 525.693594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_14\">\n",
       "      <path d=\"M 413.973839 508.32 \n",
       "L 413.973839 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 14 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(407.856808 525.693594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_15\">\n",
       "      <path d=\"M 439.740073 508.32 \n",
       "L 439.740073 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_15\">\n",
       "      <!-- 15 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(433.623042 525.693594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_16\">\n",
       "     <g id=\"line2d_16\">\n",
       "      <path d=\"M 465.506307 508.32 \n",
       "L 465.506307 64.8 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_16\">\n",
       "      <!-- 16 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(459.389276 525.693594) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" transform=\"translate(55.615234 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- $\\alpha$ -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(268.299554 540.469219) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-Oblique-3b1\" d=\"M 2619 1628 \n",
       "L 2622 2350 \n",
       "Q 2625 3088 2069 3091 \n",
       "Q 1653 3094 1394 2747 \n",
       "Q 1069 2319 959 1747 \n",
       "Q 825 1059 994 731 \n",
       "Q 1169 397 1547 397 \n",
       "Q 1966 397 2319 1063 \n",
       "L 2619 1628 \n",
       "z\n",
       "M 2166 3578 \n",
       "Q 3141 3594 3128 2584 \n",
       "Q 3128 2584 3616 3500 \n",
       "L 4128 3500 \n",
       "L 3119 1603 \n",
       "L 3109 919 \n",
       "Q 3109 766 3194 638 \n",
       "Q 3291 488 3391 488 \n",
       "L 3669 488 \n",
       "L 3575 0 \n",
       "L 3228 0 \n",
       "Q 2934 0 2722 263 \n",
       "Q 2622 394 2619 669 \n",
       "Q 2416 334 2066 50 \n",
       "Q 1900 -81 1453 -78 \n",
       "Q 722 -72 456 397 \n",
       "Q 184 884 353 1747 \n",
       "Q 534 2675 1009 3097 \n",
       "Q 1544 3569 2166 3578 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-3b1\" transform=\"translate(0 0.84375)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_17\">\n",
       "      <path d=\"M 59.688125 488.388939 \n",
       "L 484.830982 488.388939 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_18\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(44.071094 492.325736) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_18\">\n",
       "      <path d=\"M 59.688125 420.261221 \n",
       "L 484.830982 420.261221 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(31.837031 424.198018) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 59.688125 352.133503 \n",
       "L 484.830982 352.133503 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- 400 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(31.837031 356.0703) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <path d=\"M 59.688125 284.005786 \n",
       "L 484.830982 284.005786 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- 600 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(31.837031 287.942583) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 59.688125 215.878068 \n",
       "L 484.830982 215.878068 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- 800 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(31.837031 219.814865) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-38\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <path d=\"M 59.688125 147.750351 \n",
       "L 484.830982 147.750351 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.72 151.687148) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 59.688125 79.622633 \n",
       "L 484.830982 79.622633 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 1200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(25.72 83.55943) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_25\">\n",
       "     <!-- $(ms_{X,j}^\\alpha(f))$ -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(16.68 313.38) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"DejaVuSans-28\" d=\"M 1984 4856 \n",
       "Q 1566 4138 1362 3434 \n",
       "Q 1159 2731 1159 2009 \n",
       "Q 1159 1288 1364 580 \n",
       "Q 1569 -128 1984 -844 \n",
       "L 1484 -844 \n",
       "Q 1016 -109 783 600 \n",
       "Q 550 1309 550 2009 \n",
       "Q 550 2706 781 3412 \n",
       "Q 1013 4119 1484 4856 \n",
       "L 1984 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-Oblique-6d\" d=\"M 5747 2113 \n",
       "L 5338 0 \n",
       "L 4763 0 \n",
       "L 5166 2094 \n",
       "Q 5191 2228 5203 2325 \n",
       "Q 5216 2422 5216 2491 \n",
       "Q 5216 2772 5059 2928 \n",
       "Q 4903 3084 4622 3084 \n",
       "Q 4203 3084 3875 2770 \n",
       "Q 3547 2456 3450 1953 \n",
       "L 3066 0 \n",
       "L 2491 0 \n",
       "L 2900 2094 \n",
       "Q 2925 2209 2937 2307 \n",
       "Q 2950 2406 2950 2484 \n",
       "Q 2950 2769 2794 2926 \n",
       "Q 2638 3084 2363 3084 \n",
       "Q 1938 3084 1609 2770 \n",
       "Q 1281 2456 1184 1953 \n",
       "L 800 0 \n",
       "L 225 0 \n",
       "L 909 3500 \n",
       "L 1484 3500 \n",
       "L 1375 2956 \n",
       "Q 1609 3263 1923 3423 \n",
       "Q 2238 3584 2597 3584 \n",
       "Q 2978 3584 3223 3384 \n",
       "Q 3469 3184 3519 2828 \n",
       "Q 3781 3197 4126 3390 \n",
       "Q 4472 3584 4856 3584 \n",
       "Q 5306 3584 5551 3325 \n",
       "Q 5797 3066 5797 2591 \n",
       "Q 5797 2488 5784 2364 \n",
       "Q 5772 2241 5747 2113 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-Oblique-73\" d=\"M 3200 3397 \n",
       "L 3091 2853 \n",
       "Q 2863 2978 2609 3040 \n",
       "Q 2356 3103 2088 3103 \n",
       "Q 1634 3103 1373 2948 \n",
       "Q 1113 2794 1113 2528 \n",
       "Q 1113 2219 1719 2053 \n",
       "Q 1766 2041 1788 2034 \n",
       "L 1972 1978 \n",
       "Q 2547 1819 2739 1644 \n",
       "Q 2931 1469 2931 1166 \n",
       "Q 2931 609 2489 259 \n",
       "Q 2047 -91 1331 -91 \n",
       "Q 1053 -91 747 -37 \n",
       "Q 441 16 72 128 \n",
       "L 184 722 \n",
       "Q 500 559 806 475 \n",
       "Q 1113 391 1394 391 \n",
       "Q 1816 391 2080 572 \n",
       "Q 2344 753 2344 1031 \n",
       "Q 2344 1331 1650 1516 \n",
       "L 1591 1531 \n",
       "L 1394 1581 \n",
       "Q 956 1697 753 1886 \n",
       "Q 550 2075 550 2369 \n",
       "Q 550 2928 970 3256 \n",
       "Q 1391 3584 2113 3584 \n",
       "Q 2397 3584 2667 3537 \n",
       "Q 2938 3491 3200 3397 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-Oblique-58\" d=\"M 878 4666 \n",
       "L 1516 4666 \n",
       "L 2316 2981 \n",
       "L 3763 4666 \n",
       "L 4500 4666 \n",
       "L 2578 2438 \n",
       "L 3738 0 \n",
       "L 3103 0 \n",
       "L 2163 1966 \n",
       "L 459 0 \n",
       "L -275 0 \n",
       "L 1906 2509 \n",
       "L 878 4666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-2c\" d=\"M 750 794 \n",
       "L 1409 794 \n",
       "L 1409 256 \n",
       "L 897 -744 \n",
       "L 494 -744 \n",
       "L 750 256 \n",
       "L 750 794 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-Oblique-6a\" d=\"M 928 3500 \n",
       "L 1503 3500 \n",
       "L 813 -63 \n",
       "L 809 -78 \n",
       "Q 694 -675 544 -897 \n",
       "Q 403 -1106 132 -1218 \n",
       "Q -138 -1331 -506 -1331 \n",
       "L -722 -1331 \n",
       "L -628 -844 \n",
       "L -481 -844 \n",
       "Q -144 -844 -1 -703 \n",
       "Q 141 -563 238 -63 \n",
       "L 928 3500 \n",
       "z\n",
       "M 1197 4863 \n",
       "L 1772 4863 \n",
       "L 1631 4134 \n",
       "L 1056 4134 \n",
       "L 1197 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-Oblique-66\" d=\"M 3059 4863 \n",
       "L 2969 4384 \n",
       "L 2419 4384 \n",
       "Q 2106 4384 1964 4261 \n",
       "Q 1822 4138 1753 3809 \n",
       "L 1691 3500 \n",
       "L 2638 3500 \n",
       "L 2553 3053 \n",
       "L 1606 3053 \n",
       "L 1013 0 \n",
       "L 434 0 \n",
       "L 1031 3053 \n",
       "L 481 3053 \n",
       "L 563 3500 \n",
       "L 1113 3500 \n",
       "L 1159 3744 \n",
       "Q 1278 4363 1576 4613 \n",
       "Q 1875 4863 2516 4863 \n",
       "L 3059 4863 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"DejaVuSans-29\" d=\"M 513 4856 \n",
       "L 1013 4856 \n",
       "Q 1481 4119 1714 3412 \n",
       "Q 1947 2706 1947 2009 \n",
       "Q 1947 1309 1714 600 \n",
       "Q 1481 -109 1013 -844 \n",
       "L 513 -844 \n",
       "Q 928 -128 1133 580 \n",
       "Q 1338 1288 1338 2009 \n",
       "Q 1338 2731 1133 3434 \n",
       "Q 928 4138 513 4856 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(0 0.459375)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-6d\" transform=\"translate(39.013672 0.459375)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-73\" transform=\"translate(136.425781 0.459375)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-3b1\" transform=\"translate(193.175286 39.690625) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-58\" transform=\"translate(188.525391 -26.884375) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(236.479492 -26.884375) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-6a\" transform=\"translate(272.368164 -26.884375) scale(0.7)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(294.550781 0.459375)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-Oblique-66\" transform=\"translate(333.564453 0.459375)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(368.769531 0.459375)\"/>\n",
       "      <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(407.783203 0.459375)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_24\">\n",
       "    <path d=\"M 79.0128 393.865453 \n",
       "L 104.779034 375.135796 \n",
       "L 130.545268 363.512069 \n",
       "L 156.311502 355.942262 \n",
       "L 182.077735 350.625743 \n",
       "L 207.843969 346.632616 \n",
       "L 233.610203 343.469187 \n",
       "L 259.376437 340.857406 \n",
       "L 285.14267 338.631299 \n",
       "L 310.908904 336.686682 \n",
       "L 336.675138 334.955333 \n",
       "L 362.441372 333.390947 \n",
       "L 388.207606 331.961106 \n",
       "L 413.973839 330.642476 \n",
       "L 439.740073 329.417825 \n",
       "L 465.506307 328.274114 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #8000ff; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_25\">\n",
       "    <path d=\"M 79.0128 411.613909 \n",
       "L 104.779034 392.875077 \n",
       "L 130.545268 381.719589 \n",
       "L 156.311502 374.692404 \n",
       "L 182.077735 369.861197 \n",
       "L 207.843969 366.282608 \n",
       "L 233.610203 363.476458 \n",
       "L 259.376437 361.180009 \n",
       "L 285.14267 359.239188 \n",
       "L 310.908904 357.558088 \n",
       "L 336.675138 356.073947 \n",
       "L 362.441372 354.743931 \n",
       "L 388.207606 353.537751 \n",
       "L 413.973839 352.433332 \n",
       "L 439.740073 351.414164 \n",
       "L 465.506307 350.467615 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #386df9; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_26\">\n",
       "    <path d=\"M 79.0128 479.268567 \n",
       "L 104.779034 471.979527 \n",
       "L 130.545268 463.705566 \n",
       "L 156.311502 455.766127 \n",
       "L 182.077735 448.598398 \n",
       "L 207.843969 442.271109 \n",
       "L 233.610203 436.731887 \n",
       "L 259.376437 431.887031 \n",
       "L 285.14267 427.635867 \n",
       "L 310.908904 423.886051 \n",
       "L 336.675138 420.558524 \n",
       "L 362.441372 417.587621 \n",
       "L 388.207606 414.919404 \n",
       "L 413.973839 412.509639 \n",
       "L 439.740073 410.321942 \n",
       "L 465.506307 408.326235 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #12c8e6; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_27\">\n",
       "    <path d=\"M 79.0128 472.819109 \n",
       "L 104.779034 456.506029 \n",
       "L 130.545268 432.530709 \n",
       "L 156.311502 405.88639 \n",
       "L 182.077735 380.323678 \n",
       "L 207.843969 357.157927 \n",
       "L 233.610203 336.608877 \n",
       "L 259.376437 318.513188 \n",
       "L 285.14267 302.593566 \n",
       "L 310.908904 288.55873 \n",
       "L 336.675138 276.139975 \n",
       "L 362.441372 265.102473 \n",
       "L 388.207606 255.246203 \n",
       "L 413.973839 246.402853 \n",
       "L 439.740073 238.431488 \n",
       "L 465.506307 231.214173 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #5af8c8; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_28\">\n",
       "    <path d=\"M 79.0128 488.16 \n",
       "L 104.779034 488.070688 \n",
       "L 130.545268 487.988067 \n",
       "L 156.311502 487.907603 \n",
       "L 182.077735 487.827279 \n",
       "L 207.843969 487.748503 \n",
       "L 233.610203 487.673918 \n",
       "L 259.376437 487.605383 \n",
       "L 285.14267 487.543527 \n",
       "L 310.908904 487.488144 \n",
       "L 336.675138 487.438641 \n",
       "L 362.441372 487.394313 \n",
       "L 388.207606 487.354477 \n",
       "L 413.973839 487.318521 \n",
       "L 439.740073 487.285915 \n",
       "L 465.506307 487.256209 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #a4f89f; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_29\">\n",
       "    <path d=\"M 79.0128 487.749946 \n",
       "L 104.779034 487.469162 \n",
       "L 130.545268 487.253029 \n",
       "L 156.311502 487.093185 \n",
       "L 182.077735 486.971618 \n",
       "L 207.843969 486.875154 \n",
       "L 233.610203 486.795567 \n",
       "L 259.376437 486.72784 \n",
       "L 285.14267 486.668854 \n",
       "L 310.908904 486.61661 \n",
       "L 336.675138 486.569765 \n",
       "L 362.441372 486.527377 \n",
       "L 388.207606 486.488751 \n",
       "L 413.973839 486.453349 \n",
       "L 439.740073 486.420738 \n",
       "L 465.506307 486.390562 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ecc86f; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_30\">\n",
       "    <path d=\"M 79.0128 457.704983 \n",
       "L 104.779034 450.867208 \n",
       "L 130.545268 446.216684 \n",
       "L 156.311502 442.255719 \n",
       "L 182.077735 438.503976 \n",
       "L 207.843969 434.858686 \n",
       "L 233.610203 431.357003 \n",
       "L 259.376437 428.056358 \n",
       "L 285.14267 424.98877 \n",
       "L 310.908904 422.158268 \n",
       "L 336.675138 419.55213 \n",
       "L 362.441372 417.151119 \n",
       "L 388.207606 414.935329 \n",
       "L 413.973839 412.886606 \n",
       "L 439.740073 410.989098 \n",
       "L 465.506307 409.229039 \n",
       "\" clip-path=\"url(#pea6c89c4da)\" style=\"fill: none; stroke: #ff6d38; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 59.688125 508.32 \n",
       "L 59.688125 64.8 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 484.830982 508.32 \n",
       "L 484.830982 64.8 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 59.688125 508.32 \n",
       "L 484.830982 508.32 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 59.688125 64.8 \n",
       "L 484.830982 64.8 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 511.402411 508.32 \n",
       "L 617.688125 508.32 \n",
       "L 617.688125 64.8 \n",
       "L 511.402411 64.8 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"axes_3\">\n",
       "    <g id=\"patch_8\">\n",
       "     <path d=\"M 617.688125 508.32 \n",
       "L 617.688125 508.32 \n",
       "L 617.688125 64.8 \n",
       "L 617.688125 64.8 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "    </g>\n",
       "    <g id=\"matplotlib.axis_3\"/>\n",
       "    <g id=\"matplotlib.axis_4\">\n",
       "     <g id=\"ytick_8\">\n",
       "      <g id=\"line2d_31\">\n",
       "       <path d=\"M 617.688125 488.388939 \n",
       "L 617.688125 488.388939 \n",
       "\" clip-path=\"url(#p6411dbac4d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "      </g>\n",
       "      <g id=\"line2d_32\">\n",
       "       <defs>\n",
       "        <path id=\"mf28ed89bca\" d=\"M 0 0 \n",
       "L 6 0 \n",
       "\" style=\"stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </defs>\n",
       "       <g>\n",
       "        <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"488.388939\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "      <g id=\"text_26\">\n",
       "       <!-- 0 -->\n",
       "       <g style=\"fill: #555555\" transform=\"translate(627.188125 492.325736) scale(0.11 -0.11)\">\n",
       "        <use xlink:href=\"#ArialMT-30\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"ytick_9\">\n",
       "      <g id=\"line2d_33\">\n",
       "       <path d=\"M 617.688125 420.261221 \n",
       "L 617.688125 420.261221 \n",
       "\" clip-path=\"url(#p6411dbac4d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "      </g>\n",
       "      <g id=\"line2d_34\">\n",
       "       <g>\n",
       "        <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"420.261221\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "      <g id=\"text_27\">\n",
       "       <!-- 200 -->\n",
       "       <g style=\"fill: #555555\" transform=\"translate(627.188125 424.198018) scale(0.11 -0.11)\">\n",
       "        <use xlink:href=\"#ArialMT-32\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"ytick_10\">\n",
       "      <g id=\"line2d_35\">\n",
       "       <path d=\"M 617.688125 352.133503 \n",
       "L 617.688125 352.133503 \n",
       "\" clip-path=\"url(#p6411dbac4d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "      </g>\n",
       "      <g id=\"line2d_36\">\n",
       "       <g>\n",
       "        <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"352.133503\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "      <g id=\"text_28\">\n",
       "       <!-- 400 -->\n",
       "       <g style=\"fill: #555555\" transform=\"translate(627.188125 356.0703) scale(0.11 -0.11)\">\n",
       "        <use xlink:href=\"#ArialMT-34\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"ytick_11\">\n",
       "      <g id=\"line2d_37\">\n",
       "       <path d=\"M 617.688125 284.005786 \n",
       "L 617.688125 284.005786 \n",
       "\" clip-path=\"url(#p6411dbac4d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "      </g>\n",
       "      <g id=\"line2d_38\">\n",
       "       <g>\n",
       "        <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"284.005786\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "      <g id=\"text_29\">\n",
       "       <!-- 600 -->\n",
       "       <g style=\"fill: #555555\" transform=\"translate(627.188125 287.942583) scale(0.11 -0.11)\">\n",
       "        <use xlink:href=\"#ArialMT-36\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"ytick_12\">\n",
       "      <g id=\"line2d_39\">\n",
       "       <path d=\"M 617.688125 215.878068 \n",
       "L 617.688125 215.878068 \n",
       "\" clip-path=\"url(#p6411dbac4d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "      </g>\n",
       "      <g id=\"line2d_40\">\n",
       "       <g>\n",
       "        <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"215.878068\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "      <g id=\"text_30\">\n",
       "       <!-- 800 -->\n",
       "       <g style=\"fill: #555555\" transform=\"translate(627.188125 219.814865) scale(0.11 -0.11)\">\n",
       "        <use xlink:href=\"#ArialMT-38\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"ytick_13\">\n",
       "      <g id=\"line2d_41\">\n",
       "       <path d=\"M 617.688125 147.750351 \n",
       "L 617.688125 147.750351 \n",
       "\" clip-path=\"url(#p6411dbac4d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "      </g>\n",
       "      <g id=\"line2d_42\">\n",
       "       <g>\n",
       "        <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"147.750351\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "      <g id=\"text_31\">\n",
       "       <!-- 1000 -->\n",
       "       <g style=\"fill: #555555\" transform=\"translate(627.188125 151.687148) scale(0.11 -0.11)\">\n",
       "        <use xlink:href=\"#ArialMT-31\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"ytick_14\">\n",
       "      <g id=\"line2d_43\">\n",
       "       <path d=\"M 617.688125 79.622633 \n",
       "L 617.688125 79.622633 \n",
       "\" clip-path=\"url(#p6411dbac4d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "      </g>\n",
       "      <g id=\"line2d_44\">\n",
       "       <g>\n",
       "        <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"79.622633\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "      <g id=\"text_32\">\n",
       "       <!-- 1200 -->\n",
       "       <g style=\"fill: #555555\" transform=\"translate(627.188125 83.55943) scale(0.11 -0.11)\">\n",
       "        <use xlink:href=\"#ArialMT-31\"/>\n",
       "        <use xlink:href=\"#ArialMT-32\" transform=\"translate(55.615234 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "        <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       </g>\n",
       "      </g>\n",
       "     </g>\n",
       "     <g id=\"text_33\">\n",
       "      <!-- $(ms_{X,j}^\\alpha(f))^\\alpha$ -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(665.13625 316.38) rotate(-90) scale(0.12 -0.12)\">\n",
       "       <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(0 0.459375)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-Oblique-6d\" transform=\"translate(39.013672 0.459375)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-Oblique-73\" transform=\"translate(136.425781 0.459375)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-Oblique-3b1\" transform=\"translate(193.175286 39.690625) scale(0.7)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-Oblique-58\" transform=\"translate(188.525391 -26.884375) scale(0.7)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-2c\" transform=\"translate(236.479492 -26.884375) scale(0.7)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-Oblique-6a\" transform=\"translate(272.368164 -26.884375) scale(0.7)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-28\" transform=\"translate(294.550781 0.459375)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-Oblique-66\" transform=\"translate(333.564453 0.459375)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(368.769531 0.459375)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-29\" transform=\"translate(407.783203 0.459375)\"/>\n",
       "       <use xlink:href=\"#DejaVuSans-Oblique-3b1\" transform=\"translate(447.753906 38.740625) scale(0.7)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"patch_9\">\n",
       "     <path d=\"M 617.688125 508.32 \n",
       "L 617.688125 64.8 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_5\">\n",
       "    <g id=\"xtick_17\">\n",
       "     <g id=\"line2d_45\">\n",
       "      <path d=\"M 530.727086 508.32 \n",
       "L 530.727086 64.8 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_34\">\n",
       "      <!-- $\\infty$ -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.107086 525.693594) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"DejaVuSans-221e\" d=\"M 2916 1091 \n",
       "Q 2819 1203 2666 1466 \n",
       "Q 2456 1091 2272 925 \n",
       "Q 2041 725 1681 725 \n",
       "Q 1259 725 981 1041 \n",
       "Q 688 1372 688 1919 \n",
       "Q 688 2444 981 2800 \n",
       "Q 1244 3116 1688 3116 \n",
       "Q 1916 3116 2084 3022 \n",
       "Q 2281 2919 2416 2741 \n",
       "Q 2541 2581 2666 2366 \n",
       "Q 2875 2741 3059 2906 \n",
       "Q 3291 3106 3650 3106 \n",
       "Q 4072 3106 4350 2791 \n",
       "Q 4644 2459 4644 1913 \n",
       "Q 4644 1388 4350 1031 \n",
       "Q 4088 716 3644 716 \n",
       "Q 3416 716 3247 809 \n",
       "Q 3078 894 2916 1091 \n",
       "z\n",
       "M 1647 1134 \n",
       "Q 2163 1134 2472 1884 \n",
       "Q 2075 2703 1647 2703 \n",
       "Q 1334 2703 1175 2478 \n",
       "Q 1003 2238 1003 1919 \n",
       "Q 1003 1569 1175 1353 \n",
       "Q 1350 1134 1647 1134 \n",
       "z\n",
       "M 3684 2697 \n",
       "Q 3219 2697 2859 1947 \n",
       "Q 3253 1128 3684 1128 \n",
       "Q 3997 1128 4156 1353 \n",
       "Q 4328 1594 4328 1913 \n",
       "Q 4328 2263 4156 2478 \n",
       "Q 3981 2697 3684 2697 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#DejaVuSans-221e\" transform=\"translate(0 0.3125)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_6\">\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_46\">\n",
       "      <path d=\"M 511.402411 488.388939 \n",
       "L 617.688125 488.388939 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_47\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"488.388939\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_48\">\n",
       "      <path d=\"M 511.402411 420.261221 \n",
       "L 617.688125 420.261221 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_49\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"420.261221\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_50\">\n",
       "      <path d=\"M 511.402411 352.133503 \n",
       "L 617.688125 352.133503 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_51\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"352.133503\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_52\">\n",
       "      <path d=\"M 511.402411 284.005786 \n",
       "L 617.688125 284.005786 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_53\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"284.005786\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_54\">\n",
       "      <path d=\"M 511.402411 215.878068 \n",
       "L 617.688125 215.878068 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_55\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"215.878068\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_20\">\n",
       "     <g id=\"line2d_56\">\n",
       "      <path d=\"M 511.402411 147.750351 \n",
       "L 617.688125 147.750351 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_57\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"147.750351\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_21\">\n",
       "     <g id=\"line2d_58\">\n",
       "      <path d=\"M 511.402411 79.622633 \n",
       "L 617.688125 79.622633 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"line2d_59\">\n",
       "      <g>\n",
       "       <use xlink:href=\"#mf28ed89bca\" x=\"617.688125\" y=\"79.622633\" style=\"fill: #555555; stroke: #555555; stroke-width: 1.25\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 465.506307 328.274114 \n",
       "Q 493.285528 305.840173 521.064748 283.406232 \n",
       "\" style=\"fill: none; stroke-dasharray: 3.7,1.6; stroke-dashoffset: 0; stroke: #8000ff; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_1\">\n",
       "    <defs>\n",
       "     <path id=\"m6767466568\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #8000ff; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pec9cbd1170)\">\n",
       "     <use xlink:href=\"#m6767466568\" x=\"530.727086\" y=\"283.406232\" style=\"fill: #8000ff; stroke: #8000ff; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 465.506307 350.467615 \n",
       "Q 493.285528 330.925267 521.064748 311.382918 \n",
       "\" style=\"fill: none; stroke-dasharray: 3.7,1.6; stroke-dashoffset: 0; stroke: #386df9; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_2\">\n",
       "    <defs>\n",
       "     <path id=\"mf4e29c9f3a\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #386df9; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pec9cbd1170)\">\n",
       "     <use xlink:href=\"#mf4e29c9f3a\" x=\"530.727086\" y=\"311.382918\" style=\"fill: #386df9; stroke: #386df9; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 465.506307 408.326235 \n",
       "Q 493.285528 384.595517 521.064748 360.864799 \n",
       "\" style=\"fill: none; stroke-dasharray: 3.7,1.6; stroke-dashoffset: 0; stroke: #12c8e6; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_3\">\n",
       "    <defs>\n",
       "     <path id=\"mb1c0c8aefe\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #12c8e6; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pec9cbd1170)\">\n",
       "     <use xlink:href=\"#mb1c0c8aefe\" x=\"530.727086\" y=\"360.864799\" style=\"fill: #12c8e6; stroke: #12c8e6; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 465.506307 231.214173 \n",
       "Q 493.285528 158.087086 521.064748 84.96 \n",
       "\" style=\"fill: none; stroke-dasharray: 3.7,1.6; stroke-dashoffset: 0; stroke: #5af8c8; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_4\">\n",
       "    <defs>\n",
       "     <path id=\"m9b6fcae4df\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #5af8c8; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pec9cbd1170)\">\n",
       "     <use xlink:href=\"#m9b6fcae4df\" x=\"530.727086\" y=\"84.96\" style=\"fill: #5af8c8; stroke: #5af8c8; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 465.506307 487.256209 \n",
       "Q 493.285528 486.870166 521.064748 486.484123 \n",
       "\" style=\"fill: none; stroke-dasharray: 3.7,1.6; stroke-dashoffset: 0; stroke: #a4f89f; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_5\">\n",
       "    <defs>\n",
       "     <path id=\"mc2a10624c9\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #a4f89f; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pec9cbd1170)\">\n",
       "     <use xlink:href=\"#mc2a10624c9\" x=\"530.727086\" y=\"486.484123\" style=\"fill: #a4f89f; stroke: #a4f89f; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 465.506307 486.390562 \n",
       "Q 493.285528 485.839707 521.064748 485.288853 \n",
       "\" style=\"fill: none; stroke-dasharray: 3.7,1.6; stroke-dashoffset: 0; stroke: #ecc86f; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_6\">\n",
       "    <defs>\n",
       "     <path id=\"mf45384fb30\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #ecc86f; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pec9cbd1170)\">\n",
       "     <use xlink:href=\"#mf45384fb30\" x=\"530.727086\" y=\"485.288853\" style=\"fill: #ecc86f; stroke: #ecc86f; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 465.506307 409.229039 \n",
       "Q 493.285528 386.945452 521.064748 364.661864 \n",
       "\" style=\"fill: none; stroke-dasharray: 3.7,1.6; stroke-dashoffset: 0; stroke: #ff6d38; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"PathCollection_7\">\n",
       "    <defs>\n",
       "     <path id=\"mc4bfe925db\" d=\"M 0 3 \n",
       "C 0.795609 3 1.55874 2.683901 2.12132 2.12132 \n",
       "C 2.683901 1.55874 3 0.795609 3 0 \n",
       "C 3 -0.795609 2.683901 -1.55874 2.12132 -2.12132 \n",
       "C 1.55874 -2.683901 0.795609 -3 0 -3 \n",
       "C -0.795609 -3 -1.55874 -2.683901 -2.12132 -2.12132 \n",
       "C -2.683901 -1.55874 -3 -0.795609 -3 0 \n",
       "C -3 0.795609 -2.683901 1.55874 -2.12132 2.12132 \n",
       "C -1.55874 2.683901 -0.795609 3 0 3 \n",
       "z\n",
       "\" style=\"stroke: #ff6d38; stroke-width: 0.5\"/>\n",
       "    </defs>\n",
       "    <g clip-path=\"url(#pec9cbd1170)\">\n",
       "     <use xlink:href=\"#mc4bfe925db\" x=\"530.727086\" y=\"364.661864\" style=\"fill: #ff6d38; stroke: #ff6d38; stroke-width: 0.5\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"line2d_60\">\n",
       "    <path d=\"M 521.064748 283.406232 \n",
       "L 588.701112 283.406232 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #8000ff; stroke-opacity: 0.5; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_61\">\n",
       "    <path d=\"M 521.064748 283.406232 \n",
       "L 530.727086 283.406232 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #8000ff; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_62\">\n",
       "    <path d=\"M 521.064748 311.382918 \n",
       "L 588.701112 311.382918 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #386df9; stroke-opacity: 0.5; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_63\">\n",
       "    <path d=\"M 521.064748 311.382918 \n",
       "L 530.727086 311.382918 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #386df9; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_64\">\n",
       "    <path d=\"M 521.064748 360.864799 \n",
       "L 588.701112 360.864799 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #12c8e6; stroke-opacity: 0.5; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_65\">\n",
       "    <path d=\"M 521.064748 360.864799 \n",
       "L 530.727086 360.864799 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #12c8e6; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_66\">\n",
       "    <path d=\"M 521.064748 84.96 \n",
       "L 588.701112 84.96 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #5af8c8; stroke-opacity: 0.5; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_67\">\n",
       "    <path d=\"M 521.064748 84.96 \n",
       "L 530.727086 84.96 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #5af8c8; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_68\">\n",
       "    <path d=\"M 521.064748 486.484123 \n",
       "L 588.701112 486.484123 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #a4f89f; stroke-opacity: 0.5; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_69\">\n",
       "    <path d=\"M 521.064748 486.484123 \n",
       "L 530.727086 486.484123 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #a4f89f; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_70\">\n",
       "    <path d=\"M 521.064748 485.288853 \n",
       "L 588.701112 485.288853 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #ecc86f; stroke-opacity: 0.5; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_71\">\n",
       "    <path d=\"M 521.064748 485.288853 \n",
       "L 530.727086 485.288853 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ecc86f; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_72\">\n",
       "    <path d=\"M 521.064748 364.661864 \n",
       "L 588.701112 364.661864 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #ff6d38; stroke-opacity: 0.5; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_73\">\n",
       "    <path d=\"M 521.064748 364.661864 \n",
       "L 530.727086 364.661864 \n",
       "\" clip-path=\"url(#pec9cbd1170)\" style=\"fill: none; stroke: #ff6d38; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 511.402411 508.32 \n",
       "L 511.402411 64.8 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 617.688125 508.32 \n",
       "L 617.688125 64.8 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 511.402411 508.32 \n",
       "L 617.688125 508.32 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 511.402411 64.8 \n",
       "L 617.688125 64.8 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_35\">\n",
       "    <g id=\"patch_21\">\n",
       "     <path d=\"M 550.976243 284.404015 \n",
       "L 588.219993 284.404015 \n",
       "Q 590.219993 284.404015 590.219993 282.404015 \n",
       "L 590.219993 273.136828 \n",
       "Q 590.219993 271.136828 588.219993 271.136828 \n",
       "L 550.976243 271.136828 \n",
       "Q 548.976243 271.136828 548.976243 273.136828 \n",
       "L 548.976243 282.404015 \n",
       "Q 548.976243 284.404015 550.976243 284.404015 \n",
       "z\n",
       "\" style=\"fill: #d3d3d3; stroke: #8000ff; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__S -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(550.976243 280.416515) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-75\" d=\"M 2597 0 \n",
       "L 2597 488 \n",
       "Q 2209 -75 1544 -75 \n",
       "Q 1250 -75 995 37 \n",
       "Q 741 150 617 320 \n",
       "Q 494 491 444 738 \n",
       "Q 409 903 409 1263 \n",
       "L 409 3319 \n",
       "L 972 3319 \n",
       "L 972 1478 \n",
       "Q 972 1038 1006 884 \n",
       "Q 1059 663 1231 536 \n",
       "Q 1403 409 1656 409 \n",
       "Q 1909 409 2131 539 \n",
       "Q 2353 669 2445 892 \n",
       "Q 2538 1116 2538 1541 \n",
       "L 2538 3319 \n",
       "L 3100 3319 \n",
       "L 3100 0 \n",
       "L 2597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 925 3319 \n",
       "L 925 2853 \n",
       "Q 1081 3097 1340 3245 \n",
       "Q 1600 3394 1931 3394 \n",
       "Q 2300 3394 2536 3241 \n",
       "Q 2772 3088 2869 2813 \n",
       "Q 3263 3394 3894 3394 \n",
       "Q 4388 3394 4653 3120 \n",
       "Q 4919 2847 4919 2278 \n",
       "L 4919 0 \n",
       "L 4359 0 \n",
       "L 4359 2091 \n",
       "Q 4359 2428 4304 2576 \n",
       "Q 4250 2725 4106 2815 \n",
       "Q 3963 2906 3769 2906 \n",
       "Q 3419 2906 3187 2673 \n",
       "Q 2956 2441 2956 1928 \n",
       "L 2956 0 \n",
       "L 2394 0 \n",
       "L 2394 2156 \n",
       "Q 2394 2531 2256 2718 \n",
       "Q 2119 2906 1806 2906 \n",
       "Q 1569 2906 1367 2781 \n",
       "Q 1166 2656 1075 2415 \n",
       "Q 984 2175 984 1722 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-5f\" d=\"M -97 -1272 \n",
       "L -97 -866 \n",
       "L 3631 -866 \n",
       "L 3631 -1272 \n",
       "L -97 -1272 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-53\" d=\"M 288 1472 \n",
       "L 859 1522 \n",
       "Q 900 1178 1048 958 \n",
       "Q 1197 738 1509 602 \n",
       "Q 1822 466 2213 466 \n",
       "Q 2559 466 2825 569 \n",
       "Q 3091 672 3220 851 \n",
       "Q 3350 1031 3350 1244 \n",
       "Q 3350 1459 3225 1620 \n",
       "Q 3100 1781 2813 1891 \n",
       "Q 2628 1963 1997 2114 \n",
       "Q 1366 2266 1113 2400 \n",
       "Q 784 2572 623 2826 \n",
       "Q 463 3081 463 3397 \n",
       "Q 463 3744 659 4045 \n",
       "Q 856 4347 1234 4503 \n",
       "Q 1613 4659 2075 4659 \n",
       "Q 2584 4659 2973 4495 \n",
       "Q 3363 4331 3572 4012 \n",
       "Q 3781 3694 3797 3291 \n",
       "L 3216 3247 \n",
       "Q 3169 3681 2898 3903 \n",
       "Q 2628 4125 2100 4125 \n",
       "Q 1550 4125 1298 3923 \n",
       "Q 1047 3722 1047 3438 \n",
       "Q 1047 3191 1225 3031 \n",
       "Q 1400 2872 2139 2705 \n",
       "Q 2878 2538 3153 2413 \n",
       "Q 3553 2228 3743 1945 \n",
       "Q 3934 1663 3934 1294 \n",
       "Q 3934 928 3725 604 \n",
       "Q 3516 281 3123 101 \n",
       "Q 2731 -78 2241 -78 \n",
       "Q 1619 -78 1198 103 \n",
       "Q 778 284 539 648 \n",
       "Q 300 1013 288 1472 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-53\" transform=\"translate(305.761719 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_36\">\n",
       "    <g id=\"patch_22\">\n",
       "     <path d=\"M 550.977405 312.380701 \n",
       "L 588.221155 312.380701 \n",
       "Q 590.221155 312.380701 590.221155 310.380701 \n",
       "L 590.221155 301.235389 \n",
       "Q 590.221155 299.235389 588.221155 299.235389 \n",
       "L 550.977405 299.235389 \n",
       "Q 548.977405 299.235389 548.977405 301.235389 \n",
       "L 548.977405 310.380701 \n",
       "Q 548.977405 312.380701 550.977405 312.380701 \n",
       "z\n",
       "\" style=\"fill: #d3d3d3; stroke: #386df9; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__K -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(550.977405 308.393201) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-4b\" d=\"M 469 0 \n",
       "L 469 4581 \n",
       "L 1075 4581 \n",
       "L 1075 2309 \n",
       "L 3350 4581 \n",
       "L 4172 4581 \n",
       "L 2250 2725 \n",
       "L 4256 0 \n",
       "L 3456 0 \n",
       "L 1825 2319 \n",
       "L 1075 1588 \n",
       "L 1075 0 \n",
       "L 469 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4b\" transform=\"translate(305.761719 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_37\">\n",
       "    <g id=\"patch_23\">\n",
       "     <path d=\"M 551.545716 361.862582 \n",
       "L 588.226966 361.862582 \n",
       "Q 590.226966 361.862582 590.226966 359.862582 \n",
       "L 590.226966 350.71727 \n",
       "Q 590.226966 348.71727 588.226966 348.71727 \n",
       "L 551.545716 348.71727 \n",
       "Q 549.545716 348.71727 549.545716 350.71727 \n",
       "L 549.545716 359.862582 \n",
       "Q 549.545716 361.862582 551.545716 361.862582 \n",
       "z\n",
       "\" style=\"fill: #d3d3d3; stroke: #12c8e6; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__T -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(551.545716 357.875082) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-54\" d=\"M 1659 0 \n",
       "L 1659 4041 \n",
       "L 150 4041 \n",
       "L 150 4581 \n",
       "L 3781 4581 \n",
       "L 3781 4041 \n",
       "L 2266 4041 \n",
       "L 2266 0 \n",
       "L 1659 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-54\" transform=\"translate(305.761719 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_38\">\n",
       "    <g id=\"patch_24\">\n",
       "     <path d=\"M 530.715127 85.957783 \n",
       "L 587.962002 85.957783 \n",
       "Q 589.962002 85.957783 589.962002 83.957783 \n",
       "L 589.962002 74.695283 \n",
       "Q 589.962002 72.695283 587.962002 72.695283 \n",
       "L 530.715127 72.695283 \n",
       "Q 528.715127 72.695283 528.715127 74.695283 \n",
       "L 528.715127 83.957783 \n",
       "Q 528.715127 85.957783 530.715127 85.957783 \n",
       "z\n",
       "\" style=\"fill: #d3d3d3; stroke: #5af8c8; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__sigma -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(530.715127 81.853096) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-67\" d=\"M 319 -275 \n",
       "L 866 -356 \n",
       "Q 900 -609 1056 -725 \n",
       "Q 1266 -881 1628 -881 \n",
       "Q 2019 -881 2231 -725 \n",
       "Q 2444 -569 2519 -288 \n",
       "Q 2563 -116 2559 434 \n",
       "Q 2191 0 1641 0 \n",
       "Q 956 0 581 494 \n",
       "Q 206 988 206 1678 \n",
       "Q 206 2153 378 2554 \n",
       "Q 550 2956 876 3175 \n",
       "Q 1203 3394 1644 3394 \n",
       "Q 2231 3394 2613 2919 \n",
       "L 2613 3319 \n",
       "L 3131 3319 \n",
       "L 3131 450 \n",
       "Q 3131 -325 2973 -648 \n",
       "Q 2816 -972 2473 -1159 \n",
       "Q 2131 -1347 1631 -1347 \n",
       "Q 1038 -1347 672 -1080 \n",
       "Q 306 -813 319 -275 \n",
       "z\n",
       "M 784 1719 \n",
       "Q 784 1066 1043 766 \n",
       "Q 1303 466 1694 466 \n",
       "Q 2081 466 2343 764 \n",
       "Q 2606 1063 2606 1700 \n",
       "Q 2606 2309 2336 2618 \n",
       "Q 2066 2928 1684 2928 \n",
       "Q 1309 2928 1046 2623 \n",
       "Q 784 2319 784 1719 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(355.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-67\" transform=\"translate(377.978516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(433.59375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" transform=\"translate(516.894531 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_39\">\n",
       "    <g id=\"patch_25\">\n",
       "     <path d=\"M 501.424898 498.638222 \n",
       "L 587.58896 498.638222 \n",
       "Q 589.58896 498.638222 589.58896 496.638222 \n",
       "L 589.58896 487.49291 \n",
       "Q 589.58896 485.49291 587.58896 485.49291 \n",
       "L 501.424898 485.49291 \n",
       "Q 499.424898 485.49291 499.424898 487.49291 \n",
       "L 499.424898 496.638222 \n",
       "Q 499.424898 498.638222 501.424898 498.638222 \n",
       "z\n",
       "\" style=\"fill: #d3d3d3; stroke: #a4f89f; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__openInterest -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(501.424898 494.650722) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-49\" d=\"M 597 0 \n",
       "L 597 4581 \n",
       "L 1203 4581 \n",
       "L 1203 0 \n",
       "L 597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
       "L 1731 6 \n",
       "Q 1494 -44 1306 -44 \n",
       "Q 1000 -44 831 53 \n",
       "Q 663 150 594 308 \n",
       "Q 525 466 525 972 \n",
       "L 525 2881 \n",
       "L 113 2881 \n",
       "L 113 3319 \n",
       "L 525 3319 \n",
       "L 525 4141 \n",
       "L 1084 4478 \n",
       "L 1084 3319 \n",
       "L 1650 3319 \n",
       "L 1650 2881 \n",
       "L 1084 2881 \n",
       "L 1084 941 \n",
       "Q 1084 700 1114 631 \n",
       "Q 1144 563 1211 522 \n",
       "Q 1278 481 1403 481 \n",
       "Q 1497 481 1650 503 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" transform=\"translate(361.376953 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(416.992188 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(472.607422 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-49\" transform=\"translate(528.222656 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(556.005859 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(611.621094 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(639.404297 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(695.019531 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(728.320312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(783.935547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(833.935547 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_40\">\n",
       "    <g id=\"patch_26\">\n",
       "     <path d=\"M 525.080975 486.286636 \n",
       "L 587.888788 486.286636 \n",
       "Q 589.888788 486.286636 589.888788 484.286636 \n",
       "L 589.888788 475.141324 \n",
       "Q 589.888788 473.141324 587.888788 473.141324 \n",
       "L 525.080975 473.141324 \n",
       "Q 523.080975 473.141324 523.080975 475.141324 \n",
       "L 523.080975 484.286636 \n",
       "Q 523.080975 486.286636 525.080975 486.286636 \n",
       "z\n",
       "\" style=\"fill: #d3d3d3; stroke: #ecc86f; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__volume -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(525.080975 482.299136) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-76\" d=\"M 1344 0 \n",
       "L 81 3319 \n",
       "L 675 3319 \n",
       "L 1388 1331 \n",
       "Q 1503 1009 1600 663 \n",
       "Q 1675 925 1809 1294 \n",
       "L 2547 3319 \n",
       "L 3125 3319 \n",
       "L 1869 0 \n",
       "L 1344 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(355.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" transform=\"translate(411.376953 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(433.59375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(489.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(572.509766 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"text_41\">\n",
       "    <g id=\"patch_27\">\n",
       "     <path d=\"M 501.995171 376.926581 \n",
       "L 587.593609 376.926581 \n",
       "Q 589.593609 376.926581 589.593609 374.926581 \n",
       "L 589.593609 365.664081 \n",
       "Q 589.593609 363.664081 587.593609 363.664081 \n",
       "L 501.995171 363.664081 \n",
       "Q 499.995171 363.664081 499.995171 365.664081 \n",
       "L 499.995171 374.926581 \n",
       "Q 499.995171 376.926581 501.995171 376.926581 \n",
       "z\n",
       "\" style=\"fill: #d3d3d3; stroke: #ff6d38; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <!-- num__inTheMoney -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(501.995171 372.821893) scale(0.1 -0.1)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-68\" d=\"M 422 0 \n",
       "L 422 4581 \n",
       "L 984 4581 \n",
       "L 984 2938 \n",
       "Q 1378 3394 1978 3394 \n",
       "Q 2347 3394 2619 3248 \n",
       "Q 2891 3103 3008 2847 \n",
       "Q 3125 2591 3125 2103 \n",
       "L 3125 0 \n",
       "L 2563 0 \n",
       "L 2563 2103 \n",
       "Q 2563 2525 2380 2717 \n",
       "Q 2197 2909 1863 2909 \n",
       "Q 1613 2909 1392 2779 \n",
       "Q 1172 2650 1078 2428 \n",
       "Q 984 2206 984 1816 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-4d\" d=\"M 475 0 \n",
       "L 475 4581 \n",
       "L 1388 4581 \n",
       "L 2472 1338 \n",
       "Q 2622 884 2691 659 \n",
       "Q 2769 909 2934 1394 \n",
       "L 4031 4581 \n",
       "L 4847 4581 \n",
       "L 4847 0 \n",
       "L 4263 0 \n",
       "L 4263 3834 \n",
       "L 2931 0 \n",
       "L 2384 0 \n",
       "L 1059 3900 \n",
       "L 1059 0 \n",
       "L 475 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-79\" d=\"M 397 -1278 \n",
       "L 334 -750 \n",
       "Q 519 -800 656 -800 \n",
       "Q 844 -800 956 -737 \n",
       "Q 1069 -675 1141 -563 \n",
       "Q 1194 -478 1313 -144 \n",
       "Q 1328 -97 1363 -6 \n",
       "L 103 3319 \n",
       "L 709 3319 \n",
       "L 1400 1397 \n",
       "Q 1534 1031 1641 628 \n",
       "Q 1738 1016 1872 1384 \n",
       "L 2581 3319 \n",
       "L 3144 3319 \n",
       "L 1881 -56 \n",
       "Q 1678 -603 1566 -809 \n",
       "Q 1416 -1088 1222 -1217 \n",
       "Q 1028 -1347 759 -1347 \n",
       "Q 597 -1347 397 -1278 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-6e\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(55.615234 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(111.230469 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(194.53125 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-5f\" transform=\"translate(250.146484 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(305.761719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(327.978516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-54\" transform=\"translate(383.59375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-68\" transform=\"translate(444.677734 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(500.292969 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4d\" transform=\"translate(555.908203 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(639.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(694.824219 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(750.439453 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-79\" transform=\"translate(806.054688 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"text_42\">\n",
       "   <!-- alpha-curves -->\n",
       "   <g style=\"fill: #262626\" transform=\"translate(295.34 15.789375) scale(0.12 -0.12)\">\n",
       "    <defs>\n",
       "     <path id=\"ArialMT-2d\" d=\"M 203 1375 \n",
       "L 203 1941 \n",
       "L 1931 1941 \n",
       "L 1931 1375 \n",
       "L 203 1375 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     <path id=\"ArialMT-63\" d=\"M 2588 1216 \n",
       "L 3141 1144 \n",
       "Q 3050 572 2676 248 \n",
       "Q 2303 -75 1759 -75 \n",
       "Q 1078 -75 664 370 \n",
       "Q 250 816 250 1647 \n",
       "Q 250 2184 428 2587 \n",
       "Q 606 2991 970 3192 \n",
       "Q 1334 3394 1763 3394 \n",
       "Q 2303 3394 2647 3120 \n",
       "Q 2991 2847 3088 2344 \n",
       "L 2541 2259 \n",
       "Q 2463 2594 2264 2762 \n",
       "Q 2066 2931 1784 2931 \n",
       "Q 1359 2931 1093 2626 \n",
       "Q 828 2322 828 1663 \n",
       "Q 828 994 1084 691 \n",
       "Q 1341 388 1753 388 \n",
       "Q 2084 388 2306 591 \n",
       "Q 2528 794 2588 1216 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "    </defs>\n",
       "    <use xlink:href=\"#ArialMT-61\"/>\n",
       "    <use xlink:href=\"#ArialMT-6c\" transform=\"translate(55.615234 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-70\" transform=\"translate(77.832031 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-68\" transform=\"translate(133.447266 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-61\" transform=\"translate(189.0625 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-2d\" transform=\"translate(244.677734 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-63\" transform=\"translate(277.978516 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-75\" transform=\"translate(327.978516 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-72\" transform=\"translate(383.59375 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-76\" transform=\"translate(416.894531 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-65\" transform=\"translate(466.894531 0)\"/>\n",
       "    <use xlink:href=\"#ArialMT-73\" transform=\"translate(522.509766 0)\"/>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pea6c89c4da\">\n",
       "   <rect x=\"59.688125\" y=\"64.8\" width=\"425.142857\" height=\"443.52\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p6411dbac4d\">\n",
       "   <rect x=\"617.688125\" y=\"64.8\" width=\"0\" height=\"443.52\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pec9cbd1170\">\n",
       "   <rect x=\"511.402411\" y=\"64.8\" width=\"106.285714\" height=\"443.52\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns.alpha_sens_curves(sensmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcd69a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partDeriv = sensmlp.raw_sens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "21294de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 101192 entries, 0 to 101191\n",
      "Data columns (total 7 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   num__S             101192 non-null  float64\n",
      " 1   num__K             101192 non-null  float64\n",
      " 2   num__T             101192 non-null  float64\n",
      " 3   num__sigma         101192 non-null  float64\n",
      " 4   num__openInterest  101192 non-null  float64\n",
      " 5   num__volume        101192 non-null  float64\n",
      " 6   num__inTheMoney    101192 non-null  float64\n",
      "dtypes: float64(7)\n",
      "memory usage: 5.4 MB\n"
     ]
    }
   ],
   "source": [
    "df_partDeriv.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "314be223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_partial_derivative_distributions(df):\n",
    "    \"\"\"\n",
    "    Dibuja histogramas con líneas de media y mediana para cada derivada parcial,\n",
    "    adaptándose dinámicamente al número de columnas del DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame con columnas como num__S, num__K, etc.\n",
    "    \"\"\"\n",
    "    n = len(df.columns)\n",
    "    cols = 2\n",
    "    rows = int(np.ceil(n / cols))\n",
    "\n",
    "    plt.figure(figsize=(cols * 7, rows * 4))\n",
    "    for i, column in enumerate(df.columns, 1):\n",
    "        plt.subplot(rows, cols, i)\n",
    "        sns.histplot(df[column], kde=True, bins=100)\n",
    "        plt.axvline(df[column].mean(), color='red', linestyle='--', label=f\"Media: {df[column].mean():.2f}\")\n",
    "        plt.axvline(df[column].median(), color='green', linestyle=':', label=f\"Mediana: {df[column].median():.2f}\")\n",
    "        plt.title(f\"Distribución de ∂Precio/∂{column.split('__')[-1]}\")\n",
    "        plt.xlabel(\"Valor de la derivada parcial\")\n",
    "        plt.ylabel(\"Frecuencia\")\n",
    "        plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3de25765",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       "  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1000.959531pt\" height=\"1144.461469pt\" viewBox=\"0 0 1000.959531 1144.461469\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n",
       " <metadata>\n",
       "  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n",
       "   <cc:Work>\n",
       "    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n",
       "    <dc:date>2025-06-08T16:46:35.844425</dc:date>\n",
       "    <dc:format>image/svg+xml</dc:format>\n",
       "    <dc:creator>\n",
       "     <cc:Agent>\n",
       "      <dc:title>Matplotlib v3.10.1, https://matplotlib.org/</dc:title>\n",
       "     </cc:Agent>\n",
       "    </dc:creator>\n",
       "   </cc:Work>\n",
       "  </rdf:RDF>\n",
       " </metadata>\n",
       " <defs>\n",
       "  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n",
       " </defs>\n",
       " <g id=\"figure_1\">\n",
       "  <g id=\"patch_1\">\n",
       "   <path d=\"M 0 1144.461469 \n",
       "L 1000.959531 1144.461469 \n",
       "L 1000.959531 0 \n",
       "L 0 0 \n",
       "z\n",
       "\" style=\"fill: #ffffff\"/>\n",
       "  </g>\n",
       "  <g id=\"axes_1\">\n",
       "   <g id=\"patch_2\">\n",
       "    <path d=\"M 62.259531 246.82725 \n",
       "L 495.159531 246.82725 \n",
       "L 495.159531 23.50725 \n",
       "L 62.259531 23.50725 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_1\">\n",
       "    <g id=\"xtick_1\">\n",
       "     <g id=\"line2d_1\">\n",
       "      <path d=\"M 98.934389 246.82725 \n",
       "L 98.934389 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_1\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(95.875873 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-30\" d=\"M 266 2259 \n",
       "Q 266 3072 433 3567 \n",
       "Q 600 4063 929 4331 \n",
       "Q 1259 4600 1759 4600 \n",
       "Q 2128 4600 2406 4451 \n",
       "Q 2684 4303 2865 4023 \n",
       "Q 3047 3744 3150 3342 \n",
       "Q 3253 2941 3253 2259 \n",
       "Q 3253 1453 3087 958 \n",
       "Q 2922 463 2592 192 \n",
       "Q 2263 -78 1759 -78 \n",
       "Q 1097 -78 719 397 \n",
       "Q 266 969 266 2259 \n",
       "z\n",
       "M 844 2259 \n",
       "Q 844 1131 1108 757 \n",
       "Q 1372 384 1759 384 \n",
       "Q 2147 384 2411 759 \n",
       "Q 2675 1134 2675 2259 \n",
       "Q 2675 3391 2411 3762 \n",
       "Q 2147 4134 1753 4134 \n",
       "Q 1366 4134 1134 3806 \n",
       "Q 844 3388 844 2259 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_2\">\n",
       "     <g id=\"line2d_2\">\n",
       "      <path d=\"M 161.508806 246.82725 \n",
       "L 161.508806 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_2\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(152.333259 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-31\" d=\"M 2384 0 \n",
       "L 1822 0 \n",
       "L 1822 3584 \n",
       "Q 1619 3391 1289 3197 \n",
       "Q 959 3003 697 2906 \n",
       "L 697 3450 \n",
       "Q 1169 3672 1522 3987 \n",
       "Q 1875 4303 2022 4600 \n",
       "L 2384 4600 \n",
       "L 2384 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_3\">\n",
       "     <g id=\"line2d_3\">\n",
       "      <path d=\"M 224.083224 246.82725 \n",
       "L 224.083224 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_3\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(214.907677 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-32\" d=\"M 3222 541 \n",
       "L 3222 0 \n",
       "L 194 0 \n",
       "Q 188 203 259 391 \n",
       "Q 375 700 629 1000 \n",
       "Q 884 1300 1366 1694 \n",
       "Q 2113 2306 2375 2664 \n",
       "Q 2638 3022 2638 3341 \n",
       "Q 2638 3675 2398 3904 \n",
       "Q 2159 4134 1775 4134 \n",
       "Q 1369 4134 1125 3890 \n",
       "Q 881 3647 878 3216 \n",
       "L 300 3275 \n",
       "Q 359 3922 746 4261 \n",
       "Q 1134 4600 1788 4600 \n",
       "Q 2447 4600 2831 4234 \n",
       "Q 3216 3869 3216 3328 \n",
       "Q 3216 3053 3103 2787 \n",
       "Q 2991 2522 2730 2228 \n",
       "Q 2469 1934 1863 1422 \n",
       "Q 1356 997 1212 845 \n",
       "Q 1069 694 975 541 \n",
       "L 3222 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_4\">\n",
       "     <g id=\"line2d_4\">\n",
       "      <path d=\"M 286.657641 246.82725 \n",
       "L 286.657641 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_4\">\n",
       "      <!-- 300 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(277.482094 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-33\" d=\"M 269 1209 \n",
       "L 831 1284 \n",
       "Q 928 806 1161 595 \n",
       "Q 1394 384 1728 384 \n",
       "Q 2125 384 2398 659 \n",
       "Q 2672 934 2672 1341 \n",
       "Q 2672 1728 2419 1979 \n",
       "Q 2166 2231 1775 2231 \n",
       "Q 1616 2231 1378 2169 \n",
       "L 1441 2663 \n",
       "Q 1497 2656 1531 2656 \n",
       "Q 1891 2656 2178 2843 \n",
       "Q 2466 3031 2466 3422 \n",
       "Q 2466 3731 2256 3934 \n",
       "Q 2047 4138 1716 4138 \n",
       "Q 1388 4138 1169 3931 \n",
       "Q 950 3725 888 3313 \n",
       "L 325 3413 \n",
       "Q 428 3978 793 4289 \n",
       "Q 1159 4600 1703 4600 \n",
       "Q 2078 4600 2393 4439 \n",
       "Q 2709 4278 2876 4000 \n",
       "Q 3044 3722 3044 3409 \n",
       "Q 3044 3113 2884 2869 \n",
       "Q 2725 2625 2413 2481 \n",
       "Q 2819 2388 3044 2092 \n",
       "Q 3269 1797 3269 1353 \n",
       "Q 3269 753 2831 336 \n",
       "Q 2394 -81 1725 -81 \n",
       "Q 1122 -81 723 278 \n",
       "Q 325 638 269 1209 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_5\">\n",
       "     <g id=\"line2d_5\">\n",
       "      <path d=\"M 349.232059 246.82725 \n",
       "L 349.232059 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_5\">\n",
       "      <!-- 400 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(340.056512 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-34\" d=\"M 2069 0 \n",
       "L 2069 1097 \n",
       "L 81 1097 \n",
       "L 81 1613 \n",
       "L 2172 4581 \n",
       "L 2631 4581 \n",
       "L 2631 1613 \n",
       "L 3250 1613 \n",
       "L 3250 1097 \n",
       "L 2631 1097 \n",
       "L 2631 0 \n",
       "L 2069 0 \n",
       "z\n",
       "M 2069 1613 \n",
       "L 2069 3678 \n",
       "L 634 1613 \n",
       "L 2069 1613 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_6\">\n",
       "     <g id=\"line2d_6\">\n",
       "      <path d=\"M 411.806476 246.82725 \n",
       "L 411.806476 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_6\">\n",
       "      <!-- 500 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(402.630929 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-35\" d=\"M 266 1200 \n",
       "L 856 1250 \n",
       "Q 922 819 1161 601 \n",
       "Q 1400 384 1738 384 \n",
       "Q 2144 384 2425 690 \n",
       "Q 2706 997 2706 1503 \n",
       "Q 2706 1984 2436 2262 \n",
       "Q 2166 2541 1728 2541 \n",
       "Q 1456 2541 1237 2417 \n",
       "Q 1019 2294 894 2097 \n",
       "L 366 2166 \n",
       "L 809 4519 \n",
       "L 3088 4519 \n",
       "L 3088 3981 \n",
       "L 1259 3981 \n",
       "L 1013 2750 \n",
       "Q 1425 3038 1878 3038 \n",
       "Q 2478 3038 2890 2622 \n",
       "Q 3303 2206 3303 1553 \n",
       "Q 3303 931 2941 478 \n",
       "Q 2500 -78 1738 -78 \n",
       "Q 1113 -78 717 272 \n",
       "Q 322 622 266 1200 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_7\">\n",
       "     <g id=\"line2d_7\">\n",
       "      <path d=\"M 474.380894 246.82725 \n",
       "L 474.380894 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_7\">\n",
       "      <!-- 600 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(465.205347 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-36\" d=\"M 3184 3459 \n",
       "L 2625 3416 \n",
       "Q 2550 3747 2413 3897 \n",
       "Q 2184 4138 1850 4138 \n",
       "Q 1581 4138 1378 3988 \n",
       "Q 1113 3794 959 3422 \n",
       "Q 806 3050 800 2363 \n",
       "Q 1003 2672 1297 2822 \n",
       "Q 1591 2972 1913 2972 \n",
       "Q 2475 2972 2870 2558 \n",
       "Q 3266 2144 3266 1488 \n",
       "Q 3266 1056 3080 686 \n",
       "Q 2894 316 2569 119 \n",
       "Q 2244 -78 1831 -78 \n",
       "Q 1128 -78 684 439 \n",
       "Q 241 956 241 2144 \n",
       "Q 241 3472 731 4075 \n",
       "Q 1159 4600 1884 4600 \n",
       "Q 2425 4600 2770 4297 \n",
       "Q 3116 3994 3184 3459 \n",
       "z\n",
       "M 888 1484 \n",
       "Q 888 1194 1011 928 \n",
       "Q 1134 663 1356 523 \n",
       "Q 1578 384 1822 384 \n",
       "Q 2178 384 2434 671 \n",
       "Q 2691 959 2691 1453 \n",
       "Q 2691 1928 2437 2201 \n",
       "Q 2184 2475 1800 2475 \n",
       "Q 1419 2475 1153 2201 \n",
       "Q 888 1928 888 1484 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_8\">\n",
       "     <!-- Valor de la derivada parcial -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(206.447969 278.976469) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-56\" d=\"M 1803 0 \n",
       "L 28 4581 \n",
       "L 684 4581 \n",
       "L 1875 1253 \n",
       "Q 2019 853 2116 503 \n",
       "Q 2222 878 2363 1253 \n",
       "L 3600 4581 \n",
       "L 4219 4581 \n",
       "L 2425 0 \n",
       "L 1803 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-61\" d=\"M 2588 409 \n",
       "Q 2275 144 1986 34 \n",
       "Q 1697 -75 1366 -75 \n",
       "Q 819 -75 525 192 \n",
       "Q 231 459 231 875 \n",
       "Q 231 1119 342 1320 \n",
       "Q 453 1522 633 1644 \n",
       "Q 813 1766 1038 1828 \n",
       "Q 1203 1872 1538 1913 \n",
       "Q 2219 1994 2541 2106 \n",
       "Q 2544 2222 2544 2253 \n",
       "Q 2544 2597 2384 2738 \n",
       "Q 2169 2928 1744 2928 \n",
       "Q 1347 2928 1158 2789 \n",
       "Q 969 2650 878 2297 \n",
       "L 328 2372 \n",
       "Q 403 2725 575 2942 \n",
       "Q 747 3159 1072 3276 \n",
       "Q 1397 3394 1825 3394 \n",
       "Q 2250 3394 2515 3294 \n",
       "Q 2781 3194 2906 3042 \n",
       "Q 3031 2891 3081 2659 \n",
       "Q 3109 2516 3109 2141 \n",
       "L 3109 1391 \n",
       "Q 3109 606 3145 398 \n",
       "Q 3181 191 3288 0 \n",
       "L 2700 0 \n",
       "Q 2613 175 2588 409 \n",
       "z\n",
       "M 2541 1666 \n",
       "Q 2234 1541 1622 1453 \n",
       "Q 1275 1403 1131 1340 \n",
       "Q 988 1278 909 1158 \n",
       "Q 831 1038 831 891 \n",
       "Q 831 666 1001 516 \n",
       "Q 1172 366 1500 366 \n",
       "Q 1825 366 2078 508 \n",
       "Q 2331 650 2450 897 \n",
       "Q 2541 1088 2541 1459 \n",
       "L 2541 1666 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6c\" d=\"M 409 0 \n",
       "L 409 4581 \n",
       "L 972 4581 \n",
       "L 972 0 \n",
       "L 409 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6f\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-72\" d=\"M 416 0 \n",
       "L 416 3319 \n",
       "L 922 3319 \n",
       "L 922 2816 \n",
       "Q 1116 3169 1280 3281 \n",
       "Q 1444 3394 1641 3394 \n",
       "Q 1925 3394 2219 3213 \n",
       "L 2025 2691 \n",
       "Q 1819 2813 1613 2813 \n",
       "Q 1428 2813 1281 2702 \n",
       "Q 1134 2591 1072 2394 \n",
       "Q 978 2094 978 1738 \n",
       "L 978 0 \n",
       "L 416 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-20\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-64\" d=\"M 2575 0 \n",
       "L 2575 419 \n",
       "Q 2259 -75 1647 -75 \n",
       "Q 1250 -75 917 144 \n",
       "Q 584 363 401 755 \n",
       "Q 219 1147 219 1656 \n",
       "Q 219 2153 384 2558 \n",
       "Q 550 2963 881 3178 \n",
       "Q 1213 3394 1622 3394 \n",
       "Q 1922 3394 2156 3267 \n",
       "Q 2391 3141 2538 2938 \n",
       "L 2538 4581 \n",
       "L 3097 4581 \n",
       "L 3097 0 \n",
       "L 2575 0 \n",
       "z\n",
       "M 797 1656 \n",
       "Q 797 1019 1065 703 \n",
       "Q 1334 388 1700 388 \n",
       "Q 2069 388 2326 689 \n",
       "Q 2584 991 2584 1609 \n",
       "Q 2584 2291 2321 2609 \n",
       "Q 2059 2928 1675 2928 \n",
       "Q 1300 2928 1048 2622 \n",
       "Q 797 2316 797 1656 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-65\" d=\"M 2694 1069 \n",
       "L 3275 997 \n",
       "Q 3138 488 2766 206 \n",
       "Q 2394 -75 1816 -75 \n",
       "Q 1088 -75 661 373 \n",
       "Q 234 822 234 1631 \n",
       "Q 234 2469 665 2931 \n",
       "Q 1097 3394 1784 3394 \n",
       "Q 2450 3394 2872 2941 \n",
       "Q 3294 2488 3294 1666 \n",
       "Q 3294 1616 3291 1516 \n",
       "L 816 1516 \n",
       "Q 847 969 1125 678 \n",
       "Q 1403 388 1819 388 \n",
       "Q 2128 388 2347 550 \n",
       "Q 2566 713 2694 1069 \n",
       "z\n",
       "M 847 1978 \n",
       "L 2700 1978 \n",
       "Q 2663 2397 2488 2606 \n",
       "Q 2219 2931 1791 2931 \n",
       "Q 1403 2931 1139 2672 \n",
       "Q 875 2413 847 1978 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-69\" d=\"M 425 3934 \n",
       "L 425 4581 \n",
       "L 988 4581 \n",
       "L 988 3934 \n",
       "L 425 3934 \n",
       "z\n",
       "M 425 0 \n",
       "L 425 3319 \n",
       "L 988 3319 \n",
       "L 988 0 \n",
       "L 425 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-76\" d=\"M 1344 0 \n",
       "L 81 3319 \n",
       "L 675 3319 \n",
       "L 1388 1331 \n",
       "Q 1503 1009 1600 663 \n",
       "Q 1675 925 1809 1294 \n",
       "L 2547 3319 \n",
       "L 3125 3319 \n",
       "L 1869 0 \n",
       "L 1344 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-70\" d=\"M 422 -1272 \n",
       "L 422 3319 \n",
       "L 934 3319 \n",
       "L 934 2888 \n",
       "Q 1116 3141 1344 3267 \n",
       "Q 1572 3394 1897 3394 \n",
       "Q 2322 3394 2647 3175 \n",
       "Q 2972 2956 3137 2557 \n",
       "Q 3303 2159 3303 1684 \n",
       "Q 3303 1175 3120 767 \n",
       "Q 2938 359 2589 142 \n",
       "Q 2241 -75 1856 -75 \n",
       "Q 1575 -75 1351 44 \n",
       "Q 1128 163 984 344 \n",
       "L 984 -1272 \n",
       "L 422 -1272 \n",
       "z\n",
       "M 931 1641 \n",
       "Q 931 1000 1190 694 \n",
       "Q 1450 388 1819 388 \n",
       "Q 2194 388 2461 705 \n",
       "Q 2728 1022 2728 1688 \n",
       "Q 2728 2322 2467 2637 \n",
       "Q 2206 2953 1844 2953 \n",
       "Q 1484 2953 1207 2617 \n",
       "Q 931 2281 931 1641 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-63\" d=\"M 2588 1216 \n",
       "L 3141 1144 \n",
       "Q 3050 572 2676 248 \n",
       "Q 2303 -75 1759 -75 \n",
       "Q 1078 -75 664 370 \n",
       "Q 250 816 250 1647 \n",
       "Q 250 2184 428 2587 \n",
       "Q 606 2991 970 3192 \n",
       "Q 1334 3394 1763 3394 \n",
       "Q 2303 3394 2647 3120 \n",
       "Q 2991 2847 3088 2344 \n",
       "L 2541 2259 \n",
       "Q 2463 2594 2264 2762 \n",
       "Q 2066 2931 1784 2931 \n",
       "Q 1359 2931 1093 2626 \n",
       "Q 828 2322 828 1663 \n",
       "Q 828 994 1084 691 \n",
       "Q 1341 388 1753 388 \n",
       "Q 2084 388 2306 591 \n",
       "Q 2528 794 2588 1216 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(59.324219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(114.939453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(137.15625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(192.771484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(226.072266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(253.855469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(309.470703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(365.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(392.869141 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(415.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(470.701172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(498.484375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(554.099609 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(609.714844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(643.015625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(665.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(715.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(770.847656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(826.462891 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(882.078125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(909.861328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(965.476562 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(1021.091797 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(1054.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(1104.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(1126.609375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1182.224609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_2\">\n",
       "    <g id=\"ytick_1\">\n",
       "     <g id=\"line2d_8\">\n",
       "      <path d=\"M 62.259531 246.82725 \n",
       "L 495.159531 246.82725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_9\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(46.6425 250.764047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_2\">\n",
       "     <g id=\"line2d_9\">\n",
       "      <path d=\"M 62.259531 202.756443 \n",
       "L 495.159531 202.756443 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_10\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 206.69324) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_3\">\n",
       "     <g id=\"line2d_10\">\n",
       "      <path d=\"M 62.259531 158.685636 \n",
       "L 495.159531 158.685636 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_11\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 162.622433) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_4\">\n",
       "     <g id=\"line2d_11\">\n",
       "      <path d=\"M 62.259531 114.614829 \n",
       "L 495.159531 114.614829 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_12\">\n",
       "      <!-- 3000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 118.551626) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_5\">\n",
       "     <g id=\"line2d_12\">\n",
       "      <path d=\"M 62.259531 70.544022 \n",
       "L 495.159531 70.544022 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_13\">\n",
       "      <!-- 4000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 74.480819) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_6\">\n",
       "     <g id=\"line2d_13\">\n",
       "      <path d=\"M 62.259531 26.473215 \n",
       "L 495.159531 26.473215 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_14\">\n",
       "      <!-- 5000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 30.410012) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_15\">\n",
       "     <!-- Frecuencia -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(21.906406 164.845687) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-46\" d=\"M 525 0 \n",
       "L 525 4581 \n",
       "L 3616 4581 \n",
       "L 3616 4041 \n",
       "L 1131 4041 \n",
       "L 1131 2622 \n",
       "L 3281 2622 \n",
       "L 3281 2081 \n",
       "L 1131 2081 \n",
       "L 1131 0 \n",
       "L 525 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-75\" d=\"M 2597 0 \n",
       "L 2597 488 \n",
       "Q 2209 -75 1544 -75 \n",
       "Q 1250 -75 995 37 \n",
       "Q 741 150 617 320 \n",
       "Q 494 491 444 738 \n",
       "Q 409 903 409 1263 \n",
       "L 409 3319 \n",
       "L 972 3319 \n",
       "L 972 1478 \n",
       "Q 972 1038 1006 884 \n",
       "Q 1059 663 1231 536 \n",
       "Q 1403 409 1656 409 \n",
       "Q 1909 409 2131 539 \n",
       "Q 2353 669 2445 892 \n",
       "Q 2538 1116 2538 1541 \n",
       "L 2538 3319 \n",
       "L 3100 3319 \n",
       "L 3100 0 \n",
       "L 2597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-6e\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 928 3319 \n",
       "L 928 2847 \n",
       "Q 1294 3394 1984 3394 \n",
       "Q 2284 3394 2536 3286 \n",
       "Q 2788 3178 2913 3003 \n",
       "Q 3038 2828 3088 2588 \n",
       "Q 3119 2431 3119 2041 \n",
       "L 3119 0 \n",
       "L 2556 0 \n",
       "L 2556 2019 \n",
       "Q 2556 2363 2490 2533 \n",
       "Q 2425 2703 2258 2804 \n",
       "Q 2091 2906 1866 2906 \n",
       "Q 1506 2906 1245 2678 \n",
       "Q 984 2450 984 1813 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-46\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(61.083984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(94.384766 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(150 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(255.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(311.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(366.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(439.0625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_3\">\n",
       "    <path d=\"M 81.936804 246.82725 \n",
       "L 85.872259 246.82725 \n",
       "L 85.872259 246.783179 \n",
       "L 81.936804 246.783179 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_4\">\n",
       "    <path d=\"M 85.872259 246.82725 \n",
       "L 89.807713 246.82725 \n",
       "L 89.807713 246.562825 \n",
       "L 85.872259 246.562825 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_5\">\n",
       "    <path d=\"M 89.807713 246.82725 \n",
       "L 93.743168 246.82725 \n",
       "L 93.743168 245.152559 \n",
       "L 89.807713 245.152559 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_6\">\n",
       "    <path d=\"M 93.743168 246.82725 \n",
       "L 97.678622 246.82725 \n",
       "L 97.678622 242.067603 \n",
       "L 93.743168 242.067603 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_7\">\n",
       "    <path d=\"M 97.678622 246.82725 \n",
       "L 101.614077 246.82725 \n",
       "L 101.614077 227.920874 \n",
       "L 97.678622 227.920874 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_8\">\n",
       "    <path d=\"M 101.614077 246.82725 \n",
       "L 105.549531 246.82725 \n",
       "L 105.549531 225.981758 \n",
       "L 101.614077 225.981758 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_9\">\n",
       "    <path d=\"M 105.549531 246.82725 \n",
       "L 109.484986 246.82725 \n",
       "L 109.484986 226.863174 \n",
       "L 105.549531 226.863174 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_10\">\n",
       "    <path d=\"M 109.484986 246.82725 \n",
       "L 113.42044 246.82725 \n",
       "L 113.42044 234.575566 \n",
       "L 109.484986 234.575566 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_11\">\n",
       "    <path d=\"M 113.42044 246.82725 \n",
       "L 117.355895 246.82725 \n",
       "L 117.355895 225.100342 \n",
       "L 113.42044 225.100342 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_12\">\n",
       "    <path d=\"M 117.355895 246.82725 \n",
       "L 121.291349 246.82725 \n",
       "L 121.291349 218.269367 \n",
       "L 117.355895 218.269367 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_13\">\n",
       "    <path d=\"M 121.291349 246.82725 \n",
       "L 125.226804 246.82725 \n",
       "L 125.226804 224.262997 \n",
       "L 121.291349 224.262997 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_14\">\n",
       "    <path d=\"M 125.226804 246.82725 \n",
       "L 129.162259 246.82725 \n",
       "L 129.162259 44.630388 \n",
       "L 125.226804 44.630388 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_15\">\n",
       "    <path d=\"M 129.162259 246.82725 \n",
       "L 133.097713 246.82725 \n",
       "L 133.097713 178.473428 \n",
       "L 129.162259 178.473428 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_16\">\n",
       "    <path d=\"M 133.097713 246.82725 \n",
       "L 137.033168 246.82725 \n",
       "L 137.033168 179.795553 \n",
       "L 133.097713 179.795553 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_17\">\n",
       "    <path d=\"M 137.033168 246.82725 \n",
       "L 140.968622 246.82725 \n",
       "L 140.968622 157.716078 \n",
       "L 137.033168 157.716078 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_18\">\n",
       "    <path d=\"M 140.968622 246.82725 \n",
       "L 144.904077 246.82725 \n",
       "L 144.904077 34.141536 \n",
       "L 140.968622 34.141536 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_19\">\n",
       "    <path d=\"M 144.904077 246.82725 \n",
       "L 148.839531 246.82725 \n",
       "L 148.839531 54.722603 \n",
       "L 144.904077 54.722603 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_20\">\n",
       "    <path d=\"M 148.839531 246.82725 \n",
       "L 152.774986 246.82725 \n",
       "L 152.774986 136.958728 \n",
       "L 148.839531 136.958728 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_21\">\n",
       "    <path d=\"M 152.774986 246.82725 \n",
       "L 156.71044 246.82725 \n",
       "L 156.71044 141.542092 \n",
       "L 152.774986 141.542092 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_22\">\n",
       "    <path d=\"M 156.71044 246.82725 \n",
       "L 160.645895 246.82725 \n",
       "L 160.645895 158.200857 \n",
       "L 156.71044 158.200857 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_23\">\n",
       "    <path d=\"M 160.645895 246.82725 \n",
       "L 164.581349 246.82725 \n",
       "L 164.581349 164.414841 \n",
       "L 160.645895 164.414841 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_24\">\n",
       "    <path d=\"M 164.581349 246.82725 \n",
       "L 168.516804 246.82725 \n",
       "L 168.516804 187.463873 \n",
       "L 164.581349 187.463873 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_25\">\n",
       "    <path d=\"M 168.516804 246.82725 \n",
       "L 172.452259 246.82725 \n",
       "L 172.452259 191.518387 \n",
       "L 168.516804 191.518387 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_26\">\n",
       "    <path d=\"M 172.452259 246.82725 \n",
       "L 176.387713 246.82725 \n",
       "L 176.387713 186.097678 \n",
       "L 172.452259 186.097678 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_27\">\n",
       "    <path d=\"M 176.387713 246.82725 \n",
       "L 180.323168 246.82725 \n",
       "L 180.323168 200.817328 \n",
       "L 176.387713 200.817328 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_28\">\n",
       "    <path d=\"M 180.323168 246.82725 \n",
       "L 184.258622 246.82725 \n",
       "L 184.258622 170.099975 \n",
       "L 180.323168 170.099975 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_29\">\n",
       "    <path d=\"M 184.258622 246.82725 \n",
       "L 188.194077 246.82725 \n",
       "L 188.194077 184.202633 \n",
       "L 184.258622 184.202633 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_30\">\n",
       "    <path d=\"M 188.194077 246.82725 \n",
       "L 192.129531 246.82725 \n",
       "L 192.129531 188.521572 \n",
       "L 188.194077 188.521572 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_31\">\n",
       "    <path d=\"M 192.129531 246.82725 \n",
       "L 196.064986 246.82725 \n",
       "L 196.064986 201.302106 \n",
       "L 192.129531 201.302106 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_32\">\n",
       "    <path d=\"M 196.064986 246.82725 \n",
       "L 200.00044 246.82725 \n",
       "L 200.00044 210.424763 \n",
       "L 196.064986 210.424763 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_33\">\n",
       "    <path d=\"M 200.00044 246.82725 \n",
       "L 203.935895 246.82725 \n",
       "L 203.935895 206.634674 \n",
       "L 200.00044 206.634674 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_34\">\n",
       "    <path d=\"M 203.935895 246.82725 \n",
       "L 207.871349 246.82725 \n",
       "L 207.871349 212.98087 \n",
       "L 203.935895 212.98087 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_35\">\n",
       "    <path d=\"M 207.871349 246.82725 \n",
       "L 211.806804 246.82725 \n",
       "L 211.806804 227.832732 \n",
       "L 207.871349 227.832732 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_36\">\n",
       "    <path d=\"M 211.806804 246.82725 \n",
       "L 215.742259 246.82725 \n",
       "L 215.742259 220.957686 \n",
       "L 211.806804 220.957686 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_37\">\n",
       "    <path d=\"M 215.742259 246.82725 \n",
       "L 219.677713 246.82725 \n",
       "L 219.677713 219.547421 \n",
       "L 215.742259 219.547421 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_38\">\n",
       "    <path d=\"M 219.677713 246.82725 \n",
       "L 223.613168 246.82725 \n",
       "L 223.613168 214.391136 \n",
       "L 219.677713 214.391136 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_39\">\n",
       "    <path d=\"M 223.613168 246.82725 \n",
       "L 227.548622 246.82725 \n",
       "L 227.548622 222.103527 \n",
       "L 223.613168 222.103527 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_40\">\n",
       "    <path d=\"M 227.548622 246.82725 \n",
       "L 231.484077 246.82725 \n",
       "L 231.484077 227.303883 \n",
       "L 227.548622 227.303883 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_41\">\n",
       "    <path d=\"M 231.484077 246.82725 \n",
       "L 235.419531 246.82725 \n",
       "L 235.419531 228.846361 \n",
       "L 231.484077 228.846361 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_42\">\n",
       "    <path d=\"M 235.419531 246.82725 \n",
       "L 239.354986 246.82725 \n",
       "L 239.354986 231.975388 \n",
       "L 235.419531 231.975388 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_43\">\n",
       "    <path d=\"M 239.354986 246.82725 \n",
       "L 243.29044 246.82725 \n",
       "L 243.29044 232.327955 \n",
       "L 239.354986 232.327955 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_44\">\n",
       "    <path d=\"M 243.29044 246.82725 \n",
       "L 247.225895 246.82725 \n",
       "L 247.225895 229.859989 \n",
       "L 243.29044 229.859989 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_45\">\n",
       "    <path d=\"M 247.225895 246.82725 \n",
       "L 251.161349 246.82725 \n",
       "L 251.161349 237.704593 \n",
       "L 247.225895 237.704593 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_46\">\n",
       "    <path d=\"M 251.161349 246.82725 \n",
       "L 255.096804 246.82725 \n",
       "L 255.096804 229.683706 \n",
       "L 251.161349 229.683706 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_47\">\n",
       "    <path d=\"M 255.096804 246.82725 \n",
       "L 259.032259 246.82725 \n",
       "L 259.032259 228.053086 \n",
       "L 255.096804 228.053086 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_48\">\n",
       "    <path d=\"M 259.032259 246.82725 \n",
       "L 262.967713 246.82725 \n",
       "L 262.967713 234.134858 \n",
       "L 259.032259 234.134858 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_49\">\n",
       "    <path d=\"M 262.967713 246.82725 \n",
       "L 266.903168 246.82725 \n",
       "L 266.903168 224.218926 \n",
       "L 262.967713 224.218926 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_50\">\n",
       "    <path d=\"M 266.903168 246.82725 \n",
       "L 270.838622 246.82725 \n",
       "L 270.838622 231.931317 \n",
       "L 266.903168 231.931317 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_51\">\n",
       "    <path d=\"M 270.838622 246.82725 \n",
       "L 274.774077 246.82725 \n",
       "L 274.774077 239.247071 \n",
       "L 270.838622 239.247071 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_52\">\n",
       "    <path d=\"M 274.774077 246.82725 \n",
       "L 278.709531 246.82725 \n",
       "L 278.709531 235.89769 \n",
       "L 274.774077 235.89769 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_53\">\n",
       "    <path d=\"M 278.709531 246.82725 \n",
       "L 282.644986 246.82725 \n",
       "L 282.644986 243.654152 \n",
       "L 278.709531 243.654152 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_54\">\n",
       "    <path d=\"M 282.644986 246.82725 \n",
       "L 286.58044 246.82725 \n",
       "L 286.58044 236.779106 \n",
       "L 282.644986 236.779106 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_55\">\n",
       "    <path d=\"M 286.58044 246.82725 \n",
       "L 290.515895 246.82725 \n",
       "L 290.515895 245.108489 \n",
       "L 286.58044 245.108489 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_56\">\n",
       "    <path d=\"M 290.515895 246.82725 \n",
       "L 294.451349 246.82725 \n",
       "L 294.451349 243.521939 \n",
       "L 290.515895 243.521939 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_57\">\n",
       "    <path d=\"M 294.451349 246.82725 \n",
       "L 298.386804 246.82725 \n",
       "L 298.386804 244.138931 \n",
       "L 294.451349 244.138931 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_58\">\n",
       "    <path d=\"M 298.386804 246.82725 \n",
       "L 302.322259 246.82725 \n",
       "L 302.322259 242.287957 \n",
       "L 298.386804 242.287957 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_59\">\n",
       "    <path d=\"M 302.322259 246.82725 \n",
       "L 306.257713 246.82725 \n",
       "L 306.257713 240.701408 \n",
       "L 302.322259 240.701408 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_60\">\n",
       "    <path d=\"M 306.257713 246.82725 \n",
       "L 310.193168 246.82725 \n",
       "L 310.193168 240.481054 \n",
       "L 306.257713 240.481054 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_61\">\n",
       "    <path d=\"M 310.193168 246.82725 \n",
       "L 314.128622 246.82725 \n",
       "L 314.128622 240.436983 \n",
       "L 310.193168 240.436983 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_62\">\n",
       "    <path d=\"M 314.128622 246.82725 \n",
       "L 318.064077 246.82725 \n",
       "L 318.064077 240.172558 \n",
       "L 314.128622 240.172558 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_63\">\n",
       "    <path d=\"M 318.064077 246.82725 \n",
       "L 321.999531 246.82725 \n",
       "L 321.999531 232.944946 \n",
       "L 318.064077 232.944946 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_64\">\n",
       "    <path d=\"M 321.999531 246.82725 \n",
       "L 325.934986 246.82725 \n",
       "L 325.934986 242.552382 \n",
       "L 321.999531 242.552382 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_65\">\n",
       "    <path d=\"M 325.934986 246.82725 \n",
       "L 329.87044 246.82725 \n",
       "L 329.87044 225.849546 \n",
       "L 325.934986 225.849546 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_66\">\n",
       "    <path d=\"M 329.87044 246.82725 \n",
       "L 333.805895 246.82725 \n",
       "L 333.805895 233.033087 \n",
       "L 329.87044 233.033087 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_67\">\n",
       "    <path d=\"M 333.805895 246.82725 \n",
       "L 337.741349 246.82725 \n",
       "L 337.741349 226.422466 \n",
       "L 333.805895 226.422466 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_68\">\n",
       "    <path d=\"M 337.741349 246.82725 \n",
       "L 341.676804 246.82725 \n",
       "L 341.676804 218.357509 \n",
       "L 337.741349 218.357509 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_69\">\n",
       "    <path d=\"M 341.676804 246.82725 \n",
       "L 345.612259 246.82725 \n",
       "L 345.612259 231.975388 \n",
       "L 341.676804 231.975388 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_70\">\n",
       "    <path d=\"M 345.612259 246.82725 \n",
       "L 349.547713 246.82725 \n",
       "L 349.547713 187.199448 \n",
       "L 345.612259 187.199448 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_71\">\n",
       "    <path d=\"M 349.547713 246.82725 \n",
       "L 353.483168 246.82725 \n",
       "L 353.483168 164.238558 \n",
       "L 349.547713 164.238558 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_72\">\n",
       "    <path d=\"M 353.483168 246.82725 \n",
       "L 357.418622 246.82725 \n",
       "L 357.418622 135.107754 \n",
       "L 353.483168 135.107754 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_73\">\n",
       "    <path d=\"M 357.418622 246.82725 \n",
       "L 361.354077 246.82725 \n",
       "L 361.354077 161.770593 \n",
       "L 357.418622 161.770593 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_74\">\n",
       "    <path d=\"M 361.354077 246.82725 \n",
       "L 365.289531 246.82725 \n",
       "L 365.289531 153.881918 \n",
       "L 361.354077 153.881918 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_75\">\n",
       "    <path d=\"M 365.289531 246.82725 \n",
       "L 369.224986 246.82725 \n",
       "L 369.224986 118.448989 \n",
       "L 365.289531 118.448989 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_76\">\n",
       "    <path d=\"M 369.224986 246.82725 \n",
       "L 373.16044 246.82725 \n",
       "L 373.16044 131.273594 \n",
       "L 369.224986 131.273594 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_77\">\n",
       "    <path d=\"M 373.16044 246.82725 \n",
       "L 377.095895 246.82725 \n",
       "L 377.095895 165.384399 \n",
       "L 373.16044 165.384399 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_78\">\n",
       "    <path d=\"M 377.095895 246.82725 \n",
       "L 381.031349 246.82725 \n",
       "L 381.031349 169.438913 \n",
       "L 377.095895 169.438913 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_79\">\n",
       "    <path d=\"M 381.031349 246.82725 \n",
       "L 384.966804 246.82725 \n",
       "L 384.966804 123.737486 \n",
       "L 381.031349 123.737486 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_80\">\n",
       "    <path d=\"M 384.966804 246.82725 \n",
       "L 388.902259 246.82725 \n",
       "L 388.902259 138.236782 \n",
       "L 384.966804 138.236782 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_81\">\n",
       "    <path d=\"M 388.902259 246.82725 \n",
       "L 392.837713 246.82725 \n",
       "L 392.837713 70.544022 \n",
       "L 388.902259 70.544022 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_82\">\n",
       "    <path d=\"M 392.837713 246.82725 \n",
       "L 396.773168 246.82725 \n",
       "L 396.773168 67.282783 \n",
       "L 392.837713 67.282783 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_83\">\n",
       "    <path d=\"M 396.773168 246.82725 \n",
       "L 400.708622 246.82725 \n",
       "L 400.708622 163.930062 \n",
       "L 396.773168 163.930062 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_84\">\n",
       "    <path d=\"M 400.708622 246.82725 \n",
       "L 404.644077 246.82725 \n",
       "L 404.644077 209.851843 \n",
       "L 400.708622 209.851843 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_85\">\n",
       "    <path d=\"M 404.644077 246.82725 \n",
       "L 408.579531 246.82725 \n",
       "L 408.579531 222.147598 \n",
       "L 404.644077 222.147598 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_86\">\n",
       "    <path d=\"M 408.579531 246.82725 \n",
       "L 412.514986 246.82725 \n",
       "L 412.514986 210.689188 \n",
       "L 408.579531 210.689188 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_87\">\n",
       "    <path d=\"M 412.514986 246.82725 \n",
       "L 416.45044 246.82725 \n",
       "L 416.45044 197.335734 \n",
       "L 412.514986 197.335734 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_88\">\n",
       "    <path d=\"M 416.45044 246.82725 \n",
       "L 420.385895 246.82725 \n",
       "L 420.385895 190.372546 \n",
       "L 416.45044 190.372546 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_89\">\n",
       "    <path d=\"M 420.385895 246.82725 \n",
       "L 424.321349 246.82725 \n",
       "L 424.321349 202.536089 \n",
       "L 420.385895 202.536089 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_90\">\n",
       "    <path d=\"M 424.321349 246.82725 \n",
       "L 428.256804 246.82725 \n",
       "L 428.256804 193.016795 \n",
       "L 424.321349 193.016795 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_91\">\n",
       "    <path d=\"M 428.256804 246.82725 \n",
       "L 432.192259 246.82725 \n",
       "L 432.192259 175.344401 \n",
       "L 428.256804 175.344401 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_92\">\n",
       "    <path d=\"M 432.192259 246.82725 \n",
       "L 436.127713 246.82725 \n",
       "L 436.127713 229.507423 \n",
       "L 432.192259 229.507423 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_93\">\n",
       "    <path d=\"M 436.127713 246.82725 \n",
       "L 440.063168 246.82725 \n",
       "L 440.063168 212.98087 \n",
       "L 436.127713 212.98087 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_94\">\n",
       "    <path d=\"M 440.063168 246.82725 \n",
       "L 443.998622 246.82725 \n",
       "L 443.998622 228.626007 \n",
       "L 440.063168 228.626007 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_95\">\n",
       "    <path d=\"M 443.998622 246.82725 \n",
       "L 447.934077 246.82725 \n",
       "L 447.934077 229.110786 \n",
       "L 443.998622 229.110786 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_96\">\n",
       "    <path d=\"M 447.934077 246.82725 \n",
       "L 451.869531 246.82725 \n",
       "L 451.869531 222.588306 \n",
       "L 447.934077 222.588306 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_97\">\n",
       "    <path d=\"M 451.869531 246.82725 \n",
       "L 455.804986 246.82725 \n",
       "L 455.804986 233.297512 \n",
       "L 451.869531 233.297512 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_98\">\n",
       "    <path d=\"M 455.804986 246.82725 \n",
       "L 459.74044 246.82725 \n",
       "L 459.74044 236.690964 \n",
       "L 455.804986 236.690964 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_99\">\n",
       "    <path d=\"M 459.74044 246.82725 \n",
       "L 463.675895 246.82725 \n",
       "L 463.675895 242.023532 \n",
       "L 459.74044 242.023532 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_100\">\n",
       "    <path d=\"M 463.675895 246.82725 \n",
       "L 467.611349 246.82725 \n",
       "L 467.611349 244.799993 \n",
       "L 463.675895 244.799993 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_101\">\n",
       "    <path d=\"M 467.611349 246.82725 \n",
       "L 471.546804 246.82725 \n",
       "L 471.546804 246.695038 \n",
       "L 467.611349 246.695038 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_102\">\n",
       "    <path d=\"M 471.546804 246.82725 \n",
       "L 475.482259 246.82725 \n",
       "L 475.482259 246.386542 \n",
       "L 471.546804 246.386542 \n",
       "z\n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_14\">\n",
       "    <path d=\"M 81.936804 244.651757 \n",
       "L 83.914419 243.957491 \n",
       "L 85.892035 243.121685 \n",
       "L 87.86965 242.138804 \n",
       "L 89.847265 241.00711 \n",
       "L 91.824881 239.72708 \n",
       "L 93.802496 238.298566 \n",
       "L 95.780111 236.716966 \n",
       "L 97.757727 234.969022 \n",
       "L 99.735342 233.029142 \n",
       "L 101.712957 230.857288 \n",
       "L 103.690573 228.399412 \n",
       "L 105.668188 225.591055 \n",
       "L 107.645804 222.364107 \n",
       "L 109.623419 218.656002 \n",
       "L 111.601034 214.419908 \n",
       "L 113.57865 209.633988 \n",
       "L 115.556265 204.307812 \n",
       "L 117.53388 198.48449 \n",
       "L 121.489111 185.66684 \n",
       "L 131.377188 152.076877 \n",
       "L 133.354803 146.072416 \n",
       "L 135.332418 140.611369 \n",
       "L 137.310034 135.841883 \n",
       "L 139.287649 131.916733 \n",
       "L 141.265264 128.981835 \n",
       "L 143.24288 127.160021 \n",
       "L 145.220495 126.533214 \n",
       "L 147.198111 127.126946 \n",
       "L 149.175726 128.900906 \n",
       "L 151.153341 131.7479 \n",
       "L 153.130957 135.501733 \n",
       "L 155.108572 139.952611 \n",
       "L 159.063803 150.010261 \n",
       "L 163.019033 160.142185 \n",
       "L 164.996649 164.803055 \n",
       "L 166.974264 169.0505 \n",
       "L 168.951879 172.835272 \n",
       "L 170.929495 176.150531 \n",
       "L 172.90711 179.025127 \n",
       "L 174.884725 181.515327 \n",
       "L 176.862341 183.695791 \n",
       "L 180.817571 187.464004 \n",
       "L 186.750417 192.766723 \n",
       "L 190.705648 196.612305 \n",
       "L 196.638494 202.898328 \n",
       "L 200.593725 207.09993 \n",
       "L 204.548956 210.9767 \n",
       "L 208.504186 214.323044 \n",
       "L 210.481802 215.771091 \n",
       "L 214.437032 218.247984 \n",
       "L 218.392263 220.295231 \n",
       "L 224.325109 222.988264 \n",
       "L 234.213186 227.273535 \n",
       "L 238.168417 228.744176 \n",
       "L 242.123647 229.890243 \n",
       "L 246.078878 230.664146 \n",
       "L 250.034109 231.126399 \n",
       "L 257.94457 231.787149 \n",
       "L 261.899801 232.370591 \n",
       "L 265.855031 233.285537 \n",
       "L 269.810262 234.525299 \n",
       "L 275.743108 236.751105 \n",
       "L 281.675954 238.929602 \n",
       "L 285.631185 240.105149 \n",
       "L 289.586416 240.939713 \n",
       "L 293.541646 241.384342 \n",
       "L 297.496877 241.43591 \n",
       "L 301.452108 241.126073 \n",
       "L 305.407338 240.499308 \n",
       "L 309.362569 239.585023 \n",
       "L 313.3178 238.373365 \n",
       "L 317.273031 236.799027 \n",
       "L 319.250646 235.836852 \n",
       "L 321.228261 234.726786 \n",
       "L 323.205877 233.437572 \n",
       "L 325.183492 231.930981 \n",
       "L 327.161107 230.16194 \n",
       "L 329.138723 228.079813 \n",
       "L 331.116338 225.631285 \n",
       "L 333.093953 222.765062 \n",
       "L 335.071569 219.438256 \n",
       "L 337.049184 215.62385 \n",
       "L 339.026799 211.318206 \n",
       "L 341.004415 206.547283 \n",
       "L 342.98203 201.370183 \n",
       "L 346.937261 190.194082 \n",
       "L 350.892492 178.813858 \n",
       "L 352.870107 173.411582 \n",
       "L 354.847722 168.375744 \n",
       "L 356.825338 163.803951 \n",
       "L 358.802953 159.756812 \n",
       "L 360.780568 156.253701 \n",
       "L 362.758184 153.272796 \n",
       "L 364.735799 150.75544 \n",
       "L 366.713414 148.61462 \n",
       "L 368.69103 146.747122 \n",
       "L 372.64626 143.430092 \n",
       "L 378.579106 138.721817 \n",
       "L 380.556722 137.346124 \n",
       "L 382.534337 136.270622 \n",
       "L 384.511952 135.673939 \n",
       "L 386.489568 135.742879 \n",
       "L 388.467183 136.644675 \n",
       "L 390.444798 138.499395 \n",
       "L 392.422414 141.357151 \n",
       "L 394.400029 145.184266 \n",
       "L 396.377645 149.861095 \n",
       "L 398.35526 155.19228 \n",
       "L 406.265721 177.86241 \n",
       "L 408.243337 182.656676 \n",
       "L 410.220952 186.793261 \n",
       "L 412.198567 190.24212 \n",
       "L 414.176183 193.041545 \n",
       "L 416.153798 195.28414 \n",
       "L 418.131413 197.098345 \n",
       "L 420.109029 198.628691 \n",
       "L 426.041875 202.845503 \n",
       "L 428.01949 204.448928 \n",
       "L 429.997105 206.233507 \n",
       "L 431.974721 208.202048 \n",
       "L 435.929952 212.588604 \n",
       "L 445.818028 224.155236 \n",
       "L 449.773259 228.334037 \n",
       "L 453.72849 232.12993 \n",
       "L 457.68372 235.53993 \n",
       "L 461.638951 238.533813 \n",
       "L 465.594182 241.051755 \n",
       "L 467.571797 242.114968 \n",
       "L 469.549412 243.043596 \n",
       "L 471.527028 243.839287 \n",
       "L 473.504643 244.507613 \n",
       "L 475.482259 245.057592 \n",
       "L 475.482259 245.057592 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_15\">\n",
       "    <path d=\"M 272.55773 246.82725 \n",
       "L 272.55773 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_16\">\n",
       "    <path d=\"M 264.948449 246.82725 \n",
       "L 264.948449 23.50725 \n",
       "\" clip-path=\"url(#pc863c31197)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_103\">\n",
       "    <path d=\"M 62.259531 246.82725 \n",
       "L 62.259531 23.50725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_104\">\n",
       "    <path d=\"M 495.159531 246.82725 \n",
       "L 495.159531 23.50725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_105\">\n",
       "    <path d=\"M 62.259531 246.82725 \n",
       "L 495.159531 246.82725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_106\">\n",
       "    <path d=\"M 62.259531 23.50725 \n",
       "L 495.159531 23.50725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_16\">\n",
       "    <!-- Distribución de ∂Precio/∂S -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(194.762031 17.50725) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-44\" d=\"M 494 0 \n",
       "L 494 4581 \n",
       "L 2072 4581 \n",
       "Q 2606 4581 2888 4516 \n",
       "Q 3281 4425 3559 4188 \n",
       "Q 3922 3881 4101 3404 \n",
       "Q 4281 2928 4281 2316 \n",
       "Q 4281 1794 4159 1391 \n",
       "Q 4038 988 3847 723 \n",
       "Q 3656 459 3429 307 \n",
       "Q 3203 156 2883 78 \n",
       "Q 2563 0 2147 0 \n",
       "L 494 0 \n",
       "z\n",
       "M 1100 541 \n",
       "L 2078 541 \n",
       "Q 2531 541 2789 625 \n",
       "Q 3047 709 3200 863 \n",
       "Q 3416 1078 3536 1442 \n",
       "Q 3656 1806 3656 2325 \n",
       "Q 3656 3044 3420 3430 \n",
       "Q 3184 3816 2847 3947 \n",
       "Q 2603 4041 2063 4041 \n",
       "L 1100 4041 \n",
       "L 1100 541 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-73\" d=\"M 197 991 \n",
       "L 753 1078 \n",
       "Q 800 744 1014 566 \n",
       "Q 1228 388 1613 388 \n",
       "Q 2000 388 2187 545 \n",
       "Q 2375 703 2375 916 \n",
       "Q 2375 1106 2209 1216 \n",
       "Q 2094 1291 1634 1406 \n",
       "Q 1016 1563 777 1677 \n",
       "Q 538 1791 414 1992 \n",
       "Q 291 2194 291 2438 \n",
       "Q 291 2659 392 2848 \n",
       "Q 494 3038 669 3163 \n",
       "Q 800 3259 1026 3326 \n",
       "Q 1253 3394 1513 3394 \n",
       "Q 1903 3394 2198 3281 \n",
       "Q 2494 3169 2634 2976 \n",
       "Q 2775 2784 2828 2463 \n",
       "L 2278 2388 \n",
       "Q 2241 2644 2061 2787 \n",
       "Q 1881 2931 1553 2931 \n",
       "Q 1166 2931 1000 2803 \n",
       "Q 834 2675 834 2503 \n",
       "Q 834 2394 903 2306 \n",
       "Q 972 2216 1119 2156 \n",
       "Q 1203 2125 1616 2013 \n",
       "Q 2213 1853 2448 1751 \n",
       "Q 2684 1650 2818 1456 \n",
       "Q 2953 1263 2953 975 \n",
       "Q 2953 694 2789 445 \n",
       "Q 2625 197 2315 61 \n",
       "Q 2006 -75 1616 -75 \n",
       "Q 969 -75 630 194 \n",
       "Q 291 463 197 991 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-74\" d=\"M 1650 503 \n",
       "L 1731 6 \n",
       "Q 1494 -44 1306 -44 \n",
       "Q 1000 -44 831 53 \n",
       "Q 663 150 594 308 \n",
       "Q 525 466 525 972 \n",
       "L 525 2881 \n",
       "L 113 2881 \n",
       "L 113 3319 \n",
       "L 525 3319 \n",
       "L 525 4141 \n",
       "L 1084 4478 \n",
       "L 1084 3319 \n",
       "L 1650 3319 \n",
       "L 1650 2881 \n",
       "L 1084 2881 \n",
       "L 1084 941 \n",
       "Q 1084 700 1114 631 \n",
       "Q 1144 563 1211 522 \n",
       "Q 1278 481 1403 481 \n",
       "Q 1497 481 1650 503 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-62\" d=\"M 941 0 \n",
       "L 419 0 \n",
       "L 419 4581 \n",
       "L 981 4581 \n",
       "L 981 2947 \n",
       "Q 1338 3394 1891 3394 \n",
       "Q 2197 3394 2470 3270 \n",
       "Q 2744 3147 2920 2923 \n",
       "Q 3097 2700 3197 2384 \n",
       "Q 3297 2069 3297 1709 \n",
       "Q 3297 856 2875 390 \n",
       "Q 2453 -75 1863 -75 \n",
       "Q 1275 -75 941 416 \n",
       "L 941 0 \n",
       "z\n",
       "M 934 1684 \n",
       "Q 934 1088 1097 822 \n",
       "Q 1363 388 1816 388 \n",
       "Q 2184 388 2453 708 \n",
       "Q 2722 1028 2722 1663 \n",
       "Q 2722 2313 2464 2622 \n",
       "Q 2206 2931 1841 2931 \n",
       "Q 1472 2931 1203 2611 \n",
       "Q 934 2291 934 1684 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-f3\" d=\"M 213 1659 \n",
       "Q 213 2581 725 3025 \n",
       "Q 1153 3394 1769 3394 \n",
       "Q 2453 3394 2887 2945 \n",
       "Q 3322 2497 3322 1706 \n",
       "Q 3322 1066 3130 698 \n",
       "Q 2938 331 2570 128 \n",
       "Q 2203 -75 1769 -75 \n",
       "Q 1072 -75 642 372 \n",
       "Q 213 819 213 1659 \n",
       "z\n",
       "M 791 1659 \n",
       "Q 791 1022 1069 705 \n",
       "Q 1347 388 1769 388 \n",
       "Q 2188 388 2466 706 \n",
       "Q 2744 1025 2744 1678 \n",
       "Q 2744 2294 2464 2611 \n",
       "Q 2184 2928 1769 2928 \n",
       "Q 1347 2928 1069 2612 \n",
       "Q 791 2297 791 1659 \n",
       "z\n",
       "M 1454 3731 \n",
       "L 1869 4606 \n",
       "L 2607 4606 \n",
       "L 1919 3731 \n",
       "L 1454 3731 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-2202\" d=\"M 1331 3556 \n",
       "L 909 3744 \n",
       "Q 1128 4234 1434 4446 \n",
       "Q 1741 4659 2034 4659 \n",
       "Q 2272 4659 2464 4536 \n",
       "Q 2656 4413 2753 4253 \n",
       "Q 2900 4006 2970 3668 \n",
       "Q 3041 3331 3041 2894 \n",
       "Q 3041 1994 2770 1292 \n",
       "Q 2500 591 2040 256 \n",
       "Q 1581 -78 1138 -78 \n",
       "Q 709 -78 442 206 \n",
       "Q 175 491 175 1006 \n",
       "Q 175 1713 653 2216 \n",
       "Q 1269 2863 2681 2888 \n",
       "Q 2669 3413 2606 3688 \n",
       "Q 2544 3963 2394 4111 \n",
       "Q 2244 4259 2041 4259 \n",
       "Q 1847 4259 1662 4104 \n",
       "Q 1478 3950 1331 3556 \n",
       "z\n",
       "M 2669 2488 \n",
       "Q 1906 2444 1551 2275 \n",
       "Q 1197 2106 967 1723 \n",
       "Q 738 1341 738 947 \n",
       "Q 738 688 897 519 \n",
       "Q 1056 350 1269 350 \n",
       "Q 1503 350 1769 522 \n",
       "Q 2134 759 2364 1254 \n",
       "Q 2594 1750 2669 2488 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-50\" d=\"M 494 0 \n",
       "L 494 4581 \n",
       "L 2222 4581 \n",
       "Q 2678 4581 2919 4538 \n",
       "Q 3256 4481 3484 4323 \n",
       "Q 3713 4166 3852 3881 \n",
       "Q 3991 3597 3991 3256 \n",
       "Q 3991 2672 3619 2267 \n",
       "Q 3247 1863 2275 1863 \n",
       "L 1100 1863 \n",
       "L 1100 0 \n",
       "L 494 0 \n",
       "z\n",
       "M 1100 2403 \n",
       "L 2284 2403 \n",
       "Q 2872 2403 3119 2622 \n",
       "Q 3366 2841 3366 3238 \n",
       "Q 3366 3525 3220 3729 \n",
       "Q 3075 3934 2838 4000 \n",
       "Q 2684 4041 2272 4041 \n",
       "L 1100 4041 \n",
       "L 1100 2403 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-2f\" d=\"M 0 -78 \n",
       "L 1328 4659 \n",
       "L 1778 4659 \n",
       "L 453 -78 \n",
       "L 0 -78 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-53\" d=\"M 288 1472 \n",
       "L 859 1522 \n",
       "Q 900 1178 1048 958 \n",
       "Q 1197 738 1509 602 \n",
       "Q 1822 466 2213 466 \n",
       "Q 2559 466 2825 569 \n",
       "Q 3091 672 3220 851 \n",
       "Q 3350 1031 3350 1244 \n",
       "Q 3350 1459 3225 1620 \n",
       "Q 3100 1781 2813 1891 \n",
       "Q 2628 1963 1997 2114 \n",
       "Q 1366 2266 1113 2400 \n",
       "Q 784 2572 623 2826 \n",
       "Q 463 3081 463 3397 \n",
       "Q 463 3744 659 4045 \n",
       "Q 856 4347 1234 4503 \n",
       "Q 1613 4659 2075 4659 \n",
       "Q 2584 4659 2973 4495 \n",
       "Q 3363 4331 3572 4012 \n",
       "Q 3781 3694 3797 3291 \n",
       "L 3216 3247 \n",
       "Q 3169 3681 2898 3903 \n",
       "Q 2628 4125 2100 4125 \n",
       "Q 1550 4125 1298 3923 \n",
       "Q 1047 3722 1047 3438 \n",
       "Q 1047 3191 1225 3031 \n",
       "Q 1400 2872 2139 2705 \n",
       "Q 2878 2538 3153 2413 \n",
       "Q 3553 2228 3743 1945 \n",
       "Q 3934 1663 3934 1294 \n",
       "Q 3934 928 3725 604 \n",
       "Q 3516 281 3123 101 \n",
       "Q 2731 -78 2241 -78 \n",
       "Q 1619 -78 1198 103 \n",
       "Q 778 284 539 648 \n",
       "Q 300 1013 288 1472 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(94.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(144.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(172.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(205.517578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-62\" transform=\"translate(227.734375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(283.349609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(338.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(388.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-f3\" transform=\"translate(411.181641 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(466.796875 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(522.412109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(550.195312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(605.810547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(661.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(689.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-50\" transform=\"translate(738.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(805.322266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(838.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(894.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(944.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(966.455078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2f\" transform=\"translate(1022.070312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(1049.853516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-53\" transform=\"translate(1099.267578 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_1\">\n",
       "    <g id=\"patch_107\">\n",
       "     <path d=\"M 370.314687 63.426937 \n",
       "L 487.459531 63.426937 \n",
       "Q 489.659531 63.426937 489.659531 61.226937 \n",
       "L 489.659531 31.20725 \n",
       "Q 489.659531 29.00725 487.459531 29.00725 \n",
       "L 370.314687 29.00725 \n",
       "Q 368.114687 29.00725 368.114687 31.20725 \n",
       "L 368.114687 61.226937 \n",
       "Q 368.114687 63.426937 370.314687 63.426937 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_17\">\n",
       "     <path d=\"M 372.514687 37.430844 \n",
       "L 383.514687 37.430844 \n",
       "L 394.514687 37.430844 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_17\">\n",
       "     <!-- Media: 277.47 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(403.314687 41.280844) scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-4d\" d=\"M 475 0 \n",
       "L 475 4581 \n",
       "L 1388 4581 \n",
       "L 2472 1338 \n",
       "Q 2622 884 2691 659 \n",
       "Q 2769 909 2934 1394 \n",
       "L 4031 4581 \n",
       "L 4847 4581 \n",
       "L 4847 0 \n",
       "L 4263 0 \n",
       "L 4263 3834 \n",
       "L 2931 0 \n",
       "L 2384 0 \n",
       "L 1059 3900 \n",
       "L 1059 0 \n",
       "L 475 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-3a\" d=\"M 578 2678 \n",
       "L 578 3319 \n",
       "L 1219 3319 \n",
       "L 1219 2678 \n",
       "L 578 2678 \n",
       "z\n",
       "M 578 0 \n",
       "L 578 641 \n",
       "L 1219 641 \n",
       "L 1219 0 \n",
       "L 578 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-37\" d=\"M 303 3981 \n",
       "L 303 4522 \n",
       "L 3269 4522 \n",
       "L 3269 4084 \n",
       "Q 2831 3619 2401 2847 \n",
       "Q 1972 2075 1738 1259 \n",
       "Q 1569 684 1522 0 \n",
       "L 944 0 \n",
       "Q 953 541 1156 1306 \n",
       "Q 1359 2072 1739 2783 \n",
       "Q 2119 3494 2547 3981 \n",
       "L 303 3981 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       <path id=\"ArialMT-2e\" d=\"M 581 0 \n",
       "L 581 641 \n",
       "L 1222 641 \n",
       "L 1222 0 \n",
       "L 581 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(300.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(327.929688 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-37\" transform=\"translate(383.544922 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-37\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(494.775391 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-34\" transform=\"translate(522.558594 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-37\" transform=\"translate(578.173828 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_18\">\n",
       "     <path d=\"M 372.514687 52.990687 \n",
       "L 383.514687 52.990687 \n",
       "L 394.514687 52.990687 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_18\">\n",
       "     <!-- Mediana: 265.31 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(403.314687 56.840687) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-36\" transform=\"translate(494.775391 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-35\" transform=\"translate(550.390625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(606.005859 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-33\" transform=\"translate(633.789062 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(689.404297 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_2\">\n",
       "   <g id=\"patch_108\">\n",
       "    <path d=\"M 560.859531 246.82725 \n",
       "L 993.759531 246.82725 \n",
       "L 993.759531 23.50725 \n",
       "L 560.859531 23.50725 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_3\">\n",
       "    <g id=\"xtick_8\">\n",
       "     <g id=\"line2d_19\">\n",
       "      <path d=\"M 594.866598 246.82725 \n",
       "L 594.866598 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_19\">\n",
       "      <!-- −500 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(582.478708 264.200844) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-2212\" d=\"M 3381 1997 \n",
       "L 356 1997 \n",
       "L 356 2522 \n",
       "L 3381 2522 \n",
       "L 3381 1997 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_9\">\n",
       "     <g id=\"line2d_20\">\n",
       "      <path d=\"M 667.866156 246.82725 \n",
       "L 667.866156 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_20\">\n",
       "      <!-- −400 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(655.478265 264.200844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_10\">\n",
       "     <g id=\"line2d_21\">\n",
       "      <path d=\"M 740.865713 246.82725 \n",
       "L 740.865713 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_21\">\n",
       "      <!-- −300 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(728.477822 264.200844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_11\">\n",
       "     <g id=\"line2d_22\">\n",
       "      <path d=\"M 813.86527 246.82725 \n",
       "L 813.86527 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_22\">\n",
       "      <!-- −200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(801.47738 264.200844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_12\">\n",
       "     <g id=\"line2d_23\">\n",
       "      <path d=\"M 886.864828 246.82725 \n",
       "L 886.864828 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_23\">\n",
       "      <!-- −100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(874.476937 264.200844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-31\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_13\">\n",
       "     <g id=\"line2d_24\">\n",
       "      <path d=\"M 959.864385 246.82725 \n",
       "L 959.864385 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_24\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(956.805869 264.200844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_25\">\n",
       "     <!-- Valor de la derivada parcial -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(705.047969 278.976469) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(59.324219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(114.939453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(137.15625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(192.771484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(226.072266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(253.855469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(309.470703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(365.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(392.869141 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(415.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(470.701172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(498.484375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(554.099609 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(609.714844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(643.015625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(665.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(715.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(770.847656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(826.462891 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(882.078125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(909.861328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(965.476562 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(1021.091797 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(1054.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(1104.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(1126.609375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1182.224609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_4\">\n",
       "    <g id=\"ytick_7\">\n",
       "     <g id=\"line2d_25\">\n",
       "      <path d=\"M 560.859531 246.82725 \n",
       "L 993.759531 246.82725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_26\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(545.2425 250.764047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_8\">\n",
       "     <g id=\"line2d_26\">\n",
       "      <path d=\"M 560.859531 200.84115 \n",
       "L 993.759531 200.84115 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_27\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 204.777946) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_9\">\n",
       "     <g id=\"line2d_27\">\n",
       "      <path d=\"M 560.859531 154.855049 \n",
       "L 993.759531 154.855049 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_28\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 158.791846) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_10\">\n",
       "     <g id=\"line2d_28\">\n",
       "      <path d=\"M 560.859531 108.868949 \n",
       "L 993.759531 108.868949 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_29\">\n",
       "      <!-- 3000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 112.805746) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_11\">\n",
       "     <g id=\"line2d_29\">\n",
       "      <path d=\"M 560.859531 62.882848 \n",
       "L 993.759531 62.882848 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_30\">\n",
       "      <!-- 4000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 66.819645) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_31\">\n",
       "     <!-- Frecuencia -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(520.506406 164.845687) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-46\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(61.083984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(94.384766 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(150 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(255.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(311.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(366.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(439.0625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_109\">\n",
       "    <path d=\"M 580.536804 246.82725 \n",
       "L 584.472259 246.82725 \n",
       "L 584.472259 246.781264 \n",
       "L 580.536804 246.781264 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_110\">\n",
       "    <path d=\"M 584.472259 246.82725 \n",
       "L 588.407713 246.82725 \n",
       "L 588.407713 246.82725 \n",
       "L 584.472259 246.82725 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_111\">\n",
       "    <path d=\"M 588.407713 246.82725 \n",
       "L 592.343168 246.82725 \n",
       "L 592.343168 246.82725 \n",
       "L 588.407713 246.82725 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_112\">\n",
       "    <path d=\"M 592.343168 246.82725 \n",
       "L 596.278622 246.82725 \n",
       "L 596.278622 244.252028 \n",
       "L 592.343168 244.252028 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_113\">\n",
       "    <path d=\"M 596.278622 246.82725 \n",
       "L 600.214077 246.82725 \n",
       "L 600.214077 230.778101 \n",
       "L 596.278622 230.778101 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_114\">\n",
       "    <path d=\"M 600.214077 246.82725 \n",
       "L 604.149531 246.82725 \n",
       "L 604.149531 241.124974 \n",
       "L 600.214077 241.124974 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_115\">\n",
       "    <path d=\"M 604.149531 246.82725 \n",
       "L 608.084986 246.82725 \n",
       "L 608.084986 238.181863 \n",
       "L 604.149531 238.181863 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_116\">\n",
       "    <path d=\"M 608.084986 246.82725 \n",
       "L 612.02044 246.82725 \n",
       "L 612.02044 214.728952 \n",
       "L 608.084986 214.728952 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_117\">\n",
       "    <path d=\"M 612.02044 246.82725 \n",
       "L 615.955895 246.82725 \n",
       "L 615.955895 198.909733 \n",
       "L 612.02044 198.909733 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_118\">\n",
       "    <path d=\"M 615.955895 246.82725 \n",
       "L 619.891349 246.82725 \n",
       "L 619.891349 223.420325 \n",
       "L 615.955895 223.420325 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_119\">\n",
       "    <path d=\"M 619.891349 246.82725 \n",
       "L 623.826804 246.82725 \n",
       "L 623.826804 238.641724 \n",
       "L 619.891349 238.641724 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_120\">\n",
       "    <path d=\"M 623.826804 246.82725 \n",
       "L 627.762259 246.82725 \n",
       "L 627.762259 219.971367 \n",
       "L 623.826804 219.971367 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_121\">\n",
       "    <path d=\"M 627.762259 246.82725 \n",
       "L 631.697713 246.82725 \n",
       "L 631.697713 210.958092 \n",
       "L 627.762259 210.958092 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_122\">\n",
       "    <path d=\"M 631.697713 246.82725 \n",
       "L 635.633168 246.82725 \n",
       "L 635.633168 144.278246 \n",
       "L 631.697713 144.278246 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_123\">\n",
       "    <path d=\"M 635.633168 246.82725 \n",
       "L 639.568622 246.82725 \n",
       "L 639.568622 192.563652 \n",
       "L 635.633168 192.563652 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_124\">\n",
       "    <path d=\"M 639.568622 246.82725 \n",
       "L 643.504077 246.82725 \n",
       "L 643.504077 176.1926 \n",
       "L 639.568622 176.1926 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_125\">\n",
       "    <path d=\"M 643.504077 246.82725 \n",
       "L 647.439531 246.82725 \n",
       "L 647.439531 162.39677 \n",
       "L 643.504077 162.39677 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_126\">\n",
       "    <path d=\"M 647.439531 246.82725 \n",
       "L 651.374986 246.82725 \n",
       "L 651.374986 207.003287 \n",
       "L 647.439531 207.003287 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_127\">\n",
       "    <path d=\"M 651.374986 246.82725 \n",
       "L 655.31044 246.82725 \n",
       "L 655.31044 124.320279 \n",
       "L 651.374986 124.320279 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_128\">\n",
       "    <path d=\"M 655.31044 246.82725 \n",
       "L 659.245895 246.82725 \n",
       "L 659.245895 157.706187 \n",
       "L 655.31044 157.706187 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_129\">\n",
       "    <path d=\"M 659.245895 246.82725 \n",
       "L 663.181349 246.82725 \n",
       "L 663.181349 180.929168 \n",
       "L 659.245895 180.929168 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_130\">\n",
       "    <path d=\"M 663.181349 246.82725 \n",
       "L 667.116804 246.82725 \n",
       "L 667.116804 56.030919 \n",
       "L 663.181349 56.030919 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_131\">\n",
       "    <path d=\"M 667.116804 246.82725 \n",
       "L 671.052259 246.82725 \n",
       "L 671.052259 145.749801 \n",
       "L 667.116804 145.749801 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_132\">\n",
       "    <path d=\"M 671.052259 246.82725 \n",
       "L 674.987713 246.82725 \n",
       "L 674.987713 95.900869 \n",
       "L 671.052259 95.900869 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_133\">\n",
       "    <path d=\"M 674.987713 246.82725 \n",
       "L 678.923168 246.82725 \n",
       "L 678.923168 165.661783 \n",
       "L 674.987713 165.661783 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_134\">\n",
       "    <path d=\"M 678.923168 246.82725 \n",
       "L 682.858622 246.82725 \n",
       "L 682.858622 212.15373 \n",
       "L 678.923168 212.15373 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_135\">\n",
       "    <path d=\"M 682.858622 246.82725 \n",
       "L 686.794077 246.82725 \n",
       "L 686.794077 131.080235 \n",
       "L 682.858622 131.080235 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_136\">\n",
       "    <path d=\"M 686.794077 246.82725 \n",
       "L 690.729531 246.82725 \n",
       "L 690.729531 180.79121 \n",
       "L 686.794077 180.79121 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_137\">\n",
       "    <path d=\"M 690.729531 246.82725 \n",
       "L 694.664986 246.82725 \n",
       "L 694.664986 178.813808 \n",
       "L 690.729531 178.813808 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_138\">\n",
       "    <path d=\"M 694.664986 246.82725 \n",
       "L 698.60044 246.82725 \n",
       "L 698.60044 185.067917 \n",
       "L 694.664986 185.067917 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_139\">\n",
       "    <path d=\"M 698.60044 246.82725 \n",
       "L 702.535895 246.82725 \n",
       "L 702.535895 213.763244 \n",
       "L 698.60044 213.763244 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_140\">\n",
       "    <path d=\"M 702.535895 246.82725 \n",
       "L 706.471349 246.82725 \n",
       "L 706.471349 183.642348 \n",
       "L 702.535895 183.642348 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_141\">\n",
       "    <path d=\"M 706.471349 246.82725 \n",
       "L 710.406804 246.82725 \n",
       "L 710.406804 200.84115 \n",
       "L 706.471349 200.84115 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_142\">\n",
       "    <path d=\"M 710.406804 246.82725 \n",
       "L 714.342259 246.82725 \n",
       "L 714.342259 151.084189 \n",
       "L 710.406804 151.084189 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_143\">\n",
       "    <path d=\"M 714.342259 246.82725 \n",
       "L 718.277713 246.82725 \n",
       "L 718.277713 162.718672 \n",
       "L 714.342259 162.718672 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_144\">\n",
       "    <path d=\"M 718.277713 246.82725 \n",
       "L 722.213168 246.82725 \n",
       "L 722.213168 198.955719 \n",
       "L 718.277713 198.955719 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_145\">\n",
       "    <path d=\"M 722.213168 246.82725 \n",
       "L 726.148622 246.82725 \n",
       "L 726.148622 207.877023 \n",
       "L 722.213168 207.877023 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_146\">\n",
       "    <path d=\"M 726.148622 246.82725 \n",
       "L 730.084077 246.82725 \n",
       "L 730.084077 165.201922 \n",
       "L 726.148622 165.201922 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_147\">\n",
       "    <path d=\"M 730.084077 246.82725 \n",
       "L 734.019531 246.82725 \n",
       "L 734.019531 237.170169 \n",
       "L 730.084077 237.170169 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_148\">\n",
       "    <path d=\"M 734.019531 246.82725 \n",
       "L 737.954986 246.82725 \n",
       "L 737.954986 239.147571 \n",
       "L 734.019531 239.147571 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_149\">\n",
       "    <path d=\"M 737.954986 246.82725 \n",
       "L 741.89044 246.82725 \n",
       "L 741.89044 240.34321 \n",
       "L 737.954986 240.34321 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_150\">\n",
       "    <path d=\"M 741.89044 246.82725 \n",
       "L 745.825895 246.82725 \n",
       "L 745.825895 237.63003 \n",
       "L 741.89044 237.63003 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_151\">\n",
       "    <path d=\"M 745.825895 246.82725 \n",
       "L 749.761349 246.82725 \n",
       "L 749.761349 241.860751 \n",
       "L 745.825895 241.860751 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_152\">\n",
       "    <path d=\"M 749.761349 246.82725 \n",
       "L 753.696804 246.82725 \n",
       "L 753.696804 244.022098 \n",
       "L 749.761349 244.022098 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_153\">\n",
       "    <path d=\"M 753.696804 246.82725 \n",
       "L 757.632259 246.82725 \n",
       "L 757.632259 240.021307 \n",
       "L 753.696804 240.021307 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_154\">\n",
       "    <path d=\"M 757.632259 246.82725 \n",
       "L 761.567713 246.82725 \n",
       "L 761.567713 246.781264 \n",
       "L 757.632259 246.781264 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_155\">\n",
       "    <path d=\"M 761.567713 246.82725 \n",
       "L 765.503168 246.82725 \n",
       "L 765.503168 246.781264 \n",
       "L 761.567713 246.781264 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_156\">\n",
       "    <path d=\"M 765.503168 246.82725 \n",
       "L 769.438622 246.82725 \n",
       "L 769.438622 246.689292 \n",
       "L 765.503168 246.689292 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_157\">\n",
       "    <path d=\"M 769.438622 246.82725 \n",
       "L 773.374077 246.82725 \n",
       "L 773.374077 246.551333 \n",
       "L 769.438622 246.551333 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_158\">\n",
       "    <path d=\"M 773.374077 246.82725 \n",
       "L 777.309531 246.82725 \n",
       "L 777.309531 246.689292 \n",
       "L 773.374077 246.689292 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_159\">\n",
       "    <path d=\"M 777.309531 246.82725 \n",
       "L 781.244986 246.82725 \n",
       "L 781.244986 246.551333 \n",
       "L 777.309531 246.551333 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_160\">\n",
       "    <path d=\"M 781.244986 246.82725 \n",
       "L 785.18044 246.82725 \n",
       "L 785.18044 246.781264 \n",
       "L 781.244986 246.781264 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_161\">\n",
       "    <path d=\"M 785.18044 246.82725 \n",
       "L 789.115895 246.82725 \n",
       "L 789.115895 246.735278 \n",
       "L 785.18044 246.735278 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_162\">\n",
       "    <path d=\"M 789.115895 246.82725 \n",
       "L 793.051349 246.82725 \n",
       "L 793.051349 246.82725 \n",
       "L 789.115895 246.82725 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_163\">\n",
       "    <path d=\"M 793.051349 246.82725 \n",
       "L 796.986804 246.82725 \n",
       "L 796.986804 246.781264 \n",
       "L 793.051349 246.781264 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_164\">\n",
       "    <path d=\"M 796.986804 246.82725 \n",
       "L 800.922259 246.82725 \n",
       "L 800.922259 246.781264 \n",
       "L 796.986804 246.781264 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_165\">\n",
       "    <path d=\"M 800.922259 246.82725 \n",
       "L 804.857713 246.82725 \n",
       "L 804.857713 245.953514 \n",
       "L 800.922259 245.953514 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_166\">\n",
       "    <path d=\"M 804.857713 246.82725 \n",
       "L 808.793168 246.82725 \n",
       "L 808.793168 246.229431 \n",
       "L 804.857713 246.229431 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_167\">\n",
       "    <path d=\"M 808.793168 246.82725 \n",
       "L 812.728622 246.82725 \n",
       "L 812.728622 245.76957 \n",
       "L 808.793168 245.76957 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_168\">\n",
       "    <path d=\"M 812.728622 246.82725 \n",
       "L 816.664077 246.82725 \n",
       "L 816.664077 245.631611 \n",
       "L 812.728622 245.631611 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_169\">\n",
       "    <path d=\"M 816.664077 246.82725 \n",
       "L 820.599531 246.82725 \n",
       "L 820.599531 242.366598 \n",
       "L 816.664077 242.366598 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_170\">\n",
       "    <path d=\"M 820.599531 246.82725 \n",
       "L 824.534986 246.82725 \n",
       "L 824.534986 243.010404 \n",
       "L 820.599531 243.010404 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_171\">\n",
       "    <path d=\"M 824.534986 246.82725 \n",
       "L 828.47044 246.82725 \n",
       "L 828.47044 241.584835 \n",
       "L 824.534986 241.584835 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_172\">\n",
       "    <path d=\"M 828.47044 246.82725 \n",
       "L 832.405895 246.82725 \n",
       "L 832.405895 237.997919 \n",
       "L 828.47044 237.997919 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_173\">\n",
       "    <path d=\"M 832.405895 246.82725 \n",
       "L 836.341349 246.82725 \n",
       "L 836.341349 238.043905 \n",
       "L 832.405895 238.043905 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_174\">\n",
       "    <path d=\"M 836.341349 246.82725 \n",
       "L 840.276804 246.82725 \n",
       "L 840.276804 234.227058 \n",
       "L 836.341349 234.227058 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_175\">\n",
       "    <path d=\"M 840.276804 246.82725 \n",
       "L 844.212259 246.82725 \n",
       "L 844.212259 230.962045 \n",
       "L 840.276804 230.962045 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_176\">\n",
       "    <path d=\"M 844.212259 246.82725 \n",
       "L 848.147713 246.82725 \n",
       "L 848.147713 225.029838 \n",
       "L 844.212259 225.029838 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_177\">\n",
       "    <path d=\"M 848.147713 246.82725 \n",
       "L 852.083168 246.82725 \n",
       "L 852.083168 221.764825 \n",
       "L 848.147713 221.764825 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_178\">\n",
       "    <path d=\"M 852.083168 246.82725 \n",
       "L 856.018622 246.82725 \n",
       "L 856.018622 208.980689 \n",
       "L 852.083168 208.980689 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_179\">\n",
       "    <path d=\"M 856.018622 246.82725 \n",
       "L 859.954077 246.82725 \n",
       "L 859.954077 222.132714 \n",
       "L 856.018622 222.132714 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_180\">\n",
       "    <path d=\"M 859.954077 246.82725 \n",
       "L 863.889531 246.82725 \n",
       "L 863.889531 224.89188 \n",
       "L 859.954077 224.89188 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_181\">\n",
       "    <path d=\"M 863.889531 246.82725 \n",
       "L 867.824986 246.82725 \n",
       "L 867.824986 214.407049 \n",
       "L 863.889531 214.407049 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_182\">\n",
       "    <path d=\"M 867.824986 246.82725 \n",
       "L 871.76044 246.82725 \n",
       "L 871.76044 219.46552 \n",
       "L 867.824986 219.46552 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_183\">\n",
       "    <path d=\"M 871.76044 246.82725 \n",
       "L 875.695895 246.82725 \n",
       "L 875.695895 210.958092 \n",
       "L 871.76044 210.958092 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_184\">\n",
       "    <path d=\"M 875.695895 246.82725 \n",
       "L 879.631349 246.82725 \n",
       "L 879.631349 208.244912 \n",
       "L 875.695895 208.244912 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_185\">\n",
       "    <path d=\"M 879.631349 246.82725 \n",
       "L 883.566804 246.82725 \n",
       "L 883.566804 193.437387 \n",
       "L 879.631349 193.437387 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_186\">\n",
       "    <path d=\"M 883.566804 246.82725 \n",
       "L 887.502259 246.82725 \n",
       "L 887.502259 162.258811 \n",
       "L 883.566804 162.258811 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_187\">\n",
       "    <path d=\"M 887.502259 246.82725 \n",
       "L 891.437713 246.82725 \n",
       "L 891.437713 169.248699 \n",
       "L 887.502259 169.248699 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_188\">\n",
       "    <path d=\"M 891.437713 246.82725 \n",
       "L 895.373168 246.82725 \n",
       "L 895.373168 169.846518 \n",
       "L 891.437713 169.846518 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_189\">\n",
       "    <path d=\"M 895.373168 246.82725 \n",
       "L 899.308622 246.82725 \n",
       "L 899.308622 135.954762 \n",
       "L 895.373168 135.954762 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_190\">\n",
       "    <path d=\"M 899.308622 246.82725 \n",
       "L 903.244077 246.82725 \n",
       "L 903.244077 140.875275 \n",
       "L 899.308622 140.875275 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_191\">\n",
       "    <path d=\"M 903.244077 246.82725 \n",
       "L 907.179531 246.82725 \n",
       "L 907.179531 121.147238 \n",
       "L 903.244077 121.147238 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_192\">\n",
       "    <path d=\"M 907.179531 246.82725 \n",
       "L 911.114986 246.82725 \n",
       "L 911.114986 149.382703 \n",
       "L 907.179531 149.382703 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_193\">\n",
       "    <path d=\"M 911.114986 246.82725 \n",
       "L 915.05044 246.82725 \n",
       "L 915.05044 79.621789 \n",
       "L 911.114986 79.621789 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_194\">\n",
       "    <path d=\"M 915.05044 246.82725 \n",
       "L 918.985895 246.82725 \n",
       "L 918.985895 74.563318 \n",
       "L 915.05044 74.563318 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_195\">\n",
       "    <path d=\"M 918.985895 246.82725 \n",
       "L 922.921349 246.82725 \n",
       "L 922.921349 39.062048 \n",
       "L 918.985895 39.062048 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_196\">\n",
       "    <path d=\"M 922.921349 246.82725 \n",
       "L 926.856804 246.82725 \n",
       "L 926.856804 95.395021 \n",
       "L 922.921349 95.395021 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_197\">\n",
       "    <path d=\"M 926.856804 246.82725 \n",
       "L 930.792259 246.82725 \n",
       "L 930.792259 34.141536 \n",
       "L 926.856804 34.141536 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_198\">\n",
       "    <path d=\"M 930.792259 246.82725 \n",
       "L 934.727713 246.82725 \n",
       "L 934.727713 147.221357 \n",
       "L 930.792259 147.221357 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_199\">\n",
       "    <path d=\"M 934.727713 246.82725 \n",
       "L 938.663168 246.82725 \n",
       "L 938.663168 199.277622 \n",
       "L 934.727713 199.277622 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_200\">\n",
       "    <path d=\"M 938.663168 246.82725 \n",
       "L 942.598622 246.82725 \n",
       "L 942.598622 188.240958 \n",
       "L 938.663168 188.240958 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_201\">\n",
       "    <path d=\"M 942.598622 246.82725 \n",
       "L 946.534077 246.82725 \n",
       "L 946.534077 189.528569 \n",
       "L 942.598622 189.528569 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_202\">\n",
       "    <path d=\"M 946.534077 246.82725 \n",
       "L 950.469531 246.82725 \n",
       "L 950.469531 180.469307 \n",
       "L 946.534077 180.469307 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_203\">\n",
       "    <path d=\"M 950.469531 246.82725 \n",
       "L 954.404986 246.82725 \n",
       "L 954.404986 226.225477 \n",
       "L 950.469531 226.225477 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_204\">\n",
       "    <path d=\"M 954.404986 246.82725 \n",
       "L 958.34044 246.82725 \n",
       "L 958.34044 220.017353 \n",
       "L 954.404986 220.017353 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_205\">\n",
       "    <path d=\"M 958.34044 246.82725 \n",
       "L 962.275895 246.82725 \n",
       "L 962.275895 208.704773 \n",
       "L 958.34044 208.704773 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_206\">\n",
       "    <path d=\"M 962.275895 246.82725 \n",
       "L 966.211349 246.82725 \n",
       "L 966.211349 233.077406 \n",
       "L 962.275895 233.077406 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_207\">\n",
       "    <path d=\"M 966.211349 246.82725 \n",
       "L 970.146804 246.82725 \n",
       "L 970.146804 243.516251 \n",
       "L 966.211349 243.516251 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_208\">\n",
       "    <path d=\"M 970.146804 246.82725 \n",
       "L 974.082259 246.82725 \n",
       "L 974.082259 244.160056 \n",
       "L 970.146804 244.160056 \n",
       "z\n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_30\">\n",
       "    <path d=\"M 580.536804 245.406667 \n",
       "L 582.514419 244.92525 \n",
       "L 584.492035 244.32744 \n",
       "L 586.46965 243.600275 \n",
       "L 588.447265 242.73342 \n",
       "L 590.424881 241.72015 \n",
       "L 592.402496 240.558147 \n",
       "L 594.380111 239.249987 \n",
       "L 598.335342 236.229653 \n",
       "L 602.290573 232.764464 \n",
       "L 606.245804 228.978314 \n",
       "L 610.201034 224.939272 \n",
       "L 614.156265 220.597244 \n",
       "L 618.111496 215.788535 \n",
       "L 622.066726 210.33252 \n",
       "L 626.021957 204.17431 \n",
       "L 629.977188 197.469875 \n",
       "L 639.865264 180.300245 \n",
       "L 651.730957 160.562183 \n",
       "L 655.686187 154.186883 \n",
       "L 657.663803 151.246631 \n",
       "L 659.641418 148.602533 \n",
       "L 661.619033 146.365092 \n",
       "L 663.596649 144.642062 \n",
       "L 665.574264 143.527223 \n",
       "L 667.551879 143.090068 \n",
       "L 669.529495 143.367799 \n",
       "L 671.50711 144.360678 \n",
       "L 673.484725 146.0313 \n",
       "L 675.462341 148.307716 \n",
       "L 677.439956 151.08978 \n",
       "L 679.417571 154.257603 \n",
       "L 683.372802 161.227669 \n",
       "L 687.328033 168.201176 \n",
       "L 689.305648 171.416939 \n",
       "L 691.283264 174.34169 \n",
       "L 693.260879 176.919041 \n",
       "L 695.238494 179.115904 \n",
       "L 697.21611 180.923969 \n",
       "L 699.193725 182.360668 \n",
       "L 701.17134 183.469157 \n",
       "L 703.148956 184.316732 \n",
       "L 711.059417 187.029342 \n",
       "L 713.037032 188.065012 \n",
       "L 715.014648 189.424462 \n",
       "L 716.992263 191.161747 \n",
       "L 718.969878 193.302492 \n",
       "L 720.947494 195.843039 \n",
       "L 722.925109 198.752205 \n",
       "L 724.902724 201.97521 \n",
       "L 728.857955 209.059189 \n",
       "L 734.790801 219.966974 \n",
       "L 736.768417 223.349098 \n",
       "L 738.746032 226.498833 \n",
       "L 740.723647 229.376537 \n",
       "L 742.701263 231.959653 \n",
       "L 744.678878 234.24172 \n",
       "L 746.656493 236.230152 \n",
       "L 748.634109 237.943142 \n",
       "L 750.611724 239.406135 \n",
       "L 752.589339 240.648311 \n",
       "L 754.566955 241.699511 \n",
       "L 756.54457 242.587875 \n",
       "L 760.499801 243.971924 \n",
       "L 764.455031 244.953876 \n",
       "L 768.410262 245.635179 \n",
       "L 772.365493 246.086381 \n",
       "L 778.298339 246.451895 \n",
       "L 784.231185 246.570262 \n",
       "L 792.141646 246.468249 \n",
       "L 798.074492 246.184972 \n",
       "L 804.007338 245.642599 \n",
       "L 807.962569 245.081801 \n",
       "L 811.9178 244.318549 \n",
       "L 815.873031 243.316242 \n",
       "L 819.828261 242.039977 \n",
       "L 823.783492 240.458149 \n",
       "L 827.738723 238.548611 \n",
       "L 831.693953 236.312486 \n",
       "L 835.649184 233.79268 \n",
       "L 851.470107 223.120115 \n",
       "L 857.402953 219.373965 \n",
       "L 861.358184 216.524872 \n",
       "L 863.335799 214.860311 \n",
       "L 865.313414 212.975721 \n",
       "L 867.29103 210.833073 \n",
       "L 869.268645 208.403391 \n",
       "L 871.24626 205.668536 \n",
       "L 873.223876 202.6218 \n",
       "L 875.201491 199.267324 \n",
       "L 877.179106 195.618473 \n",
       "L 879.156722 191.695475 \n",
       "L 883.111952 183.12583 \n",
       "L 887.067183 173.756672 \n",
       "L 891.022414 163.752065 \n",
       "L 894.977645 153.235904 \n",
       "L 906.843337 120.933521 \n",
       "L 908.820952 116.176877 \n",
       "L 910.798567 111.933921 \n",
       "L 912.776183 108.372953 \n",
       "L 914.753798 105.665827 \n",
       "L 916.731413 103.974584 \n",
       "L 918.709029 103.436712 \n",
       "L 920.686644 104.150791 \n",
       "L 922.664259 106.164467 \n",
       "L 924.641875 109.466506 \n",
       "L 926.61949 113.98428 \n",
       "L 928.597105 119.587315 \n",
       "L 930.574721 126.096669 \n",
       "L 932.552336 133.299093 \n",
       "L 936.507567 148.86261 \n",
       "L 940.462798 164.542552 \n",
       "L 944.418028 179.061577 \n",
       "L 946.395644 185.665443 \n",
       "L 948.373259 191.792889 \n",
       "L 950.350874 197.45165 \n",
       "L 952.32849 202.66842 \n",
       "L 954.306105 207.479853 \n",
       "L 956.28372 211.924837 \n",
       "L 958.261336 216.038694 \n",
       "L 960.238951 219.849555 \n",
       "L 962.216566 223.376833 \n",
       "L 964.194182 226.631476 \n",
       "L 966.171797 229.617545 \n",
       "L 968.149412 232.334616 \n",
       "L 970.127028 234.780523 \n",
       "L 972.104643 236.953988 \n",
       "L 974.082259 238.856803 \n",
       "L 974.082259 238.856803 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_31\">\n",
       "    <path d=\"M 795.391855 246.82725 \n",
       "L 795.391855 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_32\">\n",
       "    <path d=\"M 847.335389 246.82725 \n",
       "L 847.335389 23.50725 \n",
       "\" clip-path=\"url(#p1b9137f3b7)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_209\">\n",
       "    <path d=\"M 560.859531 246.82725 \n",
       "L 560.859531 23.50725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_210\">\n",
       "    <path d=\"M 993.759531 246.82725 \n",
       "L 993.759531 23.50725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_211\">\n",
       "    <path d=\"M 560.859531 246.82725 \n",
       "L 993.759531 246.82725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_212\">\n",
       "    <path d=\"M 560.859531 23.50725 \n",
       "L 993.759531 23.50725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_32\">\n",
       "    <!-- Distribución de ∂Precio/∂K -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(693.362031 17.50725) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-4b\" d=\"M 469 0 \n",
       "L 469 4581 \n",
       "L 1075 4581 \n",
       "L 1075 2309 \n",
       "L 3350 4581 \n",
       "L 4172 4581 \n",
       "L 2250 2725 \n",
       "L 4256 0 \n",
       "L 3456 0 \n",
       "L 1825 2319 \n",
       "L 1075 1588 \n",
       "L 1075 0 \n",
       "L 469 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(94.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(144.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(172.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(205.517578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-62\" transform=\"translate(227.734375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(283.349609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(338.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(388.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-f3\" transform=\"translate(411.181641 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(466.796875 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(522.412109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(550.195312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(605.810547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(661.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(689.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-50\" transform=\"translate(738.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(805.322266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(838.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(894.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(944.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(966.455078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2f\" transform=\"translate(1022.070312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(1049.853516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4b\" transform=\"translate(1099.267578 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_2\">\n",
       "    <g id=\"patch_213\">\n",
       "     <path d=\"M 568.559531 63.426937 \n",
       "L 689.367031 63.426937 \n",
       "Q 691.567031 63.426937 691.567031 61.226937 \n",
       "L 691.567031 31.20725 \n",
       "Q 691.567031 29.00725 689.367031 29.00725 \n",
       "L 568.559531 29.00725 \n",
       "Q 566.359531 29.00725 566.359531 31.20725 \n",
       "L 566.359531 61.226937 \n",
       "Q 566.359531 63.426937 568.559531 63.426937 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_33\">\n",
       "     <path d=\"M 570.759531 37.430844 \n",
       "L 581.759531 37.430844 \n",
       "L 592.759531 37.430844 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_33\">\n",
       "     <!-- Media: -225.31 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(601.559531 41.280844) scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-2d\" d=\"M 203 1375 \n",
       "L 203 1941 \n",
       "L 1931 1941 \n",
       "L 1931 1375 \n",
       "L 203 1375 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(300.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2d\" transform=\"translate(327.929688 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(361.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-35\" transform=\"translate(472.460938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(528.076172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-33\" transform=\"translate(555.859375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(611.474609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_34\">\n",
       "     <path d=\"M 570.759531 52.990687 \n",
       "L 581.759531 52.990687 \n",
       "L 592.759531 52.990687 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_34\">\n",
       "     <!-- Mediana: -154.15 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(601.559531 56.840687) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2d\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(472.460938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-35\" transform=\"translate(528.076172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-34\" transform=\"translate(583.691406 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(639.306641 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(667.089844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-35\" transform=\"translate(722.705078 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_3\">\n",
       "   <g id=\"patch_214\">\n",
       "    <path d=\"M 62.259531 532.12725 \n",
       "L 495.159531 532.12725 \n",
       "L 495.159531 308.80725 \n",
       "L 62.259531 308.80725 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_5\">\n",
       "    <g id=\"xtick_14\">\n",
       "     <g id=\"line2d_35\">\n",
       "      <path d=\"M 131.662267 532.12725 \n",
       "L 131.662267 308.80725 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_35\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(128.603751 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_15\">\n",
       "     <g id=\"line2d_36\">\n",
       "      <path d=\"M 223.502413 532.12725 \n",
       "L 223.502413 308.80725 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_36\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(214.326866 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_16\">\n",
       "     <g id=\"line2d_37\">\n",
       "      <path d=\"M 315.34256 532.12725 \n",
       "L 315.34256 308.80725 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_37\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(306.167013 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_17\">\n",
       "     <g id=\"line2d_38\">\n",
       "      <path d=\"M 407.182706 532.12725 \n",
       "L 407.182706 308.80725 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_38\">\n",
       "      <!-- 300 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(398.007159 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_39\">\n",
       "     <!-- Valor de la derivada parcial -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(206.447969 564.276469) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(59.324219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(114.939453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(137.15625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(192.771484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(226.072266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(253.855469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(309.470703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(365.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(392.869141 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(415.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(470.701172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(498.484375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(554.099609 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(609.714844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(643.015625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(665.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(715.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(770.847656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(826.462891 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(882.078125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(909.861328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(965.476562 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(1021.091797 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(1054.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(1104.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(1126.609375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1182.224609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_6\">\n",
       "    <g id=\"ytick_12\">\n",
       "     <g id=\"line2d_39\">\n",
       "      <path d=\"M 62.259531 532.12725 \n",
       "L 495.159531 532.12725 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_40\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(46.6425 536.064047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_13\">\n",
       "     <g id=\"line2d_40\">\n",
       "      <path d=\"M 62.259531 505.288243 \n",
       "L 495.159531 505.288243 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_41\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 509.225039) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_14\">\n",
       "     <g id=\"line2d_41\">\n",
       "      <path d=\"M 62.259531 478.449235 \n",
       "L 495.159531 478.449235 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_42\">\n",
       "      <!-- 4000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 482.386032) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_15\">\n",
       "     <g id=\"line2d_42\">\n",
       "      <path d=\"M 62.259531 451.610228 \n",
       "L 495.159531 451.610228 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_43\">\n",
       "      <!-- 6000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 455.547025) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_16\">\n",
       "     <g id=\"line2d_43\">\n",
       "      <path d=\"M 62.259531 424.77122 \n",
       "L 495.159531 424.77122 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_44\">\n",
       "      <!-- 8000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 428.708017) scale(0.11 -0.11)\">\n",
       "       <defs>\n",
       "        <path id=\"ArialMT-38\" d=\"M 1131 2484 \n",
       "Q 781 2613 612 2850 \n",
       "Q 444 3088 444 3419 \n",
       "Q 444 3919 803 4259 \n",
       "Q 1163 4600 1759 4600 \n",
       "Q 2359 4600 2725 4251 \n",
       "Q 3091 3903 3091 3403 \n",
       "Q 3091 3084 2923 2848 \n",
       "Q 2756 2613 2416 2484 \n",
       "Q 2838 2347 3058 2040 \n",
       "Q 3278 1734 3278 1309 \n",
       "Q 3278 722 2862 322 \n",
       "Q 2447 -78 1769 -78 \n",
       "Q 1091 -78 675 323 \n",
       "Q 259 725 259 1325 \n",
       "Q 259 1772 486 2073 \n",
       "Q 713 2375 1131 2484 \n",
       "z\n",
       "M 1019 3438 \n",
       "Q 1019 3113 1228 2906 \n",
       "Q 1438 2700 1772 2700 \n",
       "Q 2097 2700 2305 2904 \n",
       "Q 2513 3109 2513 3406 \n",
       "Q 2513 3716 2298 3927 \n",
       "Q 2084 4138 1766 4138 \n",
       "Q 1444 4138 1231 3931 \n",
       "Q 1019 3725 1019 3438 \n",
       "z\n",
       "M 838 1322 \n",
       "Q 838 1081 952 856 \n",
       "Q 1066 631 1291 507 \n",
       "Q 1516 384 1775 384 \n",
       "Q 2178 384 2440 643 \n",
       "Q 2703 903 2703 1303 \n",
       "Q 2703 1709 2433 1975 \n",
       "Q 2163 2241 1756 2241 \n",
       "Q 1359 2241 1098 1978 \n",
       "Q 838 1716 838 1322 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "       </defs>\n",
       "       <use xlink:href=\"#ArialMT-38\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_17\">\n",
       "     <g id=\"line2d_44\">\n",
       "      <path d=\"M 62.259531 397.932213 \n",
       "L 495.159531 397.932213 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_45\">\n",
       "      <!-- 10000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.174375 401.86901) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_18\">\n",
       "     <g id=\"line2d_45\">\n",
       "      <path d=\"M 62.259531 371.093205 \n",
       "L 495.159531 371.093205 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_46\">\n",
       "      <!-- 12000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.174375 375.030002) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_19\">\n",
       "     <g id=\"line2d_46\">\n",
       "      <path d=\"M 62.259531 344.254198 \n",
       "L 495.159531 344.254198 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_47\">\n",
       "      <!-- 14000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.174375 348.190995) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_20\">\n",
       "     <g id=\"line2d_47\">\n",
       "      <path d=\"M 62.259531 317.415191 \n",
       "L 495.159531 317.415191 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_48\">\n",
       "      <!-- 16000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.174375 321.351988) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_49\">\n",
       "     <!-- Frecuencia -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(15.789375 450.145688) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-46\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(61.083984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(94.384766 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(150 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(255.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(311.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(366.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(439.0625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_215\">\n",
       "    <path d=\"M 81.936804 532.12725 \n",
       "L 85.872259 532.12725 \n",
       "L 85.872259 530.932914 \n",
       "L 81.936804 530.932914 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_216\">\n",
       "    <path d=\"M 85.872259 532.12725 \n",
       "L 89.807713 532.12725 \n",
       "L 89.807713 530.2351 \n",
       "L 85.872259 530.2351 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_217\">\n",
       "    <path d=\"M 89.807713 532.12725 \n",
       "L 93.743168 532.12725 \n",
       "L 93.743168 529.550705 \n",
       "L 89.807713 529.550705 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_218\">\n",
       "    <path d=\"M 93.743168 532.12725 \n",
       "L 97.678622 532.12725 \n",
       "L 97.678622 526.73261 \n",
       "L 93.743168 526.73261 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_219\">\n",
       "    <path d=\"M 97.678622 532.12725 \n",
       "L 101.614077 532.12725 \n",
       "L 101.614077 524.786781 \n",
       "L 97.678622 524.786781 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_220\">\n",
       "    <path d=\"M 101.614077 532.12725 \n",
       "L 105.549531 532.12725 \n",
       "L 105.549531 526.048215 \n",
       "L 101.614077 526.048215 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_221\">\n",
       "    <path d=\"M 105.549531 532.12725 \n",
       "L 109.484986 532.12725 \n",
       "L 109.484986 528.101399 \n",
       "L 105.549531 528.101399 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_222\">\n",
       "    <path d=\"M 109.484986 532.12725 \n",
       "L 113.42044 532.12725 \n",
       "L 113.42044 523.015407 \n",
       "L 109.484986 523.015407 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_223\">\n",
       "    <path d=\"M 113.42044 532.12725 \n",
       "L 117.355895 532.12725 \n",
       "L 117.355895 509.367772 \n",
       "L 113.42044 509.367772 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_224\">\n",
       "    <path d=\"M 117.355895 532.12725 \n",
       "L 121.291349 532.12725 \n",
       "L 121.291349 515.674938 \n",
       "L 117.355895 515.674938 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_225\">\n",
       "    <path d=\"M 121.291349 532.12725 \n",
       "L 125.226804 532.12725 \n",
       "L 125.226804 493.774308 \n",
       "L 121.291349 493.774308 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_226\">\n",
       "    <path d=\"M 125.226804 532.12725 \n",
       "L 129.162259 532.12725 \n",
       "L 129.162259 474.933325 \n",
       "L 125.226804 474.933325 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_227\">\n",
       "    <path d=\"M 129.162259 532.12725 \n",
       "L 133.097713 532.12725 \n",
       "L 133.097713 436.110701 \n",
       "L 129.162259 436.110701 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_228\">\n",
       "    <path d=\"M 133.097713 532.12725 \n",
       "L 137.033168 532.12725 \n",
       "L 137.033168 350.292975 \n",
       "L 133.097713 350.292975 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_229\">\n",
       "    <path d=\"M 137.033168 532.12725 \n",
       "L 140.968622 532.12725 \n",
       "L 140.968622 319.441536 \n",
       "L 137.033168 319.441536 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_230\">\n",
       "    <path d=\"M 140.968622 532.12725 \n",
       "L 144.904077 532.12725 \n",
       "L 144.904077 415.968026 \n",
       "L 140.968622 415.968026 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_231\">\n",
       "    <path d=\"M 144.904077 532.12725 \n",
       "L 148.839531 532.12725 \n",
       "L 148.839531 429.078881 \n",
       "L 144.904077 429.078881 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_232\">\n",
       "    <path d=\"M 148.839531 532.12725 \n",
       "L 152.774986 532.12725 \n",
       "L 152.774986 489.238516 \n",
       "L 148.839531 489.238516 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_233\">\n",
       "    <path d=\"M 152.774986 532.12725 \n",
       "L 156.71044 532.12725 \n",
       "L 156.71044 468.156476 \n",
       "L 152.774986 468.156476 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_234\">\n",
       "    <path d=\"M 156.71044 532.12725 \n",
       "L 160.645895 532.12725 \n",
       "L 160.645895 477.885616 \n",
       "L 156.71044 477.885616 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_235\">\n",
       "    <path d=\"M 160.645895 532.12725 \n",
       "L 164.581349 532.12725 \n",
       "L 164.581349 482.770315 \n",
       "L 160.645895 482.770315 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_236\">\n",
       "    <path d=\"M 164.581349 532.12725 \n",
       "L 168.516804 532.12725 \n",
       "L 168.516804 499.195788 \n",
       "L 164.581349 499.195788 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_237\">\n",
       "    <path d=\"M 168.516804 532.12725 \n",
       "L 172.452259 532.12725 \n",
       "L 172.452259 487.722112 \n",
       "L 168.516804 487.722112 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_238\">\n",
       "    <path d=\"M 172.452259 532.12725 \n",
       "L 176.387713 532.12725 \n",
       "L 176.387713 503.543707 \n",
       "L 172.452259 503.543707 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_239\">\n",
       "    <path d=\"M 176.387713 532.12725 \n",
       "L 180.323168 532.12725 \n",
       "L 180.323168 520.720672 \n",
       "L 176.387713 520.720672 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_240\">\n",
       "    <path d=\"M 180.323168 532.12725 \n",
       "L 184.258622 532.12725 \n",
       "L 184.258622 519.95576 \n",
       "L 180.323168 519.95576 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_241\">\n",
       "    <path d=\"M 184.258622 532.12725 \n",
       "L 188.194077 532.12725 \n",
       "L 188.194077 519.539756 \n",
       "L 184.258622 519.539756 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_242\">\n",
       "    <path d=\"M 188.194077 532.12725 \n",
       "L 192.129531 532.12725 \n",
       "L 192.129531 528.812633 \n",
       "L 188.194077 528.812633 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_243\">\n",
       "    <path d=\"M 192.129531 532.12725 \n",
       "L 196.064986 532.12725 \n",
       "L 196.064986 529.121281 \n",
       "L 192.129531 529.121281 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_244\">\n",
       "    <path d=\"M 196.064986 532.12725 \n",
       "L 200.00044 532.12725 \n",
       "L 200.00044 530.2351 \n",
       "L 196.064986 530.2351 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_245\">\n",
       "    <path d=\"M 200.00044 532.12725 \n",
       "L 203.935895 532.12725 \n",
       "L 203.935895 524.357357 \n",
       "L 200.00044 524.357357 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_246\">\n",
       "    <path d=\"M 203.935895 532.12725 \n",
       "L 207.871349 532.12725 \n",
       "L 207.871349 524.54523 \n",
       "L 203.935895 524.54523 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_247\">\n",
       "    <path d=\"M 207.871349 532.12725 \n",
       "L 211.806804 532.12725 \n",
       "L 211.806804 529.16154 \n",
       "L 207.871349 529.16154 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_248\">\n",
       "    <path d=\"M 211.806804 532.12725 \n",
       "L 215.742259 532.12725 \n",
       "L 215.742259 527.390165 \n",
       "L 211.806804 527.390165 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_249\">\n",
       "    <path d=\"M 215.742259 532.12725 \n",
       "L 219.677713 532.12725 \n",
       "L 219.677713 527.53778 \n",
       "L 215.742259 527.53778 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_250\">\n",
       "    <path d=\"M 219.677713 532.12725 \n",
       "L 223.613168 532.12725 \n",
       "L 223.613168 527.671975 \n",
       "L 219.677713 527.671975 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_251\">\n",
       "    <path d=\"M 223.613168 532.12725 \n",
       "L 227.548622 532.12725 \n",
       "L 227.548622 529.886193 \n",
       "L 223.613168 529.886193 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_252\">\n",
       "    <path d=\"M 227.548622 532.12725 \n",
       "L 231.484077 532.12725 \n",
       "L 231.484077 529.403091 \n",
       "L 227.548622 529.403091 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_253\">\n",
       "    <path d=\"M 231.484077 532.12725 \n",
       "L 235.419531 532.12725 \n",
       "L 235.419531 520.277828 \n",
       "L 231.484077 520.277828 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_254\">\n",
       "    <path d=\"M 235.419531 532.12725 \n",
       "L 239.354986 532.12725 \n",
       "L 239.354986 528.249013 \n",
       "L 235.419531 528.249013 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_255\">\n",
       "    <path d=\"M 239.354986 532.12725 \n",
       "L 243.29044 532.12725 \n",
       "L 243.29044 528.852891 \n",
       "L 239.354986 528.852891 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_256\">\n",
       "    <path d=\"M 243.29044 532.12725 \n",
       "L 247.225895 532.12725 \n",
       "L 247.225895 526.960741 \n",
       "L 243.29044 526.960741 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_257\">\n",
       "    <path d=\"M 247.225895 532.12725 \n",
       "L 251.161349 532.12725 \n",
       "L 251.161349 529.188379 \n",
       "L 247.225895 529.188379 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_258\">\n",
       "    <path d=\"M 251.161349 532.12725 \n",
       "L 255.096804 532.12725 \n",
       "L 255.096804 522.92147 \n",
       "L 251.161349 522.92147 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_259\">\n",
       "    <path d=\"M 255.096804 532.12725 \n",
       "L 259.032259 532.12725 \n",
       "L 259.032259 522.854373 \n",
       "L 255.096804 522.854373 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_260\">\n",
       "    <path d=\"M 259.032259 532.12725 \n",
       "L 262.967713 532.12725 \n",
       "L 262.967713 528.477145 \n",
       "L 259.032259 528.477145 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_261\">\n",
       "    <path d=\"M 262.967713 532.12725 \n",
       "L 266.903168 532.12725 \n",
       "L 266.903168 530.396134 \n",
       "L 262.967713 530.396134 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_262\">\n",
       "    <path d=\"M 266.903168 532.12725 \n",
       "L 270.838622 532.12725 \n",
       "L 270.838622 530.463232 \n",
       "L 266.903168 530.463232 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_263\">\n",
       "    <path d=\"M 270.838622 532.12725 \n",
       "L 274.774077 532.12725 \n",
       "L 274.774077 530.7853 \n",
       "L 270.838622 530.7853 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_264\">\n",
       "    <path d=\"M 274.774077 532.12725 \n",
       "L 278.709531 532.12725 \n",
       "L 278.709531 531.013431 \n",
       "L 274.774077 531.013431 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_265\">\n",
       "    <path d=\"M 278.709531 532.12725 \n",
       "L 282.644986 532.12725 \n",
       "L 282.644986 531.348919 \n",
       "L 278.709531 531.348919 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_266\">\n",
       "    <path d=\"M 282.644986 532.12725 \n",
       "L 286.58044 532.12725 \n",
       "L 286.58044 531.107368 \n",
       "L 282.644986 531.107368 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_267\">\n",
       "    <path d=\"M 286.58044 532.12725 \n",
       "L 290.515895 532.12725 \n",
       "L 290.515895 531.348919 \n",
       "L 286.58044 531.348919 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_268\">\n",
       "    <path d=\"M 290.515895 532.12725 \n",
       "L 294.451349 532.12725 \n",
       "L 294.451349 531.442855 \n",
       "L 290.515895 531.442855 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_269\">\n",
       "    <path d=\"M 294.451349 532.12725 \n",
       "L 298.386804 532.12725 \n",
       "L 298.386804 531.295241 \n",
       "L 294.451349 531.295241 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_270\">\n",
       "    <path d=\"M 298.386804 532.12725 \n",
       "L 302.322259 532.12725 \n",
       "L 302.322259 531.093948 \n",
       "L 298.386804 531.093948 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_271\">\n",
       "    <path d=\"M 302.322259 532.12725 \n",
       "L 306.257713 532.12725 \n",
       "L 306.257713 531.523372 \n",
       "L 302.322259 531.523372 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_272\">\n",
       "    <path d=\"M 306.257713 532.12725 \n",
       "L 310.193168 532.12725 \n",
       "L 310.193168 531.483114 \n",
       "L 306.257713 531.483114 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_273\">\n",
       "    <path d=\"M 310.193168 532.12725 \n",
       "L 314.128622 532.12725 \n",
       "L 314.128622 531.214724 \n",
       "L 310.193168 531.214724 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_274\">\n",
       "    <path d=\"M 314.128622 532.12725 \n",
       "L 318.064077 532.12725 \n",
       "L 318.064077 531.214724 \n",
       "L 314.128622 531.214724 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_275\">\n",
       "    <path d=\"M 318.064077 532.12725 \n",
       "L 321.999531 532.12725 \n",
       "L 321.999531 531.483114 \n",
       "L 318.064077 531.483114 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_276\">\n",
       "    <path d=\"M 321.999531 532.12725 \n",
       "L 325.934986 532.12725 \n",
       "L 325.934986 531.483114 \n",
       "L 321.999531 531.483114 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_277\">\n",
       "    <path d=\"M 325.934986 532.12725 \n",
       "L 329.87044 532.12725 \n",
       "L 329.87044 531.603889 \n",
       "L 325.934986 531.603889 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_278\">\n",
       "    <path d=\"M 329.87044 532.12725 \n",
       "L 333.805895 532.12725 \n",
       "L 333.805895 530.973173 \n",
       "L 329.87044 530.973173 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_279\">\n",
       "    <path d=\"M 333.805895 532.12725 \n",
       "L 337.741349 532.12725 \n",
       "L 337.741349 531.416016 \n",
       "L 333.805895 531.416016 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_280\">\n",
       "    <path d=\"M 337.741349 532.12725 \n",
       "L 341.676804 532.12725 \n",
       "L 341.676804 531.872279 \n",
       "L 337.741349 531.872279 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_281\">\n",
       "    <path d=\"M 341.676804 532.12725 \n",
       "L 345.612259 532.12725 \n",
       "L 345.612259 531.684406 \n",
       "L 341.676804 531.684406 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_282\">\n",
       "    <path d=\"M 345.612259 532.12725 \n",
       "L 349.547713 532.12725 \n",
       "L 349.547713 531.738084 \n",
       "L 345.612259 531.738084 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_283\">\n",
       "    <path d=\"M 349.547713 532.12725 \n",
       "L 353.483168 532.12725 \n",
       "L 353.483168 530.852397 \n",
       "L 349.547713 530.852397 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_284\">\n",
       "    <path d=\"M 353.483168 532.12725 \n",
       "L 357.418622 532.12725 \n",
       "L 357.418622 531.402597 \n",
       "L 353.483168 531.402597 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_285\">\n",
       "    <path d=\"M 357.418622 532.12725 \n",
       "L 361.354077 532.12725 \n",
       "L 361.354077 531.84544 \n",
       "L 357.418622 531.84544 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_286\">\n",
       "    <path d=\"M 361.354077 532.12725 \n",
       "L 365.289531 532.12725 \n",
       "L 365.289531 531.832021 \n",
       "L 361.354077 531.832021 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_287\">\n",
       "    <path d=\"M 365.289531 532.12725 \n",
       "L 369.224986 532.12725 \n",
       "L 369.224986 531.684406 \n",
       "L 365.289531 531.684406 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_288\">\n",
       "    <path d=\"M 369.224986 532.12725 \n",
       "L 373.16044 532.12725 \n",
       "L 373.16044 531.026851 \n",
       "L 369.224986 531.026851 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_289\">\n",
       "    <path d=\"M 373.16044 532.12725 \n",
       "L 377.095895 532.12725 \n",
       "L 377.095895 531.885699 \n",
       "L 373.16044 531.885699 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_290\">\n",
       "    <path d=\"M 377.095895 532.12725 \n",
       "L 381.031349 532.12725 \n",
       "L 381.031349 531.966216 \n",
       "L 377.095895 531.966216 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_291\">\n",
       "    <path d=\"M 381.031349 532.12725 \n",
       "L 384.966804 532.12725 \n",
       "L 384.966804 531.617309 \n",
       "L 381.031349 531.617309 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_292\">\n",
       "    <path d=\"M 384.966804 532.12725 \n",
       "L 388.902259 532.12725 \n",
       "L 388.902259 531.952796 \n",
       "L 384.966804 531.952796 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_293\">\n",
       "    <path d=\"M 388.902259 532.12725 \n",
       "L 392.837713 532.12725 \n",
       "L 392.837713 531.966216 \n",
       "L 388.902259 531.966216 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_294\">\n",
       "    <path d=\"M 392.837713 532.12725 \n",
       "L 396.773168 532.12725 \n",
       "L 396.773168 532.100411 \n",
       "L 392.837713 532.100411 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_295\">\n",
       "    <path d=\"M 396.773168 532.12725 \n",
       "L 400.708622 532.12725 \n",
       "L 400.708622 531.912538 \n",
       "L 396.773168 531.912538 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_296\">\n",
       "    <path d=\"M 400.708622 532.12725 \n",
       "L 404.644077 532.12725 \n",
       "L 404.644077 531.684406 \n",
       "L 400.708622 531.684406 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_297\">\n",
       "    <path d=\"M 404.644077 532.12725 \n",
       "L 408.579531 532.12725 \n",
       "L 408.579531 531.993055 \n",
       "L 404.644077 531.993055 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_298\">\n",
       "    <path d=\"M 408.579531 532.12725 \n",
       "L 412.514986 532.12725 \n",
       "L 412.514986 531.805182 \n",
       "L 408.579531 531.805182 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_299\">\n",
       "    <path d=\"M 412.514986 532.12725 \n",
       "L 416.45044 532.12725 \n",
       "L 416.45044 531.84544 \n",
       "L 412.514986 531.84544 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_300\">\n",
       "    <path d=\"M 416.45044 532.12725 \n",
       "L 420.385895 532.12725 \n",
       "L 420.385895 531.469694 \n",
       "L 416.45044 531.469694 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_301\">\n",
       "    <path d=\"M 420.385895 532.12725 \n",
       "L 424.321349 532.12725 \n",
       "L 424.321349 532.11383 \n",
       "L 420.385895 532.11383 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_302\">\n",
       "    <path d=\"M 424.321349 532.12725 \n",
       "L 428.256804 532.12725 \n",
       "L 428.256804 532.033313 \n",
       "L 424.321349 532.033313 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_303\">\n",
       "    <path d=\"M 428.256804 532.12725 \n",
       "L 432.192259 532.12725 \n",
       "L 432.192259 531.912538 \n",
       "L 428.256804 531.912538 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_304\">\n",
       "    <path d=\"M 432.192259 532.12725 \n",
       "L 436.127713 532.12725 \n",
       "L 436.127713 531.107368 \n",
       "L 432.192259 531.107368 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_305\">\n",
       "    <path d=\"M 436.127713 532.12725 \n",
       "L 440.063168 532.12725 \n",
       "L 440.063168 532.11383 \n",
       "L 436.127713 532.11383 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_306\">\n",
       "    <path d=\"M 440.063168 532.12725 \n",
       "L 443.998622 532.12725 \n",
       "L 443.998622 532.100411 \n",
       "L 440.063168 532.100411 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_307\">\n",
       "    <path d=\"M 443.998622 532.12725 \n",
       "L 447.934077 532.12725 \n",
       "L 447.934077 531.912538 \n",
       "L 443.998622 531.912538 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_308\">\n",
       "    <path d=\"M 447.934077 532.12725 \n",
       "L 451.869531 532.12725 \n",
       "L 451.869531 532.12725 \n",
       "L 447.934077 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_309\">\n",
       "    <path d=\"M 451.869531 532.12725 \n",
       "L 455.804986 532.12725 \n",
       "L 455.804986 531.496533 \n",
       "L 451.869531 531.496533 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_310\">\n",
       "    <path d=\"M 455.804986 532.12725 \n",
       "L 459.74044 532.12725 \n",
       "L 459.74044 532.12725 \n",
       "L 455.804986 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_311\">\n",
       "    <path d=\"M 459.74044 532.12725 \n",
       "L 463.675895 532.12725 \n",
       "L 463.675895 532.11383 \n",
       "L 459.74044 532.11383 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_312\">\n",
       "    <path d=\"M 463.675895 532.12725 \n",
       "L 467.611349 532.12725 \n",
       "L 467.611349 532.12725 \n",
       "L 463.675895 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_313\">\n",
       "    <path d=\"M 467.611349 532.12725 \n",
       "L 471.546804 532.12725 \n",
       "L 471.546804 532.019894 \n",
       "L 467.611349 532.019894 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_314\">\n",
       "    <path d=\"M 471.546804 532.12725 \n",
       "L 475.482259 532.12725 \n",
       "L 475.482259 531.966216 \n",
       "L 471.546804 531.966216 \n",
       "z\n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_48\">\n",
       "    <path d=\"M 81.936804 531.394835 \n",
       "L 83.914419 531.097945 \n",
       "L 85.892035 530.683458 \n",
       "L 89.847265 529.477147 \n",
       "L 91.824881 528.708499 \n",
       "L 97.757727 526.066209 \n",
       "L 99.735342 525.723258 \n",
       "L 101.712957 525.908561 \n",
       "L 103.690573 526.382805 \n",
       "L 105.668188 526.63002 \n",
       "L 107.645804 526.103382 \n",
       "L 109.623419 524.470107 \n",
       "L 111.601034 521.736686 \n",
       "L 113.57865 518.257713 \n",
       "L 117.53388 510.615431 \n",
       "L 119.511496 505.857868 \n",
       "L 121.489111 499.214339 \n",
       "L 123.466726 490.151823 \n",
       "L 125.444342 478.444607 \n",
       "L 127.421957 462.959634 \n",
       "L 129.399572 441.759545 \n",
       "L 133.354803 386.512739 \n",
       "L 135.332418 365.046612 \n",
       "L 137.310034 357.417268 \n",
       "L 139.287649 364.900796 \n",
       "L 141.265264 382.583391 \n",
       "L 145.220495 424.210957 \n",
       "L 147.198111 442.588601 \n",
       "L 149.175726 457.711607 \n",
       "L 151.153341 468.12808 \n",
       "L 153.130957 473.570371 \n",
       "L 155.108572 475.649838 \n",
       "L 157.086187 476.729299 \n",
       "L 159.063803 478.521829 \n",
       "L 161.041418 481.606913 \n",
       "L 164.996649 489.34248 \n",
       "L 166.974264 492.212343 \n",
       "L 168.951879 494.423406 \n",
       "L 170.929495 497.052023 \n",
       "L 172.90711 500.922156 \n",
       "L 176.862341 510.762959 \n",
       "L 178.839956 514.820737 \n",
       "L 180.817571 517.718273 \n",
       "L 182.795187 519.758586 \n",
       "L 190.705648 526.54547 \n",
       "L 192.683264 527.872366 \n",
       "L 194.660879 528.587432 \n",
       "L 196.638494 528.543608 \n",
       "L 198.61611 527.793448 \n",
       "L 200.593725 526.706431 \n",
       "L 202.57134 525.887409 \n",
       "L 204.548956 525.796678 \n",
       "L 206.526571 526.39304 \n",
       "L 208.504186 527.206371 \n",
       "L 210.481802 527.769652 \n",
       "L 212.459417 527.942538 \n",
       "L 218.392263 527.833354 \n",
       "L 224.325109 528.577823 \n",
       "L 226.302724 528.526981 \n",
       "L 228.28034 528.022866 \n",
       "L 232.235571 526.02496 \n",
       "L 234.213186 525.468339 \n",
       "L 236.190801 525.721662 \n",
       "L 240.146032 527.313259 \n",
       "L 242.123647 527.77117 \n",
       "L 244.101263 527.91734 \n",
       "L 246.078878 527.832624 \n",
       "L 248.056493 527.420427 \n",
       "L 250.034109 526.530868 \n",
       "L 252.011724 525.304227 \n",
       "L 253.989339 524.294733 \n",
       "L 255.966955 524.124326 \n",
       "L 257.94457 524.978772 \n",
       "L 261.899801 528.052168 \n",
       "L 263.877416 529.263734 \n",
       "L 265.855031 530.007144 \n",
       "L 267.832647 530.381556 \n",
       "L 275.743108 530.989277 \n",
       "L 279.698339 531.202896 \n",
       "L 293.541646 531.351198 \n",
       "L 301.452108 531.315327 \n",
       "L 307.384954 531.394985 \n",
       "L 315.295415 531.259371 \n",
       "L 325.183492 531.494659 \n",
       "L 333.093953 531.286044 \n",
       "L 342.98203 531.712052 \n",
       "L 346.937261 531.562619 \n",
       "L 350.892492 531.292087 \n",
       "L 352.870107 531.25951 \n",
       "L 356.825338 531.502105 \n",
       "L 360.780568 531.719673 \n",
       "L 364.735799 531.684407 \n",
       "L 370.668645 531.521342 \n",
       "L 376.601491 531.770675 \n",
       "L 380.556722 531.843873 \n",
       "L 388.467183 531.895417 \n",
       "L 396.377645 531.984933 \n",
       "L 410.220952 531.82326 \n",
       "L 422.086644 531.863373 \n",
       "L 428.01949 531.949446 \n",
       "L 437.907567 531.701315 \n",
       "L 443.840413 531.96725 \n",
       "L 449.773259 531.941491 \n",
       "L 453.72849 531.864847 \n",
       "L 471.527028 532.048609 \n",
       "L 475.482259 532.057073 \n",
       "L 475.482259 532.057073 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_49\">\n",
       "    <path d=\"M 152.863317 532.12725 \n",
       "L 152.863317 308.80725 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_50\">\n",
       "    <path d=\"M 141.37841 532.12725 \n",
       "L 141.37841 308.80725 \n",
       "\" clip-path=\"url(#p0e59718d96)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_315\">\n",
       "    <path d=\"M 62.259531 532.12725 \n",
       "L 62.259531 308.80725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_316\">\n",
       "    <path d=\"M 495.159531 532.12725 \n",
       "L 495.159531 308.80725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_317\">\n",
       "    <path d=\"M 62.259531 532.12725 \n",
       "L 495.159531 532.12725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_318\">\n",
       "    <path d=\"M 62.259531 308.80725 \n",
       "L 495.159531 308.80725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_50\">\n",
       "    <!-- Distribución de ∂Precio/∂T -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(195.167031 302.80725) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-54\" d=\"M 1659 0 \n",
       "L 1659 4041 \n",
       "L 150 4041 \n",
       "L 150 4581 \n",
       "L 3781 4581 \n",
       "L 3781 4041 \n",
       "L 2266 4041 \n",
       "L 2266 0 \n",
       "L 1659 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(94.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(144.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(172.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(205.517578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-62\" transform=\"translate(227.734375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(283.349609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(338.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(388.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-f3\" transform=\"translate(411.181641 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(466.796875 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(522.412109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(550.195312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(605.810547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(661.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(689.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-50\" transform=\"translate(738.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(805.322266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(838.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(894.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(944.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(966.455078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2f\" transform=\"translate(1022.070312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(1049.853516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-54\" transform=\"translate(1099.267578 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_3\">\n",
       "    <g id=\"patch_319\">\n",
       "     <path d=\"M 376.431719 348.726938 \n",
       "L 487.459531 348.726938 \n",
       "Q 489.659531 348.726938 489.659531 346.526938 \n",
       "L 489.659531 316.50725 \n",
       "Q 489.659531 314.30725 487.459531 314.30725 \n",
       "L 376.431719 314.30725 \n",
       "Q 374.231719 314.30725 374.231719 316.50725 \n",
       "L 374.231719 346.526938 \n",
       "Q 374.231719 348.726938 376.431719 348.726938 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_51\">\n",
       "     <path d=\"M 378.631719 322.730844 \n",
       "L 389.631719 322.730844 \n",
       "L 400.631719 322.730844 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_51\">\n",
       "     <!-- Media: 23.08 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(409.431719 326.580844) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(300.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(327.929688 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-33\" transform=\"translate(383.544922 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(466.943359 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-38\" transform=\"translate(522.558594 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_52\">\n",
       "     <path d=\"M 378.631719 338.290688 \n",
       "L 389.631719 338.290688 \n",
       "L 400.631719 338.290688 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_52\">\n",
       "     <!-- Mediana: 10.58 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(409.431719 342.140688) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(494.775391 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(550.390625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-35\" transform=\"translate(578.173828 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-38\" transform=\"translate(633.789062 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_4\">\n",
       "   <g id=\"patch_320\">\n",
       "    <path d=\"M 560.859531 532.12725 \n",
       "L 993.759531 532.12725 \n",
       "L 993.759531 308.80725 \n",
       "L 560.859531 308.80725 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_7\">\n",
       "    <g id=\"xtick_18\">\n",
       "     <g id=\"line2d_53\">\n",
       "      <path d=\"M 612.566402 532.12725 \n",
       "L 612.566402 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_53\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(609.507887 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_19\">\n",
       "     <g id=\"line2d_54\">\n",
       "      <path d=\"M 673.616188 532.12725 \n",
       "L 673.616188 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_54\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(664.440641 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_20\">\n",
       "     <g id=\"line2d_55\">\n",
       "      <path d=\"M 734.665973 532.12725 \n",
       "L 734.665973 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_55\">\n",
       "      <!-- 400 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(725.490426 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_21\">\n",
       "     <g id=\"line2d_56\">\n",
       "      <path d=\"M 795.715759 532.12725 \n",
       "L 795.715759 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_56\">\n",
       "      <!-- 600 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(786.540212 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_22\">\n",
       "     <g id=\"line2d_57\">\n",
       "      <path d=\"M 856.765544 532.12725 \n",
       "L 856.765544 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_57\">\n",
       "      <!-- 800 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(847.589997 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-38\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_23\">\n",
       "     <g id=\"line2d_58\">\n",
       "      <path d=\"M 917.81533 532.12725 \n",
       "L 917.81533 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_58\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(905.581267 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_24\">\n",
       "     <g id=\"line2d_59\">\n",
       "      <path d=\"M 978.865115 532.12725 \n",
       "L 978.865115 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_59\">\n",
       "      <!-- 1200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(966.631053 549.500844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_60\">\n",
       "     <!-- Valor de la derivada parcial -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(705.047969 564.276469) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(59.324219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(114.939453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(137.15625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(192.771484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(226.072266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(253.855469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(309.470703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(365.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(392.869141 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(415.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(470.701172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(498.484375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(554.099609 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(609.714844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(643.015625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(665.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(715.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(770.847656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(826.462891 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(882.078125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(909.861328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(965.476562 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(1021.091797 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(1054.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(1104.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(1126.609375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1182.224609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_8\">\n",
       "    <g id=\"ytick_21\">\n",
       "     <g id=\"line2d_60\">\n",
       "      <path d=\"M 560.859531 532.12725 \n",
       "L 993.759531 532.12725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_61\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(545.2425 536.064047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_22\">\n",
       "     <g id=\"line2d_61\">\n",
       "      <path d=\"M 560.859531 489.78151 \n",
       "L 993.759531 489.78151 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_62\">\n",
       "      <!-- 5000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 493.718307) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_23\">\n",
       "     <g id=\"line2d_62\">\n",
       "      <path d=\"M 560.859531 447.43577 \n",
       "L 993.759531 447.43577 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_63\">\n",
       "      <!-- 10000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(520.774375 451.372567) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_24\">\n",
       "     <g id=\"line2d_63\">\n",
       "      <path d=\"M 560.859531 405.09003 \n",
       "L 993.759531 405.09003 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_64\">\n",
       "      <!-- 15000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(520.774375 409.026827) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_25\">\n",
       "     <g id=\"line2d_64\">\n",
       "      <path d=\"M 560.859531 362.74429 \n",
       "L 993.759531 362.74429 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_65\">\n",
       "      <!-- 20000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(520.774375 366.681086) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_26\">\n",
       "     <g id=\"line2d_65\">\n",
       "      <path d=\"M 560.859531 320.398549 \n",
       "L 993.759531 320.398549 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_66\">\n",
       "      <!-- 25000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(520.774375 324.335346) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_67\">\n",
       "     <!-- Frecuencia -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(514.389375 450.145688) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-46\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(61.083984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(94.384766 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(150 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(255.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(311.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(366.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(439.0625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_321\">\n",
       "    <path d=\"M 580.536804 532.12725 \n",
       "L 584.472259 532.12725 \n",
       "L 584.472259 532.118781 \n",
       "L 580.536804 532.118781 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_322\">\n",
       "    <path d=\"M 584.472259 532.12725 \n",
       "L 588.407713 532.12725 \n",
       "L 588.407713 532.067966 \n",
       "L 584.472259 532.067966 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_323\">\n",
       "    <path d=\"M 588.407713 532.12725 \n",
       "L 592.343168 532.12725 \n",
       "L 592.343168 531.991744 \n",
       "L 588.407713 531.991744 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_324\">\n",
       "    <path d=\"M 592.343168 532.12725 \n",
       "L 596.278622 532.12725 \n",
       "L 596.278622 531.796953 \n",
       "L 592.343168 531.796953 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_325\">\n",
       "    <path d=\"M 596.278622 532.12725 \n",
       "L 600.214077 532.12725 \n",
       "L 600.214077 531.13636 \n",
       "L 596.278622 531.13636 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_326\">\n",
       "    <path d=\"M 600.214077 532.12725 \n",
       "L 604.149531 532.12725 \n",
       "L 604.149531 524.267881 \n",
       "L 600.214077 524.267881 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_327\">\n",
       "    <path d=\"M 604.149531 532.12725 \n",
       "L 608.084986 532.12725 \n",
       "L 608.084986 502.01096 \n",
       "L 604.149531 502.01096 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_328\">\n",
       "    <path d=\"M 608.084986 532.12725 \n",
       "L 612.02044 532.12725 \n",
       "L 612.02044 444.615543 \n",
       "L 608.084986 444.615543 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_329\">\n",
       "    <path d=\"M 612.02044 532.12725 \n",
       "L 615.955895 532.12725 \n",
       "L 615.955895 319.441536 \n",
       "L 612.02044 319.441536 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_330\">\n",
       "    <path d=\"M 615.955895 532.12725 \n",
       "L 619.891349 532.12725 \n",
       "L 619.891349 417.471924 \n",
       "L 615.955895 417.471924 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_331\">\n",
       "    <path d=\"M 619.891349 532.12725 \n",
       "L 623.826804 532.12725 \n",
       "L 623.826804 409.56174 \n",
       "L 619.891349 409.56174 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_332\">\n",
       "    <path d=\"M 623.826804 532.12725 \n",
       "L 627.762259 532.12725 \n",
       "L 627.762259 477.628282 \n",
       "L 623.826804 477.628282 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_333\">\n",
       "    <path d=\"M 627.762259 532.12725 \n",
       "L 631.697713 532.12725 \n",
       "L 631.697713 468.617109 \n",
       "L 627.762259 468.617109 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_334\">\n",
       "    <path d=\"M 631.697713 532.12725 \n",
       "L 635.633168 532.12725 \n",
       "L 635.633168 501.824638 \n",
       "L 631.697713 501.824638 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_335\">\n",
       "    <path d=\"M 635.633168 532.12725 \n",
       "L 639.568622 532.12725 \n",
       "L 639.568622 515.375275 \n",
       "L 635.633168 515.375275 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_336\">\n",
       "    <path d=\"M 639.568622 532.12725 \n",
       "L 643.504077 532.12725 \n",
       "L 643.504077 505.347804 \n",
       "L 639.568622 505.347804 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_337\">\n",
       "    <path d=\"M 643.504077 532.12725 \n",
       "L 647.439531 532.12725 \n",
       "L 647.439531 515.383744 \n",
       "L 643.504077 515.383744 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_338\">\n",
       "    <path d=\"M 647.439531 532.12725 \n",
       "L 651.374986 532.12725 \n",
       "L 651.374986 522.497829 \n",
       "L 647.439531 522.497829 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_339\">\n",
       "    <path d=\"M 651.374986 532.12725 \n",
       "L 655.31044 532.12725 \n",
       "L 655.31044 521.803359 \n",
       "L 651.374986 521.803359 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_340\">\n",
       "    <path d=\"M 655.31044 532.12725 \n",
       "L 659.245895 532.12725 \n",
       "L 659.245895 526.190377 \n",
       "L 655.31044 526.190377 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_341\">\n",
       "    <path d=\"M 659.245895 532.12725 \n",
       "L 663.181349 532.12725 \n",
       "L 663.181349 526.554551 \n",
       "L 659.245895 526.554551 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_342\">\n",
       "    <path d=\"M 663.181349 532.12725 \n",
       "L 667.116804 532.12725 \n",
       "L 667.116804 526.444452 \n",
       "L 663.181349 526.444452 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_343\">\n",
       "    <path d=\"M 667.116804 532.12725 \n",
       "L 671.052259 532.12725 \n",
       "L 671.052259 527.65554 \n",
       "L 667.116804 527.65554 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_344\">\n",
       "    <path d=\"M 671.052259 532.12725 \n",
       "L 674.987713 532.12725 \n",
       "L 674.987713 529.357839 \n",
       "L 671.052259 529.357839 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_345\">\n",
       "    <path d=\"M 674.987713 532.12725 \n",
       "L 678.923168 532.12725 \n",
       "L 678.923168 530.619742 \n",
       "L 674.987713 530.619742 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_346\">\n",
       "    <path d=\"M 678.923168 532.12725 \n",
       "L 682.858622 532.12725 \n",
       "L 682.858622 528.985196 \n",
       "L 678.923168 528.985196 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_347\">\n",
       "    <path d=\"M 682.858622 532.12725 \n",
       "L 686.794077 532.12725 \n",
       "L 686.794077 530.382606 \n",
       "L 682.858622 530.382606 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_348\">\n",
       "    <path d=\"M 686.794077 532.12725 \n",
       "L 690.729531 532.12725 \n",
       "L 690.729531 529.815173 \n",
       "L 686.794077 529.815173 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_349\">\n",
       "    <path d=\"M 690.729531 532.12725 \n",
       "L 694.664986 532.12725 \n",
       "L 694.664986 530.611273 \n",
       "L 690.729531 530.611273 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_350\">\n",
       "    <path d=\"M 694.664986 532.12725 \n",
       "L 698.60044 532.12725 \n",
       "L 698.60044 531.475126 \n",
       "L 694.664986 531.475126 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_351\">\n",
       "    <path d=\"M 698.60044 532.12725 \n",
       "L 702.535895 532.12725 \n",
       "L 702.535895 531.441249 \n",
       "L 698.60044 531.441249 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_352\">\n",
       "    <path d=\"M 702.535895 532.12725 \n",
       "L 706.471349 532.12725 \n",
       "L 706.471349 531.365027 \n",
       "L 702.535895 531.365027 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_353\">\n",
       "    <path d=\"M 706.471349 532.12725 \n",
       "L 710.406804 532.12725 \n",
       "L 710.406804 528.654899 \n",
       "L 706.471349 528.654899 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_354\">\n",
       "    <path d=\"M 710.406804 532.12725 \n",
       "L 714.342259 532.12725 \n",
       "L 714.342259 530.230161 \n",
       "L 710.406804 530.230161 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_355\">\n",
       "    <path d=\"M 714.342259 532.12725 \n",
       "L 718.277713 532.12725 \n",
       "L 718.277713 531.864706 \n",
       "L 714.342259 531.864706 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_356\">\n",
       "    <path d=\"M 718.277713 532.12725 \n",
       "L 722.213168 532.12725 \n",
       "L 722.213168 531.7292 \n",
       "L 718.277713 531.7292 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_357\">\n",
       "    <path d=\"M 722.213168 532.12725 \n",
       "L 726.148622 532.12725 \n",
       "L 726.148622 531.864706 \n",
       "L 722.213168 531.864706 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_358\">\n",
       "    <path d=\"M 726.148622 532.12725 \n",
       "L 730.084077 532.12725 \n",
       "L 730.084077 531.796953 \n",
       "L 726.148622 531.796953 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_359\">\n",
       "    <path d=\"M 730.084077 532.12725 \n",
       "L 734.019531 532.12725 \n",
       "L 734.019531 532.034089 \n",
       "L 730.084077 532.034089 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_360\">\n",
       "    <path d=\"M 734.019531 532.12725 \n",
       "L 737.954986 532.12725 \n",
       "L 737.954986 531.52594 \n",
       "L 734.019531 531.52594 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_361\">\n",
       "    <path d=\"M 737.954986 532.12725 \n",
       "L 741.89044 532.12725 \n",
       "L 741.89044 532.076435 \n",
       "L 737.954986 532.076435 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_362\">\n",
       "    <path d=\"M 741.89044 532.12725 \n",
       "L 745.825895 532.12725 \n",
       "L 745.825895 531.644509 \n",
       "L 741.89044 531.644509 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_363\">\n",
       "    <path d=\"M 745.825895 532.12725 \n",
       "L 749.761349 532.12725 \n",
       "L 749.761349 531.991744 \n",
       "L 745.825895 531.991744 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_364\">\n",
       "    <path d=\"M 749.761349 532.12725 \n",
       "L 753.696804 532.12725 \n",
       "L 753.696804 531.915521 \n",
       "L 749.761349 531.915521 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_365\">\n",
       "    <path d=\"M 753.696804 532.12725 \n",
       "L 757.632259 532.12725 \n",
       "L 757.632259 532.101843 \n",
       "L 753.696804 532.101843 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_366\">\n",
       "    <path d=\"M 757.632259 532.12725 \n",
       "L 761.567713 532.12725 \n",
       "L 761.567713 531.602163 \n",
       "L 757.632259 531.602163 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_367\">\n",
       "    <path d=\"M 761.567713 532.12725 \n",
       "L 765.503168 532.12725 \n",
       "L 765.503168 532.059497 \n",
       "L 761.567713 532.059497 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_368\">\n",
       "    <path d=\"M 765.503168 532.12725 \n",
       "L 769.438622 532.12725 \n",
       "L 769.438622 532.034089 \n",
       "L 765.503168 532.034089 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_369\">\n",
       "    <path d=\"M 769.438622 532.12725 \n",
       "L 773.374077 532.12725 \n",
       "L 773.374077 531.483595 \n",
       "L 769.438622 531.483595 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_370\">\n",
       "    <path d=\"M 773.374077 532.12725 \n",
       "L 777.309531 532.12725 \n",
       "L 777.309531 532.076435 \n",
       "L 773.374077 532.076435 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_371\">\n",
       "    <path d=\"M 777.309531 532.12725 \n",
       "L 781.244986 532.12725 \n",
       "L 781.244986 531.475126 \n",
       "L 777.309531 531.475126 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_372\">\n",
       "    <path d=\"M 781.244986 532.12725 \n",
       "L 785.18044 532.12725 \n",
       "L 785.18044 532.059497 \n",
       "L 781.244986 532.059497 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_373\">\n",
       "    <path d=\"M 785.18044 532.12725 \n",
       "L 789.115895 532.12725 \n",
       "L 789.115895 532.093373 \n",
       "L 785.18044 532.093373 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_374\">\n",
       "    <path d=\"M 789.115895 532.12725 \n",
       "L 793.051349 532.12725 \n",
       "L 793.051349 532.034089 \n",
       "L 789.115895 532.034089 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_375\">\n",
       "    <path d=\"M 793.051349 532.12725 \n",
       "L 796.986804 532.12725 \n",
       "L 796.986804 532.000213 \n",
       "L 793.051349 532.000213 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_376\">\n",
       "    <path d=\"M 796.986804 532.12725 \n",
       "L 800.922259 532.12725 \n",
       "L 800.922259 532.02562 \n",
       "L 796.986804 532.02562 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_377\">\n",
       "    <path d=\"M 800.922259 532.12725 \n",
       "L 804.857713 532.12725 \n",
       "L 804.857713 530.780655 \n",
       "L 800.922259 530.780655 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_378\">\n",
       "    <path d=\"M 804.857713 532.12725 \n",
       "L 808.793168 532.12725 \n",
       "L 808.793168 532.059497 \n",
       "L 804.857713 532.059497 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_379\">\n",
       "    <path d=\"M 808.793168 532.12725 \n",
       "L 812.728622 532.12725 \n",
       "L 812.728622 532.067966 \n",
       "L 808.793168 532.067966 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_380\">\n",
       "    <path d=\"M 812.728622 532.12725 \n",
       "L 816.664077 532.12725 \n",
       "L 816.664077 532.017151 \n",
       "L 812.728622 532.017151 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_381\">\n",
       "    <path d=\"M 816.664077 532.12725 \n",
       "L 820.599531 532.12725 \n",
       "L 820.599531 532.034089 \n",
       "L 816.664077 532.034089 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_382\">\n",
       "    <path d=\"M 820.599531 532.12725 \n",
       "L 824.534986 532.12725 \n",
       "L 824.534986 532.110312 \n",
       "L 820.599531 532.110312 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_383\">\n",
       "    <path d=\"M 824.534986 532.12725 \n",
       "L 828.47044 532.12725 \n",
       "L 828.47044 531.898583 \n",
       "L 824.534986 531.898583 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_384\">\n",
       "    <path d=\"M 828.47044 532.12725 \n",
       "L 832.405895 532.12725 \n",
       "L 832.405895 532.118781 \n",
       "L 828.47044 532.118781 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_385\">\n",
       "    <path d=\"M 832.405895 532.12725 \n",
       "L 836.341349 532.12725 \n",
       "L 836.341349 532.067966 \n",
       "L 832.405895 532.067966 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_386\">\n",
       "    <path d=\"M 836.341349 532.12725 \n",
       "L 840.276804 532.12725 \n",
       "L 840.276804 532.000213 \n",
       "L 836.341349 532.000213 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_387\">\n",
       "    <path d=\"M 840.276804 532.12725 \n",
       "L 844.212259 532.12725 \n",
       "L 844.212259 531.983274 \n",
       "L 840.276804 531.983274 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_388\">\n",
       "    <path d=\"M 844.212259 532.12725 \n",
       "L 848.147713 532.12725 \n",
       "L 848.147713 532.12725 \n",
       "L 844.212259 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_389\">\n",
       "    <path d=\"M 848.147713 532.12725 \n",
       "L 852.083168 532.12725 \n",
       "L 852.083168 531.864706 \n",
       "L 848.147713 531.864706 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_390\">\n",
       "    <path d=\"M 852.083168 532.12725 \n",
       "L 856.018622 532.12725 \n",
       "L 856.018622 532.034089 \n",
       "L 852.083168 532.034089 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_391\">\n",
       "    <path d=\"M 856.018622 532.12725 \n",
       "L 859.954077 532.12725 \n",
       "L 859.954077 532.059497 \n",
       "L 856.018622 532.059497 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_392\">\n",
       "    <path d=\"M 859.954077 532.12725 \n",
       "L 863.889531 532.12725 \n",
       "L 863.889531 532.076435 \n",
       "L 859.954077 532.076435 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_393\">\n",
       "    <path d=\"M 863.889531 532.12725 \n",
       "L 867.824986 532.12725 \n",
       "L 867.824986 532.076435 \n",
       "L 863.889531 532.076435 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_394\">\n",
       "    <path d=\"M 867.824986 532.12725 \n",
       "L 871.76044 532.12725 \n",
       "L 871.76044 532.059497 \n",
       "L 867.824986 532.059497 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_395\">\n",
       "    <path d=\"M 871.76044 532.12725 \n",
       "L 875.695895 532.12725 \n",
       "L 875.695895 532.110312 \n",
       "L 871.76044 532.110312 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_396\">\n",
       "    <path d=\"M 875.695895 532.12725 \n",
       "L 879.631349 532.12725 \n",
       "L 879.631349 532.110312 \n",
       "L 875.695895 532.110312 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_397\">\n",
       "    <path d=\"M 879.631349 532.12725 \n",
       "L 883.566804 532.12725 \n",
       "L 883.566804 532.101843 \n",
       "L 879.631349 532.101843 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_398\">\n",
       "    <path d=\"M 883.566804 532.12725 \n",
       "L 887.502259 532.12725 \n",
       "L 887.502259 532.067966 \n",
       "L 883.566804 532.067966 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_399\">\n",
       "    <path d=\"M 887.502259 532.12725 \n",
       "L 891.437713 532.12725 \n",
       "L 891.437713 532.110312 \n",
       "L 887.502259 532.110312 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_400\">\n",
       "    <path d=\"M 891.437713 532.12725 \n",
       "L 895.373168 532.12725 \n",
       "L 895.373168 532.067966 \n",
       "L 891.437713 532.067966 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_401\">\n",
       "    <path d=\"M 895.373168 532.12725 \n",
       "L 899.308622 532.12725 \n",
       "L 899.308622 532.12725 \n",
       "L 895.373168 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_402\">\n",
       "    <path d=\"M 899.308622 532.12725 \n",
       "L 903.244077 532.12725 \n",
       "L 903.244077 532.12725 \n",
       "L 899.308622 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_403\">\n",
       "    <path d=\"M 903.244077 532.12725 \n",
       "L 907.179531 532.12725 \n",
       "L 907.179531 532.02562 \n",
       "L 903.244077 532.02562 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_404\">\n",
       "    <path d=\"M 907.179531 532.12725 \n",
       "L 911.114986 532.12725 \n",
       "L 911.114986 532.12725 \n",
       "L 907.179531 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_405\">\n",
       "    <path d=\"M 911.114986 532.12725 \n",
       "L 915.05044 532.12725 \n",
       "L 915.05044 532.067966 \n",
       "L 911.114986 532.067966 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_406\">\n",
       "    <path d=\"M 915.05044 532.12725 \n",
       "L 918.985895 532.12725 \n",
       "L 918.985895 532.118781 \n",
       "L 915.05044 532.118781 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_407\">\n",
       "    <path d=\"M 918.985895 532.12725 \n",
       "L 922.921349 532.12725 \n",
       "L 922.921349 532.12725 \n",
       "L 918.985895 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_408\">\n",
       "    <path d=\"M 922.921349 532.12725 \n",
       "L 926.856804 532.12725 \n",
       "L 926.856804 532.110312 \n",
       "L 922.921349 532.110312 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_409\">\n",
       "    <path d=\"M 926.856804 532.12725 \n",
       "L 930.792259 532.12725 \n",
       "L 930.792259 532.12725 \n",
       "L 926.856804 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_410\">\n",
       "    <path d=\"M 930.792259 532.12725 \n",
       "L 934.727713 532.12725 \n",
       "L 934.727713 532.12725 \n",
       "L 930.792259 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_411\">\n",
       "    <path d=\"M 934.727713 532.12725 \n",
       "L 938.663168 532.12725 \n",
       "L 938.663168 532.12725 \n",
       "L 934.727713 532.12725 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_412\">\n",
       "    <path d=\"M 938.663168 532.12725 \n",
       "L 942.598622 532.12725 \n",
       "L 942.598622 532.118781 \n",
       "L 938.663168 532.118781 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_413\">\n",
       "    <path d=\"M 942.598622 532.12725 \n",
       "L 946.534077 532.12725 \n",
       "L 946.534077 532.118781 \n",
       "L 942.598622 532.118781 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_414\">\n",
       "    <path d=\"M 946.534077 532.12725 \n",
       "L 950.469531 532.12725 \n",
       "L 950.469531 532.110312 \n",
       "L 946.534077 532.110312 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_415\">\n",
       "    <path d=\"M 950.469531 532.12725 \n",
       "L 954.404986 532.12725 \n",
       "L 954.404986 532.042559 \n",
       "L 950.469531 532.042559 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_416\">\n",
       "    <path d=\"M 954.404986 532.12725 \n",
       "L 958.34044 532.12725 \n",
       "L 958.34044 532.110312 \n",
       "L 954.404986 532.110312 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_417\">\n",
       "    <path d=\"M 958.34044 532.12725 \n",
       "L 962.275895 532.12725 \n",
       "L 962.275895 531.907052 \n",
       "L 958.34044 531.907052 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_418\">\n",
       "    <path d=\"M 962.275895 532.12725 \n",
       "L 966.211349 532.12725 \n",
       "L 966.211349 532.059497 \n",
       "L 962.275895 532.059497 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_419\">\n",
       "    <path d=\"M 966.211349 532.12725 \n",
       "L 970.146804 532.12725 \n",
       "L 970.146804 531.907052 \n",
       "L 966.211349 531.907052 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_420\">\n",
       "    <path d=\"M 970.146804 532.12725 \n",
       "L 974.082259 532.12725 \n",
       "L 974.082259 531.890114 \n",
       "L 970.146804 531.890114 \n",
       "z\n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_66\">\n",
       "    <path d=\"M 580.536804 532.119063 \n",
       "L 590.424881 531.981564 \n",
       "L 594.380111 531.695372 \n",
       "L 596.357727 531.171672 \n",
       "L 598.335342 529.743025 \n",
       "L 600.312957 526.607347 \n",
       "L 602.290573 520.861503 \n",
       "L 604.268188 510.643337 \n",
       "L 606.245804 492.709578 \n",
       "L 608.223419 463.399114 \n",
       "L 612.17865 378.576463 \n",
       "L 614.156265 365.813564 \n",
       "L 616.13388 385.862381 \n",
       "L 618.111496 408.429309 \n",
       "L 620.089111 418.324095 \n",
       "L 622.066726 426.044878 \n",
       "L 624.044342 442.417465 \n",
       "L 626.021957 461.955366 \n",
       "L 627.999572 473.143011 \n",
       "L 629.977188 477.409082 \n",
       "L 631.954803 484.628339 \n",
       "L 633.932418 496.898899 \n",
       "L 635.910034 507.398707 \n",
       "L 637.887649 511.599443 \n",
       "L 639.865264 510.590191 \n",
       "L 641.84288 508.834802 \n",
       "L 643.820495 510.563245 \n",
       "L 645.798111 515.410816 \n",
       "L 647.775726 519.842102 \n",
       "L 649.753341 521.904164 \n",
       "L 653.708572 522.820714 \n",
       "L 655.686187 524.04615 \n",
       "L 657.663803 525.495152 \n",
       "L 659.641418 526.243845 \n",
       "L 663.596649 526.044143 \n",
       "L 665.574264 526.57395 \n",
       "L 673.484725 529.620709 \n",
       "L 675.462341 530.159266 \n",
       "L 677.439956 530.278137 \n",
       "L 681.395187 529.771769 \n",
       "L 685.350417 529.638913 \n",
       "L 687.328033 529.666553 \n",
       "L 695.238494 531.144114 \n",
       "L 697.21611 531.348588 \n",
       "L 701.17134 531.383523 \n",
       "L 703.148956 531.167039 \n",
       "L 705.126571 530.598071 \n",
       "L 707.104186 529.800041 \n",
       "L 709.081802 529.395919 \n",
       "L 711.059417 529.7599 \n",
       "L 715.014648 531.29179 \n",
       "L 716.992263 531.645282 \n",
       "L 720.947494 531.803465 \n",
       "L 730.835571 531.931051 \n",
       "L 742.701263 531.806755 \n",
       "L 746.656493 531.899045 \n",
       "L 750.611724 531.991961 \n",
       "L 756.54457 531.860673 \n",
       "L 758.522185 531.776033 \n",
       "L 762.477416 531.923177 \n",
       "L 766.432647 531.969366 \n",
       "L 770.387878 531.721877 \n",
       "L 778.298339 531.785683 \n",
       "L 780.275954 531.730426 \n",
       "L 788.186416 532.070776 \n",
       "L 798.074492 531.972641 \n",
       "L 800.052108 531.765207 \n",
       "L 802.029723 531.420446 \n",
       "L 804.007338 531.265407 \n",
       "L 809.940185 532.014128 \n",
       "L 815.873031 532.03865 \n",
       "L 869.268645 532.076658 \n",
       "L 879.156722 532.096732 \n",
       "L 896.95526 532.11107 \n",
       "L 922.664259 532.122117 \n",
       "L 974.082259 531.97214 \n",
       "L 974.082259 531.97214 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_67\">\n",
       "    <path d=\"M 625.346927 532.12725 \n",
       "L 625.346927 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_68\">\n",
       "    <path d=\"M 619.03621 532.12725 \n",
       "L 619.03621 308.80725 \n",
       "\" clip-path=\"url(#p816d9a6b22)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_421\">\n",
       "    <path d=\"M 560.859531 532.12725 \n",
       "L 560.859531 308.80725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_422\">\n",
       "    <path d=\"M 993.759531 532.12725 \n",
       "L 993.759531 308.80725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_423\">\n",
       "    <path d=\"M 560.859531 532.12725 \n",
       "L 993.759531 532.12725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_424\">\n",
       "    <path d=\"M 560.859531 308.80725 \n",
       "L 993.759531 308.80725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_68\">\n",
       "    <!-- Distribución de ∂Precio/∂sigma -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(678.959781 302.80725) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-67\" d=\"M 319 -275 \n",
       "L 866 -356 \n",
       "Q 900 -609 1056 -725 \n",
       "Q 1266 -881 1628 -881 \n",
       "Q 2019 -881 2231 -725 \n",
       "Q 2444 -569 2519 -288 \n",
       "Q 2563 -116 2559 434 \n",
       "Q 2191 0 1641 0 \n",
       "Q 956 0 581 494 \n",
       "Q 206 988 206 1678 \n",
       "Q 206 2153 378 2554 \n",
       "Q 550 2956 876 3175 \n",
       "Q 1203 3394 1644 3394 \n",
       "Q 2231 3394 2613 2919 \n",
       "L 2613 3319 \n",
       "L 3131 3319 \n",
       "L 3131 450 \n",
       "Q 3131 -325 2973 -648 \n",
       "Q 2816 -972 2473 -1159 \n",
       "Q 2131 -1347 1631 -1347 \n",
       "Q 1038 -1347 672 -1080 \n",
       "Q 306 -813 319 -275 \n",
       "z\n",
       "M 784 1719 \n",
       "Q 784 1066 1043 766 \n",
       "Q 1303 466 1694 466 \n",
       "Q 2081 466 2343 764 \n",
       "Q 2606 1063 2606 1700 \n",
       "Q 2606 2309 2336 2618 \n",
       "Q 2066 2928 1684 2928 \n",
       "Q 1309 2928 1046 2623 \n",
       "Q 784 2319 784 1719 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-6d\" d=\"M 422 0 \n",
       "L 422 3319 \n",
       "L 925 3319 \n",
       "L 925 2853 \n",
       "Q 1081 3097 1340 3245 \n",
       "Q 1600 3394 1931 3394 \n",
       "Q 2300 3394 2536 3241 \n",
       "Q 2772 3088 2869 2813 \n",
       "Q 3263 3394 3894 3394 \n",
       "Q 4388 3394 4653 3120 \n",
       "Q 4919 2847 4919 2278 \n",
       "L 4919 0 \n",
       "L 4359 0 \n",
       "L 4359 2091 \n",
       "Q 4359 2428 4304 2576 \n",
       "Q 4250 2725 4106 2815 \n",
       "Q 3963 2906 3769 2906 \n",
       "Q 3419 2906 3187 2673 \n",
       "Q 2956 2441 2956 1928 \n",
       "L 2956 0 \n",
       "L 2394 0 \n",
       "L 2394 2156 \n",
       "Q 2394 2531 2256 2718 \n",
       "Q 2119 2906 1806 2906 \n",
       "Q 1569 2906 1367 2781 \n",
       "Q 1166 2656 1075 2415 \n",
       "Q 984 2175 984 1722 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(94.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(144.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(172.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(205.517578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-62\" transform=\"translate(227.734375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(283.349609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(338.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(388.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-f3\" transform=\"translate(411.181641 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(466.796875 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(522.412109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(550.195312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(605.810547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(661.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(689.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-50\" transform=\"translate(738.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(805.322266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(838.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(894.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(944.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(966.455078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2f\" transform=\"translate(1022.070312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(1049.853516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(1099.267578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(1149.267578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-67\" transform=\"translate(1171.484375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(1227.099609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-61\" transform=\"translate(1310.400391 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_4\">\n",
       "    <g id=\"patch_425\">\n",
       "     <path d=\"M 875.031719 348.726938 \n",
       "L 986.059531 348.726938 \n",
       "Q 988.259531 348.726938 988.259531 346.526938 \n",
       "L 988.259531 316.50725 \n",
       "Q 988.259531 314.30725 986.059531 314.30725 \n",
       "L 875.031719 314.30725 \n",
       "Q 872.831719 314.30725 872.831719 316.50725 \n",
       "L 872.831719 346.526938 \n",
       "Q 872.831719 348.726938 875.031719 348.726938 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_69\">\n",
       "     <path d=\"M 877.231719 322.730844 \n",
       "L 888.231719 322.730844 \n",
       "L 899.231719 322.730844 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_69\">\n",
       "     <!-- Media: 41.87 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(908.031719 326.580844) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(300.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-34\" transform=\"translate(327.929688 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(383.544922 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-38\" transform=\"translate(466.943359 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-37\" transform=\"translate(522.558594 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_70\">\n",
       "     <path d=\"M 877.231719 338.290688 \n",
       "L 888.231719 338.290688 \n",
       "L 899.231719 338.290688 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_70\">\n",
       "     <!-- Mediana: 21.20 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(908.031719 342.140688) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(494.775391 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(550.390625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(578.173828 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(633.789062 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_5\">\n",
       "   <g id=\"patch_426\">\n",
       "    <path d=\"M 62.259531 817.42725 \n",
       "L 495.159531 817.42725 \n",
       "L 495.159531 594.10725 \n",
       "L 62.259531 594.10725 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_9\">\n",
       "    <g id=\"xtick_25\">\n",
       "     <g id=\"line2d_71\">\n",
       "      <path d=\"M 66.005512 817.42725 \n",
       "L 66.005512 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_71\">\n",
       "      <!-- −6 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(59.734653 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-36\" transform=\"translate(58.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_26\">\n",
       "     <g id=\"line2d_72\">\n",
       "      <path d=\"M 144.080287 817.42725 \n",
       "L 144.080287 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_72\">\n",
       "      <!-- −4 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(137.809428 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-34\" transform=\"translate(58.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_27\">\n",
       "     <g id=\"line2d_73\">\n",
       "      <path d=\"M 222.155062 817.42725 \n",
       "L 222.155062 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_73\">\n",
       "      <!-- −2 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(215.884202 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(58.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_28\">\n",
       "     <g id=\"line2d_74\">\n",
       "      <path d=\"M 300.229836 817.42725 \n",
       "L 300.229836 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_74\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(297.171321 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_29\">\n",
       "     <g id=\"line2d_75\">\n",
       "      <path d=\"M 378.304611 817.42725 \n",
       "L 378.304611 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_75\">\n",
       "      <!-- 2 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(375.246095 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_30\">\n",
       "     <g id=\"line2d_76\">\n",
       "      <path d=\"M 456.379386 817.42725 \n",
       "L 456.379386 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_76\">\n",
       "      <!-- 4 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(453.32087 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_77\">\n",
       "     <!-- Valor de la derivada parcial -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(206.447969 849.576469) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(59.324219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(114.939453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(137.15625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(192.771484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(226.072266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(253.855469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(309.470703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(365.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(392.869141 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(415.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(470.701172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(498.484375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(554.099609 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(609.714844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(643.015625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(665.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(715.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(770.847656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(826.462891 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(882.078125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(909.861328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(965.476562 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(1021.091797 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(1054.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(1104.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(1126.609375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1182.224609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_10\">\n",
       "    <g id=\"ytick_27\">\n",
       "     <g id=\"line2d_77\">\n",
       "      <path d=\"M 62.259531 817.42725 \n",
       "L 495.159531 817.42725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_78\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(46.6425 821.364047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_28\">\n",
       "     <g id=\"line2d_78\">\n",
       "      <path d=\"M 62.259531 789.338804 \n",
       "L 495.159531 789.338804 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_79\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 793.275601) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_29\">\n",
       "     <g id=\"line2d_79\">\n",
       "      <path d=\"M 62.259531 761.250358 \n",
       "L 495.159531 761.250358 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_80\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 765.187155) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_30\">\n",
       "     <g id=\"line2d_80\">\n",
       "      <path d=\"M 62.259531 733.161912 \n",
       "L 495.159531 733.161912 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_81\">\n",
       "      <!-- 3000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 737.098708) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_31\">\n",
       "     <g id=\"line2d_81\">\n",
       "      <path d=\"M 62.259531 705.073465 \n",
       "L 495.159531 705.073465 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_82\">\n",
       "      <!-- 4000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 709.010262) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_32\">\n",
       "     <g id=\"line2d_82\">\n",
       "      <path d=\"M 62.259531 676.985019 \n",
       "L 495.159531 676.985019 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_83\">\n",
       "      <!-- 5000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 680.921816) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_33\">\n",
       "     <g id=\"line2d_83\">\n",
       "      <path d=\"M 62.259531 648.896573 \n",
       "L 495.159531 648.896573 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_84\">\n",
       "      <!-- 6000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 652.83337) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_34\">\n",
       "     <g id=\"line2d_84\">\n",
       "      <path d=\"M 62.259531 620.808127 \n",
       "L 495.159531 620.808127 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_85\">\n",
       "      <!-- 7000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 624.744924) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-37\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_86\">\n",
       "     <!-- Frecuencia -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(21.906406 735.445688) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-46\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(61.083984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(94.384766 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(150 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(255.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(311.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(366.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(439.0625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_427\">\n",
       "    <path d=\"M 81.936804 817.42725 \n",
       "L 85.872259 817.42725 \n",
       "L 85.872259 817.342985 \n",
       "L 81.936804 817.342985 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_428\">\n",
       "    <path d=\"M 85.872259 817.42725 \n",
       "L 89.807713 817.42725 \n",
       "L 89.807713 817.42725 \n",
       "L 85.872259 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_429\">\n",
       "    <path d=\"M 89.807713 817.42725 \n",
       "L 93.743168 817.42725 \n",
       "L 93.743168 817.42725 \n",
       "L 89.807713 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_430\">\n",
       "    <path d=\"M 93.743168 817.42725 \n",
       "L 97.678622 817.42725 \n",
       "L 97.678622 817.342985 \n",
       "L 93.743168 817.342985 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_431\">\n",
       "    <path d=\"M 97.678622 817.42725 \n",
       "L 101.614077 817.42725 \n",
       "L 101.614077 817.286808 \n",
       "L 97.678622 817.286808 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_432\">\n",
       "    <path d=\"M 101.614077 817.42725 \n",
       "L 105.549531 817.42725 \n",
       "L 105.549531 815.657678 \n",
       "L 101.614077 815.657678 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_433\">\n",
       "    <path d=\"M 105.549531 817.42725 \n",
       "L 109.484986 817.42725 \n",
       "L 109.484986 817.314896 \n",
       "L 105.549531 817.314896 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_434\">\n",
       "    <path d=\"M 109.484986 817.42725 \n",
       "L 113.42044 817.42725 \n",
       "L 113.42044 816.865481 \n",
       "L 109.484986 816.865481 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_435\">\n",
       "    <path d=\"M 113.42044 817.42725 \n",
       "L 117.355895 817.42725 \n",
       "L 117.355895 817.090189 \n",
       "L 113.42044 817.090189 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_436\">\n",
       "    <path d=\"M 117.355895 817.42725 \n",
       "L 121.291349 817.42725 \n",
       "L 121.291349 816.191358 \n",
       "L 117.355895 816.191358 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_437\">\n",
       "    <path d=\"M 121.291349 817.42725 \n",
       "L 125.226804 817.42725 \n",
       "L 125.226804 817.202542 \n",
       "L 121.291349 817.202542 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_438\">\n",
       "    <path d=\"M 125.226804 817.42725 \n",
       "L 129.162259 817.42725 \n",
       "L 129.162259 817.230631 \n",
       "L 125.226804 817.230631 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_439\">\n",
       "    <path d=\"M 129.162259 817.42725 \n",
       "L 133.097713 817.42725 \n",
       "L 133.097713 815.79812 \n",
       "L 129.162259 815.79812 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_440\">\n",
       "    <path d=\"M 133.097713 817.42725 \n",
       "L 137.033168 817.42725 \n",
       "L 137.033168 817.342985 \n",
       "L 133.097713 817.342985 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_441\">\n",
       "    <path d=\"M 137.033168 817.42725 \n",
       "L 140.968622 817.42725 \n",
       "L 140.968622 817.42725 \n",
       "L 137.033168 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_442\">\n",
       "    <path d=\"M 140.968622 817.42725 \n",
       "L 144.904077 817.42725 \n",
       "L 144.904077 817.42725 \n",
       "L 140.968622 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_443\">\n",
       "    <path d=\"M 144.904077 817.42725 \n",
       "L 148.839531 817.42725 \n",
       "L 148.839531 817.258719 \n",
       "L 144.904077 817.258719 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_444\">\n",
       "    <path d=\"M 148.839531 817.42725 \n",
       "L 152.774986 817.42725 \n",
       "L 152.774986 816.977835 \n",
       "L 148.839531 816.977835 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_445\">\n",
       "    <path d=\"M 152.774986 817.42725 \n",
       "L 156.71044 817.42725 \n",
       "L 156.71044 816.668862 \n",
       "L 152.774986 816.668862 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_446\">\n",
       "    <path d=\"M 156.71044 817.42725 \n",
       "L 160.645895 817.42725 \n",
       "L 160.645895 817.146366 \n",
       "L 156.71044 817.146366 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_447\">\n",
       "    <path d=\"M 160.645895 817.42725 \n",
       "L 164.581349 817.42725 \n",
       "L 164.581349 817.0621 \n",
       "L 160.645895 817.0621 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_448\">\n",
       "    <path d=\"M 164.581349 817.42725 \n",
       "L 168.516804 817.42725 \n",
       "L 168.516804 817.118277 \n",
       "L 164.581349 817.118277 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_449\">\n",
       "    <path d=\"M 168.516804 817.42725 \n",
       "L 172.452259 817.42725 \n",
       "L 172.452259 817.0621 \n",
       "L 168.516804 817.0621 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_450\">\n",
       "    <path d=\"M 172.452259 817.42725 \n",
       "L 176.387713 817.42725 \n",
       "L 176.387713 815.601501 \n",
       "L 172.452259 815.601501 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_451\">\n",
       "    <path d=\"M 176.387713 817.42725 \n",
       "L 180.323168 817.42725 \n",
       "L 180.323168 817.286808 \n",
       "L 176.387713 817.286808 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_452\">\n",
       "    <path d=\"M 180.323168 817.42725 \n",
       "L 184.258622 817.42725 \n",
       "L 184.258622 815.713855 \n",
       "L 180.323168 815.713855 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_453\">\n",
       "    <path d=\"M 184.258622 817.42725 \n",
       "L 188.194077 817.42725 \n",
       "L 188.194077 816.303712 \n",
       "L 184.258622 816.303712 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_454\">\n",
       "    <path d=\"M 188.194077 817.42725 \n",
       "L 192.129531 817.42725 \n",
       "L 192.129531 816.69695 \n",
       "L 188.194077 816.69695 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_455\">\n",
       "    <path d=\"M 192.129531 817.42725 \n",
       "L 196.064986 817.42725 \n",
       "L 196.064986 817.146366 \n",
       "L 192.129531 817.146366 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_456\">\n",
       "    <path d=\"M 196.064986 817.42725 \n",
       "L 200.00044 817.42725 \n",
       "L 200.00044 815.067821 \n",
       "L 196.064986 815.067821 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_457\">\n",
       "    <path d=\"M 200.00044 817.42725 \n",
       "L 203.935895 817.42725 \n",
       "L 203.935895 813.242072 \n",
       "L 200.00044 813.242072 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_458\">\n",
       "    <path d=\"M 203.935895 817.42725 \n",
       "L 207.871349 817.42725 \n",
       "L 207.871349 808.607478 \n",
       "L 203.935895 808.607478 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_459\">\n",
       "    <path d=\"M 207.871349 817.42725 \n",
       "L 211.806804 817.42725 \n",
       "L 211.806804 808.523213 \n",
       "L 207.871349 808.523213 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_460\">\n",
       "    <path d=\"M 211.806804 817.42725 \n",
       "L 215.742259 817.42725 \n",
       "L 215.742259 807.989532 \n",
       "L 211.806804 807.989532 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_461\">\n",
       "    <path d=\"M 215.742259 817.42725 \n",
       "L 219.677713 817.42725 \n",
       "L 219.677713 797.091215 \n",
       "L 215.742259 797.091215 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_462\">\n",
       "    <path d=\"M 219.677713 817.42725 \n",
       "L 223.613168 817.42725 \n",
       "L 223.613168 805.658191 \n",
       "L 219.677713 805.658191 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_463\">\n",
       "    <path d=\"M 223.613168 817.42725 \n",
       "L 227.548622 817.42725 \n",
       "L 227.548622 798.214753 \n",
       "L 223.613168 798.214753 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_464\">\n",
       "    <path d=\"M 227.548622 817.42725 \n",
       "L 231.484077 817.42725 \n",
       "L 231.484077 789.086008 \n",
       "L 227.548622 789.086008 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_465\">\n",
       "    <path d=\"M 231.484077 817.42725 \n",
       "L 235.419531 817.42725 \n",
       "L 235.419531 798.860787 \n",
       "L 231.484077 798.860787 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_466\">\n",
       "    <path d=\"M 235.419531 817.42725 \n",
       "L 239.354986 817.42725 \n",
       "L 239.354986 781.108889 \n",
       "L 235.419531 781.108889 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_467\">\n",
       "    <path d=\"M 239.354986 817.42725 \n",
       "L 243.29044 817.42725 \n",
       "L 243.29044 746.110685 \n",
       "L 239.354986 746.110685 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_468\">\n",
       "    <path d=\"M 243.29044 817.42725 \n",
       "L 247.225895 817.42725 \n",
       "L 247.225895 777.794452 \n",
       "L 243.29044 777.794452 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_469\">\n",
       "    <path d=\"M 247.225895 817.42725 \n",
       "L 251.161349 817.42725 \n",
       "L 251.161349 791.529703 \n",
       "L 247.225895 791.529703 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_470\">\n",
       "    <path d=\"M 251.161349 817.42725 \n",
       "L 255.096804 817.42725 \n",
       "L 255.096804 787.569232 \n",
       "L 251.161349 787.569232 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_471\">\n",
       "    <path d=\"M 255.096804 817.42725 \n",
       "L 259.032259 817.42725 \n",
       "L 259.032259 756.222526 \n",
       "L 255.096804 756.222526 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_472\">\n",
       "    <path d=\"M 259.032259 817.42725 \n",
       "L 262.967713 817.42725 \n",
       "L 262.967713 754.452954 \n",
       "L 259.032259 754.452954 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_473\">\n",
       "    <path d=\"M 262.967713 817.42725 \n",
       "L 266.903168 817.42725 \n",
       "L 266.903168 729.622767 \n",
       "L 262.967713 729.622767 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_474\">\n",
       "    <path d=\"M 266.903168 817.42725 \n",
       "L 270.838622 817.42725 \n",
       "L 270.838622 688.36084 \n",
       "L 266.903168 688.36084 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_475\">\n",
       "    <path d=\"M 270.838622 817.42725 \n",
       "L 274.774077 817.42725 \n",
       "L 274.774077 749.762183 \n",
       "L 270.838622 749.762183 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_476\">\n",
       "    <path d=\"M 274.774077 817.42725 \n",
       "L 278.709531 817.42725 \n",
       "L 278.709531 773.777805 \n",
       "L 274.774077 773.777805 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_477\">\n",
       "    <path d=\"M 278.709531 817.42725 \n",
       "L 282.644986 817.42725 \n",
       "L 282.644986 744.284936 \n",
       "L 278.709531 744.284936 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_478\">\n",
       "    <path d=\"M 282.644986 817.42725 \n",
       "L 286.58044 817.42725 \n",
       "L 286.58044 604.741536 \n",
       "L 282.644986 604.741536 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_479\">\n",
       "    <path d=\"M 286.58044 817.42725 \n",
       "L 290.515895 817.42725 \n",
       "L 290.515895 637.633106 \n",
       "L 286.58044 637.633106 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_480\">\n",
       "    <path d=\"M 290.515895 817.42725 \n",
       "L 294.451349 817.42725 \n",
       "L 294.451349 677.68723 \n",
       "L 290.515895 677.68723 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_481\">\n",
       "    <path d=\"M 294.451349 817.42725 \n",
       "L 298.386804 817.42725 \n",
       "L 298.386804 631.790709 \n",
       "L 294.451349 631.790709 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_482\">\n",
       "    <path d=\"M 298.386804 817.42725 \n",
       "L 302.322259 817.42725 \n",
       "L 302.322259 614.741023 \n",
       "L 298.386804 614.741023 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_483\">\n",
       "    <path d=\"M 302.322259 817.42725 \n",
       "L 306.257713 817.42725 \n",
       "L 306.257713 649.654961 \n",
       "L 302.322259 649.654961 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_484\">\n",
       "    <path d=\"M 306.257713 817.42725 \n",
       "L 310.193168 817.42725 \n",
       "L 310.193168 649.458342 \n",
       "L 306.257713 649.458342 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_485\">\n",
       "    <path d=\"M 310.193168 817.42725 \n",
       "L 314.128622 817.42725 \n",
       "L 314.128622 690.636004 \n",
       "L 310.193168 690.636004 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_486\">\n",
       "    <path d=\"M 314.128622 817.42725 \n",
       "L 318.064077 817.42725 \n",
       "L 318.064077 700.270341 \n",
       "L 314.128622 700.270341 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_487\">\n",
       "    <path d=\"M 318.064077 817.42725 \n",
       "L 321.999531 817.42725 \n",
       "L 321.999531 759.312255 \n",
       "L 318.064077 759.312255 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_488\">\n",
       "    <path d=\"M 321.999531 817.42725 \n",
       "L 325.934986 817.42725 \n",
       "L 325.934986 769.817334 \n",
       "L 321.999531 769.817334 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_489\">\n",
       "    <path d=\"M 325.934986 817.42725 \n",
       "L 329.87044 817.42725 \n",
       "L 329.87044 775.12605 \n",
       "L 325.934986 775.12605 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_490\">\n",
       "    <path d=\"M 329.87044 817.42725 \n",
       "L 333.805895 817.42725 \n",
       "L 333.805895 771.277933 \n",
       "L 329.87044 771.277933 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_491\">\n",
       "    <path d=\"M 333.805895 817.42725 \n",
       "L 337.741349 817.42725 \n",
       "L 337.741349 791.979118 \n",
       "L 333.805895 791.979118 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_492\">\n",
       "    <path d=\"M 337.741349 817.42725 \n",
       "L 341.676804 817.42725 \n",
       "L 341.676804 788.720858 \n",
       "L 337.741349 788.720858 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_493\">\n",
       "    <path d=\"M 341.676804 817.42725 \n",
       "L 345.612259 817.42725 \n",
       "L 345.612259 782.429046 \n",
       "L 341.676804 782.429046 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_494\">\n",
       "    <path d=\"M 345.612259 817.42725 \n",
       "L 349.547713 817.42725 \n",
       "L 349.547713 796.6418 \n",
       "L 345.612259 796.6418 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_495\">\n",
       "    <path d=\"M 349.547713 817.42725 \n",
       "L 353.483168 817.42725 \n",
       "L 353.483168 787.513055 \n",
       "L 349.547713 787.513055 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_496\">\n",
       "    <path d=\"M 353.483168 817.42725 \n",
       "L 357.418622 817.42725 \n",
       "L 357.418622 805.939076 \n",
       "L 353.483168 805.939076 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_497\">\n",
       "    <path d=\"M 357.418622 817.42725 \n",
       "L 361.354077 817.42725 \n",
       "L 361.354077 799.956236 \n",
       "L 357.418622 799.956236 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_498\">\n",
       "    <path d=\"M 361.354077 817.42725 \n",
       "L 365.289531 817.42725 \n",
       "L 365.289531 808.467036 \n",
       "L 361.354077 808.467036 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_499\">\n",
       "    <path d=\"M 365.289531 817.42725 \n",
       "L 369.224986 817.42725 \n",
       "L 369.224986 802.540374 \n",
       "L 365.289531 802.540374 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_500\">\n",
       "    <path d=\"M 369.224986 817.42725 \n",
       "L 373.16044 817.42725 \n",
       "L 373.16044 811.528676 \n",
       "L 369.224986 811.528676 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_501\">\n",
       "    <path d=\"M 373.16044 817.42725 \n",
       "L 377.095895 817.42725 \n",
       "L 377.095895 809.056893 \n",
       "L 373.16044 809.056893 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_502\">\n",
       "    <path d=\"M 377.095895 817.42725 \n",
       "L 381.031349 817.42725 \n",
       "L 381.031349 809.899546 \n",
       "L 377.095895 809.899546 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_503\">\n",
       "    <path d=\"M 381.031349 817.42725 \n",
       "L 384.966804 817.42725 \n",
       "L 384.966804 790.518519 \n",
       "L 381.031349 790.518519 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_504\">\n",
       "    <path d=\"M 384.966804 817.42725 \n",
       "L 388.902259 817.42725 \n",
       "L 388.902259 812.53986 \n",
       "L 384.966804 812.53986 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_505\">\n",
       "    <path d=\"M 388.902259 817.42725 \n",
       "L 392.837713 817.42725 \n",
       "L 392.837713 813.354425 \n",
       "L 388.902259 813.354425 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_506\">\n",
       "    <path d=\"M 392.837713 817.42725 \n",
       "L 396.773168 817.42725 \n",
       "L 396.773168 816.16327 \n",
       "L 392.837713 816.16327 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_507\">\n",
       "    <path d=\"M 396.773168 817.42725 \n",
       "L 400.708622 817.42725 \n",
       "L 400.708622 812.989276 \n",
       "L 396.773168 812.989276 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_508\">\n",
       "    <path d=\"M 400.708622 817.42725 \n",
       "L 404.644077 817.42725 \n",
       "L 404.644077 814.365609 \n",
       "L 400.708622 814.365609 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_509\">\n",
       "    <path d=\"M 404.644077 817.42725 \n",
       "L 408.579531 817.42725 \n",
       "L 408.579531 814.590317 \n",
       "L 404.644077 814.590317 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_510\">\n",
       "    <path d=\"M 408.579531 817.42725 \n",
       "L 412.514986 817.42725 \n",
       "L 412.514986 815.067821 \n",
       "L 408.579531 815.067821 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_511\">\n",
       "    <path d=\"M 412.514986 817.42725 \n",
       "L 416.45044 817.42725 \n",
       "L 416.45044 815.039732 \n",
       "L 412.514986 815.039732 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_512\">\n",
       "    <path d=\"M 416.45044 817.42725 \n",
       "L 420.385895 817.42725 \n",
       "L 420.385895 816.781216 \n",
       "L 416.45044 816.781216 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_513\">\n",
       "    <path d=\"M 420.385895 817.42725 \n",
       "L 424.321349 817.42725 \n",
       "L 424.321349 816.331801 \n",
       "L 420.385895 816.331801 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_514\">\n",
       "    <path d=\"M 424.321349 817.42725 \n",
       "L 428.256804 817.42725 \n",
       "L 428.256804 816.837393 \n",
       "L 424.321349 816.837393 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_515\">\n",
       "    <path d=\"M 428.256804 817.42725 \n",
       "L 432.192259 817.42725 \n",
       "L 432.192259 817.005923 \n",
       "L 428.256804 817.005923 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_516\">\n",
       "    <path d=\"M 432.192259 817.42725 \n",
       "L 436.127713 817.42725 \n",
       "L 436.127713 817.090189 \n",
       "L 432.192259 817.090189 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_517\">\n",
       "    <path d=\"M 436.127713 817.42725 \n",
       "L 440.063168 817.42725 \n",
       "L 440.063168 817.174454 \n",
       "L 436.127713 817.174454 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_518\">\n",
       "    <path d=\"M 440.063168 817.42725 \n",
       "L 443.998622 817.42725 \n",
       "L 443.998622 816.640774 \n",
       "L 440.063168 816.640774 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_519\">\n",
       "    <path d=\"M 443.998622 817.42725 \n",
       "L 447.934077 817.42725 \n",
       "L 447.934077 816.977835 \n",
       "L 443.998622 816.977835 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_520\">\n",
       "    <path d=\"M 447.934077 817.42725 \n",
       "L 451.869531 817.42725 \n",
       "L 451.869531 817.146366 \n",
       "L 447.934077 817.146366 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_521\">\n",
       "    <path d=\"M 451.869531 817.42725 \n",
       "L 455.804986 817.42725 \n",
       "L 455.804986 817.258719 \n",
       "L 451.869531 817.258719 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_522\">\n",
       "    <path d=\"M 455.804986 817.42725 \n",
       "L 459.74044 817.42725 \n",
       "L 459.74044 817.42725 \n",
       "L 455.804986 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_523\">\n",
       "    <path d=\"M 459.74044 817.42725 \n",
       "L 463.675895 817.42725 \n",
       "L 463.675895 817.118277 \n",
       "L 459.74044 817.118277 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_524\">\n",
       "    <path d=\"M 463.675895 817.42725 \n",
       "L 467.611349 817.42725 \n",
       "L 467.611349 817.286808 \n",
       "L 463.675895 817.286808 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_525\">\n",
       "    <path d=\"M 467.611349 817.42725 \n",
       "L 471.546804 817.42725 \n",
       "L 471.546804 817.230631 \n",
       "L 467.611349 817.230631 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_526\">\n",
       "    <path d=\"M 471.546804 817.42725 \n",
       "L 475.482259 817.42725 \n",
       "L 475.482259 817.286808 \n",
       "L 471.546804 817.286808 \n",
       "z\n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_85\">\n",
       "    <path d=\"M 81.936804 817.395215 \n",
       "L 95.780111 817.297432 \n",
       "L 99.735342 816.903534 \n",
       "L 101.712957 816.647712 \n",
       "L 103.690573 816.524287 \n",
       "L 107.645804 816.757157 \n",
       "L 111.601034 816.948621 \n",
       "L 115.556265 816.865098 \n",
       "L 119.511496 816.762771 \n",
       "L 125.444342 816.886107 \n",
       "L 131.377188 816.645708 \n",
       "L 139.287649 817.369664 \n",
       "L 143.24288 817.366614 \n",
       "L 149.175726 817.090685 \n",
       "L 155.108572 816.860813 \n",
       "L 166.974264 817.099088 \n",
       "L 170.929495 816.832701 \n",
       "L 174.884725 816.421231 \n",
       "L 184.772802 816.117141 \n",
       "L 188.728033 816.485571 \n",
       "L 190.705648 816.662266 \n",
       "L 192.683264 816.602252 \n",
       "L 194.660879 816.184698 \n",
       "L 196.638494 815.405829 \n",
       "L 200.593725 813.291484 \n",
       "L 202.57134 812.097159 \n",
       "L 206.526571 809.468676 \n",
       "L 208.504186 808.551056 \n",
       "L 210.481802 807.983051 \n",
       "L 212.459417 807.170272 \n",
       "L 214.437032 805.514555 \n",
       "L 216.414648 803.306796 \n",
       "L 218.392263 801.700719 \n",
       "L 222.347494 800.736445 \n",
       "L 224.325109 798.825048 \n",
       "L 226.302724 795.947881 \n",
       "L 228.28034 793.958864 \n",
       "L 230.257955 793.493686 \n",
       "L 232.235571 792.846189 \n",
       "L 234.213186 789.726688 \n",
       "L 236.190801 783.527048 \n",
       "L 238.168417 775.852177 \n",
       "L 240.146032 769.500327 \n",
       "L 242.123647 767.041121 \n",
       "L 244.101263 769.539972 \n",
       "L 246.078878 775.757526 \n",
       "L 248.056493 782.528022 \n",
       "L 250.034109 786.308099 \n",
       "L 252.011724 784.756005 \n",
       "L 253.989339 777.62418 \n",
       "L 257.94457 757.135156 \n",
       "L 259.922185 750.134281 \n",
       "L 261.899801 744.408266 \n",
       "L 263.877416 736.119975 \n",
       "L 265.855031 725.033636 \n",
       "L 267.832647 716.737636 \n",
       "L 269.810262 717.956579 \n",
       "L 271.787878 729.505891 \n",
       "L 273.765493 744.357658 \n",
       "L 275.743108 752.881585 \n",
       "L 277.720724 749.163482 \n",
       "L 279.698339 732.186991 \n",
       "L 281.675954 704.009444 \n",
       "L 283.65357 670.691644 \n",
       "L 285.631185 643.368498 \n",
       "L 287.6088 631.909088 \n",
       "L 289.586416 635.721455 \n",
       "L 291.564031 644.452669 \n",
       "L 293.541646 648.226927 \n",
       "L 295.519262 644.981544 \n",
       "L 297.496877 638.986363 \n",
       "L 299.474492 635.277167 \n",
       "L 301.452108 635.620566 \n",
       "L 303.429723 638.653265 \n",
       "L 305.407338 643.781061 \n",
       "L 307.384954 652.806527 \n",
       "L 309.362569 666.242339 \n",
       "L 313.3178 695.878316 \n",
       "L 315.295415 710.267448 \n",
       "L 319.250646 740.923291 \n",
       "L 321.228261 753.301712 \n",
       "L 323.205877 761.795216 \n",
       "L 325.183492 767.674358 \n",
       "L 327.161107 772.470372 \n",
       "L 329.138723 776.329968 \n",
       "L 331.116338 778.816574 \n",
       "L 333.093953 780.503016 \n",
       "L 335.071569 782.499107 \n",
       "L 337.049184 784.749015 \n",
       "L 339.026799 786.177701 \n",
       "L 341.004415 786.408765 \n",
       "L 342.98203 786.354982 \n",
       "L 344.959645 787.138446 \n",
       "L 346.937261 789.025658 \n",
       "L 348.914876 791.607127 \n",
       "L 352.870107 797.179478 \n",
       "L 354.847722 799.327607 \n",
       "L 360.780568 804.641929 \n",
       "L 362.758184 805.622175 \n",
       "L 366.713414 806.010384 \n",
       "L 368.69103 807.035547 \n",
       "L 370.668645 808.518257 \n",
       "L 372.64626 809.660785 \n",
       "L 374.623876 809.956738 \n",
       "L 376.601491 809.120027 \n",
       "L 378.579106 806.971791 \n",
       "L 380.556722 804.065049 \n",
       "L 382.534337 802.04387 \n",
       "L 384.511952 802.524517 \n",
       "L 386.489568 805.482345 \n",
       "L 388.467183 809.254689 \n",
       "L 390.444798 812.169426 \n",
       "L 392.422414 813.714136 \n",
       "L 394.400029 814.245808 \n",
       "L 396.377645 814.256941 \n",
       "L 400.332875 814.053923 \n",
       "L 404.288106 814.335716 \n",
       "L 408.243337 814.77955 \n",
       "L 414.176183 815.682581 \n",
       "L 422.086644 816.443867 \n",
       "L 433.952336 817.065296 \n",
       "L 445.818028 817.013126 \n",
       "L 455.706105 817.283127 \n",
       "L 475.482259 817.341589 \n",
       "L 475.482259 817.341589 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_86\">\n",
       "    <path d=\"M 292.852674 817.42725 \n",
       "L 292.852674 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_87\">\n",
       "    <path d=\"M 294.532687 817.42725 \n",
       "L 294.532687 594.10725 \n",
       "\" clip-path=\"url(#pc103c95a8d)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_527\">\n",
       "    <path d=\"M 62.259531 817.42725 \n",
       "L 62.259531 594.10725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_528\">\n",
       "    <path d=\"M 495.159531 817.42725 \n",
       "L 495.159531 594.10725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_529\">\n",
       "    <path d=\"M 62.259531 817.42725 \n",
       "L 495.159531 817.42725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_530\">\n",
       "    <path d=\"M 62.259531 594.10725 \n",
       "L 495.159531 594.10725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_87\">\n",
       "    <!-- Distribución de ∂Precio/∂openInterest -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(159.539406 588.10725) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-49\" d=\"M 597 0 \n",
       "L 597 4581 \n",
       "L 1203 4581 \n",
       "L 1203 0 \n",
       "L 597 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(94.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(144.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(172.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(205.517578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-62\" transform=\"translate(227.734375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(283.349609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(338.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(388.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-f3\" transform=\"translate(411.181641 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(466.796875 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(522.412109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(550.195312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(605.810547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(661.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(689.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-50\" transform=\"translate(738.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(805.322266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(838.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(894.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(944.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(966.455078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2f\" transform=\"translate(1022.070312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(1049.853516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(1099.267578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-70\" transform=\"translate(1154.882812 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(1210.498047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(1266.113281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-49\" transform=\"translate(1321.728516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(1349.511719 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(1405.126953 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(1432.910156 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(1488.525391 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(1521.826172 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(1577.441406 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(1627.441406 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_5\">\n",
       "    <g id=\"patch_531\">\n",
       "     <path d=\"M 378.886094 634.026938 \n",
       "L 487.459531 634.026938 \n",
       "Q 489.659531 634.026938 489.659531 631.826938 \n",
       "L 489.659531 601.80725 \n",
       "Q 489.659531 599.60725 487.459531 599.60725 \n",
       "L 378.886094 599.60725 \n",
       "Q 376.686094 599.60725 376.686094 601.80725 \n",
       "L 376.686094 631.826938 \n",
       "Q 376.686094 634.026938 378.886094 634.026938 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_88\">\n",
       "     <path d=\"M 381.086094 608.030844 \n",
       "L 392.086094 608.030844 \n",
       "L 403.086094 608.030844 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_88\">\n",
       "     <!-- Media: -0.19 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(411.886094 611.880844) scale(0.11 -0.11)\">\n",
       "      <defs>\n",
       "       <path id=\"ArialMT-39\" d=\"M 350 1059 \n",
       "L 891 1109 \n",
       "Q 959 728 1153 556 \n",
       "Q 1347 384 1650 384 \n",
       "Q 1909 384 2104 503 \n",
       "Q 2300 622 2425 820 \n",
       "Q 2550 1019 2634 1356 \n",
       "Q 2719 1694 2719 2044 \n",
       "Q 2719 2081 2716 2156 \n",
       "Q 2547 1888 2255 1720 \n",
       "Q 1963 1553 1622 1553 \n",
       "Q 1053 1553 659 1965 \n",
       "Q 266 2378 266 3053 \n",
       "Q 266 3750 677 4175 \n",
       "Q 1088 4600 1706 4600 \n",
       "Q 2153 4600 2523 4359 \n",
       "Q 2894 4119 3086 3673 \n",
       "Q 3278 3228 3278 2384 \n",
       "Q 3278 1506 3087 986 \n",
       "Q 2897 466 2520 194 \n",
       "Q 2144 -78 1638 -78 \n",
       "Q 1100 -78 759 220 \n",
       "Q 419 519 350 1059 \n",
       "z\n",
       "M 2653 3081 \n",
       "Q 2653 3566 2395 3850 \n",
       "Q 2138 4134 1775 4134 \n",
       "Q 1400 4134 1122 3828 \n",
       "Q 844 3522 844 3034 \n",
       "Q 844 2597 1108 2323 \n",
       "Q 1372 2050 1759 2050 \n",
       "Q 2150 2050 2401 2323 \n",
       "Q 2653 2597 2653 3081 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      </defs>\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(300.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2d\" transform=\"translate(327.929688 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(361.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(444.628906 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-39\" transform=\"translate(500.244141 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_89\">\n",
       "     <path d=\"M 381.086094 623.590688 \n",
       "L 392.086094 623.590688 \n",
       "L 403.086094 623.590688 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_89\">\n",
       "     <!-- Mediana: -0.15 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(411.886094 627.440688) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2d\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(472.460938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(528.076172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(555.859375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-35\" transform=\"translate(611.474609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_6\">\n",
       "   <g id=\"patch_532\">\n",
       "    <path d=\"M 560.859531 817.42725 \n",
       "L 993.759531 817.42725 \n",
       "L 993.759531 594.10725 \n",
       "L 560.859531 594.10725 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_11\">\n",
       "    <g id=\"xtick_31\">\n",
       "     <g id=\"line2d_90\">\n",
       "      <path d=\"M 616.878739 817.42725 \n",
       "L 616.878739 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_90\">\n",
       "      <!-- −7.5 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(606.021395 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-37\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(141.796875 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_32\">\n",
       "     <g id=\"line2d_91\">\n",
       "      <path d=\"M 673.634459 817.42725 \n",
       "L 673.634459 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_91\">\n",
       "      <!-- −5.0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(662.777115 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(141.796875 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_33\">\n",
       "     <g id=\"line2d_92\">\n",
       "      <path d=\"M 730.390179 817.42725 \n",
       "L 730.390179 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_92\">\n",
       "      <!-- −2.5 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(719.532835 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(141.796875 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_34\">\n",
       "     <g id=\"line2d_93\">\n",
       "      <path d=\"M 787.145899 817.42725 \n",
       "L 787.145899 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_93\">\n",
       "      <!-- 0.0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(779.500899 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_35\">\n",
       "     <g id=\"line2d_94\">\n",
       "      <path d=\"M 843.90162 817.42725 \n",
       "L 843.90162 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_94\">\n",
       "      <!-- 2.5 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(836.25662 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_36\">\n",
       "     <g id=\"line2d_95\">\n",
       "      <path d=\"M 900.65734 817.42725 \n",
       "L 900.65734 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_95\">\n",
       "      <!-- 5.0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(893.01234 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_37\">\n",
       "     <g id=\"line2d_96\">\n",
       "      <path d=\"M 957.41306 817.42725 \n",
       "L 957.41306 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_96\">\n",
       "      <!-- 7.5 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(949.76806 834.800844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-37\"/>\n",
       "       <use xlink:href=\"#ArialMT-2e\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-35\" transform=\"translate(83.398438 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_97\">\n",
       "     <!-- Valor de la derivada parcial -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(705.047969 849.576469) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(59.324219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(114.939453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(137.15625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(192.771484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(226.072266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(253.855469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(309.470703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(365.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(392.869141 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(415.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(470.701172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(498.484375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(554.099609 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(609.714844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(643.015625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(665.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(715.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(770.847656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(826.462891 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(882.078125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(909.861328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(965.476562 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(1021.091797 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(1054.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(1104.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(1126.609375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1182.224609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_12\">\n",
       "    <g id=\"ytick_35\">\n",
       "     <g id=\"line2d_97\">\n",
       "      <path d=\"M 560.859531 817.42725 \n",
       "L 993.759531 817.42725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_98\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(545.2425 821.364047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_36\">\n",
       "     <g id=\"line2d_98\">\n",
       "      <path d=\"M 560.859531 786.603233 \n",
       "L 993.759531 786.603233 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_99\">\n",
       "      <!-- 1000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 790.54003) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_37\">\n",
       "     <g id=\"line2d_99\">\n",
       "      <path d=\"M 560.859531 755.779217 \n",
       "L 993.759531 755.779217 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_100\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 759.716014) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_38\">\n",
       "     <g id=\"line2d_100\">\n",
       "      <path d=\"M 560.859531 724.9552 \n",
       "L 993.759531 724.9552 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_101\">\n",
       "      <!-- 3000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 728.891997) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_39\">\n",
       "     <g id=\"line2d_101\">\n",
       "      <path d=\"M 560.859531 694.131184 \n",
       "L 993.759531 694.131184 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_102\">\n",
       "      <!-- 4000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 698.067981) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_40\">\n",
       "     <g id=\"line2d_102\">\n",
       "      <path d=\"M 560.859531 663.307167 \n",
       "L 993.759531 663.307167 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_103\">\n",
       "      <!-- 5000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 667.243964) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-35\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_41\">\n",
       "     <g id=\"line2d_103\">\n",
       "      <path d=\"M 560.859531 632.483151 \n",
       "L 993.759531 632.483151 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_104\">\n",
       "      <!-- 6000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 636.419947) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_42\">\n",
       "     <g id=\"line2d_104\">\n",
       "      <path d=\"M 560.859531 601.659134 \n",
       "L 993.759531 601.659134 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_105\">\n",
       "      <!-- 7000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(526.891406 605.595931) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-37\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_106\">\n",
       "     <!-- Frecuencia -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(520.506406 735.445688) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-46\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(61.083984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(94.384766 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(150 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(255.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(311.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(366.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(439.0625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_533\">\n",
       "    <path d=\"M 580.536804 817.42725 \n",
       "L 584.472259 817.42725 \n",
       "L 584.472259 817.334778 \n",
       "L 580.536804 817.334778 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_534\">\n",
       "    <path d=\"M 584.472259 817.42725 \n",
       "L 588.407713 817.42725 \n",
       "L 588.407713 817.42725 \n",
       "L 584.472259 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_535\">\n",
       "    <path d=\"M 588.407713 817.42725 \n",
       "L 592.343168 817.42725 \n",
       "L 592.343168 817.42725 \n",
       "L 588.407713 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_536\">\n",
       "    <path d=\"M 592.343168 817.42725 \n",
       "L 596.278622 817.42725 \n",
       "L 596.278622 817.11901 \n",
       "L 592.343168 817.11901 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_537\">\n",
       "    <path d=\"M 596.278622 817.42725 \n",
       "L 600.214077 817.42725 \n",
       "L 600.214077 817.365602 \n",
       "L 596.278622 817.365602 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_538\">\n",
       "    <path d=\"M 600.214077 817.42725 \n",
       "L 604.149531 817.42725 \n",
       "L 604.149531 817.42725 \n",
       "L 600.214077 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_539\">\n",
       "    <path d=\"M 604.149531 817.42725 \n",
       "L 608.084986 817.42725 \n",
       "L 608.084986 817.42725 \n",
       "L 604.149531 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_540\">\n",
       "    <path d=\"M 608.084986 817.42725 \n",
       "L 612.02044 817.42725 \n",
       "L 612.02044 817.42725 \n",
       "L 608.084986 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_541\">\n",
       "    <path d=\"M 612.02044 817.42725 \n",
       "L 615.955895 817.42725 \n",
       "L 615.955895 817.42725 \n",
       "L 612.02044 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_542\">\n",
       "    <path d=\"M 615.955895 817.42725 \n",
       "L 619.891349 817.42725 \n",
       "L 619.891349 817.42725 \n",
       "L 615.955895 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_543\">\n",
       "    <path d=\"M 619.891349 817.42725 \n",
       "L 623.826804 817.42725 \n",
       "L 623.826804 817.42725 \n",
       "L 619.891349 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_544\">\n",
       "    <path d=\"M 623.826804 817.42725 \n",
       "L 627.762259 817.42725 \n",
       "L 627.762259 817.42725 \n",
       "L 623.826804 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_545\">\n",
       "    <path d=\"M 627.762259 817.42725 \n",
       "L 631.697713 817.42725 \n",
       "L 631.697713 817.42725 \n",
       "L 627.762259 817.42725 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_546\">\n",
       "    <path d=\"M 631.697713 817.42725 \n",
       "L 635.633168 817.42725 \n",
       "L 635.633168 816.841594 \n",
       "L 631.697713 816.841594 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_547\">\n",
       "    <path d=\"M 635.633168 817.42725 \n",
       "L 639.568622 817.42725 \n",
       "L 639.568622 816.533354 \n",
       "L 635.633168 816.533354 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_548\">\n",
       "    <path d=\"M 639.568622 817.42725 \n",
       "L 643.504077 817.42725 \n",
       "L 643.504077 817.396426 \n",
       "L 639.568622 817.396426 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_549\">\n",
       "    <path d=\"M 643.504077 817.42725 \n",
       "L 647.439531 817.42725 \n",
       "L 647.439531 815.238745 \n",
       "L 643.504077 815.238745 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_550\">\n",
       "    <path d=\"M 647.439531 817.42725 \n",
       "L 651.374986 817.42725 \n",
       "L 651.374986 815.608633 \n",
       "L 647.439531 815.608633 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_551\">\n",
       "    <path d=\"M 651.374986 817.42725 \n",
       "L 655.31044 817.42725 \n",
       "L 655.31044 817.149834 \n",
       "L 651.374986 817.149834 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_552\">\n",
       "    <path d=\"M 655.31044 817.42725 \n",
       "L 659.245895 817.42725 \n",
       "L 659.245895 816.841594 \n",
       "L 655.31044 816.841594 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_553\">\n",
       "    <path d=\"M 659.245895 817.42725 \n",
       "L 663.181349 817.42725 \n",
       "L 663.181349 816.903242 \n",
       "L 659.245895 816.903242 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_554\">\n",
       "    <path d=\"M 663.181349 817.42725 \n",
       "L 667.116804 817.42725 \n",
       "L 667.116804 816.533354 \n",
       "L 663.181349 816.533354 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_555\">\n",
       "    <path d=\"M 667.116804 817.42725 \n",
       "L 671.052259 817.42725 \n",
       "L 671.052259 817.180658 \n",
       "L 667.116804 817.180658 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_556\">\n",
       "    <path d=\"M 671.052259 817.42725 \n",
       "L 674.987713 817.42725 \n",
       "L 674.987713 816.96489 \n",
       "L 671.052259 816.96489 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_557\">\n",
       "    <path d=\"M 674.987713 817.42725 \n",
       "L 678.923168 817.42725 \n",
       "L 678.923168 816.286761 \n",
       "L 674.987713 816.286761 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_558\">\n",
       "    <path d=\"M 678.923168 817.42725 \n",
       "L 682.858622 817.42725 \n",
       "L 682.858622 816.625826 \n",
       "L 678.923168 816.625826 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_559\">\n",
       "    <path d=\"M 682.858622 817.42725 \n",
       "L 686.794077 817.42725 \n",
       "L 686.794077 816.194289 \n",
       "L 682.858622 816.194289 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_560\">\n",
       "    <path d=\"M 686.794077 817.42725 \n",
       "L 690.729531 817.42725 \n",
       "L 690.729531 816.687474 \n",
       "L 686.794077 816.687474 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_561\">\n",
       "    <path d=\"M 690.729531 817.42725 \n",
       "L 694.664986 817.42725 \n",
       "L 694.664986 815.392865 \n",
       "L 690.729531 815.392865 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_562\">\n",
       "    <path d=\"M 694.664986 817.42725 \n",
       "L 698.60044 817.42725 \n",
       "L 698.60044 814.314024 \n",
       "L 694.664986 814.314024 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_563\">\n",
       "    <path d=\"M 698.60044 817.42725 \n",
       "L 702.535895 817.42725 \n",
       "L 702.535895 815.177097 \n",
       "L 698.60044 815.177097 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_564\">\n",
       "    <path d=\"M 702.535895 817.42725 \n",
       "L 706.471349 817.42725 \n",
       "L 706.471349 811.940575 \n",
       "L 702.535895 811.940575 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_565\">\n",
       "    <path d=\"M 706.471349 817.42725 \n",
       "L 710.406804 817.42725 \n",
       "L 710.406804 809.474654 \n",
       "L 706.471349 809.474654 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_566\">\n",
       "    <path d=\"M 710.406804 817.42725 \n",
       "L 714.342259 817.42725 \n",
       "L 714.342259 808.950645 \n",
       "L 710.406804 808.950645 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_567\">\n",
       "    <path d=\"M 714.342259 817.42725 \n",
       "L 718.277713 817.42725 \n",
       "L 718.277713 811.724807 \n",
       "L 714.342259 811.724807 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_568\">\n",
       "    <path d=\"M 718.277713 817.42725 \n",
       "L 722.213168 817.42725 \n",
       "L 722.213168 809.166414 \n",
       "L 718.277713 809.166414 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_569\">\n",
       "    <path d=\"M 722.213168 817.42725 \n",
       "L 726.148622 817.42725 \n",
       "L 726.148622 807.686861 \n",
       "L 722.213168 807.686861 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_570\">\n",
       "    <path d=\"M 726.148622 817.42725 \n",
       "L 730.084077 817.42725 \n",
       "L 730.084077 806.731316 \n",
       "L 726.148622 806.731316 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_571\">\n",
       "    <path d=\"M 730.084077 817.42725 \n",
       "L 734.019531 817.42725 \n",
       "L 734.019531 798.963664 \n",
       "L 730.084077 798.963664 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_572\">\n",
       "    <path d=\"M 734.019531 817.42725 \n",
       "L 737.954986 817.42725 \n",
       "L 737.954986 791.689196 \n",
       "L 734.019531 791.689196 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_573\">\n",
       "    <path d=\"M 737.954986 817.42725 \n",
       "L 741.89044 817.42725 \n",
       "L 741.89044 796.713511 \n",
       "L 737.954986 796.713511 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_574\">\n",
       "    <path d=\"M 741.89044 817.42725 \n",
       "L 745.825895 817.42725 \n",
       "L 745.825895 796.497743 \n",
       "L 741.89044 796.497743 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_575\">\n",
       "    <path d=\"M 745.825895 817.42725 \n",
       "L 749.761349 817.42725 \n",
       "L 749.761349 767.153279 \n",
       "L 745.825895 767.153279 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_576\">\n",
       "    <path d=\"M 749.761349 817.42725 \n",
       "L 753.696804 817.42725 \n",
       "L 753.696804 776.862844 \n",
       "L 749.761349 776.862844 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_577\">\n",
       "    <path d=\"M 753.696804 817.42725 \n",
       "L 757.632259 817.42725 \n",
       "L 757.632259 753.683184 \n",
       "L 753.696804 753.683184 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_578\">\n",
       "    <path d=\"M 757.632259 817.42725 \n",
       "L 761.567713 817.42725 \n",
       "L 761.567713 731.55154 \n",
       "L 757.632259 731.55154 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_579\">\n",
       "    <path d=\"M 761.567713 817.42725 \n",
       "L 765.503168 817.42725 \n",
       "L 765.503168 731.428244 \n",
       "L 761.567713 731.428244 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_580\">\n",
       "    <path d=\"M 765.503168 817.42725 \n",
       "L 769.438622 817.42725 \n",
       "L 769.438622 616.917022 \n",
       "L 765.503168 616.917022 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_581\">\n",
       "    <path d=\"M 769.438622 817.42725 \n",
       "L 773.374077 817.42725 \n",
       "L 773.374077 650.453552 \n",
       "L 769.438622 650.453552 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_582\">\n",
       "    <path d=\"M 773.374077 817.42725 \n",
       "L 777.309531 817.42725 \n",
       "L 777.309531 614.173685 \n",
       "L 773.374077 614.173685 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_583\">\n",
       "    <path d=\"M 777.309531 817.42725 \n",
       "L 781.244986 817.42725 \n",
       "L 781.244986 664.848368 \n",
       "L 777.309531 664.848368 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_584\">\n",
       "    <path d=\"M 781.244986 817.42725 \n",
       "L 785.18044 817.42725 \n",
       "L 785.18044 604.741536 \n",
       "L 781.244986 604.741536 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_585\">\n",
       "    <path d=\"M 785.18044 817.42725 \n",
       "L 789.115895 817.42725 \n",
       "L 789.115895 686.88754 \n",
       "L 785.18044 686.88754 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_586\">\n",
       "    <path d=\"M 789.115895 817.42725 \n",
       "L 793.051349 817.42725 \n",
       "L 793.051349 722.520103 \n",
       "L 789.115895 722.520103 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_587\">\n",
       "    <path d=\"M 793.051349 817.42725 \n",
       "L 796.986804 817.42725 \n",
       "L 796.986804 704.857942 \n",
       "L 793.051349 704.857942 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_588\">\n",
       "    <path d=\"M 796.986804 817.42725 \n",
       "L 800.922259 817.42725 \n",
       "L 800.922259 736.360086 \n",
       "L 796.986804 736.360086 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_589\">\n",
       "    <path d=\"M 800.922259 817.42725 \n",
       "L 804.857713 817.42725 \n",
       "L 804.857713 738.887656 \n",
       "L 800.922259 738.887656 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_590\">\n",
       "    <path d=\"M 804.857713 817.42725 \n",
       "L 808.793168 817.42725 \n",
       "L 808.793168 770.358977 \n",
       "L 804.857713 770.358977 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_591\">\n",
       "    <path d=\"M 808.793168 817.42725 \n",
       "L 812.728622 817.42725 \n",
       "L 812.728622 779.236293 \n",
       "L 808.793168 779.236293 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_592\">\n",
       "    <path d=\"M 812.728622 817.42725 \n",
       "L 816.664077 817.42725 \n",
       "L 816.664077 787.03477 \n",
       "L 812.728622 787.03477 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_593\">\n",
       "    <path d=\"M 816.664077 817.42725 \n",
       "L 820.599531 817.42725 \n",
       "L 820.599531 770.174033 \n",
       "L 816.664077 770.174033 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_594\">\n",
       "    <path d=\"M 820.599531 817.42725 \n",
       "L 824.534986 817.42725 \n",
       "L 824.534986 781.856335 \n",
       "L 820.599531 781.856335 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_595\">\n",
       "    <path d=\"M 824.534986 817.42725 \n",
       "L 828.47044 817.42725 \n",
       "L 828.47044 706.61491 \n",
       "L 824.534986 706.61491 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_596\">\n",
       "    <path d=\"M 828.47044 817.42725 \n",
       "L 832.405895 817.42725 \n",
       "L 832.405895 655.693635 \n",
       "L 828.47044 655.693635 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_597\">\n",
       "    <path d=\"M 832.405895 817.42725 \n",
       "L 836.341349 817.42725 \n",
       "L 836.341349 770.019913 \n",
       "L 832.405895 770.019913 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_598\">\n",
       "    <path d=\"M 836.341349 817.42725 \n",
       "L 840.276804 817.42725 \n",
       "L 840.276804 796.898455 \n",
       "L 836.341349 796.898455 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_599\">\n",
       "    <path d=\"M 840.276804 817.42725 \n",
       "L 844.212259 817.42725 \n",
       "L 844.212259 801.76865 \n",
       "L 840.276804 801.76865 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_600\">\n",
       "    <path d=\"M 844.212259 817.42725 \n",
       "L 848.147713 817.42725 \n",
       "L 848.147713 809.536302 \n",
       "L 844.212259 809.536302 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_601\">\n",
       "    <path d=\"M 848.147713 817.42725 \n",
       "L 852.083168 817.42725 \n",
       "L 852.083168 812.988592 \n",
       "L 848.147713 812.988592 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_602\">\n",
       "    <path d=\"M 852.083168 817.42725 \n",
       "L 856.018622 817.42725 \n",
       "L 856.018622 814.776385 \n",
       "L 852.083168 814.776385 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_603\">\n",
       "    <path d=\"M 856.018622 817.42725 \n",
       "L 859.954077 817.42725 \n",
       "L 859.954077 796.744335 \n",
       "L 856.018622 796.744335 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_604\">\n",
       "    <path d=\"M 859.954077 817.42725 \n",
       "L 863.889531 817.42725 \n",
       "L 863.889531 814.714737 \n",
       "L 859.954077 814.714737 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_605\">\n",
       "    <path d=\"M 863.889531 817.42725 \n",
       "L 867.824986 817.42725 \n",
       "L 867.824986 814.12908 \n",
       "L 863.889531 814.12908 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_606\">\n",
       "    <path d=\"M 867.824986 817.42725 \n",
       "L 871.76044 817.42725 \n",
       "L 871.76044 811.354919 \n",
       "L 867.824986 811.354919 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_607\">\n",
       "    <path d=\"M 871.76044 817.42725 \n",
       "L 875.695895 817.42725 \n",
       "L 875.695895 812.341287 \n",
       "L 871.76044 812.341287 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_608\">\n",
       "    <path d=\"M 875.695895 817.42725 \n",
       "L 879.631349 817.42725 \n",
       "L 879.631349 811.539863 \n",
       "L 875.695895 811.539863 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_609\">\n",
       "    <path d=\"M 879.631349 817.42725 \n",
       "L 883.566804 817.42725 \n",
       "L 883.566804 810.707614 \n",
       "L 879.631349 810.707614 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_610\">\n",
       "    <path d=\"M 883.566804 817.42725 \n",
       "L 887.502259 817.42725 \n",
       "L 887.502259 806.330604 \n",
       "L 883.566804 806.330604 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_611\">\n",
       "    <path d=\"M 887.502259 817.42725 \n",
       "L 891.437713 817.42725 \n",
       "L 891.437713 801.92277 \n",
       "L 887.502259 801.92277 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_612\">\n",
       "    <path d=\"M 891.437713 817.42725 \n",
       "L 895.373168 817.42725 \n",
       "L 895.373168 770.050737 \n",
       "L 891.437713 770.050737 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_613\">\n",
       "    <path d=\"M 895.373168 817.42725 \n",
       "L 899.308622 817.42725 \n",
       "L 899.308622 694.655192 \n",
       "L 895.373168 694.655192 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_614\">\n",
       "    <path d=\"M 899.308622 817.42725 \n",
       "L 903.244077 817.42725 \n",
       "L 903.244077 796.590215 \n",
       "L 899.308622 796.590215 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_615\">\n",
       "    <path d=\"M 903.244077 817.42725 \n",
       "L 907.179531 817.42725 \n",
       "L 907.179531 762.930389 \n",
       "L 903.244077 762.930389 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_616\">\n",
       "    <path d=\"M 907.179531 817.42725 \n",
       "L 911.114986 817.42725 \n",
       "L 911.114986 741.045337 \n",
       "L 907.179531 741.045337 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_617\">\n",
       "    <path d=\"M 911.114986 817.42725 \n",
       "L 915.05044 817.42725 \n",
       "L 915.05044 769.804144 \n",
       "L 911.114986 769.804144 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_618\">\n",
       "    <path d=\"M 915.05044 817.42725 \n",
       "L 918.985895 817.42725 \n",
       "L 918.985895 793.415341 \n",
       "L 915.05044 793.415341 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_619\">\n",
       "    <path d=\"M 918.985895 817.42725 \n",
       "L 922.921349 817.42725 \n",
       "L 922.921349 799.765089 \n",
       "L 918.985895 799.765089 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_620\">\n",
       "    <path d=\"M 922.921349 817.42725 \n",
       "L 926.856804 817.42725 \n",
       "L 926.856804 798.902016 \n",
       "L 922.921349 798.902016 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_621\">\n",
       "    <path d=\"M 926.856804 817.42725 \n",
       "L 930.792259 817.42725 \n",
       "L 930.792259 800.905577 \n",
       "L 926.856804 800.905577 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_622\">\n",
       "    <path d=\"M 930.792259 817.42725 \n",
       "L 934.727713 817.42725 \n",
       "L 934.727713 789.839755 \n",
       "L 930.792259 789.839755 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_623\">\n",
       "    <path d=\"M 934.727713 817.42725 \n",
       "L 938.663168 817.42725 \n",
       "L 938.663168 807.563565 \n",
       "L 934.727713 807.563565 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_624\">\n",
       "    <path d=\"M 938.663168 817.42725 \n",
       "L 942.598622 817.42725 \n",
       "L 942.598622 806.977908 \n",
       "L 938.663168 806.977908 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_625\">\n",
       "    <path d=\"M 942.598622 817.42725 \n",
       "L 946.534077 817.42725 \n",
       "L 946.534077 803.279026 \n",
       "L 942.598622 803.279026 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_626\">\n",
       "    <path d=\"M 946.534077 817.42725 \n",
       "L 950.469531 817.42725 \n",
       "L 950.469531 813.173536 \n",
       "L 946.534077 813.173536 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_627\">\n",
       "    <path d=\"M 950.469531 817.42725 \n",
       "L 954.404986 817.42725 \n",
       "L 954.404986 811.231623 \n",
       "L 950.469531 811.231623 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_628\">\n",
       "    <path d=\"M 954.404986 817.42725 \n",
       "L 958.34044 817.42725 \n",
       "L 958.34044 800.566513 \n",
       "L 954.404986 800.566513 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_629\">\n",
       "    <path d=\"M 958.34044 817.42725 \n",
       "L 962.275895 817.42725 \n",
       "L 962.275895 804.943523 \n",
       "L 958.34044 804.943523 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_630\">\n",
       "    <path d=\"M 962.275895 817.42725 \n",
       "L 966.211349 817.42725 \n",
       "L 966.211349 817.365602 \n",
       "L 962.275895 817.365602 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_631\">\n",
       "    <path d=\"M 966.211349 817.42725 \n",
       "L 970.146804 817.42725 \n",
       "L 970.146804 817.088186 \n",
       "L 966.211349 817.088186 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_632\">\n",
       "    <path d=\"M 970.146804 817.42725 \n",
       "L 974.082259 817.42725 \n",
       "L 974.082259 815.916873 \n",
       "L 970.146804 815.916873 \n",
       "z\n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_105\">\n",
       "    <path d=\"M 580.536804 817.397574 \n",
       "L 629.977188 817.209573 \n",
       "L 635.910034 816.862786 \n",
       "L 643.820495 816.243177 \n",
       "L 647.775726 816.216842 \n",
       "L 661.619033 816.802485 \n",
       "L 671.50711 816.834468 \n",
       "L 679.417571 816.490219 \n",
       "L 689.305648 815.954932 \n",
       "L 693.260879 815.434092 \n",
       "L 697.21611 814.518951 \n",
       "L 701.17134 813.184782 \n",
       "L 705.126571 811.743508 \n",
       "L 707.104186 811.157067 \n",
       "L 709.081802 810.730358 \n",
       "L 713.037032 810.286495 \n",
       "L 716.992263 809.821517 \n",
       "L 718.969878 809.336577 \n",
       "L 720.947494 808.602671 \n",
       "L 722.925109 807.589262 \n",
       "L 724.902724 806.27467 \n",
       "L 726.88034 804.656502 \n",
       "L 730.835571 800.776256 \n",
       "L 734.790801 796.91647 \n",
       "L 738.746032 793.216804 \n",
       "L 740.723647 790.916839 \n",
       "L 742.701263 787.989428 \n",
       "L 744.678878 784.323538 \n",
       "L 746.656493 779.929581 \n",
       "L 748.634109 774.860688 \n",
       "L 750.611724 769.114203 \n",
       "L 752.589339 762.561755 \n",
       "L 754.566955 754.921857 \n",
       "L 756.54457 745.782391 \n",
       "L 758.522185 734.70999 \n",
       "L 760.499801 721.480271 \n",
       "L 762.477416 706.365952 \n",
       "L 766.432647 674.690138 \n",
       "L 768.410262 661.030633 \n",
       "L 770.387878 650.360073 \n",
       "L 772.365493 643.067318 \n",
       "L 774.343108 639.013115 \n",
       "L 776.320724 637.86088 \n",
       "L 778.298339 639.371308 \n",
       "L 780.275954 643.489929 \n",
       "L 782.25357 650.196993 \n",
       "L 784.231185 659.239295 \n",
       "L 786.2088 669.961117 \n",
       "L 790.164031 692.625886 \n",
       "L 792.141646 703.048379 \n",
       "L 794.119262 712.543513 \n",
       "L 798.074492 729.585969 \n",
       "L 802.029723 745.368325 \n",
       "L 804.007338 752.84358 \n",
       "L 805.984954 759.803195 \n",
       "L 807.962569 765.905734 \n",
       "L 809.940185 770.725053 \n",
       "L 811.9178 773.823379 \n",
       "L 813.895415 774.811208 \n",
       "L 815.873031 773.369259 \n",
       "L 817.850646 769.270223 \n",
       "L 819.828261 762.488452 \n",
       "L 821.805877 753.450135 \n",
       "L 823.783492 743.329279 \n",
       "L 825.761107 734.129444 \n",
       "L 827.738723 728.293681 \n",
       "L 829.716338 727.857221 \n",
       "L 831.693953 733.543883 \n",
       "L 833.671569 744.368016 \n",
       "L 837.626799 771.912925 \n",
       "L 839.604415 783.990986 \n",
       "L 841.58203 793.337719 \n",
       "L 843.559645 799.963743 \n",
       "L 845.537261 804.3666 \n",
       "L 847.514876 807.111609 \n",
       "L 849.492492 808.641593 \n",
       "L 851.470107 809.295073 \n",
       "L 853.447722 809.396697 \n",
       "L 857.402953 809.295183 \n",
       "L 859.380568 809.576427 \n",
       "L 863.335799 810.780304 \n",
       "L 865.313414 811.362158 \n",
       "L 867.29103 811.749834 \n",
       "L 869.268645 811.916911 \n",
       "L 871.24626 811.890405 \n",
       "L 873.223876 811.691571 \n",
       "L 875.201491 811.293613 \n",
       "L 877.179106 810.602358 \n",
       "L 879.156722 809.44743 \n",
       "L 881.134337 807.577241 \n",
       "L 883.111952 804.670445 \n",
       "L 885.089568 800.393361 \n",
       "L 887.067183 794.5305 \n",
       "L 889.044798 787.177155 \n",
       "L 893.000029 770.79345 \n",
       "L 894.977645 764.10139 \n",
       "L 896.95526 759.816871 \n",
       "L 898.932875 758.160615 \n",
       "L 900.910491 758.488797 \n",
       "L 904.865721 760.893797 \n",
       "L 906.843337 761.938863 \n",
       "L 908.820952 763.42123 \n",
       "L 910.798567 766.177256 \n",
       "L 912.776183 770.657524 \n",
       "L 914.753798 776.573209 \n",
       "L 916.731413 783.007337 \n",
       "L 918.709029 788.862826 \n",
       "L 920.686644 793.339921 \n",
       "L 922.664259 796.183168 \n",
       "L 924.641875 797.631929 \n",
       "L 926.61949 798.188842 \n",
       "L 930.574721 798.593713 \n",
       "L 932.552336 799.068995 \n",
       "L 934.529952 799.885074 \n",
       "L 936.507567 801.013816 \n",
       "L 944.418028 806.381416 \n",
       "L 946.395644 807.314916 \n",
       "L 948.373259 807.90109 \n",
       "L 950.350874 808.149031 \n",
       "L 954.306105 808.174331 \n",
       "L 956.28372 808.374 \n",
       "L 958.261336 808.927249 \n",
       "L 960.238951 809.86704 \n",
       "L 964.194182 812.458281 \n",
       "L 966.171797 813.754964 \n",
       "L 968.149412 814.855976 \n",
       "L 970.127028 815.702782 \n",
       "L 972.104643 816.306332 \n",
       "L 974.082259 816.716342 \n",
       "L 974.082259 816.716342 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_106\">\n",
       "    <path d=\"M 809.612311 817.42725 \n",
       "L 809.612311 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_107\">\n",
       "    <path d=\"M 789.296166 817.42725 \n",
       "L 789.296166 594.10725 \n",
       "\" clip-path=\"url(#p0a9d3d5456)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_633\">\n",
       "    <path d=\"M 560.859531 817.42725 \n",
       "L 560.859531 594.10725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_634\">\n",
       "    <path d=\"M 993.759531 817.42725 \n",
       "L 993.759531 594.10725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_635\">\n",
       "    <path d=\"M 560.859531 817.42725 \n",
       "L 993.759531 817.42725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_636\">\n",
       "    <path d=\"M 560.859531 594.10725 \n",
       "L 993.759531 594.10725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_107\">\n",
       "    <!-- Distribución de ∂Precio/∂volume -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(674.955906 588.10725) scale(0.144 -0.144)\">\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(94.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(144.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(172.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(205.517578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-62\" transform=\"translate(227.734375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(283.349609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(338.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(388.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-f3\" transform=\"translate(411.181641 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(466.796875 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(522.412109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(550.195312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(605.810547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(661.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(689.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-50\" transform=\"translate(738.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(805.322266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(838.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(894.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(944.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(966.455078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2f\" transform=\"translate(1022.070312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(1049.853516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-76\" transform=\"translate(1099.267578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(1149.267578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1204.882812 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(1227.099609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6d\" transform=\"translate(1282.714844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(1366.015625 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_6\">\n",
       "    <g id=\"patch_637\">\n",
       "     <path d=\"M 881.14875 634.026938 \n",
       "L 986.059531 634.026938 \n",
       "Q 988.259531 634.026938 988.259531 631.826938 \n",
       "L 988.259531 601.80725 \n",
       "Q 988.259531 599.60725 986.059531 599.60725 \n",
       "L 881.14875 599.60725 \n",
       "Q 878.94875 599.60725 878.94875 601.80725 \n",
       "L 878.94875 631.826938 \n",
       "Q 878.94875 634.026938 881.14875 634.026938 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_108\">\n",
       "     <path d=\"M 883.34875 608.030844 \n",
       "L 894.34875 608.030844 \n",
       "L 905.34875 608.030844 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_108\">\n",
       "     <!-- Media: 0.99 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(914.14875 611.880844) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(300.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(327.929688 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(383.544922 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-39\" transform=\"translate(411.328125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-39\" transform=\"translate(466.943359 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_109\">\n",
       "     <path d=\"M 883.34875 623.590688 \n",
       "L 894.34875 623.590688 \n",
       "L 905.34875 623.590688 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_109\">\n",
       "     <!-- Mediana: 0.09 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(914.14875 627.440688) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(494.775391 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-30\" transform=\"translate(522.558594 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-39\" transform=\"translate(578.173828 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       "  <g id=\"axes_7\">\n",
       "   <g id=\"patch_638\">\n",
       "    <path d=\"M 62.259531 1102.72725 \n",
       "L 495.159531 1102.72725 \n",
       "L 495.159531 879.40725 \n",
       "L 62.259531 879.40725 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5\"/>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_13\">\n",
       "    <g id=\"xtick_38\">\n",
       "     <g id=\"line2d_110\">\n",
       "      <path d=\"M 67.099305 1102.72725 \n",
       "L 67.099305 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_110\">\n",
       "      <!-- −300 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(54.711414 1120.100844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-33\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_39\">\n",
       "     <g id=\"line2d_111\">\n",
       "      <path d=\"M 128.675006 1102.72725 \n",
       "L 128.675006 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_111\">\n",
       "      <!-- −200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(116.287115 1120.100844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-32\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_40\">\n",
       "     <g id=\"line2d_112\">\n",
       "      <path d=\"M 190.250707 1102.72725 \n",
       "L 190.250707 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_112\">\n",
       "      <!-- −100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(177.862816 1120.100844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-2212\"/>\n",
       "       <use xlink:href=\"#ArialMT-31\" transform=\"translate(58.398438 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(114.013672 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(169.628906 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_41\">\n",
       "     <g id=\"line2d_113\">\n",
       "      <path d=\"M 251.826407 1102.72725 \n",
       "L 251.826407 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_113\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(248.767892 1120.100844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_42\">\n",
       "     <g id=\"line2d_114\">\n",
       "      <path d=\"M 313.402108 1102.72725 \n",
       "L 313.402108 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_114\">\n",
       "      <!-- 100 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(304.226561 1120.100844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_43\">\n",
       "     <g id=\"line2d_115\">\n",
       "      <path d=\"M 374.977809 1102.72725 \n",
       "L 374.977809 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_115\">\n",
       "      <!-- 200 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(365.802262 1120.100844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"xtick_44\">\n",
       "     <g id=\"line2d_116\">\n",
       "      <path d=\"M 436.55351 1102.72725 \n",
       "L 436.55351 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_116\">\n",
       "      <!-- 300 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(427.377963 1120.100844) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-33\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_117\">\n",
       "     <!-- Valor de la derivada parcial -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(206.447969 1134.876469) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-56\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(59.324219 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(114.939453 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6f\" transform=\"translate(137.15625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(192.771484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(226.072266 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(253.855469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(309.470703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(365.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(392.869141 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(415.085938 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(470.701172 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(498.484375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(554.099609 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(609.714844 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(643.015625 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-76\" transform=\"translate(665.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(715.232422 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(770.847656 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(826.462891 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(882.078125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-70\" transform=\"translate(909.861328 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(965.476562 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(1021.091797 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(1054.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(1104.392578 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(1126.609375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6c\" transform=\"translate(1182.224609 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"matplotlib.axis_14\">\n",
       "    <g id=\"ytick_43\">\n",
       "     <g id=\"line2d_117\">\n",
       "      <path d=\"M 62.259531 1102.72725 \n",
       "L 495.159531 1102.72725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_118\">\n",
       "      <!-- 0 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(46.6425 1106.664047) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-30\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_44\">\n",
       "     <g id=\"line2d_118\">\n",
       "      <path d=\"M 62.259531 1064.659286 \n",
       "L 495.159531 1064.659286 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_119\">\n",
       "      <!-- 2000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 1068.596083) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-32\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_45\">\n",
       "     <g id=\"line2d_119\">\n",
       "      <path d=\"M 62.259531 1026.591322 \n",
       "L 495.159531 1026.591322 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_120\">\n",
       "      <!-- 4000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 1030.528119) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-34\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_46\">\n",
       "     <g id=\"line2d_120\">\n",
       "      <path d=\"M 62.259531 988.523358 \n",
       "L 495.159531 988.523358 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_121\">\n",
       "      <!-- 6000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 992.460155) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-36\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_47\">\n",
       "     <g id=\"line2d_121\">\n",
       "      <path d=\"M 62.259531 950.455394 \n",
       "L 495.159531 950.455394 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_122\">\n",
       "      <!-- 8000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(28.291406 954.392191) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-38\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"ytick_48\">\n",
       "     <g id=\"line2d_122\">\n",
       "      <path d=\"M 62.259531 912.387431 \n",
       "L 495.159531 912.387431 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #ffffff; stroke-linecap: round\"/>\n",
       "     </g>\n",
       "     <g id=\"text_123\">\n",
       "      <!-- 10000 -->\n",
       "      <g style=\"fill: #555555\" transform=\"translate(22.174375 916.324227) scale(0.11 -0.11)\">\n",
       "       <use xlink:href=\"#ArialMT-31\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(55.615234 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(111.230469 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(166.845703 0)\"/>\n",
       "       <use xlink:href=\"#ArialMT-30\" transform=\"translate(222.460938 0)\"/>\n",
       "      </g>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"text_124\">\n",
       "     <!-- Frecuencia -->\n",
       "     <g style=\"fill: #555555\" transform=\"translate(15.789375 1020.745688) rotate(-90) scale(0.12 -0.12)\">\n",
       "      <use xlink:href=\"#ArialMT-46\"/>\n",
       "      <use xlink:href=\"#ArialMT-72\" transform=\"translate(61.083984 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(94.384766 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(150 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-75\" transform=\"translate(200 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(255.615234 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(311.230469 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-63\" transform=\"translate(366.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(416.845703 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(439.0625 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"patch_639\">\n",
       "    <path d=\"M 81.936804 1102.72725 \n",
       "L 85.872259 1102.72725 \n",
       "L 85.872259 1102.232366 \n",
       "L 81.936804 1102.232366 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_640\">\n",
       "    <path d=\"M 85.872259 1102.72725 \n",
       "L 89.807713 1102.72725 \n",
       "L 89.807713 1095.303997 \n",
       "L 85.872259 1095.303997 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_641\">\n",
       "    <path d=\"M 89.807713 1102.72725 \n",
       "L 93.743168 1102.72725 \n",
       "L 93.743168 1091.516235 \n",
       "L 89.807713 1091.516235 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_642\">\n",
       "    <path d=\"M 93.743168 1102.72725 \n",
       "L 97.678622 1102.72725 \n",
       "L 97.678622 1097.017055 \n",
       "L 93.743168 1097.017055 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_643\">\n",
       "    <path d=\"M 97.678622 1102.72725 \n",
       "L 101.614077 1102.72725 \n",
       "L 101.614077 1090.240958 \n",
       "L 97.678622 1090.240958 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_644\">\n",
       "    <path d=\"M 101.614077 1102.72725 \n",
       "L 105.549531 1102.72725 \n",
       "L 105.549531 1099.948289 \n",
       "L 101.614077 1099.948289 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_645\">\n",
       "    <path d=\"M 105.549531 1102.72725 \n",
       "L 109.484986 1102.72725 \n",
       "L 109.484986 1102.460774 \n",
       "L 105.549531 1102.460774 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_646\">\n",
       "    <path d=\"M 109.484986 1102.72725 \n",
       "L 113.42044 1102.72725 \n",
       "L 113.42044 1102.194299 \n",
       "L 109.484986 1102.194299 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_647\">\n",
       "    <path d=\"M 113.42044 1102.72725 \n",
       "L 117.355895 1102.72725 \n",
       "L 117.355895 1102.080095 \n",
       "L 113.42044 1102.080095 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_648\">\n",
       "    <path d=\"M 117.355895 1102.72725 \n",
       "L 121.291349 1102.72725 \n",
       "L 121.291349 1101.946857 \n",
       "L 117.355895 1101.946857 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_649\">\n",
       "    <path d=\"M 121.291349 1102.72725 \n",
       "L 125.226804 1102.72725 \n",
       "L 125.226804 1100.519308 \n",
       "L 121.291349 1100.519308 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_650\">\n",
       "    <path d=\"M 125.226804 1102.72725 \n",
       "L 129.162259 1102.72725 \n",
       "L 129.162259 1102.194299 \n",
       "L 125.226804 1102.194299 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_651\">\n",
       "    <path d=\"M 129.162259 1102.72725 \n",
       "L 133.097713 1102.72725 \n",
       "L 133.097713 1099.910221 \n",
       "L 129.162259 1099.910221 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_652\">\n",
       "    <path d=\"M 133.097713 1102.72725 \n",
       "L 137.033168 1102.72725 \n",
       "L 137.033168 1101.299701 \n",
       "L 133.097713 1101.299701 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_653\">\n",
       "    <path d=\"M 137.033168 1102.72725 \n",
       "L 140.968622 1102.72725 \n",
       "L 140.968622 1101.128396 \n",
       "L 137.033168 1101.128396 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_654\">\n",
       "    <path d=\"M 140.968622 1102.72725 \n",
       "L 144.904077 1102.72725 \n",
       "L 144.904077 1099.072725 \n",
       "L 140.968622 1099.072725 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_655\">\n",
       "    <path d=\"M 144.904077 1102.72725 \n",
       "L 148.839531 1102.72725 \n",
       "L 148.839531 1096.84575 \n",
       "L 144.904077 1096.84575 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_656\">\n",
       "    <path d=\"M 148.839531 1102.72725 \n",
       "L 152.774986 1102.72725 \n",
       "L 152.774986 1098.387502 \n",
       "L 148.839531 1098.387502 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_657\">\n",
       "    <path d=\"M 152.774986 1102.72725 \n",
       "L 156.71044 1102.72725 \n",
       "L 156.71044 1098.673012 \n",
       "L 152.774986 1098.673012 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_658\">\n",
       "    <path d=\"M 156.71044 1102.72725 \n",
       "L 160.645895 1102.72725 \n",
       "L 160.645895 1097.664211 \n",
       "L 156.71044 1097.664211 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_659\">\n",
       "    <path d=\"M 160.645895 1102.72725 \n",
       "L 164.581349 1102.72725 \n",
       "L 164.581349 1099.358235 \n",
       "L 160.645895 1099.358235 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_660\">\n",
       "    <path d=\"M 164.581349 1102.72725 \n",
       "L 168.516804 1102.72725 \n",
       "L 168.516804 1099.186929 \n",
       "L 164.581349 1099.186929 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_661\">\n",
       "    <path d=\"M 168.516804 1102.72725 \n",
       "L 172.452259 1102.72725 \n",
       "L 172.452259 1098.292332 \n",
       "L 168.516804 1098.292332 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_662\">\n",
       "    <path d=\"M 172.452259 1102.72725 \n",
       "L 176.387713 1102.72725 \n",
       "L 176.387713 1097.492905 \n",
       "L 172.452259 1097.492905 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_663\">\n",
       "    <path d=\"M 176.387713 1102.72725 \n",
       "L 180.323168 1102.72725 \n",
       "L 180.323168 1096.122458 \n",
       "L 176.387713 1096.122458 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_664\">\n",
       "    <path d=\"M 180.323168 1102.72725 \n",
       "L 184.258622 1102.72725 \n",
       "L 184.258622 1094.390366 \n",
       "L 180.323168 1094.390366 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_665\">\n",
       "    <path d=\"M 184.258622 1102.72725 \n",
       "L 188.194077 1102.72725 \n",
       "L 188.194077 1093.172191 \n",
       "L 184.258622 1093.172191 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_666\">\n",
       "    <path d=\"M 188.194077 1102.72725 \n",
       "L 192.129531 1102.72725 \n",
       "L 192.129531 1080.457491 \n",
       "L 188.194077 1080.457491 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_667\">\n",
       "    <path d=\"M 192.129531 1102.72725 \n",
       "L 196.064986 1102.72725 \n",
       "L 196.064986 1084.188152 \n",
       "L 192.129531 1084.188152 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_668\">\n",
       "    <path d=\"M 196.064986 1102.72725 \n",
       "L 200.00044 1102.72725 \n",
       "L 200.00044 1081.846972 \n",
       "L 196.064986 1081.846972 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_669\">\n",
       "    <path d=\"M 200.00044 1102.72725 \n",
       "L 203.935895 1102.72725 \n",
       "L 203.935895 1080.305219 \n",
       "L 200.00044 1080.305219 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_670\">\n",
       "    <path d=\"M 203.935895 1102.72725 \n",
       "L 207.871349 1102.72725 \n",
       "L 207.871349 1078.021141 \n",
       "L 203.935895 1078.021141 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_671\">\n",
       "    <path d=\"M 207.871349 1102.72725 \n",
       "L 211.806804 1102.72725 \n",
       "L 211.806804 1078.344719 \n",
       "L 207.871349 1078.344719 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_672\">\n",
       "    <path d=\"M 211.806804 1102.72725 \n",
       "L 215.742259 1102.72725 \n",
       "L 215.742259 1074.328549 \n",
       "L 211.806804 1074.328549 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_673\">\n",
       "    <path d=\"M 215.742259 1102.72725 \n",
       "L 219.677713 1102.72725 \n",
       "L 219.677713 1062.889126 \n",
       "L 215.742259 1062.889126 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_674\">\n",
       "    <path d=\"M 219.677713 1102.72725 \n",
       "L 223.613168 1102.72725 \n",
       "L 223.613168 1052.230096 \n",
       "L 219.677713 1052.230096 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_675\">\n",
       "    <path d=\"M 223.613168 1102.72725 \n",
       "L 227.548622 1102.72725 \n",
       "L 227.548622 1054.323834 \n",
       "L 223.613168 1054.323834 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_676\">\n",
       "    <path d=\"M 227.548622 1102.72725 \n",
       "L 231.484077 1102.72725 \n",
       "L 231.484077 1051.811348 \n",
       "L 227.548622 1051.811348 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_677\">\n",
       "    <path d=\"M 231.484077 1102.72725 \n",
       "L 235.419531 1102.72725 \n",
       "L 235.419531 1060.129198 \n",
       "L 231.484077 1060.129198 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_678\">\n",
       "    <path d=\"M 235.419531 1102.72725 \n",
       "L 239.354986 1102.72725 \n",
       "L 239.354986 1040.314823 \n",
       "L 235.419531 1040.314823 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_679\">\n",
       "    <path d=\"M 239.354986 1102.72725 \n",
       "L 243.29044 1102.72725 \n",
       "L 243.29044 1002.475267 \n",
       "L 239.354986 1002.475267 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_680\">\n",
       "    <path d=\"M 243.29044 1102.72725 \n",
       "L 247.225895 1102.72725 \n",
       "L 247.225895 1024.897298 \n",
       "L 243.29044 1024.897298 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_681\">\n",
       "    <path d=\"M 247.225895 1102.72725 \n",
       "L 251.161349 1102.72725 \n",
       "L 251.161349 994.861674 \n",
       "L 247.225895 994.861674 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_682\">\n",
       "    <path d=\"M 251.161349 1102.72725 \n",
       "L 255.096804 1102.72725 \n",
       "L 255.096804 994.328723 \n",
       "L 251.161349 994.328723 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_683\">\n",
       "    <path d=\"M 255.096804 1102.72725 \n",
       "L 259.032259 1102.72725 \n",
       "L 259.032259 1075.71803 \n",
       "L 255.096804 1075.71803 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_684\">\n",
       "    <path d=\"M 259.032259 1102.72725 \n",
       "L 262.967713 1102.72725 \n",
       "L 262.967713 1098.006822 \n",
       "L 259.032259 1098.006822 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_685\">\n",
       "    <path d=\"M 262.967713 1102.72725 \n",
       "L 266.903168 1102.72725 \n",
       "L 266.903168 1102.061061 \n",
       "L 262.967713 1102.061061 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_686\">\n",
       "    <path d=\"M 266.903168 1102.72725 \n",
       "L 270.838622 1102.72725 \n",
       "L 270.838622 1102.72725 \n",
       "L 266.903168 1102.72725 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_687\">\n",
       "    <path d=\"M 270.838622 1102.72725 \n",
       "L 274.774077 1102.72725 \n",
       "L 274.774077 1102.613046 \n",
       "L 270.838622 1102.613046 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_688\">\n",
       "    <path d=\"M 274.774077 1102.72725 \n",
       "L 278.709531 1102.72725 \n",
       "L 278.709531 1102.708216 \n",
       "L 274.774077 1102.708216 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_689\">\n",
       "    <path d=\"M 278.709531 1102.72725 \n",
       "L 282.644986 1102.72725 \n",
       "L 282.644986 1102.708216 \n",
       "L 278.709531 1102.708216 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_690\">\n",
       "    <path d=\"M 282.644986 1102.72725 \n",
       "L 286.58044 1102.72725 \n",
       "L 286.58044 1102.555944 \n",
       "L 282.644986 1102.555944 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_691\">\n",
       "    <path d=\"M 286.58044 1102.72725 \n",
       "L 290.515895 1102.72725 \n",
       "L 290.515895 1102.689182 \n",
       "L 286.58044 1102.689182 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_692\">\n",
       "    <path d=\"M 290.515895 1102.72725 \n",
       "L 294.451349 1102.72725 \n",
       "L 294.451349 1102.080095 \n",
       "L 290.515895 1102.080095 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_693\">\n",
       "    <path d=\"M 294.451349 1102.72725 \n",
       "L 298.386804 1102.72725 \n",
       "L 298.386804 1102.422706 \n",
       "L 294.451349 1102.422706 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_694\">\n",
       "    <path d=\"M 298.386804 1102.72725 \n",
       "L 302.322259 1102.72725 \n",
       "L 302.322259 1101.166463 \n",
       "L 298.386804 1101.166463 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_695\">\n",
       "    <path d=\"M 302.322259 1102.72725 \n",
       "L 306.257713 1102.72725 \n",
       "L 306.257713 1094.732978 \n",
       "L 302.322259 1094.732978 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_696\">\n",
       "    <path d=\"M 306.257713 1102.72725 \n",
       "L 310.193168 1102.72725 \n",
       "L 310.193168 1098.406536 \n",
       "L 306.257713 1098.406536 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_697\">\n",
       "    <path d=\"M 310.193168 1102.72725 \n",
       "L 314.128622 1102.72725 \n",
       "L 314.128622 1088.946647 \n",
       "L 310.193168 1088.946647 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_698\">\n",
       "    <path d=\"M 314.128622 1102.72725 \n",
       "L 318.064077 1102.72725 \n",
       "L 318.064077 1076.384219 \n",
       "L 314.128622 1076.384219 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_699\">\n",
       "    <path d=\"M 318.064077 1102.72725 \n",
       "L 321.999531 1102.72725 \n",
       "L 321.999531 1065.744223 \n",
       "L 318.064077 1065.744223 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_700\">\n",
       "    <path d=\"M 321.999531 1102.72725 \n",
       "L 325.934986 1102.72725 \n",
       "L 325.934986 961.723512 \n",
       "L 321.999531 961.723512 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_701\">\n",
       "    <path d=\"M 325.934986 1102.72725 \n",
       "L 329.87044 1102.72725 \n",
       "L 329.87044 890.041536 \n",
       "L 325.934986 890.041536 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_702\">\n",
       "    <path d=\"M 329.87044 1102.72725 \n",
       "L 333.805895 1102.72725 \n",
       "L 333.805895 974.933095 \n",
       "L 329.87044 974.933095 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_703\">\n",
       "    <path d=\"M 333.805895 1102.72725 \n",
       "L 337.741349 1102.72725 \n",
       "L 337.741349 1031.21658 \n",
       "L 333.805895 1031.21658 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_704\">\n",
       "    <path d=\"M 337.741349 1102.72725 \n",
       "L 341.676804 1102.72725 \n",
       "L 341.676804 1019.758123 \n",
       "L 337.741349 1019.758123 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_705\">\n",
       "    <path d=\"M 341.676804 1102.72725 \n",
       "L 345.612259 1102.72725 \n",
       "L 345.612259 1049.413067 \n",
       "L 341.676804 1049.413067 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_706\">\n",
       "    <path d=\"M 345.612259 1102.72725 \n",
       "L 349.547713 1102.72725 \n",
       "L 349.547713 1074.328549 \n",
       "L 345.612259 1074.328549 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_707\">\n",
       "    <path d=\"M 349.547713 1102.72725 \n",
       "L 353.483168 1102.72725 \n",
       "L 353.483168 1091.554303 \n",
       "L 349.547713 1091.554303 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_708\">\n",
       "    <path d=\"M 353.483168 1102.72725 \n",
       "L 357.418622 1102.72725 \n",
       "L 357.418622 1072.596457 \n",
       "L 353.483168 1072.596457 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_709\">\n",
       "    <path d=\"M 357.418622 1102.72725 \n",
       "L 361.354077 1102.72725 \n",
       "L 361.354077 1070.122039 \n",
       "L 357.418622 1070.122039 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_710\">\n",
       "    <path d=\"M 361.354077 1102.72725 \n",
       "L 365.289531 1102.72725 \n",
       "L 365.289531 1093.134123 \n",
       "L 361.354077 1093.134123 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_711\">\n",
       "    <path d=\"M 365.289531 1102.72725 \n",
       "L 369.224986 1102.72725 \n",
       "L 369.224986 1097.226429 \n",
       "L 365.289531 1097.226429 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_712\">\n",
       "    <path d=\"M 369.224986 1102.72725 \n",
       "L 373.16044 1102.72725 \n",
       "L 373.16044 1097.397735 \n",
       "L 369.224986 1097.397735 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_713\">\n",
       "    <path d=\"M 373.16044 1102.72725 \n",
       "L 377.095895 1102.72725 \n",
       "L 377.095895 1100.747716 \n",
       "L 373.16044 1100.747716 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_714\">\n",
       "    <path d=\"M 377.095895 1102.72725 \n",
       "L 381.031349 1102.72725 \n",
       "L 381.031349 1100.157662 \n",
       "L 377.095895 1100.157662 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_715\">\n",
       "    <path d=\"M 381.031349 1102.72725 \n",
       "L 384.966804 1102.72725 \n",
       "L 384.966804 1102.403672 \n",
       "L 381.031349 1102.403672 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_716\">\n",
       "    <path d=\"M 384.966804 1102.72725 \n",
       "L 388.902259 1102.72725 \n",
       "L 388.902259 1101.318735 \n",
       "L 384.966804 1101.318735 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_717\">\n",
       "    <path d=\"M 388.902259 1102.72725 \n",
       "L 392.837713 1102.72725 \n",
       "L 392.837713 1095.418201 \n",
       "L 388.902259 1095.418201 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_718\">\n",
       "    <path d=\"M 392.837713 1102.72725 \n",
       "L 396.773168 1102.72725 \n",
       "L 396.773168 1101.566177 \n",
       "L 392.837713 1101.566177 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_719\">\n",
       "    <path d=\"M 396.773168 1102.72725 \n",
       "L 400.708622 1102.72725 \n",
       "L 400.708622 1101.223565 \n",
       "L 396.773168 1101.223565 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_720\">\n",
       "    <path d=\"M 400.708622 1102.72725 \n",
       "L 404.644077 1102.72725 \n",
       "L 404.644077 1102.022993 \n",
       "L 400.708622 1102.022993 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_721\">\n",
       "    <path d=\"M 404.644077 1102.72725 \n",
       "L 408.579531 1102.72725 \n",
       "L 408.579531 1102.194299 \n",
       "L 404.644077 1102.194299 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_722\">\n",
       "    <path d=\"M 408.579531 1102.72725 \n",
       "L 412.514986 1102.72725 \n",
       "L 412.514986 1102.34657 \n",
       "L 408.579531 1102.34657 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_723\">\n",
       "    <path d=\"M 412.514986 1102.72725 \n",
       "L 416.45044 1102.72725 \n",
       "L 416.45044 1102.708216 \n",
       "L 412.514986 1102.708216 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_724\">\n",
       "    <path d=\"M 416.45044 1102.72725 \n",
       "L 420.385895 1102.72725 \n",
       "L 420.385895 1102.689182 \n",
       "L 416.45044 1102.689182 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_725\">\n",
       "    <path d=\"M 420.385895 1102.72725 \n",
       "L 424.321349 1102.72725 \n",
       "L 424.321349 1102.460774 \n",
       "L 420.385895 1102.460774 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_726\">\n",
       "    <path d=\"M 424.321349 1102.72725 \n",
       "L 428.256804 1102.72725 \n",
       "L 428.256804 1102.670148 \n",
       "L 424.321349 1102.670148 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_727\">\n",
       "    <path d=\"M 428.256804 1102.72725 \n",
       "L 432.192259 1102.72725 \n",
       "L 432.192259 1102.517876 \n",
       "L 428.256804 1102.517876 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_728\">\n",
       "    <path d=\"M 432.192259 1102.72725 \n",
       "L 436.127713 1102.72725 \n",
       "L 436.127713 1102.080095 \n",
       "L 432.192259 1102.080095 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_729\">\n",
       "    <path d=\"M 436.127713 1102.72725 \n",
       "L 440.063168 1102.72725 \n",
       "L 440.063168 1102.365604 \n",
       "L 436.127713 1102.365604 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_730\">\n",
       "    <path d=\"M 440.063168 1102.72725 \n",
       "L 443.998622 1102.72725 \n",
       "L 443.998622 1102.308502 \n",
       "L 440.063168 1102.308502 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_731\">\n",
       "    <path d=\"M 443.998622 1102.72725 \n",
       "L 447.934077 1102.72725 \n",
       "L 447.934077 1102.061061 \n",
       "L 443.998622 1102.061061 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_732\">\n",
       "    <path d=\"M 447.934077 1102.72725 \n",
       "L 451.869531 1102.72725 \n",
       "L 451.869531 1102.72725 \n",
       "L 447.934077 1102.72725 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_733\">\n",
       "    <path d=\"M 451.869531 1102.72725 \n",
       "L 455.804986 1102.72725 \n",
       "L 455.804986 1102.327536 \n",
       "L 451.869531 1102.327536 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_734\">\n",
       "    <path d=\"M 455.804986 1102.72725 \n",
       "L 459.74044 1102.72725 \n",
       "L 459.74044 1101.05226 \n",
       "L 455.804986 1101.05226 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_735\">\n",
       "    <path d=\"M 459.74044 1102.72725 \n",
       "L 463.675895 1102.72725 \n",
       "L 463.675895 1102.72725 \n",
       "L 459.74044 1102.72725 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_736\">\n",
       "    <path d=\"M 463.675895 1102.72725 \n",
       "L 467.611349 1102.72725 \n",
       "L 467.611349 1101.718449 \n",
       "L 463.675895 1101.718449 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_737\">\n",
       "    <path d=\"M 467.611349 1102.72725 \n",
       "L 471.546804 1102.72725 \n",
       "L 471.546804 1102.670148 \n",
       "L 467.611349 1102.670148 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_738\">\n",
       "    <path d=\"M 471.546804 1102.72725 \n",
       "L 475.482259 1102.72725 \n",
       "L 475.482259 1102.63208 \n",
       "L 471.546804 1102.63208 \n",
       "z\n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: #e24a33; fill-opacity: 0.5; stroke: #eeeeee; stroke-width: 0.32281; stroke-linejoin: miter\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_123\">\n",
       "    <path d=\"M 81.936804 1100.080518 \n",
       "L 89.847265 1095.907048 \n",
       "L 91.824881 1095.291078 \n",
       "L 93.802496 1095.042853 \n",
       "L 95.780111 1095.193395 \n",
       "L 97.757727 1095.723307 \n",
       "L 99.735342 1096.562148 \n",
       "L 105.668188 1099.692963 \n",
       "L 107.645804 1100.521215 \n",
       "L 109.623419 1101.11871 \n",
       "L 111.601034 1101.48646 \n",
       "L 113.57865 1101.662661 \n",
       "L 117.53388 1101.665043 \n",
       "L 129.399572 1101.143177 \n",
       "L 133.354803 1100.79386 \n",
       "L 137.310034 1100.242657 \n",
       "L 147.198111 1098.524796 \n",
       "L 151.153341 1098.287471 \n",
       "L 155.108572 1098.326158 \n",
       "L 163.019033 1098.564859 \n",
       "L 166.974264 1098.42439 \n",
       "L 168.951879 1098.210339 \n",
       "L 170.929495 1097.87883 \n",
       "L 172.90711 1097.418316 \n",
       "L 174.884725 1096.81543 \n",
       "L 176.862341 1096.049043 \n",
       "L 178.839956 1095.089058 \n",
       "L 180.817571 1093.905737 \n",
       "L 182.795187 1092.490161 \n",
       "L 186.750417 1089.154157 \n",
       "L 190.705648 1085.878114 \n",
       "L 192.683264 1084.527786 \n",
       "L 194.660879 1083.407952 \n",
       "L 198.61611 1081.64202 \n",
       "L 202.57134 1079.972138 \n",
       "L 204.548956 1078.962768 \n",
       "L 206.526571 1077.705556 \n",
       "L 208.504186 1076.09717 \n",
       "L 210.481802 1074.066133 \n",
       "L 212.459417 1071.61101 \n",
       "L 216.414648 1065.871293 \n",
       "L 218.392263 1062.970753 \n",
       "L 220.369878 1060.310894 \n",
       "L 222.347494 1057.999204 \n",
       "L 224.325109 1056.016885 \n",
       "L 228.28034 1052.295737 \n",
       "L 230.257955 1049.960363 \n",
       "L 232.235571 1046.911863 \n",
       "L 234.213186 1042.992098 \n",
       "L 236.190801 1038.238823 \n",
       "L 242.123647 1022.259471 \n",
       "L 244.101263 1018.168746 \n",
       "L 246.078878 1015.881845 \n",
       "L 248.056493 1016.204442 \n",
       "L 250.034109 1019.793653 \n",
       "L 252.011724 1026.876949 \n",
       "L 253.989339 1037.025927 \n",
       "L 259.922185 1073.469535 \n",
       "L 261.899801 1083.205284 \n",
       "L 263.877416 1090.558339 \n",
       "L 265.855031 1095.627962 \n",
       "L 267.832647 1098.837586 \n",
       "L 269.810262 1100.714076 \n",
       "L 271.787878 1101.732542 \n",
       "L 273.765493 1102.247503 \n",
       "L 275.743108 1102.48882 \n",
       "L 279.698339 1102.616928 \n",
       "L 285.631185 1102.49026 \n",
       "L 289.586416 1102.217962 \n",
       "L 291.564031 1101.974433 \n",
       "L 293.541646 1101.617479 \n",
       "L 295.519262 1101.109995 \n",
       "L 297.496877 1100.414413 \n",
       "L 299.474492 1099.490946 \n",
       "L 301.452108 1098.28528 \n",
       "L 303.429723 1096.703138 \n",
       "L 305.407338 1094.57431 \n",
       "L 307.384954 1091.614741 \n",
       "L 309.362569 1087.402278 \n",
       "L 311.340185 1081.390997 \n",
       "L 313.3178 1072.99652 \n",
       "L 315.295415 1061.776807 \n",
       "L 317.273031 1047.693306 \n",
       "L 323.205877 998.228436 \n",
       "L 325.183492 985.623304 \n",
       "L 327.161107 978.13999 \n",
       "L 329.138723 976.571752 \n",
       "L 331.116338 980.573752 \n",
       "L 333.093953 988.884247 \n",
       "L 335.071569 999.823745 \n",
       "L 339.026799 1023.762772 \n",
       "L 341.004415 1035.011403 \n",
       "L 342.98203 1045.271737 \n",
       "L 344.959645 1054.356882 \n",
       "L 346.937261 1062.068045 \n",
       "L 348.914876 1068.221723 \n",
       "L 350.892492 1072.774721 \n",
       "L 352.870107 1075.933529 \n",
       "L 354.847722 1078.15149 \n",
       "L 358.802953 1081.946512 \n",
       "L 360.780568 1084.250942 \n",
       "L 366.713414 1092.217248 \n",
       "L 368.69103 1094.467365 \n",
       "L 370.668645 1096.292525 \n",
       "L 372.64626 1097.70496 \n",
       "L 374.623876 1098.763367 \n",
       "L 376.601491 1099.53059 \n",
       "L 378.579106 1100.052663 \n",
       "L 380.556722 1100.358816 \n",
       "L 382.534337 1100.474237 \n",
       "L 386.489568 1100.302284 \n",
       "L 390.444798 1100.056285 \n",
       "L 392.422414 1100.076899 \n",
       "L 396.377645 1100.489473 \n",
       "L 404.288106 1101.73814 \n",
       "L 408.243337 1102.148317 \n",
       "L 414.176183 1102.483569 \n",
       "L 420.109029 1102.574412 \n",
       "L 429.997105 1102.45158 \n",
       "L 441.862798 1102.296921 \n",
       "L 451.750874 1102.153381 \n",
       "L 457.68372 1102.084712 \n",
       "L 465.594182 1102.264775 \n",
       "L 475.482259 1102.595426 \n",
       "L 475.482259 1102.595426 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke: #e24a33; stroke-width: 1.5; stroke-linecap: round\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_124\">\n",
       "    <path d=\"M 276.40377 1102.72725 \n",
       "L 276.40377 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"line2d_125\">\n",
       "    <path d=\"M 254.422777 1102.72725 \n",
       "L 254.422777 879.40725 \n",
       "\" clip-path=\"url(#pba7274ec5f)\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_739\">\n",
       "    <path d=\"M 62.259531 1102.72725 \n",
       "L 62.259531 879.40725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_740\">\n",
       "    <path d=\"M 495.159531 1102.72725 \n",
       "L 495.159531 879.40725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_741\">\n",
       "    <path d=\"M 62.259531 1102.72725 \n",
       "L 495.159531 1102.72725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"patch_742\">\n",
       "    <path d=\"M 62.259531 879.40725 \n",
       "L 495.159531 879.40725 \n",
       "\" style=\"fill: none; stroke: #ffffff; stroke-linejoin: miter; stroke-linecap: square\"/>\n",
       "   </g>\n",
       "   <g id=\"text_125\">\n",
       "    <!-- Distribución de ∂Precio/∂inTheMoney -->\n",
       "    <g style=\"fill: #262626\" transform=\"translate(159.946656 873.40725) scale(0.144 -0.144)\">\n",
       "     <defs>\n",
       "      <path id=\"ArialMT-68\" d=\"M 422 0 \n",
       "L 422 4581 \n",
       "L 984 4581 \n",
       "L 984 2938 \n",
       "Q 1378 3394 1978 3394 \n",
       "Q 2347 3394 2619 3248 \n",
       "Q 2891 3103 3008 2847 \n",
       "Q 3125 2591 3125 2103 \n",
       "L 3125 0 \n",
       "L 2563 0 \n",
       "L 2563 2103 \n",
       "Q 2563 2525 2380 2717 \n",
       "Q 2197 2909 1863 2909 \n",
       "Q 1613 2909 1392 2779 \n",
       "Q 1172 2650 1078 2428 \n",
       "Q 984 2206 984 1816 \n",
       "L 984 0 \n",
       "L 422 0 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "      <path id=\"ArialMT-79\" d=\"M 397 -1278 \n",
       "L 334 -750 \n",
       "Q 519 -800 656 -800 \n",
       "Q 844 -800 956 -737 \n",
       "Q 1069 -675 1141 -563 \n",
       "Q 1194 -478 1313 -144 \n",
       "Q 1328 -97 1363 -6 \n",
       "L 103 3319 \n",
       "L 709 3319 \n",
       "L 1400 1397 \n",
       "Q 1534 1031 1641 628 \n",
       "Q 1738 1016 1872 1384 \n",
       "L 2581 3319 \n",
       "L 3144 3319 \n",
       "L 1881 -56 \n",
       "Q 1678 -603 1566 -809 \n",
       "Q 1416 -1088 1222 -1217 \n",
       "Q 1028 -1347 759 -1347 \n",
       "Q 597 -1347 397 -1278 \n",
       "z\n",
       "\" transform=\"scale(0.015625)\"/>\n",
       "     </defs>\n",
       "     <use xlink:href=\"#ArialMT-44\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(72.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-73\" transform=\"translate(94.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-74\" transform=\"translate(144.433594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(172.216797 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(205.517578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-62\" transform=\"translate(227.734375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-75\" transform=\"translate(283.349609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(338.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(388.964844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-f3\" transform=\"translate(411.181641 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(466.796875 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(522.412109 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-64\" transform=\"translate(550.195312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(605.810547 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-20\" transform=\"translate(661.425781 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(689.208984 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-50\" transform=\"translate(738.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-72\" transform=\"translate(805.322266 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(838.623047 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-63\" transform=\"translate(894.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(944.238281 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(966.455078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2f\" transform=\"translate(1022.070312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-2202\" transform=\"translate(1049.853516 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-69\" transform=\"translate(1099.267578 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(1121.484375 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-54\" transform=\"translate(1177.099609 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-68\" transform=\"translate(1238.183594 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(1293.798828 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-4d\" transform=\"translate(1349.414062 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6f\" transform=\"translate(1432.714844 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-6e\" transform=\"translate(1488.330078 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-65\" transform=\"translate(1543.945312 0)\"/>\n",
       "     <use xlink:href=\"#ArialMT-79\" transform=\"translate(1599.560547 0)\"/>\n",
       "    </g>\n",
       "   </g>\n",
       "   <g id=\"legend_7\">\n",
       "    <g id=\"patch_743\">\n",
       "     <path d=\"M 382.54875 919.326938 \n",
       "L 487.459531 919.326938 \n",
       "Q 489.659531 919.326938 489.659531 917.126938 \n",
       "L 489.659531 887.10725 \n",
       "Q 489.659531 884.90725 487.459531 884.90725 \n",
       "L 382.54875 884.90725 \n",
       "Q 380.34875 884.90725 380.34875 887.10725 \n",
       "L 380.34875 917.126938 \n",
       "Q 380.34875 919.326938 382.54875 919.326938 \n",
       "z\n",
       "\" style=\"fill: #e5e5e5; opacity: 0.8; stroke: #cccccc; stroke-width: 0.5; stroke-linejoin: miter\"/>\n",
       "    </g>\n",
       "    <g id=\"line2d_126\">\n",
       "     <path d=\"M 384.74875 893.330844 \n",
       "L 395.74875 893.330844 \n",
       "L 406.74875 893.330844 \n",
       "\" style=\"fill: none; stroke-dasharray: 5.55,2.4; stroke-dashoffset: 0; stroke: #ff0000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_126\">\n",
       "     <!-- Media: 39.91 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(415.54875 897.180844) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(300.146484 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-33\" transform=\"translate(327.929688 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-39\" transform=\"translate(383.544922 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-39\" transform=\"translate(466.943359 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-31\" transform=\"translate(522.558594 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "    <g id=\"line2d_127\">\n",
       "     <path d=\"M 384.74875 908.890688 \n",
       "L 395.74875 908.890688 \n",
       "L 406.74875 908.890688 \n",
       "\" style=\"fill: none; stroke-dasharray: 1.5,2.475; stroke-dashoffset: 0; stroke: #008000; stroke-width: 1.5\"/>\n",
       "    </g>\n",
       "    <g id=\"text_127\">\n",
       "     <!-- Mediana: 4.22 -->\n",
       "     <g style=\"fill: #262626\" transform=\"translate(415.54875 912.740688) scale(0.11 -0.11)\">\n",
       "      <use xlink:href=\"#ArialMT-4d\"/>\n",
       "      <use xlink:href=\"#ArialMT-65\" transform=\"translate(83.300781 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-64\" transform=\"translate(138.916016 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-69\" transform=\"translate(194.53125 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(216.748047 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-6e\" transform=\"translate(272.363281 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-61\" transform=\"translate(327.978516 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-3a\" transform=\"translate(383.59375 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-20\" transform=\"translate(411.376953 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-34\" transform=\"translate(439.160156 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-2e\" transform=\"translate(494.775391 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(522.558594 0)\"/>\n",
       "      <use xlink:href=\"#ArialMT-32\" transform=\"translate(578.173828 0)\"/>\n",
       "     </g>\n",
       "    </g>\n",
       "   </g>\n",
       "  </g>\n",
       " </g>\n",
       " <defs>\n",
       "  <clipPath id=\"pc863c31197\">\n",
       "   <rect x=\"62.259531\" y=\"23.50725\" width=\"432.9\" height=\"223.32\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p1b9137f3b7\">\n",
       "   <rect x=\"560.859531\" y=\"23.50725\" width=\"432.9\" height=\"223.32\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p0e59718d96\">\n",
       "   <rect x=\"62.259531\" y=\"308.80725\" width=\"432.9\" height=\"223.32\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p816d9a6b22\">\n",
       "   <rect x=\"560.859531\" y=\"308.80725\" width=\"432.9\" height=\"223.32\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pc103c95a8d\">\n",
       "   <rect x=\"62.259531\" y=\"594.10725\" width=\"432.9\" height=\"223.32\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"p0a9d3d5456\">\n",
       "   <rect x=\"560.859531\" y=\"594.10725\" width=\"432.9\" height=\"223.32\"/>\n",
       "  </clipPath>\n",
       "  <clipPath id=\"pba7274ec5f\">\n",
       "   <rect x=\"62.259531\" y=\"879.40725\" width=\"432.9\" height=\"223.32\"/>\n",
       "  </clipPath>\n",
       " </defs>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<Figure size 1400x1600 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_partial_derivative_distributions(df_partDeriv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ad06c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outliers_std(df, column, n_std=3):\n",
    "    media = df[column].mean()\n",
    "    std = df[column].std()\n",
    "    return df[np.abs(df[column] - media) > n_std * std]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "27ce8d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outliers in the training set:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>sigma</th>\n",
       "      <th>openInterest</th>\n",
       "      <th>volume</th>\n",
       "      <th>inTheMoney</th>\n",
       "      <th>midPrice</th>\n",
       "      <th>BS_predict</th>\n",
       "      <th>MLP_pred</th>\n",
       "      <th>MLP_diff</th>\n",
       "      <th>BS_diff</th>\n",
       "      <th>MLP_better</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90498</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>677.650</td>\n",
       "      <td>720.114499</td>\n",
       "      <td>492.544849</td>\n",
       "      <td>185.105151</td>\n",
       "      <td>42.464499</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20334</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5560.0</td>\n",
       "      <td>0.052055</td>\n",
       "      <td>0.252205</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>151.950</td>\n",
       "      <td>164.732394</td>\n",
       "      <td>134.852957</td>\n",
       "      <td>17.097043</td>\n",
       "      <td>12.782394</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15828</th>\n",
       "      <td>791.85</td>\n",
       "      <td>460.0</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.600</td>\n",
       "      <td>347.732351</td>\n",
       "      <td>215.527472</td>\n",
       "      <td>64.927472</td>\n",
       "      <td>197.132351</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21181</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>1.027397</td>\n",
       "      <td>0.380570</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1086.000</td>\n",
       "      <td>1227.464357</td>\n",
       "      <td>1085.410978</td>\n",
       "      <td>0.589022</td>\n",
       "      <td>141.464357</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18533</th>\n",
       "      <td>989.05</td>\n",
       "      <td>870.0</td>\n",
       "      <td>1.528767</td>\n",
       "      <td>0.282081</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>192.500</td>\n",
       "      <td>232.235651</td>\n",
       "      <td>196.699451</td>\n",
       "      <td>4.199451</td>\n",
       "      <td>39.735651</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15134</th>\n",
       "      <td>3719.24</td>\n",
       "      <td>3110.0</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.615574</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>611.850</td>\n",
       "      <td>622.315928</td>\n",
       "      <td>654.960232</td>\n",
       "      <td>43.110232</td>\n",
       "      <td>10.465928</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90139</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>603.000</td>\n",
       "      <td>1153.597064</td>\n",
       "      <td>835.851748</td>\n",
       "      <td>232.851748</td>\n",
       "      <td>550.597064</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91017</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>1240.0</td>\n",
       "      <td>1.605479</td>\n",
       "      <td>0.442165</td>\n",
       "      <td>57.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>271.825</td>\n",
       "      <td>310.352618</td>\n",
       "      <td>240.288549</td>\n",
       "      <td>31.536451</td>\n",
       "      <td>38.527618</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51118</th>\n",
       "      <td>1775.10</td>\n",
       "      <td>1540.0</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.543767</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>242.550</td>\n",
       "      <td>242.645857</td>\n",
       "      <td>263.348768</td>\n",
       "      <td>20.798768</td>\n",
       "      <td>0.095857</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20361</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5610.0</td>\n",
       "      <td>0.068493</td>\n",
       "      <td>0.258304</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>143.500</td>\n",
       "      <td>162.285860</td>\n",
       "      <td>123.226817</td>\n",
       "      <td>20.273183</td>\n",
       "      <td>18.785860</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20993</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>3650.0</td>\n",
       "      <td>0.608219</td>\n",
       "      <td>0.514678</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2096.400</td>\n",
       "      <td>2174.982118</td>\n",
       "      <td>1979.872521</td>\n",
       "      <td>116.527479</td>\n",
       "      <td>78.582118</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83577</th>\n",
       "      <td>1184.34</td>\n",
       "      <td>1160.0</td>\n",
       "      <td>0.608219</td>\n",
       "      <td>0.394858</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.300</td>\n",
       "      <td>171.060447</td>\n",
       "      <td>125.683783</td>\n",
       "      <td>24.616217</td>\n",
       "      <td>20.760447</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20531</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5280.0</td>\n",
       "      <td>0.186301</td>\n",
       "      <td>0.360877</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>521.550</td>\n",
       "      <td>559.338721</td>\n",
       "      <td>462.666833</td>\n",
       "      <td>58.883167</td>\n",
       "      <td>37.788721</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82595</th>\n",
       "      <td>697.71</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.027397</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>482.000</td>\n",
       "      <td>669.065413</td>\n",
       "      <td>464.429245</td>\n",
       "      <td>17.570755</td>\n",
       "      <td>187.065413</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112623</th>\n",
       "      <td>1030.21</td>\n",
       "      <td>360.0</td>\n",
       "      <td>1.528767</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>694.143347</td>\n",
       "      <td>432.133809</td>\n",
       "      <td>432.133809</td>\n",
       "      <td>694.143347</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21101</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.373649</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>976.600</td>\n",
       "      <td>1089.588007</td>\n",
       "      <td>963.357746</td>\n",
       "      <td>13.242254</td>\n",
       "      <td>112.988007</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91116</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>2.024658</td>\n",
       "      <td>0.416893</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>186.500</td>\n",
       "      <td>227.538827</td>\n",
       "      <td>181.753775</td>\n",
       "      <td>4.746225</td>\n",
       "      <td>41.038827</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18345</th>\n",
       "      <td>989.05</td>\n",
       "      <td>660.0</td>\n",
       "      <td>0.608219</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>346.869143</td>\n",
       "      <td>212.768556</td>\n",
       "      <td>212.768556</td>\n",
       "      <td>346.869143</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21200</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>1.027397</td>\n",
       "      <td>0.324682</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>500.000</td>\n",
       "      <td>610.796786</td>\n",
       "      <td>509.402291</td>\n",
       "      <td>9.402291</td>\n",
       "      <td>110.796786</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112301</th>\n",
       "      <td>1030.21</td>\n",
       "      <td>480.0</td>\n",
       "      <td>0.454795</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>539.450</td>\n",
       "      <td>559.933721</td>\n",
       "      <td>378.687151</td>\n",
       "      <td>160.762849</td>\n",
       "      <td>20.483721</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83138</th>\n",
       "      <td>697.71</td>\n",
       "      <td>820.0</td>\n",
       "      <td>2.526027</td>\n",
       "      <td>0.422125</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>143.375</td>\n",
       "      <td>171.157642</td>\n",
       "      <td>143.842552</td>\n",
       "      <td>0.467552</td>\n",
       "      <td>27.782642</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20123</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>1.533755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2720.500</td>\n",
       "      <td>2722.101946</td>\n",
       "      <td>2725.926198</td>\n",
       "      <td>5.426198</td>\n",
       "      <td>1.601946</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20312</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>0.052055</td>\n",
       "      <td>0.341002</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>441.850</td>\n",
       "      <td>460.682884</td>\n",
       "      <td>418.596415</td>\n",
       "      <td>23.253585</td>\n",
       "      <td>18.832884</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20935</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.608219</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1215.000</td>\n",
       "      <td>3036.156561</td>\n",
       "      <td>1857.128445</td>\n",
       "      <td>642.128445</td>\n",
       "      <td>1821.156561</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82136</th>\n",
       "      <td>697.71</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "      <td>585.427915</td>\n",
       "      <td>412.357393</td>\n",
       "      <td>412.357393</td>\n",
       "      <td>585.427915</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20639</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5800.0</td>\n",
       "      <td>0.282192</td>\n",
       "      <td>0.300542</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>271.850</td>\n",
       "      <td>307.457818</td>\n",
       "      <td>251.156809</td>\n",
       "      <td>20.693191</td>\n",
       "      <td>35.607818</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15280</th>\n",
       "      <td>3719.24</td>\n",
       "      <td>1720.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.515721</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1999.250</td>\n",
       "      <td>2045.643672</td>\n",
       "      <td>1844.711620</td>\n",
       "      <td>154.538380</td>\n",
       "      <td>46.393672</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20159</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>3570.0</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>1.124882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2051.800</td>\n",
       "      <td>2053.995248</td>\n",
       "      <td>2061.648933</td>\n",
       "      <td>9.848933</td>\n",
       "      <td>2.195248</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91086</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>900.0</td>\n",
       "      <td>2.024658</td>\n",
       "      <td>0.500329</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>497.325</td>\n",
       "      <td>541.012054</td>\n",
       "      <td>490.015374</td>\n",
       "      <td>7.309626</td>\n",
       "      <td>43.687054</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90874</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>1.528767</td>\n",
       "      <td>0.419119</td>\n",
       "      <td>148.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>189.325</td>\n",
       "      <td>222.401255</td>\n",
       "      <td>179.516180</td>\n",
       "      <td>9.808820</td>\n",
       "      <td>33.076255</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112777</th>\n",
       "      <td>1030.21</td>\n",
       "      <td>800.0</td>\n",
       "      <td>2.024658</td>\n",
       "      <td>0.502214</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>377.100</td>\n",
       "      <td>422.092664</td>\n",
       "      <td>377.802462</td>\n",
       "      <td>0.702462</td>\n",
       "      <td>44.992664</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21430</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>7300.0</td>\n",
       "      <td>2.526027</td>\n",
       "      <td>0.316736</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>590.000</td>\n",
       "      <td>805.887902</td>\n",
       "      <td>593.546222</td>\n",
       "      <td>3.546222</td>\n",
       "      <td>215.887902</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51473</th>\n",
       "      <td>1775.10</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.445932</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>211.250</td>\n",
       "      <td>237.005386</td>\n",
       "      <td>199.640376</td>\n",
       "      <td>11.609624</td>\n",
       "      <td>25.755386</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20532</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5285.0</td>\n",
       "      <td>0.186301</td>\n",
       "      <td>0.359746</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>516.900</td>\n",
       "      <td>555.194033</td>\n",
       "      <td>458.236207</td>\n",
       "      <td>58.663793</td>\n",
       "      <td>38.294033</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37007</th>\n",
       "      <td>1014.94</td>\n",
       "      <td>475.0</td>\n",
       "      <td>0.608219</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>489.500</td>\n",
       "      <td>552.764384</td>\n",
       "      <td>375.860392</td>\n",
       "      <td>113.639608</td>\n",
       "      <td>63.264384</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83063</th>\n",
       "      <td>697.71</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2.526027</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>562.000</td>\n",
       "      <td>626.305892</td>\n",
       "      <td>432.508934</td>\n",
       "      <td>129.491066</td>\n",
       "      <td>64.305892</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21122</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>6300.0</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.307580</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>347.250</td>\n",
       "      <td>425.301424</td>\n",
       "      <td>345.583631</td>\n",
       "      <td>1.666369</td>\n",
       "      <td>78.051424</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83162</th>\n",
       "      <td>697.71</td>\n",
       "      <td>1060.0</td>\n",
       "      <td>2.526027</td>\n",
       "      <td>0.398295</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>80.550</td>\n",
       "      <td>102.157501</td>\n",
       "      <td>79.624529</td>\n",
       "      <td>0.925471</td>\n",
       "      <td>21.607501</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20828</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>4150.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1173.550</td>\n",
       "      <td>1562.691284</td>\n",
       "      <td>965.948142</td>\n",
       "      <td>207.601858</td>\n",
       "      <td>389.141284</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20622</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>4950.0</td>\n",
       "      <td>0.282192</td>\n",
       "      <td>0.383704</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>829.950</td>\n",
       "      <td>884.305358</td>\n",
       "      <td>775.022638</td>\n",
       "      <td>54.927362</td>\n",
       "      <td>54.355358</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97047</th>\n",
       "      <td>1377.72</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.364234</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>264.500</td>\n",
       "      <td>294.374945</td>\n",
       "      <td>261.707655</td>\n",
       "      <td>2.792345</td>\n",
       "      <td>29.874945</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15318</th>\n",
       "      <td>3719.24</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.502736</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1340.000</td>\n",
       "      <td>1387.269070</td>\n",
       "      <td>1322.544092</td>\n",
       "      <td>17.455908</td>\n",
       "      <td>47.269070</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20375</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>6060.0</td>\n",
       "      <td>0.090411</td>\n",
       "      <td>0.223667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.550</td>\n",
       "      <td>28.231529</td>\n",
       "      <td>14.218922</td>\n",
       "      <td>4.331078</td>\n",
       "      <td>9.681529</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51461</th>\n",
       "      <td>1775.10</td>\n",
       "      <td>1560.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.498430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>356.550</td>\n",
       "      <td>384.257816</td>\n",
       "      <td>343.834573</td>\n",
       "      <td>12.715427</td>\n",
       "      <td>27.707816</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20821</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.531507</td>\n",
       "      <td>0.504396</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1981.700</td>\n",
       "      <td>2053.042342</td>\n",
       "      <td>1870.179298</td>\n",
       "      <td>111.520702</td>\n",
       "      <td>71.342342</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20595</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>3750.0</td>\n",
       "      <td>0.282192</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1634.750</td>\n",
       "      <td>1911.928785</td>\n",
       "      <td>1148.196756</td>\n",
       "      <td>486.553244</td>\n",
       "      <td>277.178785</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90523</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>790.0</td>\n",
       "      <td>0.780822</td>\n",
       "      <td>0.354682</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>457.475</td>\n",
       "      <td>486.562794</td>\n",
       "      <td>438.386423</td>\n",
       "      <td>19.088577</td>\n",
       "      <td>29.087794</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20474</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>5410.0</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.287416</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1</td>\n",
       "      <td>320.750</td>\n",
       "      <td>344.301740</td>\n",
       "      <td>269.271007</td>\n",
       "      <td>51.478993</td>\n",
       "      <td>23.551740</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20155</th>\n",
       "      <td>5614.61</td>\n",
       "      <td>3530.0</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>1.144719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2091.600</td>\n",
       "      <td>2093.801141</td>\n",
       "      <td>2099.550575</td>\n",
       "      <td>7.950575</td>\n",
       "      <td>2.201141</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91153</th>\n",
       "      <td>1241.47</td>\n",
       "      <td>680.0</td>\n",
       "      <td>2.526027</td>\n",
       "      <td>0.554253</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>674.500</td>\n",
       "      <td>719.460143</td>\n",
       "      <td>685.965710</td>\n",
       "      <td>11.465710</td>\n",
       "      <td>44.960143</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              S       K         T     sigma  openInterest  volume  inTheMoney  \\\n",
       "90498   1241.47   540.0  0.780822  0.000010           6.0     2.0           1   \n",
       "20334   5614.61  5560.0  0.052055  0.252205           2.0     2.0           1   \n",
       "15828    791.85   460.0  0.780822  0.000010           1.0     1.0           1   \n",
       "21181   5614.61  5100.0  1.027397  0.380570          11.0     1.0           1   \n",
       "18533    989.05   870.0  1.528767  0.282081           2.0     2.0           1   \n",
       "15134   3719.24  3110.0  0.032877  0.615574           6.0     1.0           1   \n",
       "90139   1241.47    90.0  0.531507  0.000010           1.0     1.0           1   \n",
       "91017   1241.47  1240.0  1.605479  0.442165          57.0     1.0           1   \n",
       "51118   1775.10  1540.0  0.032877  0.543767           2.0     2.0           1   \n",
       "20361   5614.61  5610.0  0.068493  0.258304           3.0     3.0           1   \n",
       "20993   5614.61  3650.0  0.608219  0.514678           8.0     1.0           1   \n",
       "83577   1184.34  1160.0  0.608219  0.394858           1.0     1.0           1   \n",
       "20531   5614.61  5280.0  0.186301  0.360877           2.0     1.0           1   \n",
       "82595    697.71    30.0  1.027397  0.000010           2.0     2.0           1   \n",
       "112623  1030.21   360.0  1.528767  0.000010           0.0     1.0           1   \n",
       "21101   5614.61  5100.0  0.780822  0.373649          14.0     1.0           1   \n",
       "91116   1241.47  1560.0  2.024658  0.416893           2.0     2.0           0   \n",
       "18345    989.05   660.0  0.608219  0.000010           0.0     1.0           1   \n",
       "21200   5614.61  6200.0  1.027397  0.324682          10.0     1.0           0   \n",
       "112301  1030.21   480.0  0.454795  0.000010           1.0     2.0           1   \n",
       "83138    697.71   820.0  2.526027  0.422125          16.0     2.0           0   \n",
       "20123   5614.61  2900.0  0.032877  1.533755           0.0    55.0           1   \n",
       "20312   5614.61  5200.0  0.052055  0.341002           3.0     1.0           1   \n",
       "20935   5614.61  2650.0  0.608219  0.000010           3.0     3.0           1   \n",
       "82136    697.71   115.0  0.531507  0.000010           0.0     1.0           1   \n",
       "20639   5614.61  5800.0  0.282192  0.300542          98.0     1.0           0   \n",
       "15280   3719.24  1720.0  0.531507  0.515721           1.0     1.0           1   \n",
       "20159   5614.61  3570.0  0.032877  1.124882           0.0     5.0           1   \n",
       "91086   1241.47   900.0  2.024658  0.500329           6.0     2.0           1   \n",
       "90874   1241.47  1420.0  1.528767  0.419119         148.0     8.0           0   \n",
       "112777  1030.21   800.0  2.024658  0.502214          10.0     1.0           1   \n",
       "21430   5614.61  7300.0  2.526027  0.316736           1.0     1.0           0   \n",
       "51473   1775.10  1800.0  0.531507  0.445932          12.0     1.0           0   \n",
       "20532   5614.61  5285.0  0.186301  0.359746           3.0     1.0           1   \n",
       "37007   1014.94   475.0  0.608219  0.000010          10.0     2.0           1   \n",
       "83063    697.71    80.0  2.526027  0.000010           0.0     1.0           1   \n",
       "21122   5614.61  6300.0  0.780822  0.307580           9.0     8.0           0   \n",
       "83162    697.71  1060.0  2.526027  0.398295          32.0     5.0           0   \n",
       "20828   5614.61  4150.0  0.531507  0.000010           5.0     1.0           1   \n",
       "20622   5614.61  4950.0  0.282192  0.383704          32.0     1.0           1   \n",
       "97047   1377.72  1200.0  0.780822  0.364234           2.0     1.0           1   \n",
       "15318   3719.24  2450.0  0.531507  0.502736           4.0     1.0           1   \n",
       "20375   5614.61  6060.0  0.090411  0.223667           1.0     1.0           0   \n",
       "51461   1775.10  1560.0  0.531507  0.498430           2.0     1.0           1   \n",
       "20821   5614.61  3750.0  0.531507  0.504396           2.0     5.0           1   \n",
       "20595   5614.61  3750.0  0.282192  0.000010           2.0     1.0           1   \n",
       "90523   1241.47   790.0  0.780822  0.354682          12.0     2.0           1   \n",
       "20474   5614.61  5410.0  0.109589  0.287416           5.0    10.0           1   \n",
       "20155   5614.61  3530.0  0.032877  1.144719           0.0     5.0           1   \n",
       "91153   1241.47   680.0  2.526027  0.554253          30.0     1.0           1   \n",
       "\n",
       "        midPrice   BS_predict     MLP_pred    MLP_diff      BS_diff  \\\n",
       "90498    677.650   720.114499   492.544849  185.105151    42.464499   \n",
       "20334    151.950   164.732394   134.852957   17.097043    12.782394   \n",
       "15828    150.600   347.732351   215.527472   64.927472   197.132351   \n",
       "21181   1086.000  1227.464357  1085.410978    0.589022   141.464357   \n",
       "18533    192.500   232.235651   196.699451    4.199451    39.735651   \n",
       "15134    611.850   622.315928   654.960232   43.110232    10.465928   \n",
       "90139    603.000  1153.597064   835.851748  232.851748   550.597064   \n",
       "91017    271.825   310.352618   240.288549   31.536451    38.527618   \n",
       "51118    242.550   242.645857   263.348768   20.798768     0.095857   \n",
       "20361    143.500   162.285860   123.226817   20.273183    18.785860   \n",
       "20993   2096.400  2174.982118  1979.872521  116.527479    78.582118   \n",
       "83577    150.300   171.060447   125.683783   24.616217    20.760447   \n",
       "20531    521.550   559.338721   462.666833   58.883167    37.788721   \n",
       "82595    482.000   669.065413   464.429245   17.570755   187.065413   \n",
       "112623     0.000   694.143347   432.133809  432.133809   694.143347   \n",
       "21101    976.600  1089.588007   963.357746   13.242254   112.988007   \n",
       "91116    186.500   227.538827   181.753775    4.746225    41.038827   \n",
       "18345      0.000   346.869143   212.768556  212.768556   346.869143   \n",
       "21200    500.000   610.796786   509.402291    9.402291   110.796786   \n",
       "112301   539.450   559.933721   378.687151  160.762849    20.483721   \n",
       "83138    143.375   171.157642   143.842552    0.467552    27.782642   \n",
       "20123   2720.500  2722.101946  2725.926198    5.426198     1.601946   \n",
       "20312    441.850   460.682884   418.596415   23.253585    18.832884   \n",
       "20935   1215.000  3036.156561  1857.128445  642.128445  1821.156561   \n",
       "82136      0.000   585.427915   412.357393  412.357393   585.427915   \n",
       "20639    271.850   307.457818   251.156809   20.693191    35.607818   \n",
       "15280   1999.250  2045.643672  1844.711620  154.538380    46.393672   \n",
       "20159   2051.800  2053.995248  2061.648933    9.848933     2.195248   \n",
       "91086    497.325   541.012054   490.015374    7.309626    43.687054   \n",
       "90874    189.325   222.401255   179.516180    9.808820    33.076255   \n",
       "112777   377.100   422.092664   377.802462    0.702462    44.992664   \n",
       "21430    590.000   805.887902   593.546222    3.546222   215.887902   \n",
       "51473    211.250   237.005386   199.640376   11.609624    25.755386   \n",
       "20532    516.900   555.194033   458.236207   58.663793    38.294033   \n",
       "37007    489.500   552.764384   375.860392  113.639608    63.264384   \n",
       "83063    562.000   626.305892   432.508934  129.491066    64.305892   \n",
       "21122    347.250   425.301424   345.583631    1.666369    78.051424   \n",
       "83162     80.550   102.157501    79.624529    0.925471    21.607501   \n",
       "20828   1173.550  1562.691284   965.948142  207.601858   389.141284   \n",
       "20622    829.950   884.305358   775.022638   54.927362    54.355358   \n",
       "97047    264.500   294.374945   261.707655    2.792345    29.874945   \n",
       "15318   1340.000  1387.269070  1322.544092   17.455908    47.269070   \n",
       "20375     18.550    28.231529    14.218922    4.331078     9.681529   \n",
       "51461    356.550   384.257816   343.834573   12.715427    27.707816   \n",
       "20821   1981.700  2053.042342  1870.179298  111.520702    71.342342   \n",
       "20595   1634.750  1911.928785  1148.196756  486.553244   277.178785   \n",
       "90523    457.475   486.562794   438.386423   19.088577    29.087794   \n",
       "20474    320.750   344.301740   269.271007   51.478993    23.551740   \n",
       "20155   2091.600  2093.801141  2099.550575    7.950575     2.201141   \n",
       "91153    674.500   719.460143   685.965710   11.465710    44.960143   \n",
       "\n",
       "        MLP_better  \n",
       "90498        False  \n",
       "20334        False  \n",
       "15828         True  \n",
       "21181         True  \n",
       "18533         True  \n",
       "15134        False  \n",
       "90139         True  \n",
       "91017         True  \n",
       "51118        False  \n",
       "20361        False  \n",
       "20993        False  \n",
       "83577        False  \n",
       "20531        False  \n",
       "82595         True  \n",
       "112623        True  \n",
       "21101         True  \n",
       "91116         True  \n",
       "18345         True  \n",
       "21200         True  \n",
       "112301       False  \n",
       "83138         True  \n",
       "20123        False  \n",
       "20312        False  \n",
       "20935         True  \n",
       "82136         True  \n",
       "20639         True  \n",
       "15280        False  \n",
       "20159        False  \n",
       "91086         True  \n",
       "90874         True  \n",
       "112777        True  \n",
       "21430         True  \n",
       "51473         True  \n",
       "20532        False  \n",
       "37007        False  \n",
       "83063        False  \n",
       "21122         True  \n",
       "83162         True  \n",
       "20828         True  \n",
       "20622        False  \n",
       "97047         True  \n",
       "15318         True  \n",
       "20375         True  \n",
       "51461         True  \n",
       "20821        False  \n",
       "20595        False  \n",
       "90523         True  \n",
       "20474        False  \n",
       "20155        False  \n",
       "91153         True  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_sigma = get_outliers_std(df_partDeriv, 'num__sigma', n_std=3)\n",
    "\n",
    "## get a subdataframe with the outliers using the positional index in outlier_indices\n",
    "outlier_rows = dfTR_eval.iloc[outliers_sigma.index]\n",
    "# Display the outlier rows\n",
    "outlier_rows.head(50)\n",
    "\n",
    "# Mostrar los outliers en el conjunto de entrenamiento\n",
    "print(\"Outliers in the training set:\")\n",
    "outlier_rows.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cdeabb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>sigma</th>\n",
       "      <th>midPrice</th>\n",
       "      <th>BS_predict</th>\n",
       "      <th>MLP_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>412.23</td>\n",
       "      <td>367.5</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>1.290043</td>\n",
       "      <td>44.475</td>\n",
       "      <td>45.252410</td>\n",
       "      <td>63.274039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88692</th>\n",
       "      <td>57.46</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>4.976566</td>\n",
       "      <td>30.800</td>\n",
       "      <td>30.468848</td>\n",
       "      <td>21.839552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79617</th>\n",
       "      <td>140.22</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.060274</td>\n",
       "      <td>2.735355</td>\n",
       "      <td>96.400</td>\n",
       "      <td>96.283884</td>\n",
       "      <td>94.561327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108521</th>\n",
       "      <td>23.18</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>2.031255</td>\n",
       "      <td>5.325</td>\n",
       "      <td>5.188486</td>\n",
       "      <td>-2.397472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54413</th>\n",
       "      <td>1619.94</td>\n",
       "      <td>2900.0</td>\n",
       "      <td>0.136986</td>\n",
       "      <td>0.670902</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.839285</td>\n",
       "      <td>-8.789537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21908</th>\n",
       "      <td>5475.26</td>\n",
       "      <td>5050.0</td>\n",
       "      <td>0.309589</td>\n",
       "      <td>0.374503</td>\n",
       "      <td>671.050</td>\n",
       "      <td>725.274694</td>\n",
       "      <td>667.310561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22001</th>\n",
       "      <td>5475.26</td>\n",
       "      <td>4860.0</td>\n",
       "      <td>0.386301</td>\n",
       "      <td>0.393458</td>\n",
       "      <td>856.750</td>\n",
       "      <td>923.651096</td>\n",
       "      <td>862.809864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7112</th>\n",
       "      <td>173.38</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>2.167973</td>\n",
       "      <td>63.475</td>\n",
       "      <td>63.393667</td>\n",
       "      <td>54.126889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88703</th>\n",
       "      <td>57.46</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>1.792970</td>\n",
       "      <td>12.700</td>\n",
       "      <td>12.472399</td>\n",
       "      <td>11.564038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79905</th>\n",
       "      <td>469.98</td>\n",
       "      <td>522.5</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.937989</td>\n",
       "      <td>2.150</td>\n",
       "      <td>0.134918</td>\n",
       "      <td>35.192955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              S       K         T     sigma  midPrice  BS_predict    MLP_pred\n",
       "1608     412.23   367.5  0.002740  1.290043    44.475   45.252410   63.274039\n",
       "88692     57.46    27.0  0.002740  4.976566    30.800   30.468848   21.839552\n",
       "79617    140.22    45.0  0.060274  2.735355    96.400   96.283884   94.561327\n",
       "108521    23.18    18.0  0.002740  2.031255     5.325    5.188486   -2.397472\n",
       "54413   1619.94  2900.0  0.136986  0.670902     2.000    1.839285   -8.789537\n",
       "21908   5475.26  5050.0  0.309589  0.374503   671.050  725.274694  667.310561\n",
       "22001   5475.26  4860.0  0.386301  0.393458   856.750  923.651096  862.809864\n",
       "7112     173.38   110.0  0.002740  2.167973    63.475   63.393667   54.126889\n",
       "88703     57.46    45.0  0.002740  1.792970    12.700   12.472399   11.564038\n",
       "79905    469.98   522.5  0.002740  0.937989     2.150    0.134918   35.192955"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_T = get_outliers_std(df_partDeriv, 'num__T', n_std=3)\n",
    "outlier_rows_T = dfTR_eval.iloc[outliers_T.index]\n",
    "# Display the outlier rows for T\n",
    "outlier_rows_T.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4292d377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>sigma</th>\n",
       "      <th>midPrice</th>\n",
       "      <th>BS_predict</th>\n",
       "      <th>MLP_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95499</th>\n",
       "      <td>1208.550</td>\n",
       "      <td>220.0</td>\n",
       "      <td>0.558904</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>463.775</td>\n",
       "      <td>994.014149</td>\n",
       "      <td>760.335055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22079</th>\n",
       "      <td>5475.260</td>\n",
       "      <td>3220.0</td>\n",
       "      <td>0.558904</td>\n",
       "      <td>0.583351</td>\n",
       "      <td>2354.650</td>\n",
       "      <td>2420.646073</td>\n",
       "      <td>2156.485336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95141</th>\n",
       "      <td>1208.550</td>\n",
       "      <td>720.0</td>\n",
       "      <td>0.213699</td>\n",
       "      <td>0.737033</td>\n",
       "      <td>497.875</td>\n",
       "      <td>503.648013</td>\n",
       "      <td>499.728534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95501</th>\n",
       "      <td>1208.550</td>\n",
       "      <td>240.0</td>\n",
       "      <td>0.558904</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>703.275</td>\n",
       "      <td>974.510890</td>\n",
       "      <td>736.849971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38957</th>\n",
       "      <td>1013.140</td>\n",
       "      <td>580.0</td>\n",
       "      <td>0.213699</td>\n",
       "      <td>0.727054</td>\n",
       "      <td>438.625</td>\n",
       "      <td>443.465796</td>\n",
       "      <td>434.397539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126301</th>\n",
       "      <td>356.900</td>\n",
       "      <td>165.0</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>2.843753</td>\n",
       "      <td>191.925</td>\n",
       "      <td>191.920342</td>\n",
       "      <td>190.086268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81209</th>\n",
       "      <td>315.745</td>\n",
       "      <td>125.0</td>\n",
       "      <td>0.213699</td>\n",
       "      <td>1.198734</td>\n",
       "      <td>192.975</td>\n",
       "      <td>193.938449</td>\n",
       "      <td>190.619642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95691</th>\n",
       "      <td>1208.550</td>\n",
       "      <td>270.0</td>\n",
       "      <td>0.635616</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>348.000</td>\n",
       "      <td>946.163339</td>\n",
       "      <td>704.608266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87751</th>\n",
       "      <td>643.580</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1.632877</td>\n",
       "      <td>0.568120</td>\n",
       "      <td>504.950</td>\n",
       "      <td>514.465031</td>\n",
       "      <td>528.665841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95683</th>\n",
       "      <td>1208.550</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.635616</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>411.000</td>\n",
       "      <td>1019.048523</td>\n",
       "      <td>792.643399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               S       K         T     sigma  midPrice   BS_predict  \\\n",
       "95499   1208.550   220.0  0.558904  0.000010   463.775   994.014149   \n",
       "22079   5475.260  3220.0  0.558904  0.583351  2354.650  2420.646073   \n",
       "95141   1208.550   720.0  0.213699  0.737033   497.875   503.648013   \n",
       "95501   1208.550   240.0  0.558904  0.000010   703.275   974.510890   \n",
       "38957   1013.140   580.0  0.213699  0.727054   438.625   443.465796   \n",
       "126301   356.900   165.0  0.002740  2.843753   191.925   191.920342   \n",
       "81209    315.745   125.0  0.213699  1.198734   192.975   193.938449   \n",
       "95691   1208.550   270.0  0.635616  0.000010   348.000   946.163339   \n",
       "87751    643.580   140.0  1.632877  0.568120   504.950   514.465031   \n",
       "95683   1208.550   195.0  0.635616  0.000010   411.000  1019.048523   \n",
       "\n",
       "           MLP_pred  \n",
       "95499    760.335055  \n",
       "22079   2156.485336  \n",
       "95141    499.728534  \n",
       "95501    736.849971  \n",
       "38957    434.397539  \n",
       "126301   190.086268  \n",
       "81209    190.619642  \n",
       "95691    704.608266  \n",
       "87751    528.665841  \n",
       "95683    792.643399  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers_K = get_outliers_std(df_partDeriv, 'num__K', n_std=3)\n",
    "outlier_rows_K = dfTR_eval.iloc[outliers_K.index]\n",
    "outlier_rows_K.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3895dcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>sigma</th>\n",
       "      <th>midPrice</th>\n",
       "      <th>BS_predict</th>\n",
       "      <th>MLP_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [S, K, T, sigma, midPrice, BS_predict, MLP_pred]\n",
       "Index: []"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outlier_rows[outlier_rows['sigma']== 0].head(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TFM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
